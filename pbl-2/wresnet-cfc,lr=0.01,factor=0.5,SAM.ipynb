{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "516f9d5f-6361-4b03-98ee-e1ba4de86b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>model_parameters</td><td>36546980</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">wideresnet_28_10_cfc,SAM_SGD</strong> at: <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/64dg415w' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/64dg415w</a><br> View project at: <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250424_103838-64dg415w/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/guswls/EEN4015_Intro2ML/pbl-2/wandb/run-20250424_105429-f7bzcjne</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/f7bzcjne' target=\"_blank\">wideresnet_28_20_cfc,SAM_SGD</a></strong> to <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/f7bzcjne' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/f7bzcjne</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Train set size: 50000\n",
      "Test set size: 10000\n",
      "Using device: cuda\n",
      "GPU 0: NVIDIA RTX A5000\n",
      "Memory Allocated: 0.29 GB\n",
      "Memory Reserved: 4.14 GB\n",
      "Max Memory Allocated: 3.67 GB\n",
      "GPU 1: NVIDIA RTX A5000\n",
      "Memory Allocated: 0.02 GB\n",
      "Memory Reserved: 3.75 GB\n",
      "Max Memory Allocated: 3.08 GB\n",
      "| Wide-Resnet 28x20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wide-ResNet-28-20 initialized with 145,950,980 parameters\n",
      "2개의 GPU를 사용합니다.\n",
      "Model: WideResNet-28-20\n",
      "Batch size: 128\n",
      "Learning rate: 0.01\n",
      "Optimizer: SGD with SAM\n",
      "Dropout rate: 0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                       | 0/300 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Batch [50/391], Loss: 4.6630, LR: 0.000256\n",
      "Epoch [1], Batch [100/391], Loss: 4.6675, LR: 0.000512\n",
      "Epoch [1], Batch [150/391], Loss: 4.6683, LR: 0.000767\n",
      "Epoch [1], Batch [200/391], Loss: 4.6222, LR: 0.001023\n",
      "Epoch [1], Batch [250/391], Loss: 4.5743, LR: 0.001279\n",
      "Epoch [1], Batch [300/391], Loss: 4.5507, LR: 0.001535\n",
      "Epoch [1], Batch [350/391], Loss: 4.4548, LR: 0.001790\n",
      "Train set: Epoch: 1, Average loss:4.6047, LR: 0.002000 Top-1 Accuracy: 1.2660%, Top-5 Accuracy: 6.4780%, Time consumed:351.03s\n",
      "Test set: Epoch: 1, Average loss:4.3440, Top-1 Accuracy: 4.5000%, Top-5 Accuracy: 17.2400%, Time consumed:14.10s\n",
      "\n",
      "새로운 최고 top-1 정확도: 4.50%, top-5 정확도: 17.24%\n",
      "새로운 최고 top-5 정확도: 17.24%\n",
      "Accuracy improved (-inf% --> 4.50%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                                          | 1/300 [06:07<30:33:32, 367.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], Batch [50/391], Loss: 4.3117, LR: 0.002256\n",
      "Epoch [2], Batch [100/391], Loss: 4.5163, LR: 0.002512\n",
      "Epoch [2], Batch [150/391], Loss: 4.4251, LR: 0.002767\n",
      "Epoch [2], Batch [200/391], Loss: 4.2523, LR: 0.003023\n",
      "Epoch [2], Batch [250/391], Loss: 4.3578, LR: 0.003279\n",
      "Epoch [2], Batch [300/391], Loss: 4.3730, LR: 0.003535\n",
      "Epoch [2], Batch [350/391], Loss: 4.1435, LR: 0.003790\n",
      "Train set: Epoch: 2, Average loss:4.3395, LR: 0.004000 Top-1 Accuracy: 4.1320%, Top-5 Accuracy: 16.8400%, Time consumed:353.40s\n",
      "Test set: Epoch: 2, Average loss:4.0932, Top-1 Accuracy: 7.2800%, Top-5 Accuracy: 23.7000%, Time consumed:14.09s\n",
      "\n",
      "새로운 최고 top-1 정확도: 7.28%, top-5 정확도: 23.70%\n",
      "새로운 최고 top-5 정확도: 23.70%\n",
      "Accuracy improved (4.50% --> 7.28%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▌                                                                                          | 2/300 [12:18<30:35:24, 369.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3], Batch [50/391], Loss: 4.3685, LR: 0.004256\n",
      "Epoch [3], Batch [100/391], Loss: 3.9996, LR: 0.004512\n",
      "Epoch [3], Batch [150/391], Loss: 4.2974, LR: 0.004767\n",
      "Epoch [3], Batch [200/391], Loss: 4.1784, LR: 0.005023\n",
      "Epoch [3], Batch [250/391], Loss: 4.3309, LR: 0.005279\n",
      "Epoch [3], Batch [300/391], Loss: 4.1278, LR: 0.005535\n",
      "Epoch [3], Batch [350/391], Loss: 4.0793, LR: 0.005790\n",
      "Train set: Epoch: 3, Average loss:4.1827, LR: 0.006000 Top-1 Accuracy: 6.6620%, Top-5 Accuracy: 22.8840%, Time consumed:352.15s\n",
      "Test set: Epoch: 3, Average loss:4.0522, Top-1 Accuracy: 8.6900%, Top-5 Accuracy: 26.8300%, Time consumed:14.18s\n",
      "\n",
      "새로운 최고 top-1 정확도: 8.69%, top-5 정확도: 26.83%\n",
      "새로운 최고 top-5 정확도: 26.83%\n",
      "Accuracy improved (7.28% --> 8.69%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▉                                                                                          | 3/300 [18:28<30:29:32, 369.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4], Batch [50/391], Loss: 3.9287, LR: 0.006256\n",
      "Epoch [4], Batch [100/391], Loss: 3.9187, LR: 0.006512\n",
      "Epoch [4], Batch [150/391], Loss: 3.9289, LR: 0.006767\n",
      "Epoch [4], Batch [200/391], Loss: 3.7224, LR: 0.007023\n",
      "Epoch [4], Batch [250/391], Loss: 3.7457, LR: 0.007279\n",
      "Epoch [4], Batch [300/391], Loss: 4.2918, LR: 0.007535\n",
      "Epoch [4], Batch [350/391], Loss: 3.8171, LR: 0.007790\n",
      "Train set: Epoch: 4, Average loss:4.0201, LR: 0.008000 Top-1 Accuracy: 9.0060%, Top-5 Accuracy: 28.5180%, Time consumed:352.73s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▏                                                                                         | 4/300 [24:35<30:18:12, 368.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 4, Average loss:4.1782, Top-1 Accuracy: 8.4600%, Top-5 Accuracy: 27.3900%, Time consumed:14.21s\n",
      "\n",
      "새로운 최고 top-5 정확도: 27.39%\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [5], Batch [50/391], Loss: 3.6453, LR: 0.008256\n",
      "Epoch [5], Batch [100/391], Loss: 4.2531, LR: 0.008512\n",
      "Epoch [5], Batch [150/391], Loss: 3.9560, LR: 0.008767\n",
      "Epoch [5], Batch [200/391], Loss: 4.3448, LR: 0.009023\n",
      "Epoch [5], Batch [250/391], Loss: 3.9596, LR: 0.009279\n",
      "Epoch [5], Batch [300/391], Loss: 4.1879, LR: 0.009535\n",
      "Epoch [5], Batch [350/391], Loss: 3.9444, LR: 0.009790\n",
      "Train set: Epoch: 5, Average loss:3.8701, LR: 0.010000 Top-1 Accuracy: 11.4420%, Top-5 Accuracy: 33.7440%, Time consumed:352.78s\n",
      "Test set: Epoch: 5, Average loss:4.1616, Top-1 Accuracy: 9.3300%, Top-5 Accuracy: 30.9400%, Time consumed:14.10s\n",
      "\n",
      "새로운 최고 top-1 정확도: 9.33%, top-5 정확도: 30.94%\n",
      "새로운 최고 top-5 정확도: 30.94%\n",
      "Accuracy improved (8.69% --> 9.33%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▌                                                                                         | 5/300 [30:45<30:14:23, 369.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6], Batch [50/391], Loss: 4.1545, LR: 0.010000\n",
      "Epoch [6], Batch [100/391], Loss: 3.9823, LR: 0.010000\n",
      "Epoch [6], Batch [150/391], Loss: 4.1626, LR: 0.010000\n",
      "Epoch [6], Batch [200/391], Loss: 3.4858, LR: 0.010000\n",
      "Epoch [6], Batch [250/391], Loss: 3.8108, LR: 0.010000\n",
      "Epoch [6], Batch [300/391], Loss: 4.2219, LR: 0.010000\n",
      "Epoch [6], Batch [350/391], Loss: 3.3461, LR: 0.010000\n",
      "Train set: Epoch: 6, Average loss:3.6960, LR: 0.010000 Top-1 Accuracy: 14.9440%, Top-5 Accuracy: 39.6480%, Time consumed:352.06s\n",
      "Test set: Epoch: 6, Average loss:3.8482, Top-1 Accuracy: 14.3600%, Top-5 Accuracy: 40.2500%, Time consumed:14.14s\n",
      "\n",
      "새로운 최고 top-1 정확도: 14.36%, top-5 정확도: 40.25%\n",
      "새로운 최고 top-5 정확도: 40.25%\n",
      "Accuracy improved (9.33% --> 14.36%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▊                                                                                         | 6/300 [36:54<30:08:46, 369.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7], Batch [50/391], Loss: 3.8685, LR: 0.010000\n",
      "Epoch [7], Batch [100/391], Loss: 3.3695, LR: 0.010000\n",
      "Epoch [7], Batch [150/391], Loss: 3.8786, LR: 0.010000\n",
      "Epoch [7], Batch [200/391], Loss: 3.0042, LR: 0.010000\n",
      "Epoch [7], Batch [250/391], Loss: 3.3386, LR: 0.010000\n",
      "Epoch [7], Batch [300/391], Loss: 3.1885, LR: 0.010000\n",
      "Epoch [7], Batch [350/391], Loss: 3.4726, LR: 0.010000\n",
      "Train set: Epoch: 7, Average loss:3.4741, LR: 0.010000 Top-1 Accuracy: 18.9480%, Top-5 Accuracy: 46.3960%, Time consumed:352.90s\n",
      "Test set: Epoch: 7, Average loss:3.9050, Top-1 Accuracy: 16.2200%, Top-5 Accuracy: 44.7800%, Time consumed:22.23s\n",
      "\n",
      "새로운 최고 top-1 정확도: 16.22%, top-5 정확도: 44.78%\n",
      "새로운 최고 top-5 정확도: 44.78%\n",
      "Accuracy improved (14.36% --> 16.22%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██                                                                                         | 7/300 [43:12<30:16:54, 372.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8], Batch [50/391], Loss: 3.7292, LR: 0.010000\n",
      "Epoch [8], Batch [100/391], Loss: 3.2139, LR: 0.010000\n",
      "Epoch [8], Batch [150/391], Loss: 2.9168, LR: 0.010000\n",
      "Epoch [8], Batch [200/391], Loss: 2.9220, LR: 0.010000\n",
      "Epoch [8], Batch [250/391], Loss: 2.9710, LR: 0.010000\n",
      "Epoch [8], Batch [300/391], Loss: 2.8906, LR: 0.010000\n",
      "Epoch [8], Batch [350/391], Loss: 2.8467, LR: 0.010000\n",
      "Train set: Epoch: 8, Average loss:3.2989, LR: 0.010000 Top-1 Accuracy: 22.4720%, Top-5 Accuracy: 51.4780%, Time consumed:351.96s\n",
      "Test set: Epoch: 8, Average loss:3.1963, Top-1 Accuracy: 23.4100%, Top-5 Accuracy: 55.0900%, Time consumed:14.09s\n",
      "\n",
      "새로운 최고 top-1 정확도: 23.41%, top-5 정확도: 55.09%\n",
      "새로운 최고 top-5 정확도: 55.09%\n",
      "Accuracy improved (16.22% --> 23.41%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▍                                                                                        | 8/300 [49:21<30:06:19, 371.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9], Batch [50/391], Loss: 3.7134, LR: 0.010000\n",
      "Epoch [9], Batch [100/391], Loss: 3.9521, LR: 0.010000\n",
      "Epoch [9], Batch [150/391], Loss: 3.5269, LR: 0.010000\n",
      "Epoch [9], Batch [200/391], Loss: 3.0054, LR: 0.010000\n",
      "Epoch [9], Batch [250/391], Loss: 3.2700, LR: 0.010000\n",
      "Epoch [9], Batch [300/391], Loss: 3.9279, LR: 0.010000\n",
      "Epoch [9], Batch [350/391], Loss: 2.8206, LR: 0.010000\n",
      "Train set: Epoch: 9, Average loss:3.2170, LR: 0.010000 Top-1 Accuracy: 24.7040%, Top-5 Accuracy: 54.4860%, Time consumed:352.71s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▋                                                                                        | 9/300 [55:28<29:53:44, 369.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 9, Average loss:3.5475, Top-1 Accuracy: 21.0300%, Top-5 Accuracy: 50.6000%, Time consumed:14.21s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [10], Batch [50/391], Loss: 2.7734, LR: 0.010000\n",
      "Epoch [10], Batch [100/391], Loss: 3.2328, LR: 0.010000\n",
      "Epoch [10], Batch [150/391], Loss: 3.9803, LR: 0.010000\n",
      "Epoch [10], Batch [200/391], Loss: 4.0290, LR: 0.010000\n",
      "Epoch [10], Batch [250/391], Loss: 4.0603, LR: 0.010000\n",
      "Epoch [10], Batch [300/391], Loss: 3.6790, LR: 0.010000\n",
      "Epoch [10], Batch [350/391], Loss: 2.4179, LR: 0.010000\n",
      "Train set: Epoch: 10, Average loss:3.0646, LR: 0.010000 Top-1 Accuracy: 27.7740%, Top-5 Accuracy: 58.6860%, Time consumed:352.77s\n",
      "Test set: Epoch: 10, Average loss:3.0745, Top-1 Accuracy: 27.6700%, Top-5 Accuracy: 60.4200%, Time consumed:14.60s\n",
      "\n",
      "새로운 최고 top-1 정확도: 27.67%, top-5 정확도: 60.42%\n",
      "새로운 최고 top-5 정확도: 60.42%\n",
      "Accuracy improved (23.41% --> 27.67%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▉                                                                                     | 10/300 [1:01:39<29:48:35, 370.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11], Batch [50/391], Loss: 3.6898, LR: 0.010000\n",
      "Epoch [11], Batch [100/391], Loss: 3.8377, LR: 0.010000\n",
      "Epoch [11], Batch [150/391], Loss: 3.0710, LR: 0.010000\n",
      "Epoch [11], Batch [200/391], Loss: 3.5239, LR: 0.010000\n",
      "Epoch [11], Batch [250/391], Loss: 2.6321, LR: 0.010000\n",
      "Epoch [11], Batch [300/391], Loss: 2.8625, LR: 0.010000\n",
      "Epoch [11], Batch [350/391], Loss: 3.8202, LR: 0.010000\n",
      "Train set: Epoch: 11, Average loss:2.9987, LR: 0.010000 Top-1 Accuracy: 29.9440%, Top-5 Accuracy: 60.7740%, Time consumed:352.02s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▏                                                                                    | 11/300 [1:07:45<29:36:39, 368.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 11, Average loss:3.4073, Top-1 Accuracy: 23.9500%, Top-5 Accuracy: 52.8800%, Time consumed:14.12s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [12], Batch [50/391], Loss: 2.6414, LR: 0.010000\n",
      "Epoch [12], Batch [100/391], Loss: 3.6202, LR: 0.010000\n",
      "Epoch [12], Batch [150/391], Loss: 2.3753, LR: 0.010000\n",
      "Epoch [12], Batch [200/391], Loss: 2.4050, LR: 0.010000\n",
      "Epoch [12], Batch [250/391], Loss: 2.6183, LR: 0.010000\n",
      "Epoch [12], Batch [300/391], Loss: 3.6506, LR: 0.010000\n",
      "Epoch [12], Batch [350/391], Loss: 3.5988, LR: 0.010000\n",
      "Train set: Epoch: 12, Average loss:2.9109, LR: 0.010000 Top-1 Accuracy: 31.5060%, Top-5 Accuracy: 62.5980%, Time consumed:352.77s\n",
      "Test set: Epoch: 12, Average loss:2.8311, Top-1 Accuracy: 30.8100%, Top-5 Accuracy: 63.0800%, Time consumed:14.02s\n",
      "\n",
      "새로운 최고 top-1 정확도: 30.81%, top-5 정확도: 63.08%\n",
      "새로운 최고 top-5 정확도: 63.08%\n",
      "Accuracy improved (27.67% --> 30.81%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▌                                                                                    | 12/300 [1:13:55<29:31:51, 369.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13], Batch [50/391], Loss: 3.2745, LR: 0.010000\n",
      "Epoch [13], Batch [100/391], Loss: 3.0062, LR: 0.010000\n",
      "Epoch [13], Batch [150/391], Loss: 3.5113, LR: 0.010000\n",
      "Epoch [13], Batch [200/391], Loss: 2.4171, LR: 0.010000\n",
      "Epoch [13], Batch [250/391], Loss: 3.8284, LR: 0.010000\n",
      "Epoch [13], Batch [300/391], Loss: 3.3365, LR: 0.010000\n",
      "Epoch [13], Batch [350/391], Loss: 2.4196, LR: 0.010000\n",
      "Train set: Epoch: 13, Average loss:2.7746, LR: 0.010000 Top-1 Accuracy: 34.6500%, Top-5 Accuracy: 65.7360%, Time consumed:352.52s\n",
      "Test set: Epoch: 13, Average loss:2.6823, Top-1 Accuracy: 34.5400%, Top-5 Accuracy: 67.5100%, Time consumed:14.19s\n",
      "\n",
      "새로운 최고 top-1 정확도: 34.54%, top-5 정확도: 67.51%\n",
      "새로운 최고 top-5 정확도: 67.51%\n",
      "Accuracy improved (30.81% --> 34.54%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▊                                                                                    | 13/300 [1:20:04<29:26:43, 369.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14], Batch [50/391], Loss: 2.1716, LR: 0.010000\n",
      "Epoch [14], Batch [100/391], Loss: 3.4570, LR: 0.010000\n",
      "Epoch [14], Batch [150/391], Loss: 3.5568, LR: 0.010000\n",
      "Epoch [14], Batch [200/391], Loss: 1.9473, LR: 0.010000\n",
      "Epoch [14], Batch [250/391], Loss: 3.8191, LR: 0.010000\n",
      "Epoch [14], Batch [300/391], Loss: 2.1046, LR: 0.010000\n",
      "Epoch [14], Batch [350/391], Loss: 2.2248, LR: 0.010000\n",
      "Train set: Epoch: 14, Average loss:2.6912, LR: 0.010000 Top-1 Accuracy: 36.9780%, Top-5 Accuracy: 68.3060%, Time consumed:352.03s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████                                                                                    | 14/300 [1:26:19<29:28:06, 370.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 14, Average loss:2.9747, Top-1 Accuracy: 30.0100%, Top-5 Accuracy: 62.7200%, Time consumed:22.55s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [15], Batch [50/391], Loss: 2.0811, LR: 0.010000\n",
      "Epoch [15], Batch [100/391], Loss: 2.0296, LR: 0.010000\n",
      "Epoch [15], Batch [150/391], Loss: 2.0640, LR: 0.010000\n",
      "Epoch [15], Batch [200/391], Loss: 3.5283, LR: 0.010000\n",
      "Epoch [15], Batch [250/391], Loss: 3.7401, LR: 0.010000\n",
      "Epoch [15], Batch [300/391], Loss: 1.9706, LR: 0.010000\n",
      "Epoch [15], Batch [350/391], Loss: 3.7651, LR: 0.010000\n",
      "Train set: Epoch: 15, Average loss:2.6655, LR: 0.010000 Top-1 Accuracy: 37.8080%, Top-5 Accuracy: 68.3980%, Time consumed:352.14s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▍                                                                                   | 15/300 [1:32:25<29:15:16, 369.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 15, Average loss:3.2422, Top-1 Accuracy: 28.3600%, Top-5 Accuracy: 59.3300%, Time consumed:14.14s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [16], Batch [50/391], Loss: 3.3319, LR: 0.010000\n",
      "Epoch [16], Batch [100/391], Loss: 2.1069, LR: 0.010000\n",
      "Epoch [16], Batch [150/391], Loss: 1.9904, LR: 0.010000\n",
      "Epoch [16], Batch [200/391], Loss: 1.9810, LR: 0.010000\n",
      "Epoch [16], Batch [250/391], Loss: 1.7556, LR: 0.010000\n",
      "Epoch [16], Batch [300/391], Loss: 3.1083, LR: 0.010000\n",
      "Epoch [16], Batch [350/391], Loss: 3.1758, LR: 0.010000\n",
      "Train set: Epoch: 16, Average loss:2.5500, LR: 0.010000 Top-1 Accuracy: 40.6920%, Top-5 Accuracy: 72.0020%, Time consumed:351.83s\n",
      "Test set: Epoch: 16, Average loss:2.6808, Top-1 Accuracy: 35.7500%, Top-5 Accuracy: 68.0200%, Time consumed:14.48s\n",
      "\n",
      "새로운 최고 top-1 정확도: 35.75%, top-5 정확도: 68.02%\n",
      "새로운 최고 top-5 정확도: 68.02%\n",
      "Accuracy improved (34.54% --> 35.75%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▋                                                                                   | 16/300 [1:38:35<29:09:01, 369.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17], Batch [50/391], Loss: 2.3739, LR: 0.010000\n",
      "Epoch [17], Batch [100/391], Loss: 2.0985, LR: 0.010000\n",
      "Epoch [17], Batch [150/391], Loss: 2.0883, LR: 0.010000\n",
      "Epoch [17], Batch [200/391], Loss: 2.8503, LR: 0.010000\n",
      "Epoch [17], Batch [250/391], Loss: 2.1461, LR: 0.010000\n",
      "Epoch [17], Batch [300/391], Loss: 1.8367, LR: 0.010000\n",
      "Epoch [17], Batch [350/391], Loss: 3.2314, LR: 0.010000\n",
      "Train set: Epoch: 17, Average loss:2.5048, LR: 0.010000 Top-1 Accuracy: 41.7200%, Top-5 Accuracy: 72.4500%, Time consumed:352.77s\n",
      "Test set: Epoch: 17, Average loss:2.2287, Top-1 Accuracy: 43.9500%, Top-5 Accuracy: 75.8600%, Time consumed:14.14s\n",
      "\n",
      "새로운 최고 top-1 정확도: 43.95%, top-5 정확도: 75.86%\n",
      "새로운 최고 top-5 정확도: 75.86%\n",
      "Accuracy improved (35.75% --> 43.95%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▉                                                                                   | 17/300 [1:44:45<29:03:40, 369.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18], Batch [50/391], Loss: 1.7954, LR: 0.010000\n",
      "Epoch [18], Batch [100/391], Loss: 3.5552, LR: 0.010000\n",
      "Epoch [18], Batch [150/391], Loss: 3.6114, LR: 0.010000\n",
      "Epoch [18], Batch [200/391], Loss: 3.3095, LR: 0.010000\n",
      "Epoch [18], Batch [250/391], Loss: 1.7913, LR: 0.010000\n",
      "Epoch [18], Batch [300/391], Loss: 1.8320, LR: 0.010000\n",
      "Epoch [18], Batch [350/391], Loss: 2.8563, LR: 0.010000\n",
      "Train set: Epoch: 18, Average loss:2.4725, LR: 0.010000 Top-1 Accuracy: 42.2420%, Top-5 Accuracy: 72.6300%, Time consumed:352.36s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████▎                                                                                  | 18/300 [1:50:52<28:54:19, 369.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 18, Average loss:2.5874, Top-1 Accuracy: 38.4800%, Top-5 Accuracy: 69.6800%, Time consumed:15.05s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [19], Batch [50/391], Loss: 1.6813, LR: 0.010000\n",
      "Epoch [19], Batch [100/391], Loss: 3.3124, LR: 0.010000\n",
      "Epoch [19], Batch [150/391], Loss: 3.6201, LR: 0.010000\n",
      "Epoch [19], Batch [200/391], Loss: 3.0804, LR: 0.010000\n",
      "Epoch [19], Batch [250/391], Loss: 1.6006, LR: 0.010000\n",
      "Epoch [19], Batch [300/391], Loss: 1.8978, LR: 0.010000\n",
      "Epoch [19], Batch [350/391], Loss: 1.8372, LR: 0.010000\n",
      "Train set: Epoch: 19, Average loss:2.4097, LR: 0.010000 Top-1 Accuracy: 43.8580%, Top-5 Accuracy: 74.3960%, Time consumed:352.61s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████▌                                                                                  | 19/300 [1:56:59<28:45:07, 368.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 19, Average loss:2.2997, Top-1 Accuracy: 43.2000%, Top-5 Accuracy: 74.9400%, Time consumed:14.22s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [20], Batch [50/391], Loss: 3.7049, LR: 0.010000\n",
      "Epoch [20], Batch [100/391], Loss: 1.6625, LR: 0.010000\n",
      "Epoch [20], Batch [150/391], Loss: 2.2338, LR: 0.010000\n",
      "Epoch [20], Batch [200/391], Loss: 3.4912, LR: 0.010000\n",
      "Epoch [20], Batch [250/391], Loss: 1.7750, LR: 0.010000\n",
      "Epoch [20], Batch [300/391], Loss: 3.0288, LR: 0.010000\n",
      "Epoch [20], Batch [350/391], Loss: 3.1874, LR: 0.010000\n",
      "Train set: Epoch: 20, Average loss:2.3192, LR: 0.010000 Top-1 Accuracy: 46.3480%, Top-5 Accuracy: 76.4280%, Time consumed:352.15s\n",
      "Test set: Epoch: 20, Average loss:2.1934, Top-1 Accuracy: 44.2400%, Top-5 Accuracy: 76.5400%, Time consumed:14.18s\n",
      "\n",
      "새로운 최고 top-1 정확도: 44.24%, top-5 정확도: 76.54%\n",
      "새로운 최고 top-5 정확도: 76.54%\n",
      "Accuracy improved (43.95% --> 44.24%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████▊                                                                                  | 20/300 [2:03:08<28:40:17, 368.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21], Batch [50/391], Loss: 3.7127, LR: 0.010000\n",
      "Epoch [21], Batch [100/391], Loss: 3.1619, LR: 0.010000\n",
      "Epoch [21], Batch [150/391], Loss: 1.6550, LR: 0.010000\n",
      "Epoch [21], Batch [200/391], Loss: 1.3015, LR: 0.010000\n",
      "Epoch [21], Batch [250/391], Loss: 3.2467, LR: 0.010000\n",
      "Epoch [21], Batch [300/391], Loss: 1.6247, LR: 0.010000\n",
      "Epoch [21], Batch [350/391], Loss: 2.2077, LR: 0.010000\n",
      "Train set: Epoch: 21, Average loss:2.3117, LR: 0.010000 Top-1 Accuracy: 46.7860%, Top-5 Accuracy: 76.5920%, Time consumed:352.86s\n",
      "Test set: Epoch: 21, Average loss:2.1829, Top-1 Accuracy: 45.2300%, Top-5 Accuracy: 76.4500%, Time consumed:14.45s\n",
      "\n",
      "새로운 최고 top-1 정확도: 45.23%, top-5 정확도: 76.45%\n",
      "Accuracy improved (44.24% --> 45.23%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████▏                                                                                 | 21/300 [2:09:19<28:36:44, 369.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22], Batch [50/391], Loss: 1.8085, LR: 0.010000\n",
      "Epoch [22], Batch [100/391], Loss: 3.2574, LR: 0.010000\n",
      "Epoch [22], Batch [150/391], Loss: 3.2081, LR: 0.010000\n",
      "Epoch [22], Batch [200/391], Loss: 1.7195, LR: 0.010000\n",
      "Epoch [22], Batch [250/391], Loss: 1.3402, LR: 0.010000\n",
      "Epoch [22], Batch [300/391], Loss: 3.5088, LR: 0.010000\n",
      "Epoch [22], Batch [350/391], Loss: 1.5514, LR: 0.010000\n",
      "Train set: Epoch: 22, Average loss:2.2973, LR: 0.010000 Top-1 Accuracy: 47.6600%, Top-5 Accuracy: 77.1440%, Time consumed:352.79s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████▍                                                                                 | 22/300 [2:15:26<28:27:26, 368.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 22, Average loss:2.4460, Top-1 Accuracy: 41.8400%, Top-5 Accuracy: 73.9100%, Time consumed:14.13s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [23], Batch [50/391], Loss: 1.5118, LR: 0.010000\n",
      "Epoch [23], Batch [100/391], Loss: 1.6105, LR: 0.010000\n",
      "Epoch [23], Batch [150/391], Loss: 1.4405, LR: 0.010000\n",
      "Epoch [23], Batch [200/391], Loss: 2.4104, LR: 0.010000\n",
      "Epoch [23], Batch [250/391], Loss: 1.6800, LR: 0.010000\n",
      "Epoch [23], Batch [300/391], Loss: 2.8958, LR: 0.010000\n",
      "Epoch [23], Batch [350/391], Loss: 1.3936, LR: 0.010000\n",
      "Train set: Epoch: 23, Average loss:2.2263, LR: 0.010000 Top-1 Accuracy: 49.3460%, Top-5 Accuracy: 78.2660%, Time consumed:352.41s\n",
      "Test set: Epoch: 23, Average loss:2.2277, Top-1 Accuracy: 46.5100%, Top-5 Accuracy: 76.8100%, Time consumed:14.17s\n",
      "\n",
      "새로운 최고 top-1 정확도: 46.51%, top-5 정확도: 76.81%\n",
      "새로운 최고 top-5 정확도: 76.81%\n",
      "Accuracy improved (45.23% --> 46.51%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▋                                                                                 | 23/300 [2:21:36<28:23:00, 368.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24], Batch [50/391], Loss: 2.9576, LR: 0.010000\n",
      "Epoch [24], Batch [100/391], Loss: 3.5239, LR: 0.010000\n",
      "Epoch [24], Batch [150/391], Loss: 2.8798, LR: 0.010000\n",
      "Epoch [24], Batch [200/391], Loss: 2.9750, LR: 0.010000\n",
      "Epoch [24], Batch [250/391], Loss: 3.3821, LR: 0.010000\n",
      "Epoch [24], Batch [300/391], Loss: 1.3380, LR: 0.010000\n",
      "Epoch [24], Batch [350/391], Loss: 2.8053, LR: 0.010000\n",
      "Train set: Epoch: 24, Average loss:2.1317, LR: 0.010000 Top-1 Accuracy: 51.2220%, Top-5 Accuracy: 79.8440%, Time consumed:352.83s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███████                                                                                 | 24/300 [2:27:43<28:14:10, 368.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 24, Average loss:2.4783, Top-1 Accuracy: 43.6800%, Top-5 Accuracy: 74.5300%, Time consumed:14.10s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [25], Batch [50/391], Loss: 1.5070, LR: 0.010000\n",
      "Epoch [25], Batch [100/391], Loss: 3.3442, LR: 0.010000\n",
      "Epoch [25], Batch [150/391], Loss: 3.1081, LR: 0.010000\n",
      "Epoch [25], Batch [200/391], Loss: 1.4126, LR: 0.010000\n",
      "Epoch [25], Batch [250/391], Loss: 3.4183, LR: 0.010000\n",
      "Epoch [25], Batch [300/391], Loss: 2.8445, LR: 0.010000\n",
      "Epoch [25], Batch [350/391], Loss: 3.2986, LR: 0.010000\n",
      "Train set: Epoch: 25, Average loss:2.1591, LR: 0.010000 Top-1 Accuracy: 50.6020%, Top-5 Accuracy: 79.2180%, Time consumed:352.31s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███████▎                                                                                | 25/300 [2:33:57<28:17:01, 370.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 25, Average loss:2.2136, Top-1 Accuracy: 46.4600%, Top-5 Accuracy: 77.1000%, Time consumed:22.52s\n",
      "\n",
      "새로운 최고 top-5 정확도: 77.10%\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [26], Batch [50/391], Loss: 2.5345, LR: 0.010000\n",
      "Epoch [26], Batch [100/391], Loss: 2.8889, LR: 0.010000\n",
      "Epoch [26], Batch [150/391], Loss: 2.2245, LR: 0.010000\n",
      "Epoch [26], Batch [200/391], Loss: 3.1117, LR: 0.010000\n",
      "Epoch [26], Batch [250/391], Loss: 3.0117, LR: 0.010000\n",
      "Epoch [26], Batch [300/391], Loss: 1.2619, LR: 0.010000\n",
      "Epoch [26], Batch [350/391], Loss: 1.3069, LR: 0.010000\n",
      "Train set: Epoch: 26, Average loss:2.0780, LR: 0.010000 Top-1 Accuracy: 52.5860%, Top-5 Accuracy: 80.9000%, Time consumed:352.68s\n",
      "Test set: Epoch: 26, Average loss:2.1655, Top-1 Accuracy: 48.3000%, Top-5 Accuracy: 78.0500%, Time consumed:14.16s\n",
      "\n",
      "새로운 최고 top-1 정확도: 48.30%, top-5 정확도: 78.05%\n",
      "새로운 최고 top-5 정확도: 78.05%\n",
      "Accuracy improved (46.51% --> 48.30%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███████▋                                                                                | 26/300 [2:40:07<28:10:33, 370.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27], Batch [50/391], Loss: 3.2081, LR: 0.010000\n",
      "Epoch [27], Batch [100/391], Loss: 2.6499, LR: 0.010000\n",
      "Epoch [27], Batch [150/391], Loss: 1.3828, LR: 0.010000\n",
      "Epoch [27], Batch [200/391], Loss: 3.0109, LR: 0.010000\n",
      "Epoch [27], Batch [250/391], Loss: 2.0510, LR: 0.010000\n",
      "Epoch [27], Batch [300/391], Loss: 1.1723, LR: 0.010000\n",
      "Epoch [27], Batch [350/391], Loss: 3.1732, LR: 0.010000\n",
      "Train set: Epoch: 27, Average loss:2.0557, LR: 0.010000 Top-1 Accuracy: 53.6560%, Top-5 Accuracy: 81.1800%, Time consumed:353.07s\n",
      "Test set: Epoch: 27, Average loss:1.8127, Top-1 Accuracy: 54.2600%, Top-5 Accuracy: 82.3400%, Time consumed:14.59s\n",
      "\n",
      "새로운 최고 top-1 정확도: 54.26%, top-5 정확도: 82.34%\n",
      "새로운 최고 top-5 정확도: 82.34%\n",
      "Accuracy improved (48.30% --> 54.26%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███████▉                                                                                | 27/300 [2:46:18<28:05:24, 370.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28], Batch [50/391], Loss: 1.1462, LR: 0.010000\n",
      "Epoch [28], Batch [100/391], Loss: 1.1526, LR: 0.010000\n",
      "Epoch [28], Batch [150/391], Loss: 1.3992, LR: 0.010000\n",
      "Epoch [28], Batch [200/391], Loss: 1.2478, LR: 0.010000\n",
      "Epoch [28], Batch [250/391], Loss: 1.2703, LR: 0.010000\n",
      "Epoch [28], Batch [300/391], Loss: 1.3316, LR: 0.010000\n",
      "Epoch [28], Batch [350/391], Loss: 1.3173, LR: 0.010000\n",
      "Train set: Epoch: 28, Average loss:1.9546, LR: 0.010000 Top-1 Accuracy: 55.9300%, Top-5 Accuracy: 82.9260%, Time consumed:352.47s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|████████▏                                                                               | 28/300 [2:52:25<27:54:08, 369.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 28, Average loss:1.9670, Top-1 Accuracy: 51.4800%, Top-5 Accuracy: 80.8700%, Time consumed:14.20s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [29], Batch [50/391], Loss: 1.3635, LR: 0.010000\n",
      "Epoch [29], Batch [100/391], Loss: 1.2210, LR: 0.010000\n",
      "Epoch [29], Batch [150/391], Loss: 1.2708, LR: 0.010000\n",
      "Epoch [29], Batch [200/391], Loss: 1.3503, LR: 0.010000\n",
      "Epoch [29], Batch [250/391], Loss: 1.3019, LR: 0.010000\n",
      "Epoch [29], Batch [300/391], Loss: 2.8955, LR: 0.010000\n",
      "Epoch [29], Batch [350/391], Loss: 1.2347, LR: 0.010000\n",
      "Train set: Epoch: 29, Average loss:2.0266, LR: 0.010000 Top-1 Accuracy: 55.1060%, Top-5 Accuracy: 82.3680%, Time consumed:352.93s\n",
      "Test set: Epoch: 29, Average loss:1.8162, Top-1 Accuracy: 54.3500%, Top-5 Accuracy: 82.3300%, Time consumed:14.29s\n",
      "\n",
      "새로운 최고 top-1 정확도: 54.35%, top-5 정확도: 82.33%\n",
      "Accuracy improved (54.26% --> 54.35%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▌                                                                               | 29/300 [2:58:35<27:49:26, 369.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30], Batch [50/391], Loss: 1.2090, LR: 0.010000\n",
      "Epoch [30], Batch [100/391], Loss: 1.2626, LR: 0.010000\n",
      "Epoch [30], Batch [150/391], Loss: 1.1675, LR: 0.010000\n",
      "Epoch [30], Batch [200/391], Loss: 1.2762, LR: 0.010000\n",
      "Epoch [30], Batch [250/391], Loss: 1.1463, LR: 0.010000\n",
      "Epoch [30], Batch [300/391], Loss: 1.3408, LR: 0.010000\n",
      "Epoch [30], Batch [350/391], Loss: 3.1874, LR: 0.010000\n",
      "Train set: Epoch: 30, Average loss:1.9239, LR: 0.010000 Top-1 Accuracy: 56.4020%, Top-5 Accuracy: 83.2560%, Time consumed:352.88s\n",
      "Test set: Epoch: 30, Average loss:1.7283, Top-1 Accuracy: 56.5400%, Top-5 Accuracy: 83.5100%, Time consumed:14.18s\n",
      "\n",
      "새로운 최고 top-1 정확도: 56.54%, top-5 정확도: 83.51%\n",
      "새로운 최고 top-5 정확도: 83.51%\n",
      "Accuracy improved (54.35% --> 56.54%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▊                                                                               | 30/300 [3:04:46<27:44:08, 369.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31], Batch [50/391], Loss: 1.0758, LR: 0.010000\n",
      "Epoch [31], Batch [100/391], Loss: 3.2907, LR: 0.010000\n",
      "Epoch [31], Batch [150/391], Loss: 0.9932, LR: 0.010000\n",
      "Epoch [31], Batch [200/391], Loss: 1.9487, LR: 0.010000\n",
      "Epoch [31], Batch [250/391], Loss: 1.4973, LR: 0.010000\n",
      "Epoch [31], Batch [300/391], Loss: 3.1979, LR: 0.010000\n",
      "Epoch [31], Batch [350/391], Loss: 3.1425, LR: 0.010000\n",
      "Train set: Epoch: 31, Average loss:1.9520, LR: 0.010000 Top-1 Accuracy: 56.4160%, Top-5 Accuracy: 83.1580%, Time consumed:352.25s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█████████                                                                               | 31/300 [3:10:52<27:33:56, 368.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 31, Average loss:1.8033, Top-1 Accuracy: 55.3100%, Top-5 Accuracy: 83.9900%, Time consumed:14.55s\n",
      "\n",
      "새로운 최고 top-5 정확도: 83.99%\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [32], Batch [50/391], Loss: 2.7096, LR: 0.010000\n",
      "Epoch [32], Batch [100/391], Loss: 3.5253, LR: 0.010000\n",
      "Epoch [32], Batch [150/391], Loss: 1.0580, LR: 0.010000\n",
      "Epoch [32], Batch [200/391], Loss: 1.9157, LR: 0.010000\n",
      "Epoch [32], Batch [250/391], Loss: 1.7761, LR: 0.010000\n",
      "Epoch [32], Batch [300/391], Loss: 1.1950, LR: 0.010000\n",
      "Epoch [32], Batch [350/391], Loss: 3.1835, LR: 0.010000\n",
      "Train set: Epoch: 32, Average loss:1.9306, LR: 0.010000 Top-1 Accuracy: 58.1760%, Top-5 Accuracy: 84.1260%, Time consumed:352.73s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█████████▍                                                                              | 32/300 [3:17:08<27:36:08, 370.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 32, Average loss:1.7698, Top-1 Accuracy: 56.4600%, Top-5 Accuracy: 84.0300%, Time consumed:22.40s\n",
      "\n",
      "새로운 최고 top-5 정확도: 84.03%\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [33], Batch [50/391], Loss: 3.1191, LR: 0.010000\n",
      "Epoch [33], Batch [100/391], Loss: 1.3165, LR: 0.010000\n",
      "Epoch [33], Batch [150/391], Loss: 1.0397, LR: 0.010000\n",
      "Epoch [33], Batch [200/391], Loss: 1.1164, LR: 0.010000\n",
      "Epoch [33], Batch [250/391], Loss: 2.9394, LR: 0.010000\n",
      "Epoch [33], Batch [300/391], Loss: 1.6652, LR: 0.010000\n",
      "Epoch [33], Batch [350/391], Loss: 1.2903, LR: 0.010000\n",
      "Train set: Epoch: 33, Average loss:1.8712, LR: 0.010000 Top-1 Accuracy: 58.6480%, Top-5 Accuracy: 84.6980%, Time consumed:352.88s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█████████▋                                                                              | 33/300 [3:23:15<27:24:57, 369.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 33, Average loss:1.9184, Top-1 Accuracy: 54.3400%, Top-5 Accuracy: 81.6500%, Time consumed:14.14s\n",
      "\n",
      "EarlyStopping 카운터: 3 / 30\n",
      "Epoch [34], Batch [50/391], Loss: 1.0162, LR: 0.010000\n",
      "Epoch [34], Batch [100/391], Loss: 1.1404, LR: 0.010000\n",
      "Epoch [34], Batch [150/391], Loss: 2.4643, LR: 0.010000\n",
      "Epoch [34], Batch [200/391], Loss: 1.1381, LR: 0.010000\n",
      "Epoch [34], Batch [250/391], Loss: 2.9535, LR: 0.010000\n",
      "Epoch [34], Batch [300/391], Loss: 1.0075, LR: 0.010000\n",
      "Epoch [34], Batch [350/391], Loss: 1.0204, LR: 0.010000\n",
      "Train set: Epoch: 34, Average loss:1.8872, LR: 0.010000 Top-1 Accuracy: 58.9460%, Top-5 Accuracy: 85.0100%, Time consumed:352.29s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█████████▉                                                                              | 34/300 [3:29:21<27:14:41, 368.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 34, Average loss:1.7915, Top-1 Accuracy: 56.5100%, Top-5 Accuracy: 83.8400%, Time consumed:14.27s\n",
      "\n",
      "EarlyStopping 카운터: 4 / 30\n",
      "Epoch [35], Batch [50/391], Loss: 1.2843, LR: 0.010000\n",
      "Epoch [35], Batch [100/391], Loss: 1.0364, LR: 0.010000\n",
      "Epoch [35], Batch [150/391], Loss: 0.9981, LR: 0.010000\n",
      "Epoch [35], Batch [200/391], Loss: 2.9553, LR: 0.010000\n",
      "Epoch [35], Batch [250/391], Loss: 3.2080, LR: 0.010000\n",
      "Epoch [35], Batch [300/391], Loss: 2.4847, LR: 0.010000\n",
      "Epoch [35], Batch [350/391], Loss: 1.0591, LR: 0.010000\n",
      "Train set: Epoch: 35, Average loss:1.7669, LR: 0.010000 Top-1 Accuracy: 61.4960%, Top-5 Accuracy: 86.6260%, Time consumed:353.05s\n",
      "Test set: Epoch: 35, Average loss:1.6239, Top-1 Accuracy: 59.9800%, Top-5 Accuracy: 86.9500%, Time consumed:14.63s\n",
      "\n",
      "새로운 최고 top-1 정확도: 59.98%, top-5 정확도: 86.95%\n",
      "새로운 최고 top-5 정확도: 86.95%\n",
      "Accuracy improved (56.54% --> 59.98%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████▎                                                                             | 35/300 [3:35:32<27:11:35, 369.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36], Batch [50/391], Loss: 3.0186, LR: 0.010000\n",
      "Epoch [36], Batch [100/391], Loss: 0.9002, LR: 0.010000\n",
      "Epoch [36], Batch [150/391], Loss: 2.2988, LR: 0.010000\n",
      "Epoch [36], Batch [200/391], Loss: 3.1473, LR: 0.010000\n",
      "Epoch [36], Batch [250/391], Loss: 2.7706, LR: 0.010000\n",
      "Epoch [36], Batch [300/391], Loss: 2.5066, LR: 0.010000\n",
      "Epoch [36], Batch [350/391], Loss: 1.0570, LR: 0.010000\n",
      "Train set: Epoch: 36, Average loss:1.7428, LR: 0.010000 Top-1 Accuracy: 61.5620%, Top-5 Accuracy: 86.3620%, Time consumed:352.81s\n",
      "Test set: Epoch: 36, Average loss:1.6492, Top-1 Accuracy: 60.9500%, Top-5 Accuracy: 86.3800%, Time consumed:14.17s\n",
      "\n",
      "새로운 최고 top-1 정확도: 60.95%, top-5 정확도: 86.38%\n",
      "Accuracy improved (59.98% --> 60.95%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████▌                                                                             | 36/300 [3:41:42<27:06:21, 369.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37], Batch [50/391], Loss: 3.0743, LR: 0.010000\n",
      "Epoch [37], Batch [100/391], Loss: 2.4295, LR: 0.010000\n",
      "Epoch [37], Batch [150/391], Loss: 0.9664, LR: 0.010000\n",
      "Epoch [37], Batch [200/391], Loss: 1.1064, LR: 0.010000\n",
      "Epoch [37], Batch [250/391], Loss: 0.7922, LR: 0.010000\n",
      "Epoch [37], Batch [300/391], Loss: 3.0325, LR: 0.010000\n",
      "Epoch [37], Batch [350/391], Loss: 1.0174, LR: 0.010000\n",
      "Train set: Epoch: 37, Average loss:1.7584, LR: 0.010000 Top-1 Accuracy: 60.9940%, Top-5 Accuracy: 86.1120%, Time consumed:352.68s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████▊                                                                             | 37/300 [3:47:50<26:57:04, 368.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 37, Average loss:1.9243, Top-1 Accuracy: 56.5700%, Top-5 Accuracy: 84.3300%, Time consumed:14.56s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [38], Batch [50/391], Loss: 2.8161, LR: 0.010000\n",
      "Epoch [38], Batch [100/391], Loss: 1.1044, LR: 0.010000\n",
      "Epoch [38], Batch [150/391], Loss: 0.9785, LR: 0.010000\n",
      "Epoch [38], Batch [200/391], Loss: 0.8434, LR: 0.010000\n",
      "Epoch [38], Batch [250/391], Loss: 2.4370, LR: 0.010000\n",
      "Epoch [38], Batch [300/391], Loss: 1.0180, LR: 0.010000\n",
      "Epoch [38], Batch [350/391], Loss: 1.1204, LR: 0.010000\n",
      "Train set: Epoch: 38, Average loss:1.6290, LR: 0.010000 Top-1 Accuracy: 63.6720%, Top-5 Accuracy: 87.8580%, Time consumed:352.44s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|███████████▏                                                                            | 38/300 [3:53:56<26:47:58, 368.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 38, Average loss:1.7153, Top-1 Accuracy: 59.9100%, Top-5 Accuracy: 86.2400%, Time consumed:14.21s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [39], Batch [50/391], Loss: 0.9229, LR: 0.010000\n",
      "Epoch [39], Batch [100/391], Loss: 0.9939, LR: 0.010000\n",
      "Epoch [39], Batch [150/391], Loss: 0.8332, LR: 0.010000\n",
      "Epoch [39], Batch [200/391], Loss: 3.2384, LR: 0.010000\n",
      "Epoch [39], Batch [250/391], Loss: 0.9914, LR: 0.010000\n",
      "Epoch [39], Batch [300/391], Loss: 0.8419, LR: 0.010000\n",
      "Epoch [39], Batch [350/391], Loss: 2.8590, LR: 0.010000\n",
      "Train set: Epoch: 39, Average loss:1.6812, LR: 0.010000 Top-1 Accuracy: 63.5120%, Top-5 Accuracy: 87.1880%, Time consumed:352.30s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|███████████▍                                                                            | 39/300 [4:00:03<26:39:30, 367.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 39, Average loss:1.7840, Top-1 Accuracy: 58.4500%, Top-5 Accuracy: 84.6900%, Time consumed:14.15s\n",
      "\n",
      "EarlyStopping 카운터: 3 / 30\n",
      "Epoch [40], Batch [50/391], Loss: 3.0533, LR: 0.010000\n",
      "Epoch [40], Batch [100/391], Loss: 0.7552, LR: 0.010000\n",
      "Epoch [40], Batch [150/391], Loss: 0.7771, LR: 0.010000\n",
      "Epoch [40], Batch [200/391], Loss: 2.9847, LR: 0.010000\n",
      "Epoch [40], Batch [250/391], Loss: 0.8995, LR: 0.010000\n",
      "Epoch [40], Batch [300/391], Loss: 0.8845, LR: 0.010000\n",
      "Epoch [40], Batch [350/391], Loss: 2.9530, LR: 0.010000\n",
      "Train set: Epoch: 40, Average loss:1.6655, LR: 0.010000 Top-1 Accuracy: 64.1180%, Top-5 Accuracy: 87.6160%, Time consumed:352.72s\n",
      "Test set: Epoch: 40, Average loss:1.5762, Top-1 Accuracy: 62.5200%, Top-5 Accuracy: 87.9400%, Time consumed:14.18s\n",
      "\n",
      "새로운 최고 top-1 정확도: 62.52%, top-5 정확도: 87.94%\n",
      "새로운 최고 top-5 정확도: 87.94%\n",
      "Accuracy improved (60.95% --> 62.52%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|███████████▋                                                                            | 40/300 [4:06:13<26:36:29, 368.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41], Batch [50/391], Loss: 0.7544, LR: 0.010000\n",
      "Epoch [41], Batch [100/391], Loss: 1.8897, LR: 0.010000\n",
      "Epoch [41], Batch [150/391], Loss: 1.2687, LR: 0.010000\n",
      "Epoch [41], Batch [200/391], Loss: 2.5895, LR: 0.010000\n",
      "Epoch [41], Batch [250/391], Loss: 0.8824, LR: 0.010000\n",
      "Epoch [41], Batch [300/391], Loss: 1.9142, LR: 0.010000\n",
      "Epoch [41], Batch [350/391], Loss: 0.9150, LR: 0.010000\n",
      "Train set: Epoch: 41, Average loss:1.6500, LR: 0.010000 Top-1 Accuracy: 64.4040%, Top-5 Accuracy: 87.6120%, Time consumed:352.91s\n",
      "Test set: Epoch: 41, Average loss:1.5327, Top-1 Accuracy: 63.1800%, Top-5 Accuracy: 88.1100%, Time consumed:14.68s\n",
      "\n",
      "새로운 최고 top-1 정확도: 63.18%, top-5 정확도: 88.11%\n",
      "새로운 최고 top-5 정확도: 88.11%\n",
      "Accuracy improved (62.52% --> 63.18%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████                                                                            | 41/300 [4:12:23<26:33:10, 369.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42], Batch [50/391], Loss: 1.9878, LR: 0.010000\n",
      "Epoch [42], Batch [100/391], Loss: 0.8079, LR: 0.010000\n",
      "Epoch [42], Batch [150/391], Loss: 2.6797, LR: 0.010000\n",
      "Epoch [42], Batch [200/391], Loss: 2.6131, LR: 0.010000\n",
      "Epoch [42], Batch [250/391], Loss: 1.7698, LR: 0.010000\n",
      "Epoch [42], Batch [300/391], Loss: 0.8088, LR: 0.010000\n",
      "Epoch [42], Batch [350/391], Loss: 0.8715, LR: 0.010000\n",
      "Train set: Epoch: 42, Average loss:1.5573, LR: 0.010000 Top-1 Accuracy: 66.5900%, Top-5 Accuracy: 89.2920%, Time consumed:352.25s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████▎                                                                           | 42/300 [4:18:30<26:23:49, 368.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 42, Average loss:1.6969, Top-1 Accuracy: 60.3900%, Top-5 Accuracy: 86.9700%, Time consumed:14.33s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [43], Batch [50/391], Loss: 0.7819, LR: 0.010000\n",
      "Epoch [43], Batch [100/391], Loss: 2.5320, LR: 0.010000\n",
      "Epoch [43], Batch [150/391], Loss: 2.9960, LR: 0.010000\n",
      "Epoch [43], Batch [200/391], Loss: 1.8729, LR: 0.010000\n",
      "Epoch [43], Batch [250/391], Loss: 0.7907, LR: 0.010000\n",
      "Epoch [43], Batch [300/391], Loss: 0.6984, LR: 0.010000\n",
      "Epoch [43], Batch [350/391], Loss: 0.7128, LR: 0.010000\n",
      "Train set: Epoch: 43, Average loss:1.5441, LR: 0.010000 Top-1 Accuracy: 66.1200%, Top-5 Accuracy: 88.7760%, Time consumed:352.51s\n",
      "Test set: Epoch: 43, Average loss:1.5404, Top-1 Accuracy: 64.0800%, Top-5 Accuracy: 89.0400%, Time consumed:22.32s\n",
      "\n",
      "새로운 최고 top-1 정확도: 64.08%, top-5 정확도: 89.04%\n",
      "새로운 최고 top-5 정확도: 89.04%\n",
      "Accuracy improved (63.18% --> 64.08%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████▌                                                                           | 43/300 [4:24:48<26:29:53, 371.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44], Batch [50/391], Loss: 0.9034, LR: 0.010000\n",
      "Epoch [44], Batch [100/391], Loss: 2.8877, LR: 0.010000\n",
      "Epoch [44], Batch [150/391], Loss: 1.0028, LR: 0.010000\n",
      "Epoch [44], Batch [200/391], Loss: 2.4361, LR: 0.010000\n",
      "Epoch [44], Batch [250/391], Loss: 2.8893, LR: 0.010000\n",
      "Epoch [44], Batch [300/391], Loss: 2.8312, LR: 0.010000\n",
      "Epoch [44], Batch [350/391], Loss: 0.7643, LR: 0.010000\n",
      "Train set: Epoch: 44, Average loss:1.6222, LR: 0.010000 Top-1 Accuracy: 65.8620%, Top-5 Accuracy: 88.7660%, Time consumed:352.79s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████████████▉                                                                           | 44/300 [4:30:55<26:18:52, 370.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 44, Average loss:1.5246, Top-1 Accuracy: 63.7800%, Top-5 Accuracy: 88.5200%, Time consumed:14.61s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [45], Batch [50/391], Loss: 0.8931, LR: 0.010000\n",
      "Epoch [45], Batch [100/391], Loss: 0.9668, LR: 0.010000\n",
      "Epoch [45], Batch [150/391], Loss: 2.2034, LR: 0.010000\n",
      "Epoch [45], Batch [200/391], Loss: 0.6738, LR: 0.010000\n",
      "Epoch [45], Batch [250/391], Loss: 1.1003, LR: 0.010000\n",
      "Epoch [45], Batch [300/391], Loss: 0.8205, LR: 0.010000\n",
      "Epoch [45], Batch [350/391], Loss: 2.5203, LR: 0.010000\n",
      "Train set: Epoch: 45, Average loss:1.5455, LR: 0.010000 Top-1 Accuracy: 66.6880%, Top-5 Accuracy: 88.8840%, Time consumed:352.83s\n",
      "Test set: Epoch: 45, Average loss:1.4744, Top-1 Accuracy: 66.1700%, Top-5 Accuracy: 90.2200%, Time consumed:14.17s\n",
      "\n",
      "새로운 최고 top-1 정확도: 66.17%, top-5 정확도: 90.22%\n",
      "새로운 최고 top-5 정확도: 90.22%\n",
      "Accuracy improved (64.08% --> 66.17%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████████████▏                                                                          | 45/300 [4:37:05<26:12:35, 370.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46], Batch [50/391], Loss: 2.2729, LR: 0.010000\n",
      "Epoch [46], Batch [100/391], Loss: 2.9325, LR: 0.010000\n",
      "Epoch [46], Batch [150/391], Loss: 2.2811, LR: 0.010000\n",
      "Epoch [46], Batch [200/391], Loss: 0.7683, LR: 0.010000\n",
      "Epoch [46], Batch [250/391], Loss: 1.0198, LR: 0.010000\n",
      "Epoch [46], Batch [300/391], Loss: 0.6838, LR: 0.010000\n",
      "Epoch [46], Batch [350/391], Loss: 0.9447, LR: 0.010000\n",
      "Train set: Epoch: 46, Average loss:1.4997, LR: 0.010000 Top-1 Accuracy: 67.9920%, Top-5 Accuracy: 89.7600%, Time consumed:352.41s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████████████▍                                                                          | 46/300 [4:43:12<26:02:34, 369.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 46, Average loss:1.4990, Top-1 Accuracy: 65.4400%, Top-5 Accuracy: 89.2200%, Time consumed:14.57s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [47], Batch [50/391], Loss: 2.3147, LR: 0.010000\n",
      "Epoch [47], Batch [100/391], Loss: 0.5917, LR: 0.010000\n",
      "Epoch [47], Batch [150/391], Loss: 2.1514, LR: 0.010000\n",
      "Epoch [47], Batch [200/391], Loss: 0.6543, LR: 0.010000\n",
      "Epoch [47], Batch [250/391], Loss: 0.6421, LR: 0.010000\n",
      "Epoch [47], Batch [300/391], Loss: 2.7536, LR: 0.010000\n",
      "Epoch [47], Batch [350/391], Loss: 2.7385, LR: 0.010000\n",
      "Train set: Epoch: 47, Average loss:1.4979, LR: 0.010000 Top-1 Accuracy: 68.2960%, Top-5 Accuracy: 89.8540%, Time consumed:352.88s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█████████████▊                                                                          | 47/300 [4:49:19<25:53:54, 368.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 47, Average loss:1.6927, Top-1 Accuracy: 61.8600%, Top-5 Accuracy: 86.8600%, Time consumed:14.23s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [48], Batch [50/391], Loss: 0.6706, LR: 0.010000\n",
      "Epoch [48], Batch [100/391], Loss: 0.6184, LR: 0.010000\n",
      "Epoch [48], Batch [150/391], Loss: 2.5785, LR: 0.010000\n",
      "Epoch [48], Batch [200/391], Loss: 0.8376, LR: 0.010000\n",
      "Epoch [48], Batch [250/391], Loss: 0.8605, LR: 0.010000\n",
      "Epoch [48], Batch [300/391], Loss: 2.5632, LR: 0.010000\n",
      "Epoch [48], Batch [350/391], Loss: 0.8371, LR: 0.010000\n",
      "Train set: Epoch: 48, Average loss:1.5056, LR: 0.010000 Top-1 Accuracy: 68.3840%, Top-5 Accuracy: 89.9320%, Time consumed:352.20s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████████████                                                                          | 48/300 [4:55:26<25:45:05, 367.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 48, Average loss:1.5870, Top-1 Accuracy: 65.1500%, Top-5 Accuracy: 88.7200%, Time consumed:14.19s\n",
      "\n",
      "EarlyStopping 카운터: 3 / 30\n",
      "Epoch [49], Batch [50/391], Loss: 2.9867, LR: 0.010000\n",
      "Epoch [49], Batch [100/391], Loss: 2.8252, LR: 0.010000\n",
      "Epoch [49], Batch [150/391], Loss: 2.3586, LR: 0.010000\n",
      "Epoch [49], Batch [200/391], Loss: 0.6481, LR: 0.010000\n",
      "Epoch [49], Batch [250/391], Loss: 0.5485, LR: 0.010000\n",
      "Epoch [49], Batch [300/391], Loss: 2.8473, LR: 0.010000\n",
      "Epoch [49], Batch [350/391], Loss: 0.6753, LR: 0.010000\n",
      "Train set: Epoch: 49, Average loss:1.4198, LR: 0.010000 Top-1 Accuracy: 70.3520%, Top-5 Accuracy: 90.9240%, Time consumed:352.26s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████████████▎                                                                         | 49/300 [5:01:32<25:37:05, 367.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 49, Average loss:1.7376, Top-1 Accuracy: 63.7300%, Top-5 Accuracy: 88.1900%, Time consumed:14.12s\n",
      "\n",
      "EarlyStopping 카운터: 4 / 30\n",
      "Epoch [50], Batch [50/391], Loss: 2.3683, LR: 0.010000\n",
      "Epoch [50], Batch [100/391], Loss: 2.8625, LR: 0.010000\n",
      "Epoch [50], Batch [150/391], Loss: 1.1074, LR: 0.010000\n",
      "Epoch [50], Batch [200/391], Loss: 0.6971, LR: 0.010000\n",
      "Epoch [50], Batch [250/391], Loss: 0.5708, LR: 0.010000\n",
      "Epoch [50], Batch [300/391], Loss: 2.2141, LR: 0.010000\n",
      "Epoch [50], Batch [350/391], Loss: 1.6032, LR: 0.010000\n",
      "Train set: Epoch: 50, Average loss:1.4728, LR: 0.010000 Top-1 Accuracy: 69.6580%, Top-5 Accuracy: 90.7260%, Time consumed:352.70s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████████████▋                                                                         | 50/300 [5:07:47<25:40:21, 369.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 50, Average loss:1.7335, Top-1 Accuracy: 62.7700%, Top-5 Accuracy: 87.6900%, Time consumed:22.23s\n",
      "\n",
      "EarlyStopping 카운터: 5 / 30\n",
      "Epoch [51], Batch [50/391], Loss: 0.8411, LR: 0.010000\n",
      "Epoch [51], Batch [100/391], Loss: 0.5749, LR: 0.010000\n",
      "Epoch [51], Batch [150/391], Loss: 1.5451, LR: 0.010000\n",
      "Epoch [51], Batch [200/391], Loss: 2.8328, LR: 0.010000\n",
      "Epoch [51], Batch [250/391], Loss: 0.6468, LR: 0.010000\n",
      "Epoch [51], Batch [300/391], Loss: 0.6402, LR: 0.010000\n",
      "Epoch [51], Batch [350/391], Loss: 0.5873, LR: 0.010000\n",
      "Train set: Epoch: 51, Average loss:1.5606, LR: 0.010000 Top-1 Accuracy: 68.4720%, Top-5 Accuracy: 89.9000%, Time consumed:352.40s\n",
      "Test set: Epoch: 51, Average loss:1.4831, Top-1 Accuracy: 66.4300%, Top-5 Accuracy: 89.9100%, Time consumed:14.20s\n",
      "\n",
      "새로운 최고 top-1 정확도: 66.43%, top-5 정확도: 89.91%\n",
      "Accuracy improved (66.17% --> 66.43%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████████████▉                                                                         | 51/300 [5:13:57<25:34:05, 369.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52], Batch [50/391], Loss: 2.8859, LR: 0.005000\n",
      "Epoch [52], Batch [100/391], Loss: 0.5399, LR: 0.005000\n",
      "Epoch [52], Batch [150/391], Loss: 0.4349, LR: 0.005000\n",
      "Epoch [52], Batch [200/391], Loss: 1.6332, LR: 0.005000\n",
      "Epoch [52], Batch [250/391], Loss: 0.5352, LR: 0.005000\n",
      "Epoch [52], Batch [300/391], Loss: 0.5260, LR: 0.005000\n",
      "Epoch [52], Batch [350/391], Loss: 0.7038, LR: 0.005000\n",
      "Train set: Epoch: 52, Average loss:1.3214, LR: 0.005000 Top-1 Accuracy: 74.7020%, Top-5 Accuracy: 92.6580%, Time consumed:352.23s\n",
      "Test set: Epoch: 52, Average loss:1.3548, Top-1 Accuracy: 68.8900%, Top-5 Accuracy: 91.0300%, Time consumed:14.73s\n",
      "\n",
      "새로운 최고 top-1 정확도: 68.89%, top-5 정확도: 91.03%\n",
      "새로운 최고 top-5 정확도: 91.03%\n",
      "Accuracy improved (66.43% --> 68.89%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████████████▎                                                                        | 52/300 [5:20:07<25:28:32, 369.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53], Batch [50/391], Loss: 0.5056, LR: 0.005000\n",
      "Epoch [53], Batch [100/391], Loss: 2.6882, LR: 0.005000\n",
      "Epoch [53], Batch [150/391], Loss: 0.5317, LR: 0.005000\n",
      "Epoch [53], Batch [200/391], Loss: 0.4567, LR: 0.005000\n",
      "Epoch [53], Batch [250/391], Loss: 2.6748, LR: 0.005000\n",
      "Epoch [53], Batch [300/391], Loss: 2.5309, LR: 0.005000\n",
      "Epoch [53], Batch [350/391], Loss: 0.4746, LR: 0.005000\n",
      "Train set: Epoch: 53, Average loss:1.2750, LR: 0.005000 Top-1 Accuracy: 75.5500%, Top-5 Accuracy: 93.0780%, Time consumed:353.06s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████████████▌                                                                        | 53/300 [5:26:14<25:19:14, 369.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 53, Average loss:1.4820, Top-1 Accuracy: 68.3600%, Top-5 Accuracy: 90.3200%, Time consumed:14.21s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [54], Batch [50/391], Loss: 1.3966, LR: 0.005000\n",
      "Epoch [54], Batch [100/391], Loss: 1.6492, LR: 0.005000\n",
      "Epoch [54], Batch [150/391], Loss: 2.5689, LR: 0.005000\n",
      "Epoch [54], Batch [200/391], Loss: 0.5206, LR: 0.005000\n",
      "Epoch [54], Batch [250/391], Loss: 0.3676, LR: 0.005000\n",
      "Epoch [54], Batch [300/391], Loss: 0.6649, LR: 0.005000\n",
      "Epoch [54], Batch [350/391], Loss: 2.3738, LR: 0.005000\n",
      "Train set: Epoch: 54, Average loss:1.2910, LR: 0.005000 Top-1 Accuracy: 75.6740%, Top-5 Accuracy: 93.0160%, Time consumed:352.38s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████████████▊                                                                        | 54/300 [5:32:21<25:09:59, 368.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 54, Average loss:1.4545, Top-1 Accuracy: 67.5100%, Top-5 Accuracy: 90.1200%, Time consumed:14.14s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [55], Batch [50/391], Loss: 2.4210, LR: 0.005000\n",
      "Epoch [55], Batch [100/391], Loss: 1.9792, LR: 0.005000\n",
      "Epoch [55], Batch [150/391], Loss: 2.4681, LR: 0.005000\n",
      "Epoch [55], Batch [200/391], Loss: 0.4017, LR: 0.005000\n",
      "Epoch [55], Batch [250/391], Loss: 0.3558, LR: 0.005000\n",
      "Epoch [55], Batch [300/391], Loss: 0.3752, LR: 0.005000\n",
      "Epoch [55], Batch [350/391], Loss: 0.4997, LR: 0.005000\n",
      "Train set: Epoch: 55, Average loss:1.2084, LR: 0.005000 Top-1 Accuracy: 77.0320%, Top-5 Accuracy: 93.4800%, Time consumed:351.96s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|████████████████▏                                                                       | 55/300 [5:38:27<25:01:42, 367.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 55, Average loss:1.3949, Top-1 Accuracy: 68.7200%, Top-5 Accuracy: 91.1800%, Time consumed:14.57s\n",
      "\n",
      "새로운 최고 top-5 정확도: 91.18%\n",
      "EarlyStopping 카운터: 3 / 30\n",
      "Epoch [56], Batch [50/391], Loss: 2.0708, LR: 0.005000\n",
      "Epoch [56], Batch [100/391], Loss: 0.4636, LR: 0.005000\n",
      "Epoch [56], Batch [150/391], Loss: 0.4043, LR: 0.005000\n",
      "Epoch [56], Batch [200/391], Loss: 0.6698, LR: 0.005000\n",
      "Epoch [56], Batch [250/391], Loss: 2.4596, LR: 0.005000\n",
      "Epoch [56], Batch [300/391], Loss: 0.5802, LR: 0.005000\n",
      "Epoch [56], Batch [350/391], Loss: 2.2022, LR: 0.005000\n",
      "Train set: Epoch: 56, Average loss:1.2168, LR: 0.005000 Top-1 Accuracy: 76.9500%, Top-5 Accuracy: 93.5440%, Time consumed:352.39s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|████████████████▍                                                                       | 56/300 [5:44:34<24:54:12, 367.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 56, Average loss:1.3818, Top-1 Accuracy: 68.7200%, Top-5 Accuracy: 90.6300%, Time consumed:14.25s\n",
      "\n",
      "EarlyStopping 카운터: 4 / 30\n",
      "Epoch [57], Batch [50/391], Loss: 2.0800, LR: 0.005000\n",
      "Epoch [57], Batch [100/391], Loss: 0.4215, LR: 0.005000\n",
      "Epoch [57], Batch [150/391], Loss: 2.3183, LR: 0.005000\n",
      "Epoch [57], Batch [200/391], Loss: 0.3663, LR: 0.005000\n",
      "Epoch [57], Batch [250/391], Loss: 0.4764, LR: 0.005000\n",
      "Epoch [57], Batch [300/391], Loss: 2.5694, LR: 0.005000\n",
      "Epoch [57], Batch [350/391], Loss: 0.3088, LR: 0.005000\n",
      "Train set: Epoch: 57, Average loss:1.2247, LR: 0.005000 Top-1 Accuracy: 76.4980%, Top-5 Accuracy: 93.1900%, Time consumed:352.55s\n",
      "Test set: Epoch: 57, Average loss:1.3726, Top-1 Accuracy: 69.2400%, Top-5 Accuracy: 91.3000%, Time consumed:22.66s\n",
      "\n",
      "새로운 최고 top-1 정확도: 69.24%, top-5 정확도: 91.30%\n",
      "새로운 최고 top-5 정확도: 91.30%\n",
      "Accuracy improved (68.89% --> 69.24%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|████████████████▋                                                                       | 57/300 [5:50:52<25:01:23, 370.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58], Batch [50/391], Loss: 2.8450, LR: 0.005000\n",
      "Epoch [58], Batch [100/391], Loss: 2.7288, LR: 0.005000\n",
      "Epoch [58], Batch [150/391], Loss: 2.4503, LR: 0.005000\n",
      "Epoch [58], Batch [200/391], Loss: 2.6333, LR: 0.005000\n",
      "Epoch [58], Batch [250/391], Loss: 2.4782, LR: 0.005000\n",
      "Epoch [58], Batch [300/391], Loss: 2.7943, LR: 0.005000\n",
      "Epoch [58], Batch [350/391], Loss: 2.1190, LR: 0.005000\n",
      "Train set: Epoch: 58, Average loss:1.2519, LR: 0.005000 Top-1 Accuracy: 75.6900%, Top-5 Accuracy: 92.8260%, Time consumed:352.16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█████████████████                                                                       | 58/300 [5:56:59<24:50:01, 369.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 58, Average loss:1.4695, Top-1 Accuracy: 67.6200%, Top-5 Accuracy: 90.3300%, Time consumed:14.25s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [59], Batch [50/391], Loss: 2.3634, LR: 0.002500\n",
      "Epoch [59], Batch [100/391], Loss: 2.3630, LR: 0.002500\n",
      "Epoch [59], Batch [150/391], Loss: 0.6703, LR: 0.002500\n",
      "Epoch [59], Batch [200/391], Loss: 0.3392, LR: 0.002500\n",
      "Epoch [59], Batch [250/391], Loss: 0.3289, LR: 0.002500\n",
      "Epoch [59], Batch [300/391], Loss: 2.4741, LR: 0.002500\n",
      "Epoch [59], Batch [350/391], Loss: 2.4265, LR: 0.002500\n",
      "Train set: Epoch: 59, Average loss:1.1163, LR: 0.002500 Top-1 Accuracy: 79.7760%, Top-5 Accuracy: 94.5100%, Time consumed:352.33s\n",
      "Test set: Epoch: 59, Average loss:1.3901, Top-1 Accuracy: 69.5400%, Top-5 Accuracy: 90.8900%, Time consumed:14.37s\n",
      "\n",
      "새로운 최고 top-1 정확도: 69.54%, top-5 정확도: 90.89%\n",
      "Accuracy improved (69.24% --> 69.54%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█████████████████▎                                                                      | 59/300 [6:03:09<24:44:28, 369.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60], Batch [50/391], Loss: 2.3979, LR: 0.002500\n",
      "Epoch [60], Batch [100/391], Loss: 2.1995, LR: 0.002500\n",
      "Epoch [60], Batch [150/391], Loss: 2.6270, LR: 0.002500\n",
      "Epoch [60], Batch [200/391], Loss: 2.3463, LR: 0.002500\n",
      "Epoch [60], Batch [250/391], Loss: 2.1183, LR: 0.002500\n",
      "Epoch [60], Batch [300/391], Loss: 0.2676, LR: 0.002500\n",
      "Epoch [60], Batch [350/391], Loss: 2.3013, LR: 0.002500\n",
      "Train set: Epoch: 60, Average loss:1.1906, LR: 0.002500 Top-1 Accuracy: 78.8940%, Top-5 Accuracy: 93.9620%, Time consumed:352.19s\n",
      "Test set: Epoch: 60, Average loss:1.3550, Top-1 Accuracy: 69.6000%, Top-5 Accuracy: 90.9500%, Time consumed:14.31s\n",
      "\n",
      "새로운 최고 top-1 정확도: 69.60%, top-5 정확도: 90.95%\n",
      "Accuracy improved (69.54% --> 69.60%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█████████████████▌                                                                      | 60/300 [6:09:18<24:38:26, 369.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61], Batch [50/391], Loss: 2.4306, LR: 0.002500\n",
      "Epoch [61], Batch [100/391], Loss: 2.3644, LR: 0.002500\n",
      "Epoch [61], Batch [150/391], Loss: 0.2414, LR: 0.002500\n",
      "Epoch [61], Batch [200/391], Loss: 0.3700, LR: 0.002500\n",
      "Epoch [61], Batch [250/391], Loss: 0.3255, LR: 0.002500\n",
      "Epoch [61], Batch [300/391], Loss: 0.2874, LR: 0.002500\n",
      "Epoch [61], Batch [350/391], Loss: 1.5517, LR: 0.002500\n",
      "Train set: Epoch: 61, Average loss:1.0937, LR: 0.002500 Top-1 Accuracy: 81.2240%, Top-5 Accuracy: 94.9380%, Time consumed:351.77s\n",
      "Test set: Epoch: 61, Average loss:1.3561, Top-1 Accuracy: 70.4000%, Top-5 Accuracy: 91.5900%, Time consumed:22.50s\n",
      "\n",
      "새로운 최고 top-1 정확도: 70.40%, top-5 정확도: 91.59%\n",
      "새로운 최고 top-5 정확도: 91.59%\n",
      "Accuracy improved (69.60% --> 70.40%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█████████████████▉                                                                      | 61/300 [6:15:36<24:41:38, 371.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [62], Batch [50/391], Loss: 0.2746, LR: 0.002500\n",
      "Epoch [62], Batch [100/391], Loss: 0.1955, LR: 0.002500\n",
      "Epoch [62], Batch [150/391], Loss: 0.2787, LR: 0.002500\n",
      "Epoch [62], Batch [200/391], Loss: 2.5323, LR: 0.002500\n",
      "Epoch [62], Batch [250/391], Loss: 0.8968, LR: 0.002500\n",
      "Epoch [62], Batch [300/391], Loss: 0.2327, LR: 0.002500\n",
      "Epoch [62], Batch [350/391], Loss: 2.2056, LR: 0.002500\n",
      "Train set: Epoch: 62, Average loss:1.1784, LR: 0.002500 Top-1 Accuracy: 78.7880%, Top-5 Accuracy: 93.6880%, Time consumed:352.01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██████████████████▏                                                                     | 62/300 [6:21:42<24:28:41, 370.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 62, Average loss:1.3889, Top-1 Accuracy: 69.6000%, Top-5 Accuracy: 90.3300%, Time consumed:14.28s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [63], Batch [50/391], Loss: 0.2738, LR: 0.002500\n",
      "Epoch [63], Batch [100/391], Loss: 0.2320, LR: 0.002500\n",
      "Epoch [63], Batch [150/391], Loss: 0.2009, LR: 0.002500\n",
      "Epoch [63], Batch [200/391], Loss: 0.3187, LR: 0.002500\n",
      "Epoch [63], Batch [250/391], Loss: 0.3276, LR: 0.002500\n",
      "Epoch [63], Batch [300/391], Loss: 0.4619, LR: 0.002500\n",
      "Epoch [63], Batch [350/391], Loss: 0.2411, LR: 0.002500\n",
      "Train set: Epoch: 63, Average loss:1.0573, LR: 0.002500 Top-1 Accuracy: 81.6320%, Top-5 Accuracy: 95.1940%, Time consumed:352.77s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██████████████████▍                                                                     | 63/300 [6:27:49<24:18:41, 369.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 63, Average loss:1.3565, Top-1 Accuracy: 68.9900%, Top-5 Accuracy: 90.9100%, Time consumed:14.25s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [64], Batch [50/391], Loss: 2.5195, LR: 0.002500\n",
      "Epoch [64], Batch [100/391], Loss: 0.2443, LR: 0.002500\n",
      "Epoch [64], Batch [150/391], Loss: 2.2154, LR: 0.002500\n",
      "Epoch [64], Batch [200/391], Loss: 0.2428, LR: 0.002500\n",
      "Epoch [64], Batch [250/391], Loss: 0.6665, LR: 0.002500\n",
      "Epoch [64], Batch [300/391], Loss: 2.4448, LR: 0.002500\n",
      "Epoch [64], Batch [350/391], Loss: 0.3003, LR: 0.002500\n",
      "Train set: Epoch: 64, Average loss:1.0489, LR: 0.002500 Top-1 Accuracy: 81.0940%, Top-5 Accuracy: 94.7540%, Time consumed:352.13s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██████████████████▊                                                                     | 64/300 [6:33:55<24:09:10, 368.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 64, Average loss:1.4862, Top-1 Accuracy: 69.0400%, Top-5 Accuracy: 90.4800%, Time consumed:14.31s\n",
      "\n",
      "EarlyStopping 카운터: 3 / 30\n",
      "Epoch [65], Batch [50/391], Loss: 0.2305, LR: 0.002500\n",
      "Epoch [65], Batch [100/391], Loss: 0.5457, LR: 0.002500\n",
      "Epoch [65], Batch [150/391], Loss: 0.2957, LR: 0.002500\n",
      "Epoch [65], Batch [200/391], Loss: 2.1614, LR: 0.002500\n",
      "Epoch [65], Batch [250/391], Loss: 2.5178, LR: 0.002500\n",
      "Epoch [65], Batch [300/391], Loss: 0.2618, LR: 0.002500\n",
      "Epoch [65], Batch [350/391], Loss: 0.2827, LR: 0.002500\n",
      "Train set: Epoch: 65, Average loss:1.0444, LR: 0.002500 Top-1 Accuracy: 81.3800%, Top-5 Accuracy: 94.9860%, Time consumed:352.01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|███████████████████                                                                     | 65/300 [6:40:02<24:00:29, 367.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 65, Average loss:1.3652, Top-1 Accuracy: 70.0700%, Top-5 Accuracy: 91.0300%, Time consumed:14.25s\n",
      "\n",
      "EarlyStopping 카운터: 4 / 30\n",
      "Epoch [66], Batch [50/391], Loss: 2.2090, LR: 0.002500\n",
      "Epoch [66], Batch [100/391], Loss: 0.2965, LR: 0.002500\n",
      "Epoch [66], Batch [150/391], Loss: 1.2676, LR: 0.002500\n",
      "Epoch [66], Batch [200/391], Loss: 2.6350, LR: 0.002500\n",
      "Epoch [66], Batch [250/391], Loss: 2.4761, LR: 0.002500\n",
      "Epoch [66], Batch [300/391], Loss: 0.4069, LR: 0.002500\n",
      "Epoch [66], Batch [350/391], Loss: 0.5415, LR: 0.002500\n",
      "Train set: Epoch: 66, Average loss:1.0592, LR: 0.002500 Top-1 Accuracy: 81.1340%, Top-5 Accuracy: 94.7680%, Time consumed:352.50s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|███████████████████▎                                                                    | 66/300 [6:46:09<23:53:35, 367.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 66, Average loss:1.5435, Top-1 Accuracy: 68.2600%, Top-5 Accuracy: 90.5100%, Time consumed:14.62s\n",
      "\n",
      "EarlyStopping 카운터: 5 / 30\n",
      "Epoch [67], Batch [50/391], Loss: 2.3338, LR: 0.002500\n",
      "Epoch [67], Batch [100/391], Loss: 0.2065, LR: 0.002500\n",
      "Epoch [67], Batch [150/391], Loss: 2.6171, LR: 0.002500\n",
      "Epoch [67], Batch [200/391], Loss: 0.2845, LR: 0.002500\n",
      "Epoch [67], Batch [250/391], Loss: 2.5647, LR: 0.002500\n",
      "Epoch [67], Batch [300/391], Loss: 1.8952, LR: 0.002500\n",
      "Epoch [67], Batch [350/391], Loss: 0.2739, LR: 0.002500\n",
      "Train set: Epoch: 67, Average loss:0.9922, LR: 0.002500 Top-1 Accuracy: 83.3620%, Top-5 Accuracy: 95.8760%, Time consumed:352.59s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|███████████████████▋                                                                    | 67/300 [6:52:15<23:46:20, 367.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 67, Average loss:1.4214, Top-1 Accuracy: 70.0400%, Top-5 Accuracy: 90.9000%, Time consumed:14.03s\n",
      "\n",
      "EarlyStopping 카운터: 6 / 30\n",
      "Epoch [68], Batch [50/391], Loss: 0.2817, LR: 0.001250\n",
      "Epoch [68], Batch [100/391], Loss: 0.2194, LR: 0.001250\n",
      "Epoch [68], Batch [150/391], Loss: 0.2083, LR: 0.001250\n",
      "Epoch [68], Batch [200/391], Loss: 0.2747, LR: 0.001250\n",
      "Epoch [68], Batch [250/391], Loss: 1.9083, LR: 0.001250\n",
      "Epoch [68], Batch [300/391], Loss: 2.8696, LR: 0.001250\n",
      "Epoch [68], Batch [350/391], Loss: 0.1752, LR: 0.001250\n",
      "Train set: Epoch: 68, Average loss:1.0504, LR: 0.001250 Top-1 Accuracy: 82.5480%, Top-5 Accuracy: 95.0380%, Time consumed:352.27s\n",
      "Test set: Epoch: 68, Average loss:1.3906, Top-1 Accuracy: 72.4300%, Top-5 Accuracy: 92.2800%, Time consumed:22.50s\n",
      "\n",
      "새로운 최고 top-1 정확도: 72.43%, top-5 정확도: 92.28%\n",
      "새로운 최고 top-5 정확도: 92.28%\n",
      "Accuracy improved (70.40% --> 72.43%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|███████████████████▉                                                                    | 68/300 [6:58:33<23:52:25, 370.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [69], Batch [50/391], Loss: 0.3517, LR: 0.001250\n",
      "Epoch [69], Batch [100/391], Loss: 2.2566, LR: 0.001250\n",
      "Epoch [69], Batch [150/391], Loss: 0.2284, LR: 0.001250\n",
      "Epoch [69], Batch [200/391], Loss: 2.6769, LR: 0.001250\n",
      "Epoch [69], Batch [250/391], Loss: 0.2263, LR: 0.001250\n",
      "Epoch [69], Batch [300/391], Loss: 0.1880, LR: 0.001250\n",
      "Epoch [69], Batch [350/391], Loss: 0.1905, LR: 0.001250\n",
      "Train set: Epoch: 69, Average loss:0.9576, LR: 0.001250 Top-1 Accuracy: 84.0000%, Top-5 Accuracy: 95.7020%, Time consumed:352.10s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|████████████████████▏                                                                   | 69/300 [7:04:40<23:41:37, 369.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 69, Average loss:1.3611, Top-1 Accuracy: 71.4500%, Top-5 Accuracy: 91.0500%, Time consumed:14.35s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [70], Batch [50/391], Loss: 0.1900, LR: 0.001250\n",
      "Epoch [70], Batch [100/391], Loss: 2.3901, LR: 0.001250\n",
      "Epoch [70], Batch [150/391], Loss: 0.1404, LR: 0.001250\n",
      "Epoch [70], Batch [200/391], Loss: 2.3760, LR: 0.001250\n",
      "Epoch [70], Batch [250/391], Loss: 0.2145, LR: 0.001250\n",
      "Epoch [70], Batch [300/391], Loss: 2.4144, LR: 0.001250\n",
      "Epoch [70], Batch [350/391], Loss: 1.3743, LR: 0.001250\n",
      "Train set: Epoch: 70, Average loss:0.9564, LR: 0.001250 Top-1 Accuracy: 84.5500%, Top-5 Accuracy: 95.9860%, Time consumed:352.78s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|████████████████████▌                                                                   | 70/300 [7:10:47<23:33:02, 368.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 70, Average loss:1.3170, Top-1 Accuracy: 71.4900%, Top-5 Accuracy: 91.5800%, Time consumed:14.35s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [71], Batch [50/391], Loss: 0.1693, LR: 0.001250\n",
      "Epoch [71], Batch [100/391], Loss: 0.2246, LR: 0.001250\n",
      "Epoch [71], Batch [150/391], Loss: 0.1938, LR: 0.001250\n",
      "Epoch [71], Batch [200/391], Loss: 0.2165, LR: 0.001250\n",
      "Epoch [71], Batch [250/391], Loss: 0.1836, LR: 0.001250\n",
      "Epoch [71], Batch [300/391], Loss: 0.1868, LR: 0.001250\n",
      "Epoch [71], Batch [350/391], Loss: 0.1353, LR: 0.001250\n",
      "Train set: Epoch: 71, Average loss:1.0790, LR: 0.001250 Top-1 Accuracy: 83.1540%, Top-5 Accuracy: 95.7580%, Time consumed:352.50s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|████████████████████▊                                                                   | 71/300 [7:16:54<23:24:57, 368.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 71, Average loss:1.2922, Top-1 Accuracy: 72.1400%, Top-5 Accuracy: 91.6600%, Time consumed:14.42s\n",
      "\n",
      "EarlyStopping 카운터: 3 / 30\n",
      "Epoch [72], Batch [50/391], Loss: 0.1566, LR: 0.001250\n",
      "Epoch [72], Batch [100/391], Loss: 1.0045, LR: 0.001250\n",
      "Epoch [72], Batch [150/391], Loss: 2.4001, LR: 0.001250\n",
      "Epoch [72], Batch [200/391], Loss: 2.4107, LR: 0.001250\n",
      "Epoch [72], Batch [250/391], Loss: 1.3984, LR: 0.001250\n",
      "Epoch [72], Batch [300/391], Loss: 0.4902, LR: 0.001250\n",
      "Epoch [72], Batch [350/391], Loss: 0.2361, LR: 0.001250\n",
      "Train set: Epoch: 72, Average loss:0.9977, LR: 0.001250 Top-1 Accuracy: 83.6620%, Top-5 Accuracy: 95.5680%, Time consumed:352.58s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|█████████████████████                                                                   | 72/300 [7:23:01<23:17:27, 367.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 72, Average loss:1.2746, Top-1 Accuracy: 71.8600%, Top-5 Accuracy: 91.7500%, Time consumed:14.34s\n",
      "\n",
      "EarlyStopping 카운터: 4 / 30\n",
      "Epoch [73], Batch [50/391], Loss: 0.2646, LR: 0.001250\n",
      "Epoch [73], Batch [100/391], Loss: 2.0018, LR: 0.001250\n",
      "Epoch [73], Batch [150/391], Loss: 1.9863, LR: 0.001250\n",
      "Epoch [73], Batch [200/391], Loss: 1.9303, LR: 0.001250\n",
      "Epoch [73], Batch [250/391], Loss: 0.1979, LR: 0.001250\n",
      "Epoch [73], Batch [300/391], Loss: 2.3810, LR: 0.001250\n",
      "Epoch [73], Batch [350/391], Loss: 0.2055, LR: 0.001250\n",
      "Train set: Epoch: 73, Average loss:1.0237, LR: 0.001250 Top-1 Accuracy: 83.3300%, Top-5 Accuracy: 95.5920%, Time consumed:352.46s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|█████████████████████▍                                                                  | 73/300 [7:29:08<23:10:38, 367.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 73, Average loss:1.2703, Top-1 Accuracy: 71.5700%, Top-5 Accuracy: 91.4900%, Time consumed:14.67s\n",
      "\n",
      "EarlyStopping 카운터: 5 / 30\n",
      "Epoch [74], Batch [50/391], Loss: 2.3506, LR: 0.001250\n",
      "Epoch [74], Batch [100/391], Loss: 0.1692, LR: 0.001250\n",
      "Epoch [74], Batch [150/391], Loss: 0.1674, LR: 0.001250\n",
      "Epoch [74], Batch [200/391], Loss: 2.4036, LR: 0.001250\n",
      "Epoch [74], Batch [250/391], Loss: 2.1299, LR: 0.001250\n",
      "Epoch [74], Batch [300/391], Loss: 0.1709, LR: 0.001250\n",
      "Epoch [74], Batch [350/391], Loss: 0.1652, LR: 0.001250\n",
      "Train set: Epoch: 74, Average loss:1.0009, LR: 0.001250 Top-1 Accuracy: 83.4180%, Top-5 Accuracy: 95.5480%, Time consumed:352.65s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|█████████████████████▋                                                                  | 74/300 [7:35:15<23:03:46, 367.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 74, Average loss:1.2868, Top-1 Accuracy: 71.3300%, Top-5 Accuracy: 91.4600%, Time consumed:14.25s\n",
      "\n",
      "EarlyStopping 카운터: 6 / 30\n",
      "Epoch [75], Batch [50/391], Loss: 0.1775, LR: 0.000625\n",
      "Epoch [75], Batch [100/391], Loss: 2.4598, LR: 0.000625\n",
      "Epoch [75], Batch [150/391], Loss: 2.2838, LR: 0.000625\n",
      "Epoch [75], Batch [200/391], Loss: 0.5977, LR: 0.000625\n",
      "Epoch [75], Batch [250/391], Loss: 0.1980, LR: 0.000625\n",
      "Epoch [75], Batch [300/391], Loss: 1.3987, LR: 0.000625\n",
      "Epoch [75], Batch [350/391], Loss: 2.3182, LR: 0.000625\n",
      "Train set: Epoch: 75, Average loss:0.9864, LR: 0.000625 Top-1 Accuracy: 83.5260%, Top-5 Accuracy: 95.4060%, Time consumed:352.50s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██████████████████████                                                                  | 75/300 [7:41:22<22:57:27, 367.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 75, Average loss:1.2553, Top-1 Accuracy: 71.5500%, Top-5 Accuracy: 91.5000%, Time consumed:14.70s\n",
      "\n",
      "EarlyStopping 카운터: 7 / 30\n",
      "Epoch [76], Batch [50/391], Loss: 1.0227, LR: 0.000625\n",
      "Epoch [76], Batch [100/391], Loss: 2.0713, LR: 0.000625\n",
      "Epoch [76], Batch [150/391], Loss: 2.2337, LR: 0.000625\n",
      "Epoch [76], Batch [200/391], Loss: 0.1558, LR: 0.000625\n",
      "Epoch [76], Batch [250/391], Loss: 0.5038, LR: 0.000625\n",
      "Epoch [76], Batch [300/391], Loss: 0.2043, LR: 0.000625\n",
      "Epoch [76], Batch [350/391], Loss: 0.1615, LR: 0.000625\n",
      "Train set: Epoch: 76, Average loss:0.9398, LR: 0.000625 Top-1 Accuracy: 84.5520%, Top-5 Accuracy: 96.1820%, Time consumed:352.03s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██████████████████████▎                                                                 | 76/300 [7:47:28<22:50:14, 367.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 76, Average loss:1.2749, Top-1 Accuracy: 72.4300%, Top-5 Accuracy: 92.1600%, Time consumed:14.31s\n",
      "\n",
      "EarlyStopping 카운터: 8 / 30\n",
      "Epoch [77], Batch [50/391], Loss: 1.6737, LR: 0.000625\n",
      "Epoch [77], Batch [100/391], Loss: 1.1826, LR: 0.000625\n",
      "Epoch [77], Batch [150/391], Loss: 2.3134, LR: 0.000625\n",
      "Epoch [77], Batch [200/391], Loss: 0.9422, LR: 0.000625\n",
      "Epoch [77], Batch [250/391], Loss: 0.1406, LR: 0.000625\n",
      "Epoch [77], Batch [300/391], Loss: 0.2443, LR: 0.000625\n",
      "Epoch [77], Batch [350/391], Loss: 2.3780, LR: 0.000625\n",
      "Train set: Epoch: 77, Average loss:0.9446, LR: 0.000625 Top-1 Accuracy: 84.8500%, Top-5 Accuracy: 96.0000%, Time consumed:352.64s\n",
      "Test set: Epoch: 77, Average loss:1.2638, Top-1 Accuracy: 72.9500%, Top-5 Accuracy: 92.2500%, Time consumed:14.31s\n",
      "\n",
      "새로운 최고 top-1 정확도: 72.95%, top-5 정확도: 92.25%\n",
      "Accuracy improved (72.43% --> 72.95%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██████████████████████▌                                                                 | 77/300 [7:53:38<22:47:21, 367.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [78], Batch [50/391], Loss: 0.1738, LR: 0.000625\n",
      "Epoch [78], Batch [100/391], Loss: 0.1596, LR: 0.000625\n",
      "Epoch [78], Batch [150/391], Loss: 2.0060, LR: 0.000625\n",
      "Epoch [78], Batch [200/391], Loss: 0.1336, LR: 0.000625\n",
      "Epoch [78], Batch [250/391], Loss: 0.1972, LR: 0.000625\n",
      "Epoch [78], Batch [300/391], Loss: 0.2143, LR: 0.000625\n",
      "Epoch [78], Batch [350/391], Loss: 1.6497, LR: 0.000625\n",
      "Train set: Epoch: 78, Average loss:1.0225, LR: 0.000625 Top-1 Accuracy: 83.2760%, Top-5 Accuracy: 95.3040%, Time consumed:352.84s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██████████████████████▉                                                                 | 78/300 [7:59:46<22:40:56, 367.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 78, Average loss:1.2452, Top-1 Accuracy: 72.2700%, Top-5 Accuracy: 91.7800%, Time consumed:14.79s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [79], Batch [50/391], Loss: 2.3977, LR: 0.000625\n",
      "Epoch [79], Batch [100/391], Loss: 0.1234, LR: 0.000625\n",
      "Epoch [79], Batch [150/391], Loss: 0.1575, LR: 0.000625\n",
      "Epoch [79], Batch [200/391], Loss: 0.1901, LR: 0.000625\n",
      "Epoch [79], Batch [250/391], Loss: 2.0667, LR: 0.000625\n",
      "Epoch [79], Batch [300/391], Loss: 0.1256, LR: 0.000625\n",
      "Epoch [79], Batch [350/391], Loss: 0.1478, LR: 0.000625\n",
      "Train set: Epoch: 79, Average loss:0.9307, LR: 0.000625 Top-1 Accuracy: 84.4920%, Top-5 Accuracy: 95.7460%, Time consumed:352.39s\n",
      "Test set: Epoch: 79, Average loss:1.2455, Top-1 Accuracy: 73.0700%, Top-5 Accuracy: 92.1200%, Time consumed:22.40s\n",
      "\n",
      "새로운 최고 top-1 정확도: 73.07%, top-5 정확도: 92.12%\n",
      "Accuracy improved (72.95% --> 73.07%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|███████████████████████▏                                                                | 79/300 [8:06:04<22:46:02, 370.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [80], Batch [50/391], Loss: 0.1102, LR: 0.000625\n",
      "Epoch [80], Batch [100/391], Loss: 2.0025, LR: 0.000625\n",
      "Epoch [80], Batch [150/391], Loss: 1.0172, LR: 0.000625\n",
      "Epoch [80], Batch [200/391], Loss: 0.1243, LR: 0.000625\n",
      "Epoch [80], Batch [250/391], Loss: 0.1285, LR: 0.000625\n",
      "Epoch [80], Batch [300/391], Loss: 1.1723, LR: 0.000625\n",
      "Epoch [80], Batch [350/391], Loss: 2.1394, LR: 0.000625\n",
      "Train set: Epoch: 80, Average loss:0.8991, LR: 0.000625 Top-1 Accuracy: 84.7120%, Top-5 Accuracy: 95.8980%, Time consumed:352.43s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|███████████████████████▍                                                                | 80/300 [8:12:11<22:35:31, 369.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 80, Average loss:1.2673, Top-1 Accuracy: 72.9300%, Top-5 Accuracy: 92.3400%, Time consumed:14.50s\n",
      "\n",
      "새로운 최고 top-5 정확도: 92.34%\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [81], Batch [50/391], Loss: 0.1420, LR: 0.000312\n",
      "Epoch [81], Batch [100/391], Loss: 0.1347, LR: 0.000312\n",
      "Epoch [81], Batch [150/391], Loss: 1.9383, LR: 0.000312\n",
      "Epoch [81], Batch [200/391], Loss: 1.1220, LR: 0.000312\n",
      "Epoch [81], Batch [250/391], Loss: 0.1342, LR: 0.000312\n",
      "Epoch [81], Batch [300/391], Loss: 2.2429, LR: 0.000312\n",
      "Epoch [81], Batch [350/391], Loss: 0.1151, LR: 0.000312\n",
      "Train set: Epoch: 81, Average loss:0.9150, LR: 0.000312 Top-1 Accuracy: 85.6700%, Top-5 Accuracy: 96.2860%, Time consumed:353.04s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|███████████████████████▊                                                                | 81/300 [8:18:18<22:26:46, 368.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 81, Average loss:1.2651, Top-1 Accuracy: 72.9900%, Top-5 Accuracy: 92.2500%, Time consumed:14.27s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [82], Batch [50/391], Loss: 0.1128, LR: 0.000312\n",
      "Epoch [82], Batch [100/391], Loss: 0.1163, LR: 0.000312\n",
      "Epoch [82], Batch [150/391], Loss: 0.1274, LR: 0.000312\n",
      "Epoch [82], Batch [200/391], Loss: 0.8699, LR: 0.000312\n",
      "Epoch [82], Batch [250/391], Loss: 0.8432, LR: 0.000312\n",
      "Epoch [82], Batch [300/391], Loss: 0.1674, LR: 0.000312\n",
      "Epoch [82], Batch [350/391], Loss: 0.1776, LR: 0.000312\n",
      "Train set: Epoch: 82, Average loss:1.0150, LR: 0.000312 Top-1 Accuracy: 82.9480%, Top-5 Accuracy: 95.2860%, Time consumed:352.03s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|████████████████████████                                                                | 82/300 [8:24:24<22:17:47, 368.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 82, Average loss:1.3097, Top-1 Accuracy: 72.8600%, Top-5 Accuracy: 92.0900%, Time consumed:14.35s\n",
      "\n",
      "EarlyStopping 카운터: 3 / 30\n",
      "Epoch [83], Batch [50/391], Loss: 0.1055, LR: 0.000312\n",
      "Epoch [83], Batch [100/391], Loss: 1.3769, LR: 0.000312\n",
      "Epoch [83], Batch [150/391], Loss: 2.1473, LR: 0.000312\n",
      "Epoch [83], Batch [200/391], Loss: 0.1294, LR: 0.000312\n",
      "Epoch [83], Batch [250/391], Loss: 0.1400, LR: 0.000312\n",
      "Epoch [83], Batch [300/391], Loss: 0.1530, LR: 0.000312\n",
      "Epoch [83], Batch [350/391], Loss: 0.1342, LR: 0.000312\n",
      "Train set: Epoch: 83, Average loss:0.9565, LR: 0.000312 Top-1 Accuracy: 84.5080%, Top-5 Accuracy: 95.9280%, Time consumed:352.56s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|████████████████████████▎                                                               | 83/300 [8:30:31<22:10:13, 367.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 83, Average loss:1.2106, Top-1 Accuracy: 73.0000%, Top-5 Accuracy: 92.1000%, Time consumed:14.31s\n",
      "\n",
      "EarlyStopping 카운터: 4 / 30\n",
      "Epoch [84], Batch [50/391], Loss: 0.1359, LR: 0.000312\n",
      "Epoch [84], Batch [100/391], Loss: 0.6888, LR: 0.000312\n",
      "Epoch [84], Batch [150/391], Loss: 0.1606, LR: 0.000312\n",
      "Epoch [84], Batch [200/391], Loss: 0.1115, LR: 0.000312\n",
      "Epoch [84], Batch [250/391], Loss: 2.4256, LR: 0.000312\n",
      "Epoch [84], Batch [300/391], Loss: 0.1289, LR: 0.000312\n",
      "Epoch [84], Batch [350/391], Loss: 2.4130, LR: 0.000312\n",
      "Train set: Epoch: 84, Average loss:0.8597, LR: 0.000312 Top-1 Accuracy: 86.3460%, Top-5 Accuracy: 96.5120%, Time consumed:352.78s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|████████████████████████▋                                                               | 84/300 [8:36:39<22:03:22, 367.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 84, Average loss:1.3318, Top-1 Accuracy: 72.9300%, Top-5 Accuracy: 92.1100%, Time consumed:14.36s\n",
      "\n",
      "EarlyStopping 카운터: 5 / 30\n",
      "Epoch [85], Batch [50/391], Loss: 0.1434, LR: 0.000312\n",
      "Epoch [85], Batch [100/391], Loss: 0.1502, LR: 0.000312\n",
      "Epoch [85], Batch [150/391], Loss: 2.2140, LR: 0.000312\n",
      "Epoch [85], Batch [200/391], Loss: 0.1859, LR: 0.000312\n",
      "Epoch [85], Batch [250/391], Loss: 2.2140, LR: 0.000312\n",
      "Epoch [85], Batch [300/391], Loss: 0.1622, LR: 0.000312\n",
      "Epoch [85], Batch [350/391], Loss: 2.2135, LR: 0.000312\n",
      "Train set: Epoch: 85, Average loss:0.9345, LR: 0.000312 Top-1 Accuracy: 85.7960%, Top-5 Accuracy: 96.3940%, Time consumed:351.77s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|████████████████████████▉                                                               | 85/300 [8:42:45<21:55:42, 367.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 85, Average loss:1.2693, Top-1 Accuracy: 72.9800%, Top-5 Accuracy: 92.4000%, Time consumed:14.39s\n",
      "\n",
      "새로운 최고 top-5 정확도: 92.40%\n",
      "EarlyStopping 카운터: 6 / 30\n",
      "Epoch [86], Batch [50/391], Loss: 2.2087, LR: 0.000312\n",
      "Epoch [86], Batch [100/391], Loss: 0.1519, LR: 0.000312\n",
      "Epoch [86], Batch [150/391], Loss: 0.1362, LR: 0.000312\n",
      "Epoch [86], Batch [200/391], Loss: 1.4351, LR: 0.000312\n",
      "Epoch [86], Batch [250/391], Loss: 0.1449, LR: 0.000312\n",
      "Epoch [86], Batch [300/391], Loss: 1.9002, LR: 0.000312\n",
      "Epoch [86], Batch [350/391], Loss: 0.1121, LR: 0.000312\n",
      "Train set: Epoch: 86, Average loss:0.9118, LR: 0.000312 Top-1 Accuracy: 85.0860%, Top-5 Accuracy: 96.0700%, Time consumed:352.49s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|█████████████████████████▏                                                              | 86/300 [8:49:00<21:57:56, 369.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 86, Average loss:1.2624, Top-1 Accuracy: 72.9700%, Top-5 Accuracy: 92.3900%, Time consumed:22.48s\n",
      "\n",
      "EarlyStopping 카운터: 7 / 30\n",
      "Epoch [87], Batch [50/391], Loss: 2.2826, LR: 0.000156\n",
      "Epoch [87], Batch [100/391], Loss: 0.1280, LR: 0.000156\n",
      "Epoch [87], Batch [150/391], Loss: 0.1314, LR: 0.000156\n",
      "Epoch [87], Batch [200/391], Loss: 0.1454, LR: 0.000156\n",
      "Epoch [87], Batch [250/391], Loss: 2.2010, LR: 0.000156\n",
      "Epoch [87], Batch [300/391], Loss: 2.2669, LR: 0.000156\n",
      "Epoch [87], Batch [350/391], Loss: 2.3158, LR: 0.000156\n",
      "Train set: Epoch: 87, Average loss:0.9031, LR: 0.000156 Top-1 Accuracy: 84.9820%, Top-5 Accuracy: 96.1700%, Time consumed:352.77s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|█████████████████████████▌                                                              | 87/300 [8:55:07<21:49:11, 368.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 87, Average loss:1.3151, Top-1 Accuracy: 72.9600%, Top-5 Accuracy: 92.3100%, Time consumed:14.31s\n",
      "\n",
      "EarlyStopping 카운터: 8 / 30\n",
      "Epoch [88], Batch [50/391], Loss: 0.1493, LR: 0.000156\n",
      "Epoch [88], Batch [100/391], Loss: 0.6637, LR: 0.000156\n",
      "Epoch [88], Batch [150/391], Loss: 0.4989, LR: 0.000156\n",
      "Epoch [88], Batch [200/391], Loss: 0.0916, LR: 0.000156\n",
      "Epoch [88], Batch [250/391], Loss: 2.4035, LR: 0.000156\n",
      "Epoch [88], Batch [300/391], Loss: 1.9437, LR: 0.000156\n",
      "Epoch [88], Batch [350/391], Loss: 0.1279, LR: 0.000156\n",
      "Train set: Epoch: 88, Average loss:0.9227, LR: 0.000156 Top-1 Accuracy: 84.9120%, Top-5 Accuracy: 95.8900%, Time consumed:352.71s\n",
      "Test set: Epoch: 88, Average loss:1.2777, Top-1 Accuracy: 73.6600%, Top-5 Accuracy: 92.2900%, Time consumed:14.23s\n",
      "\n",
      "새로운 최고 top-1 정확도: 73.66%, top-5 정확도: 92.29%\n",
      "Accuracy improved (73.07% --> 73.66%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|█████████████████████████▊                                                              | 88/300 [9:01:17<21:44:09, 369.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [89], Batch [50/391], Loss: 0.3114, LR: 0.000156\n",
      "Epoch [89], Batch [100/391], Loss: 0.1228, LR: 0.000156\n",
      "Epoch [89], Batch [150/391], Loss: 0.1338, LR: 0.000156\n",
      "Epoch [89], Batch [200/391], Loss: 0.1227, LR: 0.000156\n",
      "Epoch [89], Batch [250/391], Loss: 0.1903, LR: 0.000156\n",
      "Epoch [89], Batch [300/391], Loss: 2.3027, LR: 0.000156\n",
      "Epoch [89], Batch [350/391], Loss: 1.7770, LR: 0.000156\n",
      "Train set: Epoch: 89, Average loss:0.8937, LR: 0.000156 Top-1 Accuracy: 86.0380%, Top-5 Accuracy: 96.3740%, Time consumed:352.05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██████████████████████████                                                              | 89/300 [9:07:23<21:35:13, 368.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 89, Average loss:1.2608, Top-1 Accuracy: 72.2400%, Top-5 Accuracy: 91.5300%, Time consumed:14.40s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [90], Batch [50/391], Loss: 2.4767, LR: 0.000156\n",
      "Epoch [90], Batch [100/391], Loss: 1.3477, LR: 0.000156\n",
      "Epoch [90], Batch [150/391], Loss: 0.1048, LR: 0.000156\n",
      "Epoch [90], Batch [200/391], Loss: 0.1334, LR: 0.000156\n",
      "Epoch [90], Batch [250/391], Loss: 0.1221, LR: 0.000156\n",
      "Epoch [90], Batch [300/391], Loss: 2.4758, LR: 0.000156\n",
      "Epoch [90], Batch [350/391], Loss: 0.1007, LR: 0.000156\n",
      "Train set: Epoch: 90, Average loss:0.9148, LR: 0.000156 Top-1 Accuracy: 84.5020%, Top-5 Accuracy: 95.6360%, Time consumed:352.34s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██████████████████████████▍                                                             | 90/300 [9:13:30<21:27:24, 367.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 90, Average loss:1.2462, Top-1 Accuracy: 72.9200%, Top-5 Accuracy: 92.0600%, Time consumed:14.36s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [91], Batch [50/391], Loss: 2.2110, LR: 0.000156\n",
      "Epoch [91], Batch [100/391], Loss: 0.1282, LR: 0.000156\n",
      "Epoch [91], Batch [150/391], Loss: 0.0886, LR: 0.000156\n",
      "Epoch [91], Batch [200/391], Loss: 2.2798, LR: 0.000156\n",
      "Epoch [91], Batch [250/391], Loss: 2.3996, LR: 0.000156\n",
      "Epoch [91], Batch [300/391], Loss: 0.1083, LR: 0.000156\n",
      "Epoch [91], Batch [350/391], Loss: 0.1072, LR: 0.000156\n",
      "Train set: Epoch: 91, Average loss:0.8847, LR: 0.000156 Top-1 Accuracy: 85.6780%, Top-5 Accuracy: 96.1960%, Time consumed:352.32s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██████████████████████████▋                                                             | 91/300 [9:19:37<21:20:24, 367.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 91, Average loss:1.2939, Top-1 Accuracy: 73.1000%, Top-5 Accuracy: 92.3100%, Time consumed:14.64s\n",
      "\n",
      "EarlyStopping 카운터: 3 / 30\n",
      "Epoch [92], Batch [50/391], Loss: 0.1639, LR: 0.000156\n",
      "Epoch [92], Batch [100/391], Loss: 1.7317, LR: 0.000156\n",
      "Epoch [92], Batch [150/391], Loss: 0.1197, LR: 0.000156\n",
      "Epoch [92], Batch [200/391], Loss: 1.5561, LR: 0.000156\n",
      "Epoch [92], Batch [250/391], Loss: 0.1434, LR: 0.000156\n",
      "Epoch [92], Batch [300/391], Loss: 0.1317, LR: 0.000156\n",
      "Epoch [92], Batch [350/391], Loss: 1.1050, LR: 0.000156\n",
      "Train set: Epoch: 92, Average loss:0.9659, LR: 0.000156 Top-1 Accuracy: 85.2680%, Top-5 Accuracy: 96.3200%, Time consumed:351.87s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|██████████████████████████▉                                                             | 92/300 [9:25:43<21:12:50, 367.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 92, Average loss:1.2988, Top-1 Accuracy: 72.9700%, Top-5 Accuracy: 92.2600%, Time consumed:14.33s\n",
      "\n",
      "EarlyStopping 카운터: 4 / 30\n",
      "Epoch [93], Batch [50/391], Loss: 0.1330, LR: 0.000156\n",
      "Epoch [93], Batch [100/391], Loss: 0.1185, LR: 0.000156\n",
      "Epoch [93], Batch [150/391], Loss: 0.1643, LR: 0.000156\n",
      "Epoch [93], Batch [200/391], Loss: 2.0722, LR: 0.000156\n",
      "Epoch [93], Batch [250/391], Loss: 1.3003, LR: 0.000156\n",
      "Epoch [93], Batch [300/391], Loss: 0.1183, LR: 0.000156\n",
      "Epoch [93], Batch [350/391], Loss: 1.3338, LR: 0.000156\n",
      "Train set: Epoch: 93, Average loss:0.8579, LR: 0.000156 Top-1 Accuracy: 87.0500%, Top-5 Accuracy: 96.7800%, Time consumed:352.29s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███████████████████████████▎                                                            | 93/300 [9:31:58<21:14:25, 369.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 93, Average loss:1.2622, Top-1 Accuracy: 72.8100%, Top-5 Accuracy: 91.9000%, Time consumed:22.31s\n",
      "\n",
      "EarlyStopping 카운터: 5 / 30\n",
      "Epoch [94], Batch [50/391], Loss: 2.1718, LR: 0.000156\n",
      "Epoch [94], Batch [100/391], Loss: 1.9295, LR: 0.000156\n",
      "Epoch [94], Batch [150/391], Loss: 2.0831, LR: 0.000156\n",
      "Epoch [94], Batch [200/391], Loss: 1.0069, LR: 0.000156\n",
      "Epoch [94], Batch [250/391], Loss: 2.4885, LR: 0.000156\n",
      "Epoch [94], Batch [300/391], Loss: 0.1172, LR: 0.000156\n",
      "Epoch [94], Batch [350/391], Loss: 2.4688, LR: 0.000156\n",
      "Train set: Epoch: 94, Average loss:0.9594, LR: 0.000156 Top-1 Accuracy: 84.1920%, Top-5 Accuracy: 95.5720%, Time consumed:352.28s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███████████████████████████▌                                                            | 94/300 [9:38:04<21:05:32, 368.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 94, Average loss:1.2528, Top-1 Accuracy: 73.3500%, Top-5 Accuracy: 92.1500%, Time consumed:14.46s\n",
      "\n",
      "EarlyStopping 카운터: 6 / 30\n",
      "Epoch [95], Batch [50/391], Loss: 0.1002, LR: 0.000078\n",
      "Epoch [95], Batch [100/391], Loss: 0.0958, LR: 0.000078\n",
      "Epoch [95], Batch [150/391], Loss: 2.3265, LR: 0.000078\n",
      "Epoch [95], Batch [200/391], Loss: 0.1841, LR: 0.000078\n",
      "Epoch [95], Batch [250/391], Loss: 0.1165, LR: 0.000078\n",
      "Epoch [95], Batch [300/391], Loss: 2.1534, LR: 0.000078\n",
      "Epoch [95], Batch [350/391], Loss: 2.2914, LR: 0.000078\n",
      "Train set: Epoch: 95, Average loss:0.8610, LR: 0.000078 Top-1 Accuracy: 86.6080%, Top-5 Accuracy: 96.6400%, Time consumed:352.21s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███████████████████████████▊                                                            | 95/300 [9:44:11<20:57:41, 368.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 95, Average loss:1.3347, Top-1 Accuracy: 72.8100%, Top-5 Accuracy: 91.9600%, Time consumed:14.73s\n",
      "\n",
      "EarlyStopping 카운터: 7 / 30\n",
      "Epoch [96], Batch [50/391], Loss: 2.1645, LR: 0.000078\n",
      "Epoch [96], Batch [100/391], Loss: 0.1336, LR: 0.000078\n",
      "Epoch [96], Batch [150/391], Loss: 2.5212, LR: 0.000078\n",
      "Epoch [96], Batch [200/391], Loss: 0.1020, LR: 0.000078\n",
      "Epoch [96], Batch [250/391], Loss: 0.1103, LR: 0.000078\n",
      "Epoch [96], Batch [300/391], Loss: 0.1250, LR: 0.000078\n",
      "Epoch [96], Batch [350/391], Loss: 1.1405, LR: 0.000078\n",
      "Train set: Epoch: 96, Average loss:0.8720, LR: 0.000078 Top-1 Accuracy: 85.6900%, Top-5 Accuracy: 96.1360%, Time consumed:351.80s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|████████████████████████████▏                                                           | 96/300 [9:50:17<20:49:36, 367.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 96, Average loss:1.2826, Top-1 Accuracy: 72.8900%, Top-5 Accuracy: 92.2000%, Time consumed:14.39s\n",
      "\n",
      "EarlyStopping 카운터: 8 / 30\n",
      "Epoch [97], Batch [50/391], Loss: 1.6271, LR: 0.000078\n",
      "Epoch [97], Batch [100/391], Loss: 0.1653, LR: 0.000078\n",
      "Epoch [97], Batch [150/391], Loss: 2.0783, LR: 0.000078\n",
      "Epoch [97], Batch [200/391], Loss: 1.3379, LR: 0.000078\n",
      "Epoch [97], Batch [250/391], Loss: 0.1537, LR: 0.000078\n",
      "Epoch [97], Batch [300/391], Loss: 2.1548, LR: 0.000078\n",
      "Epoch [97], Batch [350/391], Loss: 2.2038, LR: 0.000078\n",
      "Train set: Epoch: 97, Average loss:0.9446, LR: 0.000078 Top-1 Accuracy: 85.1700%, Top-5 Accuracy: 96.0060%, Time consumed:352.30s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|████████████████████████████▍                                                           | 97/300 [9:56:24<20:42:38, 367.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 97, Average loss:1.2426, Top-1 Accuracy: 73.1400%, Top-5 Accuracy: 92.2800%, Time consumed:14.38s\n",
      "\n",
      "EarlyStopping 카운터: 9 / 30\n",
      "Epoch [98], Batch [50/391], Loss: 1.3913, LR: 0.000078\n",
      "Epoch [98], Batch [100/391], Loss: 0.6660, LR: 0.000078\n",
      "Epoch [98], Batch [150/391], Loss: 0.1278, LR: 0.000078\n",
      "Epoch [98], Batch [200/391], Loss: 0.1247, LR: 0.000078\n",
      "Epoch [98], Batch [250/391], Loss: 0.1193, LR: 0.000078\n",
      "Epoch [98], Batch [300/391], Loss: 0.7113, LR: 0.000078\n",
      "Epoch [98], Batch [350/391], Loss: 0.1068, LR: 0.000078\n",
      "Train set: Epoch: 98, Average loss:0.8703, LR: 0.000078 Top-1 Accuracy: 86.1140%, Top-5 Accuracy: 96.7360%, Time consumed:352.98s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|████████████████████████████▍                                                          | 98/300 [10:02:32<20:36:37, 367.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 98, Average loss:1.2578, Top-1 Accuracy: 73.3900%, Top-5 Accuracy: 92.3800%, Time consumed:14.41s\n",
      "\n",
      "EarlyStopping 카운터: 10 / 30\n",
      "Epoch [99], Batch [50/391], Loss: 0.1342, LR: 0.000078\n",
      "Epoch [99], Batch [100/391], Loss: 1.9260, LR: 0.000078\n",
      "Epoch [99], Batch [150/391], Loss: 2.3197, LR: 0.000078\n",
      "Epoch [99], Batch [200/391], Loss: 2.3589, LR: 0.000078\n",
      "Epoch [99], Batch [250/391], Loss: 1.9330, LR: 0.000078\n",
      "Epoch [99], Batch [300/391], Loss: 1.7600, LR: 0.000078\n",
      "Epoch [99], Batch [350/391], Loss: 0.1342, LR: 0.000078\n",
      "Train set: Epoch: 99, Average loss:0.9047, LR: 0.000078 Top-1 Accuracy: 85.7420%, Top-5 Accuracy: 96.2500%, Time consumed:351.95s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|████████████████████████████▋                                                          | 99/300 [10:08:38<20:29:29, 367.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 99, Average loss:1.2972, Top-1 Accuracy: 72.8700%, Top-5 Accuracy: 92.2400%, Time consumed:14.35s\n",
      "\n",
      "EarlyStopping 카운터: 11 / 30\n",
      "Epoch [100], Batch [50/391], Loss: 0.1423, LR: 0.000078\n",
      "Epoch [100], Batch [100/391], Loss: 0.1589, LR: 0.000078\n",
      "Epoch [100], Batch [150/391], Loss: 0.1412, LR: 0.000078\n",
      "Epoch [100], Batch [200/391], Loss: 0.1344, LR: 0.000078\n",
      "Epoch [100], Batch [250/391], Loss: 2.0283, LR: 0.000078\n",
      "Epoch [100], Batch [300/391], Loss: 0.1062, LR: 0.000078\n",
      "Epoch [100], Batch [350/391], Loss: 2.4663, LR: 0.000078\n",
      "Train set: Epoch: 100, Average loss:0.8979, LR: 0.000078 Top-1 Accuracy: 85.3660%, Top-5 Accuracy: 96.1640%, Time consumed:352.27s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|████████████████████████████▋                                                         | 100/300 [10:14:44<20:22:54, 366.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 100, Average loss:1.2735, Top-1 Accuracy: 72.7200%, Top-5 Accuracy: 91.8300%, Time consumed:14.27s\n",
      "\n",
      "EarlyStopping 카운터: 12 / 30\n",
      "Epoch [101], Batch [50/391], Loss: 2.1853, LR: 0.000039\n",
      "Epoch [101], Batch [100/391], Loss: 0.1170, LR: 0.000039\n",
      "Epoch [101], Batch [150/391], Loss: 0.0978, LR: 0.000039\n",
      "Epoch [101], Batch [200/391], Loss: 0.1082, LR: 0.000039\n",
      "Epoch [101], Batch [250/391], Loss: 1.4298, LR: 0.000039\n",
      "Epoch [101], Batch [300/391], Loss: 0.1457, LR: 0.000039\n",
      "Epoch [101], Batch [350/391], Loss: 2.0943, LR: 0.000039\n",
      "Train set: Epoch: 101, Average loss:0.9282, LR: 0.000039 Top-1 Accuracy: 85.2520%, Top-5 Accuracy: 96.1680%, Time consumed:352.48s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|████████████████████████████▉                                                         | 101/300 [10:20:51<20:16:46, 366.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 101, Average loss:1.2580, Top-1 Accuracy: 73.0800%, Top-5 Accuracy: 92.1600%, Time consumed:14.37s\n",
      "\n",
      "EarlyStopping 카운터: 13 / 30\n",
      "Epoch [102], Batch [50/391], Loss: 0.1124, LR: 0.000039\n",
      "Epoch [102], Batch [100/391], Loss: 1.2060, LR: 0.000039\n",
      "Epoch [102], Batch [150/391], Loss: 0.1226, LR: 0.000039\n",
      "Epoch [102], Batch [200/391], Loss: 0.1354, LR: 0.000039\n",
      "Epoch [102], Batch [250/391], Loss: 1.4120, LR: 0.000039\n",
      "Epoch [102], Batch [300/391], Loss: 0.1308, LR: 0.000039\n",
      "Epoch [102], Batch [350/391], Loss: 0.1367, LR: 0.000039\n",
      "Train set: Epoch: 102, Average loss:0.8648, LR: 0.000039 Top-1 Accuracy: 85.8200%, Top-5 Accuracy: 96.3900%, Time consumed:352.63s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|█████████████████████████████▏                                                        | 102/300 [10:26:58<20:10:53, 366.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 102, Average loss:1.2968, Top-1 Accuracy: 73.5500%, Top-5 Accuracy: 92.4700%, Time consumed:14.47s\n",
      "\n",
      "새로운 최고 top-5 정확도: 92.47%\n",
      "EarlyStopping 카운터: 14 / 30\n",
      "Epoch [103], Batch [50/391], Loss: 0.5526, LR: 0.000039\n",
      "Epoch [103], Batch [100/391], Loss: 2.4954, LR: 0.000039\n",
      "Epoch [103], Batch [150/391], Loss: 0.1288, LR: 0.000039\n",
      "Epoch [103], Batch [200/391], Loss: 2.2941, LR: 0.000039\n",
      "Epoch [103], Batch [250/391], Loss: 2.3530, LR: 0.000039\n",
      "Epoch [103], Batch [300/391], Loss: 0.1173, LR: 0.000039\n",
      "Epoch [103], Batch [350/391], Loss: 0.1006, LR: 0.000039\n",
      "Train set: Epoch: 103, Average loss:0.9412, LR: 0.000039 Top-1 Accuracy: 85.4320%, Top-5 Accuracy: 96.3400%, Time consumed:351.92s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|█████████████████████████████▌                                                        | 103/300 [10:33:05<20:04:16, 366.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 103, Average loss:1.2966, Top-1 Accuracy: 73.0700%, Top-5 Accuracy: 92.2500%, Time consumed:14.50s\n",
      "\n",
      "EarlyStopping 카운터: 15 / 30\n",
      "Epoch [104], Batch [50/391], Loss: 0.0692, LR: 0.000039\n",
      "Epoch [104], Batch [100/391], Loss: 0.1630, LR: 0.000039\n",
      "Epoch [104], Batch [150/391], Loss: 0.1163, LR: 0.000039\n",
      "Epoch [104], Batch [200/391], Loss: 0.1290, LR: 0.000039\n",
      "Epoch [104], Batch [250/391], Loss: 0.1209, LR: 0.000039\n",
      "Epoch [104], Batch [300/391], Loss: 2.3776, LR: 0.000039\n",
      "Epoch [104], Batch [350/391], Loss: 0.1468, LR: 0.000039\n",
      "Train set: Epoch: 104, Average loss:0.8653, LR: 0.000039 Top-1 Accuracy: 86.5200%, Top-5 Accuracy: 96.6520%, Time consumed:352.16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|█████████████████████████████▊                                                        | 104/300 [10:39:11<19:57:52, 366.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 104, Average loss:1.3060, Top-1 Accuracy: 73.0800%, Top-5 Accuracy: 92.1800%, Time consumed:14.33s\n",
      "\n",
      "EarlyStopping 카운터: 16 / 30\n",
      "Epoch [105], Batch [50/391], Loss: 0.0941, LR: 0.000039\n",
      "Epoch [105], Batch [100/391], Loss: 0.1212, LR: 0.000039\n",
      "Epoch [105], Batch [150/391], Loss: 2.4687, LR: 0.000039\n",
      "Epoch [105], Batch [200/391], Loss: 2.1406, LR: 0.000039\n",
      "Epoch [105], Batch [250/391], Loss: 0.1300, LR: 0.000039\n",
      "Epoch [105], Batch [300/391], Loss: 0.1164, LR: 0.000039\n",
      "Epoch [105], Batch [350/391], Loss: 1.8101, LR: 0.000039\n",
      "Train set: Epoch: 105, Average loss:0.8845, LR: 0.000039 Top-1 Accuracy: 85.6900%, Top-5 Accuracy: 96.2560%, Time consumed:352.67s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|██████████████████████████████                                                        | 105/300 [10:45:18<19:52:09, 366.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 105, Average loss:1.2427, Top-1 Accuracy: 72.7100%, Top-5 Accuracy: 92.1000%, Time consumed:14.42s\n",
      "\n",
      "EarlyStopping 카운터: 17 / 30\n",
      "Epoch [106], Batch [50/391], Loss: 2.3074, LR: 0.000039\n",
      "Epoch [106], Batch [100/391], Loss: 0.1250, LR: 0.000039\n",
      "Epoch [106], Batch [150/391], Loss: 1.1233, LR: 0.000039\n",
      "Epoch [106], Batch [200/391], Loss: 0.7323, LR: 0.000039\n",
      "Epoch [106], Batch [250/391], Loss: 0.1404, LR: 0.000039\n",
      "Epoch [106], Batch [300/391], Loss: 0.1161, LR: 0.000039\n",
      "Epoch [106], Batch [350/391], Loss: 2.0044, LR: 0.000039\n",
      "Train set: Epoch: 106, Average loss:0.8892, LR: 0.000039 Top-1 Accuracy: 87.4740%, Top-5 Accuracy: 97.0740%, Time consumed:352.50s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|██████████████████████████████▍                                                       | 106/300 [10:51:25<19:46:10, 366.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 106, Average loss:1.2460, Top-1 Accuracy: 72.7900%, Top-5 Accuracy: 92.0300%, Time consumed:14.45s\n",
      "\n",
      "EarlyStopping 카운터: 18 / 30\n",
      "Epoch [107], Batch [50/391], Loss: 0.1190, LR: 0.000020\n",
      "Epoch [107], Batch [100/391], Loss: 0.0981, LR: 0.000020\n",
      "Epoch [107], Batch [150/391], Loss: 0.1297, LR: 0.000020\n",
      "Epoch [107], Batch [200/391], Loss: 0.1216, LR: 0.000020\n",
      "Epoch [107], Batch [250/391], Loss: 2.0620, LR: 0.000020\n",
      "Epoch [107], Batch [300/391], Loss: 2.3531, LR: 0.000020\n",
      "Epoch [107], Batch [350/391], Loss: 0.1093, LR: 0.000020\n",
      "Train set: Epoch: 107, Average loss:0.9525, LR: 0.000020 Top-1 Accuracy: 84.7660%, Top-5 Accuracy: 95.8040%, Time consumed:352.13s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|██████████████████████████████▋                                                       | 107/300 [10:57:32<19:39:54, 366.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 107, Average loss:1.3167, Top-1 Accuracy: 72.7300%, Top-5 Accuracy: 91.8900%, Time consumed:14.56s\n",
      "\n",
      "EarlyStopping 카운터: 19 / 30\n",
      "Epoch [108], Batch [50/391], Loss: 0.1382, LR: 0.000020\n",
      "Epoch [108], Batch [100/391], Loss: 0.0907, LR: 0.000020\n",
      "Epoch [108], Batch [150/391], Loss: 2.0371, LR: 0.000020\n",
      "Epoch [108], Batch [200/391], Loss: 2.2445, LR: 0.000020\n",
      "Epoch [108], Batch [250/391], Loss: 0.0994, LR: 0.000020\n",
      "Epoch [108], Batch [300/391], Loss: 0.0972, LR: 0.000020\n",
      "Epoch [108], Batch [350/391], Loss: 0.1338, LR: 0.000020\n",
      "Train set: Epoch: 108, Average loss:0.8450, LR: 0.000020 Top-1 Accuracy: 86.6540%, Top-5 Accuracy: 96.5640%, Time consumed:352.36s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|██████████████████████████████▉                                                       | 108/300 [11:03:39<19:34:07, 366.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 108, Average loss:1.3103, Top-1 Accuracy: 73.5500%, Top-5 Accuracy: 92.4900%, Time consumed:14.78s\n",
      "\n",
      "새로운 최고 top-5 정확도: 92.49%\n",
      "EarlyStopping 카운터: 20 / 30\n",
      "Epoch [109], Batch [50/391], Loss: 2.2862, LR: 0.000020\n",
      "Epoch [109], Batch [100/391], Loss: 0.1224, LR: 0.000020\n",
      "Epoch [109], Batch [150/391], Loss: 1.1383, LR: 0.000020\n",
      "Epoch [109], Batch [200/391], Loss: 0.1089, LR: 0.000020\n",
      "Epoch [109], Batch [250/391], Loss: 2.0266, LR: 0.000020\n",
      "Epoch [109], Batch [300/391], Loss: 0.1433, LR: 0.000020\n",
      "Epoch [109], Batch [350/391], Loss: 0.0996, LR: 0.000020\n",
      "Train set: Epoch: 109, Average loss:0.9585, LR: 0.000020 Top-1 Accuracy: 84.9100%, Top-5 Accuracy: 95.7140%, Time consumed:352.43s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███████████████████████████████▏                                                      | 109/300 [11:09:46<19:27:57, 366.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 109, Average loss:1.2492, Top-1 Accuracy: 73.4200%, Top-5 Accuracy: 92.2700%, Time consumed:14.42s\n",
      "\n",
      "EarlyStopping 카운터: 21 / 30\n",
      "Epoch [110], Batch [50/391], Loss: 0.1171, LR: 0.000020\n",
      "Epoch [110], Batch [100/391], Loss: 0.1274, LR: 0.000020\n",
      "Epoch [110], Batch [150/391], Loss: 1.0683, LR: 0.000020\n",
      "Epoch [110], Batch [200/391], Loss: 1.8332, LR: 0.000020\n",
      "Epoch [110], Batch [250/391], Loss: 1.8583, LR: 0.000020\n",
      "Epoch [110], Batch [300/391], Loss: 0.0953, LR: 0.000020\n",
      "Epoch [110], Batch [350/391], Loss: 2.1680, LR: 0.000020\n",
      "Train set: Epoch: 110, Average loss:0.8816, LR: 0.000020 Top-1 Accuracy: 86.1680%, Top-5 Accuracy: 96.5140%, Time consumed:351.80s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███████████████████████████████▌                                                      | 110/300 [11:15:52<19:21:06, 366.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 110, Average loss:1.2530, Top-1 Accuracy: 72.5200%, Top-5 Accuracy: 92.1200%, Time consumed:14.32s\n",
      "\n",
      "EarlyStopping 카운터: 22 / 30\n",
      "Epoch [111], Batch [50/391], Loss: 0.1034, LR: 0.000020\n",
      "Epoch [111], Batch [100/391], Loss: 2.0687, LR: 0.000020\n",
      "Epoch [111], Batch [150/391], Loss: 0.1206, LR: 0.000020\n",
      "Epoch [111], Batch [200/391], Loss: 2.4102, LR: 0.000020\n",
      "Epoch [111], Batch [250/391], Loss: 0.1326, LR: 0.000020\n",
      "Epoch [111], Batch [300/391], Loss: 2.3158, LR: 0.000020\n",
      "Epoch [111], Batch [350/391], Loss: 1.1803, LR: 0.000020\n",
      "Train set: Epoch: 111, Average loss:0.9123, LR: 0.000020 Top-1 Accuracy: 85.1380%, Top-5 Accuracy: 96.0160%, Time consumed:352.31s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███████████████████████████████▊                                                      | 111/300 [11:22:08<19:23:12, 369.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 111, Average loss:1.2642, Top-1 Accuracy: 73.0100%, Top-5 Accuracy: 92.4300%, Time consumed:23.04s\n",
      "\n",
      "EarlyStopping 카운터: 23 / 30\n",
      "Epoch [112], Batch [50/391], Loss: 0.1033, LR: 0.000020\n",
      "Epoch [112], Batch [100/391], Loss: 2.5006, LR: 0.000020\n",
      "Epoch [112], Batch [150/391], Loss: 1.9706, LR: 0.000020\n",
      "Epoch [112], Batch [200/391], Loss: 0.1987, LR: 0.000020\n",
      "Epoch [112], Batch [250/391], Loss: 0.1021, LR: 0.000020\n",
      "Epoch [112], Batch [300/391], Loss: 1.5583, LR: 0.000020\n",
      "Epoch [112], Batch [350/391], Loss: 1.7803, LR: 0.000020\n",
      "Train set: Epoch: 112, Average loss:0.9629, LR: 0.000020 Top-1 Accuracy: 85.4520%, Top-5 Accuracy: 96.1280%, Time consumed:352.39s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|████████████████████████████████                                                      | 112/300 [11:28:14<19:14:46, 368.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 112, Average loss:1.3044, Top-1 Accuracy: 72.6700%, Top-5 Accuracy: 92.0900%, Time consumed:14.45s\n",
      "\n",
      "EarlyStopping 카운터: 24 / 30\n",
      "Epoch [113], Batch [50/391], Loss: 0.0684, LR: 0.000010\n",
      "Epoch [113], Batch [100/391], Loss: 0.6666, LR: 0.000010\n",
      "Epoch [113], Batch [150/391], Loss: 0.1148, LR: 0.000010\n",
      "Epoch [113], Batch [200/391], Loss: 2.3840, LR: 0.000010\n",
      "Epoch [113], Batch [250/391], Loss: 2.1651, LR: 0.000010\n",
      "Epoch [113], Batch [300/391], Loss: 2.0165, LR: 0.000010\n",
      "Epoch [113], Batch [350/391], Loss: 0.1015, LR: 0.000010\n",
      "Train set: Epoch: 113, Average loss:0.9311, LR: 0.000010 Top-1 Accuracy: 85.0080%, Top-5 Accuracy: 95.9980%, Time consumed:351.97s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|████████████████████████████████▍                                                     | 113/300 [11:34:21<19:06:35, 367.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 113, Average loss:1.2803, Top-1 Accuracy: 72.7200%, Top-5 Accuracy: 92.0100%, Time consumed:14.39s\n",
      "\n",
      "EarlyStopping 카운터: 25 / 30\n",
      "Epoch [114], Batch [50/391], Loss: 1.7463, LR: 0.000010\n",
      "Epoch [114], Batch [100/391], Loss: 0.1456, LR: 0.000010\n",
      "Epoch [114], Batch [150/391], Loss: 0.0821, LR: 0.000010\n",
      "Epoch [114], Batch [200/391], Loss: 0.1083, LR: 0.000010\n",
      "Epoch [114], Batch [250/391], Loss: 0.1171, LR: 0.000010\n",
      "Epoch [114], Batch [300/391], Loss: 0.1504, LR: 0.000010\n",
      "Epoch [114], Batch [350/391], Loss: 0.1158, LR: 0.000010\n",
      "Train set: Epoch: 114, Average loss:0.8656, LR: 0.000010 Top-1 Accuracy: 86.3220%, Top-5 Accuracy: 96.5860%, Time consumed:352.47s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|████████████████████████████████▋                                                     | 114/300 [11:40:28<18:59:32, 367.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 114, Average loss:1.3136, Top-1 Accuracy: 73.6100%, Top-5 Accuracy: 92.5000%, Time consumed:14.43s\n",
      "\n",
      "새로운 최고 top-5 정확도: 92.50%\n",
      "EarlyStopping 카운터: 26 / 30\n",
      "Epoch [115], Batch [50/391], Loss: 0.1772, LR: 0.000010\n",
      "Epoch [115], Batch [100/391], Loss: 0.1106, LR: 0.000010\n",
      "Epoch [115], Batch [150/391], Loss: 0.9231, LR: 0.000010\n",
      "Epoch [115], Batch [200/391], Loss: 2.2896, LR: 0.000010\n",
      "Epoch [115], Batch [250/391], Loss: 0.1631, LR: 0.000010\n",
      "Epoch [115], Batch [300/391], Loss: 0.0733, LR: 0.000010\n",
      "Epoch [115], Batch [350/391], Loss: 2.3126, LR: 0.000010\n",
      "Train set: Epoch: 115, Average loss:0.8956, LR: 0.000010 Top-1 Accuracy: 85.8780%, Top-5 Accuracy: 96.4040%, Time consumed:352.54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|████████████████████████████████▉                                                     | 115/300 [11:46:43<19:00:21, 369.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 115, Average loss:1.2281, Top-1 Accuracy: 73.4000%, Top-5 Accuracy: 92.4500%, Time consumed:22.56s\n",
      "\n",
      "EarlyStopping 카운터: 27 / 30\n",
      "Epoch [116], Batch [50/391], Loss: 0.1123, LR: 0.000010\n",
      "Epoch [116], Batch [100/391], Loss: 2.1613, LR: 0.000010\n",
      "Epoch [116], Batch [150/391], Loss: 2.1438, LR: 0.000010\n",
      "Epoch [116], Batch [200/391], Loss: 2.1633, LR: 0.000010\n",
      "Epoch [116], Batch [250/391], Loss: 0.1277, LR: 0.000010\n",
      "Epoch [116], Batch [300/391], Loss: 1.7348, LR: 0.000010\n",
      "Epoch [116], Batch [350/391], Loss: 0.1265, LR: 0.000010\n",
      "Train set: Epoch: 116, Average loss:0.9322, LR: 0.000010 Top-1 Accuracy: 85.4000%, Top-5 Accuracy: 96.3440%, Time consumed:352.27s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|█████████████████████████████████▎                                                    | 116/300 [11:52:50<18:51:23, 368.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 116, Average loss:1.2364, Top-1 Accuracy: 73.4100%, Top-5 Accuracy: 92.1600%, Time consumed:14.53s\n",
      "\n",
      "EarlyStopping 카운터: 28 / 30\n",
      "Epoch [117], Batch [50/391], Loss: 0.1256, LR: 0.000010\n",
      "Epoch [117], Batch [100/391], Loss: 1.6082, LR: 0.000010\n",
      "Epoch [117], Batch [150/391], Loss: 0.1083, LR: 0.000010\n",
      "Epoch [117], Batch [200/391], Loss: 0.1575, LR: 0.000010\n",
      "Epoch [117], Batch [250/391], Loss: 2.3081, LR: 0.000010\n",
      "Epoch [117], Batch [300/391], Loss: 1.9877, LR: 0.000010\n",
      "Epoch [117], Batch [350/391], Loss: 0.1066, LR: 0.000010\n",
      "Train set: Epoch: 117, Average loss:0.9685, LR: 0.000010 Top-1 Accuracy: 83.3060%, Top-5 Accuracy: 95.3440%, Time consumed:351.95s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|█████████████████████████████████▌                                                    | 117/300 [11:58:56<18:43:21, 368.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 117, Average loss:1.3534, Top-1 Accuracy: 73.0300%, Top-5 Accuracy: 92.3000%, Time consumed:14.90s\n",
      "\n",
      "EarlyStopping 카운터: 29 / 30\n",
      "Epoch [118], Batch [50/391], Loss: 0.1086, LR: 0.000010\n",
      "Epoch [118], Batch [100/391], Loss: 0.1267, LR: 0.000010\n",
      "Epoch [118], Batch [150/391], Loss: 1.5958, LR: 0.000010\n",
      "Epoch [118], Batch [200/391], Loss: 0.1023, LR: 0.000010\n",
      "Epoch [118], Batch [250/391], Loss: 0.1167, LR: 0.000010\n",
      "Epoch [118], Batch [300/391], Loss: 0.0895, LR: 0.000010\n",
      "Epoch [118], Batch [350/391], Loss: 1.9541, LR: 0.000010\n",
      "Train set: Epoch: 118, Average loss:0.9796, LR: 0.000010 Top-1 Accuracy: 85.1340%, Top-5 Accuracy: 96.2360%, Time consumed:352.55s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|█████████████████████████████████▌                                                    | 117/300 [12:05:03<18:54:04, 371.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 118, Average loss:1.3297, Top-1 Accuracy: 72.4300%, Top-5 Accuracy: 91.9300%, Time consumed:14.55s\n",
      "\n",
      "EarlyStopping 카운터: 30 / 30\n",
      "에폭 118에서 학습 조기 종료. 최고 성능 에폭: 88\n",
      "테스트 정확도 기준 최고 모델 로드 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 300, Average loss:1.2777, Top-1 Accuracy: 73.6600%, Top-5 Accuracy: 92.2900%, Time consumed:14.60s\n",
      "\n",
      "완료! 최고 테스트 top-1 정확도: 73.66%, 최고 테스트 top-5 정확도: 92.50%\n",
      "최종 테스트 top-1 정확도: 73.66%, 최종 테스트 top-5 정확도: 92.29%\n",
      "전체 학습 시간: 43519.32 초\n",
      "전체 학습 시간: 12.09 시간\n",
      "GPU 0: NVIDIA RTX A5000\n",
      "Memory Allocated: 1.38 GB\n",
      "Memory Reserved: 7.20 GB\n",
      "Max Memory Allocated: 5.14 GB\n",
      "GPU 1: NVIDIA RTX A5000\n",
      "Memory Allocated: 0.02 GB\n",
      "Memory Reserved: 5.25 GB\n",
      "Max Memory Allocated: 3.44 GB\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>learning_rate</td><td>▂███████████████▄▄▃▃▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_accuracy_top1</td><td>▁▁▁▁▃▃▄▄▄▄▅▅▅▆▆▆▇▇▆▇▇▇▇█████████████████</td></tr><tr><td>test_accuracy_top5</td><td>▁▂▂▃▄▅▅▆▆▇▇▇▇▇▇▇████████████████████████</td></tr><tr><td>test_loss</td><td>█▆▆▄▃▃▂▃▂▂▂▂▂▂▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>total_training_time</td><td>▁</td></tr><tr><td>train_accuracy_top1</td><td>▁▂▂▃▃▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇███████████████</td></tr><tr><td>train_accuracy_top5</td><td>▁▃▄▅▅▆▆▇▆▇▇▇▇▇▇▇████████████████████████</td></tr><tr><td>train_loss</td><td>█▇▆▆▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>88</td></tr><tr><td>best_test_accuracy_top1</td><td>73.66</td></tr><tr><td>best_test_accuracy_top5</td><td>92.5</td></tr><tr><td>early_stopped</td><td>True</td></tr><tr><td>early_stopped_epoch</td><td>118</td></tr><tr><td>epoch</td><td>118</td></tr><tr><td>final_test_accuracy_top1</td><td>73.66</td></tr><tr><td>final_test_accuracy_top5</td><td>92.29</td></tr><tr><td>learning_rate</td><td>0.0</td></tr><tr><td>model_parameters</td><td>145950980</td></tr><tr><td>test_accuracy_top1</td><td>72.43</td></tr><tr><td>test_accuracy_top5</td><td>91.93</td></tr><tr><td>test_loss</td><td>1.32969</td></tr><tr><td>total_training_time</td><td>43519.31946</td></tr><tr><td>train_accuracy_top1</td><td>85.134</td></tr><tr><td>train_accuracy_top5</td><td>96.236</td></tr><tr><td>train_loss</td><td>0.97961</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">wideresnet_28_20_cfc,SAM_SGD</strong> at: <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/f7bzcjne' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/f7bzcjne</a><br> View project at: <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250424_105429-f7bzcjne/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.v2 as transforms_v2\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "from tools.tool import AccuracyEarlyStopping, WarmUpLR, SAM\n",
    "# Wide ResNet 모델 임포트\n",
    "from models.wideresidual import Wide_ResNet, conv_init\n",
    "\n",
    "# 중요: wideresidual.py 파일에서 \"*wide*layer\" 메서드명을 \"_wide_layer\"로 수정해야 합니다!\n",
    "\n",
    "wandb.login(key=\"ef091b9abcea3186341ddf8995d62bde62d7469e\")\n",
    "wandb.init(project=\"PBL-2\", name=\"wideresnet_28_20_cfc,SAM_SGD\")  \n",
    "\n",
    "# WandB 설정 - WideResNet 28x20으로 변경\n",
    "config = {\n",
    "    \"model\": \"wideresnet\",  \n",
    "    \"depth\": 28,            \n",
    "    \"widen_factor\": 20,     # 10에서 20으로 변경\n",
    "    \"dropout_rate\": 0.3,    \n",
    "    \"batch_size\": 128,       # 메모리 부족 가능성 고려하여 더 작은 배치 크기로 조정\n",
    "    \"num_epochs\": 300,\n",
    "    \"learning_rate\": 0.01,  \n",
    "    \"optimizer\": \"SGD\",     \n",
    "    \"momentum\": 0.9,        \n",
    "    \"weight_decay\": 5e-4,   \n",
    "    \"deterministic\": False,\n",
    "    \"patience\": 30,         \n",
    "    \"max_epochs_wait\": float('inf'),\n",
    "    \"cutmix_alpha\": 1.0,    \n",
    "    \"cutmix_prob\": 0.5,     \n",
    "    \"crop_padding\": 4,      \n",
    "    \"crop_size\": 32,        \n",
    "    \"warmup_epochs\": 5,     \n",
    "}\n",
    "wandb.config.update(config)\n",
    "\n",
    "\n",
    "# CIFAR-100 데이터셋 로드 - 강화된 데이터 증강 추가\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(config[\"crop_size\"], padding=config[\"crop_padding\"]),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR100(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR100(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "# DataLoader 생성\n",
    "trainloader = DataLoader(trainset, batch_size=config[\"batch_size\"], shuffle=True, \n",
    "                        num_workers=32, pin_memory=True)  # GPU 전송 속도 향상\n",
    "testloader = DataLoader(testset, batch_size=config[\"batch_size\"], shuffle=False, \n",
    "                       num_workers=32, pin_memory=True)\n",
    "\n",
    "print(f\"Train set size: {len(trainset)}\")\n",
    "print(f\"Test set size: {len(testset)}\")\n",
    "\n",
    "# CutMix 변환 정의\n",
    "cutmix = transforms_v2.CutMix(alpha=config[\"cutmix_alpha\"], num_classes=100)  # CIFAR-100은 100개 클래스\n",
    "\n",
    "def train(model, trainloader, criterion, optimizer, device, epoch, warmup_scheduler=None, warmup_epochs=None):\n",
    "    \"\"\"\n",
    "    학습 함수 (CutMix 적용)\n",
    "    \"\"\"\n",
    "    if warmup_epochs is None:\n",
    "        warmup_epochs = config[\"warmup_epochs\"]\n",
    "        \n",
    "    model.train()   # 모델을 학습 모드로 설정\n",
    "    start_time = time.time()  # 시간 측정 시작\n",
    "    running_loss = 0.0\n",
    "    correct_top1 = 0\n",
    "    correct_top5 = 0\n",
    "    total = 0\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(trainloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # CutMix 확률적 적용\n",
    "        if random.random() < config[\"cutmix_prob\"]:\n",
    "            inputs, labels = cutmix(inputs, labels)\n",
    "            use_cutmix = True\n",
    "        else:\n",
    "            use_cutmix = False\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # CutMix 적용 여부에 따라 손실 함수 선택\n",
    "        if use_cutmix:\n",
    "            loss = torch.nn.functional.cross_entropy(outputs, labels)\n",
    "        else:\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "        loss.backward()\n",
    "        optimizer.first_step(zero_grad=True)\n",
    "        \n",
    "        # 두 번째 forward-backward 패스 (SAM 최적화)\n",
    "        outputs = model(inputs)  # 항상 새 forward 패스 필요\n",
    "        \n",
    "        if use_cutmix:\n",
    "            loss = torch.nn.functional.cross_entropy(outputs, labels)\n",
    "        else:\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.second_step(zero_grad=True)\n",
    "        \n",
    "        # 학습률 스케줄러 업데이트\n",
    "        if epoch < warmup_epochs and warmup_scheduler is not None:\n",
    "            warmup_scheduler.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # 정확도 계산\n",
    "        if use_cutmix:\n",
    "            _, label_idx = labels.max(1)\n",
    "        else:\n",
    "            label_idx = labels\n",
    "        \n",
    "        # top-1 정확도 계산\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += inputs.size(0)\n",
    "        correct_top1 += predicted.eq(label_idx).sum().item()\n",
    "        \n",
    "        # top-5 정확도 계산\n",
    "        _, top5_idx = outputs.topk(5, 1, largest=True, sorted=True)\n",
    "        correct_top5 += sum([1 for i in range(len(label_idx)) if label_idx[i] in top5_idx[i]])\n",
    "        \n",
    "        if (i + 1) % 50 == 0:  # 50 배치마다 출력\n",
    "            print(f'Epoch [{epoch+1}], Batch [{i+1}/{len(trainloader)}], Loss: {loss.item():.4f}, LR: {optimizer.param_groups[0][\"lr\"]:.6f}')\n",
    "    \n",
    "    epoch_loss = running_loss / len(trainloader)\n",
    "    accuracy_top1 = 100.0 * correct_top1 / total\n",
    "    accuracy_top5 = 100.0 * correct_top5 / total\n",
    "    \n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    # 학습 세트에 대한 성능 출력\n",
    "    print(f'Train set: Epoch: {epoch+1}, Average loss:{epoch_loss:.4f}, LR: {optimizer.param_groups[0][\"lr\"]:.6f} '\n",
    "          f'Top-1 Accuracy: {accuracy_top1:.4f}%, Top-5 Accuracy: {accuracy_top5:.4f}%, Time consumed:{train_time:.2f}s')\n",
    "    \n",
    "    return epoch_loss, accuracy_top1, accuracy_top5\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device, epoch, phase=\"test\"):\n",
    "    \"\"\"\n",
    "    평가 함수\n",
    "    \"\"\"\n",
    "    model.eval()  # 모델을 평가 모드로 설정\n",
    "    start_time = time.time()  # 시간 측정 시작\n",
    "    \n",
    "    eval_loss = 0.0\n",
    "    correct_top1 = 0\n",
    "    correct_top5 = 0\n",
    "    total = 0\n",
    "    \n",
    "    # 그래디언트 계산 비활성화\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # 순전파\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # 손실 계산\n",
    "            loss = criterion(outputs, labels)\n",
    "            eval_loss += loss.item()\n",
    "            \n",
    "            # top-1 정확도 계산\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct_top1 += (predicted == labels).sum().item()\n",
    "            \n",
    "            # top-5 정확도 계산\n",
    "            _, top5_idx = outputs.topk(5, 1, largest=True, sorted=True)\n",
    "            correct_top5 += top5_idx.eq(labels.view(-1, 1).expand_as(top5_idx)).sum().item()\n",
    "    \n",
    "    # 평균 손실 및 정확도 계산\n",
    "    eval_loss = eval_loss / len(dataloader)\n",
    "    accuracy_top1 = 100.0 * correct_top1 / total\n",
    "    accuracy_top5 = 100.0 * correct_top5 / total\n",
    "    \n",
    "    # 평가 시간 계산\n",
    "    eval_time = time.time() - start_time\n",
    "    \n",
    "    # 테스트 세트에 대한 성능 출력\n",
    "    print(f'{phase.capitalize()} set: Epoch: {epoch+1}, Average loss:{eval_loss:.4f}, '\n",
    "          f'Top-1 Accuracy: {accuracy_top1:.4f}%, Top-5 Accuracy: {accuracy_top5:.4f}%, Time consumed:{eval_time:.2f}s')\n",
    "    print()\n",
    "    \n",
    "    return eval_loss, accuracy_top1, accuracy_top5\n",
    "\n",
    "def main_training_loop(model, trainloader, testloader, criterion, optimizer, device, num_epochs, patience, max_epochs_wait, warmup_scheduler=None, main_scheduler=None, warmup_epochs=None):\n",
    "    \"\"\"\n",
    "    메인 학습 루프 (accuracy 기준 early stopping)\n",
    "    \"\"\"\n",
    "    if warmup_epochs is None:\n",
    "        warmup_epochs = config[\"warmup_epochs\"]\n",
    "        \n",
    "    # 정확도 기반 얼리 스토핑 사용\n",
    "    early_stopping = AccuracyEarlyStopping(patience=patience, verbose=True, path='checkpoint.pt', max_epochs=max_epochs_wait)\n",
    "    \n",
    "    best_test_acc_top1 = 0.0\n",
    "    best_test_acc_top5 = 0.0\n",
    "    \n",
    "    # 테스트 정확도 기록을 위한 리스트\n",
    "    test_acc_top1_history = []\n",
    "    \n",
    "    # tqdm을 사용한 진행 상황 표시\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        # 학습\n",
    "        train_loss, train_acc_top1, train_acc_top5 = train(\n",
    "            model, \n",
    "            trainloader, \n",
    "            criterion, \n",
    "            optimizer, \n",
    "            device, \n",
    "            epoch, \n",
    "            warmup_scheduler, \n",
    "            warmup_epochs\n",
    "        )\n",
    "        \n",
    "        # 테스트 데이터로 평가\n",
    "        test_loss, test_acc_top1, test_acc_top5 = evaluate(model, testloader, criterion, device, epoch, phase=\"test\")\n",
    "\n",
    "        # 웜업 이후 ReduceLROnPlateau 스케줄러 업데이트 \n",
    "        if epoch >= warmup_epochs and main_scheduler is not None:\n",
    "            main_scheduler.step(test_acc_top1)  # 테스트 정확도에 따라 학습률 업데이트       \n",
    "            \n",
    "        # 테스트 정확도 기록\n",
    "        test_acc_top1_history.append(test_acc_top1)\n",
    "        \n",
    "        # WandB에 로깅\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_accuracy_top1\": train_acc_top1,\n",
    "            \"train_accuracy_top5\": train_acc_top5,\n",
    "            \"test_loss\": test_loss,\n",
    "            \"test_accuracy_top1\": test_acc_top1,\n",
    "            \"test_accuracy_top5\": test_acc_top5\n",
    "        })\n",
    "            \n",
    "        # 최고 정확도 모델 저장 (top-1 기준)\n",
    "        if test_acc_top1 > best_test_acc_top1:\n",
    "            best_test_acc_top1 = test_acc_top1\n",
    "            best_test_acc_top5_at_best_top1 = test_acc_top5\n",
    "            print(f'새로운 최고 top-1 정확도: {best_test_acc_top1:.2f}%, top-5 정확도: {best_test_acc_top5_at_best_top1:.2f}%')\n",
    "            # 모델 저장\n",
    "            model_path = f'best_model_{wandb.run.name}.pth'\n",
    "            if isinstance(model, nn.DataParallel):\n",
    "                torch.save(model.module.state_dict(), model_path)  # DataParallel 래퍼 제거\n",
    "            else:\n",
    "                torch.save(model.state_dict(), model_path)\n",
    "            \n",
    "            # WandB에 모델 아티팩트 저장\n",
    "            wandb.save(model_path)\n",
    "        \n",
    "        # top-5 accuracy 기록 업데이트\n",
    "        if test_acc_top5 > best_test_acc_top5:\n",
    "            best_test_acc_top5 = test_acc_top5\n",
    "            print(f'새로운 최고 top-5 정확도: {best_test_acc_top5:.2f}%')\n",
    "\n",
    "        # Early stopping 체크 (test_acc_top1 기준)\n",
    "        early_stopping(test_acc_top1, model, epoch)\n",
    "        if early_stopping.early_stop:\n",
    "            print(f\"에폭 {epoch+1}에서 학습 조기 종료. 최고 성능 에폭: {early_stopping.best_epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    # 훈련 완료 후 최고 모델 로드\n",
    "    print(\"테스트 정확도 기준 최고 모델 로드 중...\")\n",
    "    model_path = f'best_model_{wandb.run.name}.pth'\n",
    "    \n",
    "    # 올바른 모델 로드를 위한 처리\n",
    "    if isinstance(model, nn.DataParallel):\n",
    "        model.module.load_state_dict(torch.load(model_path))\n",
    "    else:\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    # 최종 테스트 세트 평가\n",
    "    final_test_loss, final_test_acc_top1, final_test_acc_top5 = evaluate(model, testloader, criterion, device, num_epochs-1, phase=\"test\")\n",
    "    \n",
    "    print(f'완료! 최고 테스트 top-1 정확도: {best_test_acc_top1:.2f}%, 최고 테스트 top-5 정확도: {best_test_acc_top5:.2f}%')\n",
    "    print(f'최종 테스트 top-1 정확도: {final_test_acc_top1:.2f}%, 최종 테스트 top-5 정확도: {final_test_acc_top5:.2f}%')\n",
    "    \n",
    "    # WandB에 최종 결과 기록\n",
    "    wandb.run.summary[\"best_test_accuracy_top1\"] = best_test_acc_top1\n",
    "    wandb.run.summary[\"best_test_accuracy_top5\"] = best_test_acc_top5\n",
    "    wandb.run.summary[\"final_test_accuracy_top1\"] = final_test_acc_top1\n",
    "    wandb.run.summary[\"final_test_accuracy_top5\"] = final_test_acc_top5\n",
    "\n",
    "    # Early stopping 정보 저장\n",
    "    if early_stopping.early_stop:\n",
    "        wandb.run.summary[\"early_stopped\"] = True\n",
    "        wandb.run.summary[\"early_stopped_epoch\"] = epoch+1\n",
    "        wandb.run.summary[\"best_epoch\"] = early_stopping.best_epoch+1\n",
    "    else:\n",
    "        wandb.run.summary[\"early_stopped\"] = False\n",
    "\n",
    "\n",
    "# 디바이스 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 메모리 사용량 출력 함수 (디버깅용)\n",
    "def print_gpu_memory():\n",
    "    if torch.cuda.is_available():\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "            print(f\"Memory Allocated: {torch.cuda.memory_allocated(i)/1024**3:.2f} GB\")\n",
    "            print(f\"Memory Reserved: {torch.cuda.memory_reserved(i)/1024**3:.2f} GB\")\n",
    "            print(f\"Max Memory Allocated: {torch.cuda.max_memory_allocated(i)/1024**3:.2f} GB\")\n",
    "\n",
    "# GPU 메모리 초기 상태 출력\n",
    "print_gpu_memory()\n",
    "\n",
    "# Wide ResNet 모델 초기화\n",
    "model = Wide_ResNet(\n",
    "    depth=config[\"depth\"],\n",
    "    widen_factor=config[\"widen_factor\"],\n",
    "    dropout_rate=config[\"dropout_rate\"],\n",
    "    num_classes=100  # CIFAR-100은 100개 클래스\n",
    ").to(device)\n",
    "\n",
    "# 가중치 초기화 적용\n",
    "model.apply(conv_init)\n",
    "\n",
    "# 모델 파라미터 수 계산 및 출력\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "num_params = count_parameters(model)\n",
    "print(f'Wide-ResNet-{config[\"depth\"]}-{config[\"widen_factor\"]} initialized with {num_params:,} parameters')\n",
    "wandb.run.summary[\"model_parameters\"] = num_params\n",
    "\n",
    "# 손실 함수 설정 (라벨 스무딩 사용)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# SGD 옵티마이저 사용\n",
    "base_optimizer = optim.SGD\n",
    "optimizer = SAM(\n",
    "    model.parameters(), \n",
    "    base_optimizer, \n",
    "    lr=config[\"learning_rate\"],\n",
    "    momentum=config[\"momentum\"],\n",
    "    weight_decay=config[\"weight_decay\"],\n",
    "    nesterov=True  # Nesterov 모멘텀 사용\n",
    ")\n",
    "\n",
    "# WarmUpLR 스케줄러 초기화\n",
    "warmup_steps = config[\"warmup_epochs\"] * len(trainloader)\n",
    "warmup_scheduler = WarmUpLR(optimizer, total_iters=warmup_steps)\n",
    "\n",
    "# 웜업 이후 사용할 스케줄러 설정 \n",
    "main_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    mode='max',          \n",
    "    factor=0.5,          \n",
    "    patience=5,          \n",
    "    verbose=True,        \n",
    "    threshold=0.01,      \n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "# WandB에 모델 구조 기록\n",
    "wandb.watch(model, log=\"all\")\n",
    "\n",
    "# GPU 가속\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"{torch.cuda.device_count()}개의 GPU를 사용합니다.\")\n",
    "    model = nn.DataParallel(model)\n",
    "    \n",
    "# 모델 상태 요약 출력\n",
    "print(f\"Model: WideResNet-{config['depth']}-{config['widen_factor']}\")\n",
    "print(f\"Batch size: {config['batch_size']}\")\n",
    "print(f\"Learning rate: {config['learning_rate']}\")\n",
    "print(f\"Optimizer: {config['optimizer']} with SAM\")\n",
    "print(f\"Dropout rate: {config['dropout_rate']}\")\n",
    "\n",
    "# 훈련 시작 시간 기록\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    # 메인 학습 루프 호출\n",
    "    main_training_loop(\n",
    "        model=model,\n",
    "        trainloader=trainloader,\n",
    "        testloader=testloader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        device=device,\n",
    "        num_epochs=config[\"num_epochs\"],\n",
    "        patience=config[\"patience\"],\n",
    "        max_epochs_wait=config[\"max_epochs_wait\"],\n",
    "        warmup_scheduler=warmup_scheduler,\n",
    "        main_scheduler=main_scheduler,\n",
    "        warmup_epochs=config[\"warmup_epochs\"]\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"학습 중 오류 발생: {e}\")\n",
    "    # 오류 발생시 메모리 상태 출력\n",
    "    print_gpu_memory()\n",
    "    raise\n",
    "\n",
    "# 훈련 종료 시간 기록 및 출력\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "wandb.log({\"total_training_time\": total_time})\n",
    "\n",
    "print(f\"전체 학습 시간: {total_time:.2f} 초\")\n",
    "print(f\"전체 학습 시간: {total_time/3600:.2f} 시간\")\n",
    "\n",
    "# 최종 메모리 상태 출력\n",
    "print_gpu_memory()\n",
    "\n",
    "# WandB 실행 종료\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a335fa8-5b9c-49b7-9aac-11448f0e0225",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
