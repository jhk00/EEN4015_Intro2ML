{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "516f9d5f-6361-4b03-98ee-e1ba4de86b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">resnet18_cfc,warmup,reduce_standard</strong> at: <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/u8wz4ygc' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/u8wz4ygc</a><br> View project at: <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250417_135856-u8wz4ygc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/guswls/EEN4015_Intro2ML/pbl-2/wandb/run-20250417_135957-uhx0tl6z</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/uhx0tl6z' target=\"_blank\">resnet18_cfc,warmup,reduce_standard</a></strong> to <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/uhx0tl6z' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/uhx0tl6z</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 50000\n",
      "Test set size: 10000\n",
      "Using device: cuda\n",
      "2개의 GPU를 사용합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                       | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Batch [50/391], Loss: 4.5667, LR: 0.000026\n",
      "Epoch [1], Batch [100/391], Loss: 4.2502, LR: 0.000051\n",
      "Epoch [1], Batch [150/391], Loss: 3.9143, LR: 0.000077\n",
      "Epoch [1], Batch [200/391], Loss: 3.8876, LR: 0.000102\n",
      "Epoch [1], Batch [250/391], Loss: 3.8415, LR: 0.000128\n",
      "Epoch [1], Batch [300/391], Loss: 4.0891, LR: 0.000153\n",
      "Epoch [1], Batch [350/391], Loss: 4.2873, LR: 0.000179\n",
      "Train set: Epoch: 1, Average loss:4.1037, LR: 0.000200 Top-1 Accuracy: 8.5960%, Top-5 Accuracy: 26.3220%, Time consumed:47.61s\n",
      "Test set: Epoch: 1, Average loss:3.4827, Top-1 Accuracy: 16.7700%, Top-5 Accuracy: 43.9900%, Time consumed:8.13s\n",
      "\n",
      "새로운 최고 top-1 정확도: 16.77%, top-5 정확도: 43.99%\n",
      "새로운 최고 top-5 정확도: 43.99%\n",
      "Accuracy improved (-inf% --> 16.77%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                                            | 1/300 [00:55<4:38:53, 55.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], Batch [50/391], Loss: 3.3708, LR: 0.000226\n",
      "Epoch [2], Batch [100/391], Loss: 3.9990, LR: 0.000251\n",
      "Epoch [2], Batch [150/391], Loss: 3.8491, LR: 0.000277\n",
      "Epoch [2], Batch [200/391], Loss: 4.1340, LR: 0.000302\n",
      "Epoch [2], Batch [250/391], Loss: 3.9686, LR: 0.000328\n",
      "Epoch [2], Batch [300/391], Loss: 3.0584, LR: 0.000353\n",
      "Epoch [2], Batch [350/391], Loss: 3.8684, LR: 0.000379\n",
      "Train set: Epoch: 2, Average loss:3.5322, LR: 0.000400 Top-1 Accuracy: 18.4500%, Top-5 Accuracy: 44.9520%, Time consumed:51.09s\n",
      "Test set: Epoch: 2, Average loss:3.0410, Top-1 Accuracy: 25.2600%, Top-5 Accuracy: 55.4700%, Time consumed:9.24s\n",
      "\n",
      "새로운 최고 top-1 정확도: 25.26%, top-5 정확도: 55.47%\n",
      "새로운 최고 top-5 정확도: 55.47%\n",
      "Accuracy improved (16.77% --> 25.26%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▌                                                                                            | 2/300 [01:56<4:51:29, 58.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3], Batch [50/391], Loss: 3.0028, LR: 0.000426\n",
      "Epoch [3], Batch [100/391], Loss: 2.6660, LR: 0.000451\n",
      "Epoch [3], Batch [150/391], Loss: 2.6623, LR: 0.000477\n",
      "Epoch [3], Batch [200/391], Loss: 2.7751, LR: 0.000502\n",
      "Epoch [3], Batch [250/391], Loss: 2.6655, LR: 0.000528\n",
      "Epoch [3], Batch [300/391], Loss: 4.0198, LR: 0.000553\n",
      "Epoch [3], Batch [350/391], Loss: 2.4812, LR: 0.000579\n",
      "Train set: Epoch: 3, Average loss:3.1838, LR: 0.000600 Top-1 Accuracy: 25.6760%, Top-5 Accuracy: 55.3520%, Time consumed:50.77s\n",
      "Test set: Epoch: 3, Average loss:2.6383, Top-1 Accuracy: 32.5100%, Top-5 Accuracy: 65.3500%, Time consumed:8.39s\n",
      "\n",
      "새로운 최고 top-1 정확도: 32.51%, top-5 정확도: 65.35%\n",
      "새로운 최고 top-5 정확도: 65.35%\n",
      "Accuracy improved (25.26% --> 32.51%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▉                                                                                            | 3/300 [02:55<4:52:07, 59.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4], Batch [50/391], Loss: 3.7926, LR: 0.000626\n",
      "Epoch [4], Batch [100/391], Loss: 3.5072, LR: 0.000651\n",
      "Epoch [4], Batch [150/391], Loss: 3.8868, LR: 0.000677\n",
      "Epoch [4], Batch [200/391], Loss: 2.3241, LR: 0.000702\n",
      "Epoch [4], Batch [250/391], Loss: 3.8252, LR: 0.000728\n",
      "Epoch [4], Batch [300/391], Loss: 2.2208, LR: 0.000753\n",
      "Epoch [4], Batch [350/391], Loss: 2.8877, LR: 0.000779\n",
      "Train set: Epoch: 4, Average loss:2.8993, LR: 0.000800 Top-1 Accuracy: 31.9880%, Top-5 Accuracy: 62.5260%, Time consumed:48.90s\n",
      "Test set: Epoch: 4, Average loss:2.5303, Top-1 Accuracy: 36.1400%, Top-5 Accuracy: 67.5400%, Time consumed:8.80s\n",
      "\n",
      "새로운 최고 top-1 정확도: 36.14%, top-5 정확도: 67.54%\n",
      "새로운 최고 top-5 정확도: 67.54%\n",
      "Accuracy improved (32.51% --> 36.14%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▏                                                                                           | 4/300 [03:53<4:49:05, 58.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5], Batch [50/391], Loss: 1.9692, LR: 0.000826\n",
      "Epoch [5], Batch [100/391], Loss: 2.1236, LR: 0.000851\n",
      "Epoch [5], Batch [150/391], Loss: 2.0970, LR: 0.000877\n",
      "Epoch [5], Batch [200/391], Loss: 2.0776, LR: 0.000902\n",
      "Epoch [5], Batch [250/391], Loss: 3.7593, LR: 0.000928\n",
      "Epoch [5], Batch [300/391], Loss: 3.8061, LR: 0.000953\n",
      "Epoch [5], Batch [350/391], Loss: 3.7532, LR: 0.000979\n",
      "Train set: Epoch: 5, Average loss:2.7099, LR: 0.001000 Top-1 Accuracy: 36.9560%, Top-5 Accuracy: 67.4820%, Time consumed:47.73s\n",
      "Test set: Epoch: 5, Average loss:2.2061, Top-1 Accuracy: 42.4000%, Top-5 Accuracy: 73.5700%, Time consumed:9.32s\n",
      "\n",
      "새로운 최고 top-1 정확도: 42.40%, top-5 정확도: 73.57%\n",
      "새로운 최고 top-5 정확도: 73.57%\n",
      "Accuracy improved (36.14% --> 42.40%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▌                                                                                           | 5/300 [04:51<4:45:49, 58.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6], Batch [50/391], Loss: 1.6615, LR: 0.001000\n",
      "Epoch [6], Batch [100/391], Loss: 3.7853, LR: 0.001000\n",
      "Epoch [6], Batch [150/391], Loss: 2.0626, LR: 0.001000\n",
      "Epoch [6], Batch [200/391], Loss: 1.8427, LR: 0.001000\n",
      "Epoch [6], Batch [250/391], Loss: 3.7322, LR: 0.001000\n",
      "Epoch [6], Batch [300/391], Loss: 1.6547, LR: 0.001000\n",
      "Epoch [6], Batch [350/391], Loss: 1.6629, LR: 0.001000\n",
      "Train set: Epoch: 6, Average loss:2.5590, LR: 0.001000 Top-1 Accuracy: 40.6580%, Top-5 Accuracy: 70.7980%, Time consumed:47.78s\n",
      "Test set: Epoch: 6, Average loss:2.0171, Top-1 Accuracy: 45.7100%, Top-5 Accuracy: 77.1700%, Time consumed:8.18s\n",
      "\n",
      "새로운 최고 top-1 정확도: 45.71%, top-5 정확도: 77.17%\n",
      "새로운 최고 top-5 정확도: 77.17%\n",
      "Accuracy improved (42.40% --> 45.71%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▊                                                                                           | 6/300 [05:47<4:41:39, 57.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7], Batch [50/391], Loss: 3.5860, LR: 0.001000\n",
      "Epoch [7], Batch [100/391], Loss: 1.9806, LR: 0.001000\n",
      "Epoch [7], Batch [150/391], Loss: 1.6608, LR: 0.001000\n",
      "Epoch [7], Batch [200/391], Loss: 1.8116, LR: 0.001000\n",
      "Epoch [7], Batch [250/391], Loss: 3.2755, LR: 0.001000\n",
      "Epoch [7], Batch [300/391], Loss: 3.2914, LR: 0.001000\n",
      "Epoch [7], Batch [350/391], Loss: 1.7905, LR: 0.001000\n",
      "Train set: Epoch: 7, Average loss:2.3795, LR: 0.001000 Top-1 Accuracy: 45.0800%, Top-5 Accuracy: 74.9160%, Time consumed:47.83s\n",
      "Test set: Epoch: 7, Average loss:1.8059, Top-1 Accuracy: 51.2900%, Top-5 Accuracy: 81.0100%, Time consumed:8.69s\n",
      "\n",
      "새로운 최고 top-1 정확도: 51.29%, top-5 정확도: 81.01%\n",
      "새로운 최고 top-5 정확도: 81.01%\n",
      "Accuracy improved (45.71% --> 51.29%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██▏                                                                                          | 7/300 [06:44<4:39:34, 57.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8], Batch [50/391], Loss: 1.5912, LR: 0.001000\n",
      "Epoch [8], Batch [100/391], Loss: 1.6320, LR: 0.001000\n",
      "Epoch [8], Batch [150/391], Loss: 2.5498, LR: 0.001000\n",
      "Epoch [8], Batch [200/391], Loss: 3.1517, LR: 0.001000\n",
      "Epoch [8], Batch [250/391], Loss: 1.3832, LR: 0.001000\n",
      "Epoch [8], Batch [300/391], Loss: 1.5156, LR: 0.001000\n",
      "Epoch [8], Batch [350/391], Loss: 2.3058, LR: 0.001000\n",
      "Train set: Epoch: 8, Average loss:2.1331, LR: 0.001000 Top-1 Accuracy: 50.0480%, Top-5 Accuracy: 79.1520%, Time consumed:47.61s\n",
      "Test set: Epoch: 8, Average loss:1.6482, Top-1 Accuracy: 53.9400%, Top-5 Accuracy: 83.5300%, Time consumed:9.42s\n",
      "\n",
      "새로운 최고 top-1 정확도: 53.94%, top-5 정확도: 83.53%\n",
      "새로운 최고 top-5 정확도: 83.53%\n",
      "Accuracy improved (51.29% --> 53.94%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▍                                                                                          | 8/300 [07:41<4:38:40, 57.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9], Batch [50/391], Loss: 1.9324, LR: 0.001000\n",
      "Epoch [9], Batch [100/391], Loss: 3.8451, LR: 0.001000\n",
      "Epoch [9], Batch [150/391], Loss: 1.3709, LR: 0.001000\n",
      "Epoch [9], Batch [200/391], Loss: 3.2900, LR: 0.001000\n",
      "Epoch [9], Batch [250/391], Loss: 3.1220, LR: 0.001000\n",
      "Epoch [9], Batch [300/391], Loss: 2.8283, LR: 0.001000\n",
      "Epoch [9], Batch [350/391], Loss: 2.3589, LR: 0.001000\n",
      "Train set: Epoch: 9, Average loss:2.1968, LR: 0.001000 Top-1 Accuracy: 50.5000%, Top-5 Accuracy: 78.6800%, Time consumed:51.42s\n",
      "Test set: Epoch: 9, Average loss:1.5977, Top-1 Accuracy: 56.0300%, Top-5 Accuracy: 84.3200%, Time consumed:8.56s\n",
      "\n",
      "새로운 최고 top-1 정확도: 56.03%, top-5 정확도: 84.32%\n",
      "새로운 최고 top-5 정확도: 84.32%\n",
      "Accuracy improved (53.94% --> 56.03%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▊                                                                                          | 9/300 [08:41<4:42:12, 58.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10], Batch [50/391], Loss: 1.1499, LR: 0.001000\n",
      "Epoch [10], Batch [100/391], Loss: 1.4477, LR: 0.001000\n",
      "Epoch [10], Batch [150/391], Loss: 1.2525, LR: 0.001000\n",
      "Epoch [10], Batch [200/391], Loss: 1.4289, LR: 0.001000\n",
      "Epoch [10], Batch [250/391], Loss: 1.4138, LR: 0.001000\n",
      "Epoch [10], Batch [300/391], Loss: 3.0765, LR: 0.001000\n",
      "Epoch [10], Batch [350/391], Loss: 2.3160, LR: 0.001000\n",
      "Train set: Epoch: 10, Average loss:2.0969, LR: 0.001000 Top-1 Accuracy: 51.8860%, Top-5 Accuracy: 79.3580%, Time consumed:48.15s\n",
      "Test set: Epoch: 10, Average loss:1.5081, Top-1 Accuracy: 58.5500%, Top-5 Accuracy: 85.7200%, Time consumed:9.18s\n",
      "\n",
      "새로운 최고 top-1 정확도: 58.55%, top-5 정확도: 85.72%\n",
      "새로운 최고 top-5 정확도: 85.72%\n",
      "Accuracy improved (56.03% --> 58.55%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|███                                                                                         | 10/300 [09:39<4:40:20, 58.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11], Batch [50/391], Loss: 1.3691, LR: 0.001000\n",
      "Epoch [11], Batch [100/391], Loss: 3.3095, LR: 0.001000\n",
      "Epoch [11], Batch [150/391], Loss: 3.2352, LR: 0.001000\n",
      "Epoch [11], Batch [200/391], Loss: 2.0988, LR: 0.001000\n",
      "Epoch [11], Batch [250/391], Loss: 3.2170, LR: 0.001000\n",
      "Epoch [11], Batch [300/391], Loss: 1.1732, LR: 0.001000\n",
      "Epoch [11], Batch [350/391], Loss: 2.2417, LR: 0.001000\n",
      "Train set: Epoch: 11, Average loss:2.0666, LR: 0.001000 Top-1 Accuracy: 54.5580%, Top-5 Accuracy: 81.1360%, Time consumed:51.33s\n",
      "Test set: Epoch: 11, Average loss:1.3884, Top-1 Accuracy: 61.1600%, Top-5 Accuracy: 87.2700%, Time consumed:8.27s\n",
      "\n",
      "새로운 최고 top-1 정확도: 61.16%, top-5 정확도: 87.27%\n",
      "새로운 최고 top-5 정확도: 87.27%\n",
      "Accuracy improved (58.55% --> 61.16%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▎                                                                                        | 11/300 [10:39<4:42:07, 58.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12], Batch [50/391], Loss: 3.1684, LR: 0.001000\n",
      "Epoch [12], Batch [100/391], Loss: 3.4721, LR: 0.001000\n",
      "Epoch [12], Batch [150/391], Loss: 1.2905, LR: 0.001000\n",
      "Epoch [12], Batch [200/391], Loss: 1.1458, LR: 0.001000\n",
      "Epoch [12], Batch [250/391], Loss: 2.8443, LR: 0.001000\n",
      "Epoch [12], Batch [300/391], Loss: 1.0915, LR: 0.001000\n",
      "Epoch [12], Batch [350/391], Loss: 1.2041, LR: 0.001000\n",
      "Train set: Epoch: 12, Average loss:1.9488, LR: 0.001000 Top-1 Accuracy: 56.3580%, Top-5 Accuracy: 82.8880%, Time consumed:48.49s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▋                                                                                        | 12/300 [11:35<4:38:29, 58.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 12, Average loss:1.4164, Top-1 Accuracy: 61.1400%, Top-5 Accuracy: 87.0300%, Time consumed:8.25s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [13], Batch [50/391], Loss: 1.2462, LR: 0.001000\n",
      "Epoch [13], Batch [100/391], Loss: 1.0907, LR: 0.001000\n",
      "Epoch [13], Batch [150/391], Loss: 1.5844, LR: 0.001000\n",
      "Epoch [13], Batch [200/391], Loss: 1.2130, LR: 0.001000\n",
      "Epoch [13], Batch [250/391], Loss: 2.3885, LR: 0.001000\n",
      "Epoch [13], Batch [300/391], Loss: 2.8457, LR: 0.001000\n",
      "Epoch [13], Batch [350/391], Loss: 1.5751, LR: 0.001000\n",
      "Train set: Epoch: 13, Average loss:1.8465, LR: 0.001000 Top-1 Accuracy: 58.5120%, Top-5 Accuracy: 84.0800%, Time consumed:48.21s\n",
      "Test set: Epoch: 13, Average loss:1.3353, Top-1 Accuracy: 62.5700%, Top-5 Accuracy: 88.3700%, Time consumed:9.80s\n",
      "\n",
      "새로운 최고 top-1 정확도: 62.57%, top-5 정확도: 88.37%\n",
      "새로운 최고 top-5 정확도: 88.37%\n",
      "Accuracy improved (61.16% --> 62.57%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▉                                                                                        | 13/300 [12:34<4:37:51, 58.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14], Batch [50/391], Loss: 2.9162, LR: 0.001000\n",
      "Epoch [14], Batch [100/391], Loss: 3.1983, LR: 0.001000\n",
      "Epoch [14], Batch [150/391], Loss: 3.2710, LR: 0.001000\n",
      "Epoch [14], Batch [200/391], Loss: 3.4571, LR: 0.001000\n",
      "Epoch [14], Batch [250/391], Loss: 3.2631, LR: 0.001000\n",
      "Epoch [14], Batch [300/391], Loss: 1.0338, LR: 0.001000\n",
      "Epoch [14], Batch [350/391], Loss: 2.2666, LR: 0.001000\n",
      "Train set: Epoch: 14, Average loss:1.8358, LR: 0.001000 Top-1 Accuracy: 60.1560%, Top-5 Accuracy: 85.1840%, Time consumed:52.56s\n",
      "Test set: Epoch: 14, Average loss:1.2567, Top-1 Accuracy: 65.3400%, Top-5 Accuracy: 89.3300%, Time consumed:8.32s\n",
      "\n",
      "새로운 최고 top-1 정확도: 65.34%, top-5 정확도: 89.33%\n",
      "새로운 최고 top-5 정확도: 89.33%\n",
      "Accuracy improved (62.57% --> 65.34%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▎                                                                                       | 14/300 [13:35<4:41:17, 59.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15], Batch [50/391], Loss: 1.5715, LR: 0.001000\n",
      "Epoch [15], Batch [100/391], Loss: 1.9629, LR: 0.001000\n",
      "Epoch [15], Batch [150/391], Loss: 2.4121, LR: 0.001000\n",
      "Epoch [15], Batch [200/391], Loss: 0.8060, LR: 0.001000\n",
      "Epoch [15], Batch [250/391], Loss: 2.5764, LR: 0.001000\n",
      "Epoch [15], Batch [300/391], Loss: 3.4006, LR: 0.001000\n",
      "Epoch [15], Batch [350/391], Loss: 1.2691, LR: 0.001000\n",
      "Train set: Epoch: 15, Average loss:1.8002, LR: 0.001000 Top-1 Accuracy: 61.4560%, Top-5 Accuracy: 85.5480%, Time consumed:50.62s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▌                                                                                       | 15/300 [14:34<4:40:28, 59.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 15, Average loss:1.3697, Top-1 Accuracy: 62.3500%, Top-5 Accuracy: 87.7300%, Time consumed:8.50s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [16], Batch [50/391], Loss: 2.9985, LR: 0.001000\n",
      "Epoch [16], Batch [100/391], Loss: 2.2050, LR: 0.001000\n",
      "Epoch [16], Batch [150/391], Loss: 1.7121, LR: 0.001000\n",
      "Epoch [16], Batch [200/391], Loss: 0.8839, LR: 0.001000\n",
      "Epoch [16], Batch [250/391], Loss: 0.7522, LR: 0.001000\n",
      "Epoch [16], Batch [300/391], Loss: 0.8923, LR: 0.001000\n",
      "Epoch [16], Batch [350/391], Loss: 1.0826, LR: 0.001000\n",
      "Train set: Epoch: 16, Average loss:1.7868, LR: 0.001000 Top-1 Accuracy: 61.7040%, Top-5 Accuracy: 85.5280%, Time consumed:47.64s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▉                                                                                       | 16/300 [15:30<4:35:32, 58.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 16, Average loss:1.3763, Top-1 Accuracy: 62.6400%, Top-5 Accuracy: 87.9100%, Time consumed:8.63s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [17], Batch [50/391], Loss: 0.7295, LR: 0.001000\n",
      "Epoch [17], Batch [100/391], Loss: 3.0197, LR: 0.001000\n",
      "Epoch [17], Batch [150/391], Loss: 2.6658, LR: 0.001000\n",
      "Epoch [17], Batch [200/391], Loss: 1.0164, LR: 0.001000\n",
      "Epoch [17], Batch [250/391], Loss: 0.8728, LR: 0.001000\n",
      "Epoch [17], Batch [300/391], Loss: 1.5211, LR: 0.001000\n",
      "Epoch [17], Batch [350/391], Loss: 0.8094, LR: 0.001000\n",
      "Train set: Epoch: 17, Average loss:1.6887, LR: 0.001000 Top-1 Accuracy: 63.8700%, Top-5 Accuracy: 87.3300%, Time consumed:48.16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████▏                                                                                      | 17/300 [16:26<4:31:34, 57.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 17, Average loss:1.2884, Top-1 Accuracy: 64.7700%, Top-5 Accuracy: 89.0700%, Time consumed:7.93s\n",
      "\n",
      "EarlyStopping 카운터: 3 / 30\n",
      "Epoch [18], Batch [50/391], Loss: 2.6952, LR: 0.001000\n",
      "Epoch [18], Batch [100/391], Loss: 0.8060, LR: 0.001000\n",
      "Epoch [18], Batch [150/391], Loss: 0.6728, LR: 0.001000\n",
      "Epoch [18], Batch [200/391], Loss: 0.9202, LR: 0.001000\n",
      "Epoch [18], Batch [250/391], Loss: 0.7610, LR: 0.001000\n",
      "Epoch [18], Batch [300/391], Loss: 2.8026, LR: 0.001000\n",
      "Epoch [18], Batch [350/391], Loss: 0.7157, LR: 0.001000\n",
      "Train set: Epoch: 18, Average loss:1.6731, LR: 0.001000 Top-1 Accuracy: 65.0620%, Top-5 Accuracy: 88.0000%, Time consumed:48.31s\n",
      "Test set: Epoch: 18, Average loss:1.2657, Top-1 Accuracy: 65.9200%, Top-5 Accuracy: 89.0200%, Time consumed:8.20s\n",
      "\n",
      "새로운 최고 top-1 정확도: 65.92%, top-5 정확도: 89.02%\n",
      "Accuracy improved (65.34% --> 65.92%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████▌                                                                                      | 18/300 [17:23<4:29:29, 57.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19], Batch [50/391], Loss: 0.6263, LR: 0.000100\n",
      "Epoch [19], Batch [100/391], Loss: 0.6601, LR: 0.000100\n",
      "Epoch [19], Batch [150/391], Loss: 0.7138, LR: 0.000100\n",
      "Epoch [19], Batch [200/391], Loss: 0.8856, LR: 0.000100\n",
      "Epoch [19], Batch [250/391], Loss: 0.5445, LR: 0.000100\n",
      "Epoch [19], Batch [300/391], Loss: 2.9405, LR: 0.000100\n",
      "Epoch [19], Batch [350/391], Loss: 0.6672, LR: 0.000100\n",
      "Train set: Epoch: 19, Average loss:1.4490, LR: 0.000100 Top-1 Accuracy: 71.7700%, Top-5 Accuracy: 91.0160%, Time consumed:47.98s\n",
      "Test set: Epoch: 19, Average loss:0.9832, Top-1 Accuracy: 72.0600%, Top-5 Accuracy: 92.6100%, Time consumed:9.61s\n",
      "\n",
      "새로운 최고 top-1 정확도: 72.06%, top-5 정확도: 92.61%\n",
      "새로운 최고 top-5 정확도: 92.61%\n",
      "Accuracy improved (65.92% --> 72.06%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████▊                                                                                      | 19/300 [18:21<4:29:13, 57.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20], Batch [50/391], Loss: 0.5530, LR: 0.000100\n",
      "Epoch [20], Batch [100/391], Loss: 3.1170, LR: 0.000100\n",
      "Epoch [20], Batch [150/391], Loss: 2.5401, LR: 0.000100\n",
      "Epoch [20], Batch [200/391], Loss: 0.5595, LR: 0.000100\n",
      "Epoch [20], Batch [250/391], Loss: 2.8339, LR: 0.000100\n",
      "Epoch [20], Batch [300/391], Loss: 2.7012, LR: 0.000100\n",
      "Epoch [20], Batch [350/391], Loss: 1.9927, LR: 0.000100\n",
      "Train set: Epoch: 20, Average loss:1.4056, LR: 0.000100 Top-1 Accuracy: 73.0600%, Top-5 Accuracy: 91.4100%, Time consumed:48.35s\n",
      "Test set: Epoch: 20, Average loss:0.9497, Top-1 Accuracy: 73.0500%, Top-5 Accuracy: 93.0400%, Time consumed:8.57s\n",
      "\n",
      "새로운 최고 top-1 정확도: 73.05%, top-5 정확도: 93.04%\n",
      "새로운 최고 top-5 정확도: 93.04%\n",
      "Accuracy improved (72.06% --> 73.05%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████▏                                                                                     | 20/300 [19:18<4:27:48, 57.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21], Batch [50/391], Loss: 2.7247, LR: 0.000100\n",
      "Epoch [21], Batch [100/391], Loss: 2.6232, LR: 0.000100\n",
      "Epoch [21], Batch [150/391], Loss: 0.6535, LR: 0.000100\n",
      "Epoch [21], Batch [200/391], Loss: 0.4913, LR: 0.000100\n",
      "Epoch [21], Batch [250/391], Loss: 2.9943, LR: 0.000100\n",
      "Epoch [21], Batch [300/391], Loss: 2.7610, LR: 0.000100\n",
      "Epoch [21], Batch [350/391], Loss: 0.4995, LR: 0.000100\n",
      "Train set: Epoch: 21, Average loss:1.4657, LR: 0.000100 Top-1 Accuracy: 71.7660%, Top-5 Accuracy: 90.1540%, Time consumed:50.39s\n",
      "Test set: Epoch: 21, Average loss:0.9598, Top-1 Accuracy: 73.2100%, Top-5 Accuracy: 93.0100%, Time consumed:8.40s\n",
      "\n",
      "새로운 최고 top-1 정확도: 73.21%, top-5 정확도: 93.01%\n",
      "Accuracy improved (73.05% --> 73.21%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████▍                                                                                     | 21/300 [20:17<4:29:07, 57.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22], Batch [50/391], Loss: 2.1788, LR: 0.000100\n",
      "Epoch [22], Batch [100/391], Loss: 0.5103, LR: 0.000100\n",
      "Epoch [22], Batch [150/391], Loss: 0.6943, LR: 0.000100\n",
      "Epoch [22], Batch [200/391], Loss: 0.5197, LR: 0.000100\n",
      "Epoch [22], Batch [250/391], Loss: 0.4985, LR: 0.000100\n",
      "Epoch [22], Batch [300/391], Loss: 2.0957, LR: 0.000100\n",
      "Epoch [22], Batch [350/391], Loss: 2.3854, LR: 0.000100\n",
      "Train set: Epoch: 22, Average loss:1.3343, LR: 0.000100 Top-1 Accuracy: 74.8780%, Top-5 Accuracy: 92.1480%, Time consumed:47.85s\n",
      "Test set: Epoch: 22, Average loss:0.9570, Top-1 Accuracy: 73.4200%, Top-5 Accuracy: 93.1600%, Time consumed:8.54s\n",
      "\n",
      "새로운 최고 top-1 정확도: 73.42%, top-5 정확도: 93.16%\n",
      "새로운 최고 top-5 정확도: 93.16%\n",
      "Accuracy improved (73.21% --> 73.42%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████▋                                                                                     | 22/300 [21:14<4:26:25, 57.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23], Batch [50/391], Loss: 2.9184, LR: 0.000100\n",
      "Epoch [23], Batch [100/391], Loss: 0.4291, LR: 0.000100\n",
      "Epoch [23], Batch [150/391], Loss: 0.5478, LR: 0.000100\n",
      "Epoch [23], Batch [200/391], Loss: 0.4441, LR: 0.000100\n",
      "Epoch [23], Batch [250/391], Loss: 0.5310, LR: 0.000100\n",
      "Epoch [23], Batch [300/391], Loss: 0.3851, LR: 0.000100\n",
      "Epoch [23], Batch [350/391], Loss: 0.5148, LR: 0.000100\n",
      "Train set: Epoch: 23, Average loss:1.3931, LR: 0.000100 Top-1 Accuracy: 74.1940%, Top-5 Accuracy: 91.8240%, Time consumed:49.62s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███████                                                                                     | 23/300 [22:12<4:26:04, 57.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 23, Average loss:0.9735, Top-1 Accuracy: 73.2900%, Top-5 Accuracy: 93.1900%, Time consumed:8.32s\n",
      "\n",
      "새로운 최고 top-5 정확도: 93.19%\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [24], Batch [50/391], Loss: 2.7751, LR: 0.000100\n",
      "Epoch [24], Batch [100/391], Loss: 2.6640, LR: 0.000100\n",
      "Epoch [24], Batch [150/391], Loss: 1.8063, LR: 0.000100\n",
      "Epoch [24], Batch [200/391], Loss: 1.9915, LR: 0.000100\n",
      "Epoch [24], Batch [250/391], Loss: 2.5300, LR: 0.000100\n",
      "Epoch [24], Batch [300/391], Loss: 2.8273, LR: 0.000100\n",
      "Epoch [24], Batch [350/391], Loss: 0.5006, LR: 0.000100\n",
      "Train set: Epoch: 24, Average loss:1.3464, LR: 0.000100 Top-1 Accuracy: 73.8940%, Top-5 Accuracy: 91.4900%, Time consumed:47.79s\n",
      "Test set: Epoch: 24, Average loss:0.9419, Top-1 Accuracy: 73.5800%, Top-5 Accuracy: 93.1700%, Time consumed:8.30s\n",
      "\n",
      "새로운 최고 top-1 정확도: 73.58%, top-5 정확도: 93.17%\n",
      "Accuracy improved (73.42% --> 73.58%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███████▎                                                                                    | 24/300 [23:08<4:23:17, 57.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25], Batch [50/391], Loss: 0.5716, LR: 0.000010\n",
      "Epoch [25], Batch [100/391], Loss: 2.3999, LR: 0.000010\n",
      "Epoch [25], Batch [150/391], Loss: 0.4294, LR: 0.000010\n",
      "Epoch [25], Batch [200/391], Loss: 2.7599, LR: 0.000010\n",
      "Epoch [25], Batch [250/391], Loss: 0.3487, LR: 0.000010\n",
      "Epoch [25], Batch [300/391], Loss: 0.3911, LR: 0.000010\n",
      "Epoch [25], Batch [350/391], Loss: 1.7832, LR: 0.000010\n",
      "Train set: Epoch: 25, Average loss:1.3006, LR: 0.000010 Top-1 Accuracy: 75.7380%, Top-5 Accuracy: 92.4440%, Time consumed:50.28s\n",
      "Test set: Epoch: 25, Average loss:0.9237, Top-1 Accuracy: 74.1700%, Top-5 Accuracy: 93.4700%, Time consumed:8.79s\n",
      "\n",
      "새로운 최고 top-1 정확도: 74.17%, top-5 정확도: 93.47%\n",
      "새로운 최고 top-5 정확도: 93.47%\n",
      "Accuracy improved (73.58% --> 74.17%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███████▋                                                                                    | 25/300 [24:07<4:25:13, 57.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26], Batch [50/391], Loss: 2.6141, LR: 0.000010\n",
      "Epoch [26], Batch [100/391], Loss: 0.3675, LR: 0.000010\n",
      "Epoch [26], Batch [150/391], Loss: 1.8872, LR: 0.000010\n",
      "Epoch [26], Batch [200/391], Loss: 0.3545, LR: 0.000010\n",
      "Epoch [26], Batch [250/391], Loss: 1.4703, LR: 0.000010\n",
      "Epoch [26], Batch [300/391], Loss: 0.3037, LR: 0.000010\n",
      "Epoch [26], Batch [350/391], Loss: 2.7304, LR: 0.000010\n",
      "Train set: Epoch: 26, Average loss:1.3774, LR: 0.000010 Top-1 Accuracy: 75.1100%, Top-5 Accuracy: 92.1120%, Time consumed:52.37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███████▉                                                                                    | 26/300 [25:08<4:28:00, 58.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 26, Average loss:0.9327, Top-1 Accuracy: 74.1000%, Top-5 Accuracy: 93.4500%, Time consumed:8.23s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [27], Batch [50/391], Loss: 2.7330, LR: 0.000010\n",
      "Epoch [27], Batch [100/391], Loss: 2.6292, LR: 0.000010\n",
      "Epoch [27], Batch [150/391], Loss: 0.5123, LR: 0.000010\n",
      "Epoch [27], Batch [200/391], Loss: 2.3585, LR: 0.000010\n",
      "Epoch [27], Batch [250/391], Loss: 2.9326, LR: 0.000010\n",
      "Epoch [27], Batch [300/391], Loss: 0.3722, LR: 0.000010\n",
      "Epoch [27], Batch [350/391], Loss: 2.3613, LR: 0.000010\n",
      "Train set: Epoch: 27, Average loss:1.3044, LR: 0.000010 Top-1 Accuracy: 76.0500%, Top-5 Accuracy: 92.7560%, Time consumed:49.20s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|████████▎                                                                                   | 27/300 [26:05<4:25:17, 58.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 27, Average loss:0.9414, Top-1 Accuracy: 74.0600%, Top-5 Accuracy: 93.3400%, Time consumed:8.20s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [28], Batch [50/391], Loss: 0.4267, LR: 0.000010\n",
      "Epoch [28], Batch [100/391], Loss: 0.3681, LR: 0.000010\n",
      "Epoch [28], Batch [150/391], Loss: 0.3935, LR: 0.000010\n",
      "Epoch [28], Batch [200/391], Loss: 2.6576, LR: 0.000010\n",
      "Epoch [28], Batch [250/391], Loss: 2.1262, LR: 0.000010\n",
      "Epoch [28], Batch [300/391], Loss: 0.3892, LR: 0.000010\n",
      "Epoch [28], Batch [350/391], Loss: 2.8046, LR: 0.000010\n",
      "Train set: Epoch: 28, Average loss:1.3586, LR: 0.000010 Top-1 Accuracy: 75.2240%, Top-5 Accuracy: 92.2080%, Time consumed:51.37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|████████▌                                                                                   | 28/300 [27:06<4:27:25, 58.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 28, Average loss:0.9422, Top-1 Accuracy: 74.0400%, Top-5 Accuracy: 93.3600%, Time consumed:9.21s\n",
      "\n",
      "EarlyStopping 카운터: 3 / 30\n",
      "Epoch [29], Batch [50/391], Loss: 0.3751, LR: 0.000010\n",
      "Epoch [29], Batch [100/391], Loss: 0.4460, LR: 0.000010\n",
      "Epoch [29], Batch [150/391], Loss: 0.4041, LR: 0.000010\n",
      "Epoch [29], Batch [200/391], Loss: 2.5497, LR: 0.000010\n",
      "Epoch [29], Batch [250/391], Loss: 0.4580, LR: 0.000010\n",
      "Epoch [29], Batch [300/391], Loss: 2.7370, LR: 0.000010\n",
      "Epoch [29], Batch [350/391], Loss: 0.3592, LR: 0.000010\n",
      "Train set: Epoch: 29, Average loss:1.3174, LR: 0.000010 Top-1 Accuracy: 76.1240%, Top-5 Accuracy: 92.5000%, Time consumed:48.30s\n",
      "Test set: Epoch: 29, Average loss:0.9273, Top-1 Accuracy: 74.3900%, Top-5 Accuracy: 93.5100%, Time consumed:8.27s\n",
      "\n",
      "새로운 최고 top-1 정확도: 74.39%, top-5 정확도: 93.51%\n",
      "새로운 최고 top-5 정확도: 93.51%\n",
      "Accuracy improved (74.17% --> 74.39%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▉                                                                                   | 29/300 [28:03<4:23:31, 58.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30], Batch [50/391], Loss: 2.4854, LR: 0.000001\n",
      "Epoch [30], Batch [100/391], Loss: 0.3948, LR: 0.000001\n",
      "Epoch [30], Batch [150/391], Loss: 0.3469, LR: 0.000001\n",
      "Epoch [30], Batch [200/391], Loss: 2.3994, LR: 0.000001\n",
      "Epoch [30], Batch [250/391], Loss: 1.7425, LR: 0.000001\n",
      "Epoch [30], Batch [300/391], Loss: 0.3550, LR: 0.000001\n",
      "Epoch [30], Batch [350/391], Loss: 1.6889, LR: 0.000001\n",
      "Train set: Epoch: 30, Average loss:1.2573, LR: 0.000001 Top-1 Accuracy: 77.3120%, Top-5 Accuracy: 93.0800%, Time consumed:48.36s\n",
      "Test set: Epoch: 30, Average loss:0.9335, Top-1 Accuracy: 74.4300%, Top-5 Accuracy: 93.5300%, Time consumed:8.84s\n",
      "\n",
      "새로운 최고 top-1 정확도: 74.43%, top-5 정확도: 93.53%\n",
      "새로운 최고 top-5 정확도: 93.53%\n",
      "Accuracy improved (74.39% --> 74.43%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█████████▏                                                                                  | 30/300 [29:00<4:21:18, 58.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31], Batch [50/391], Loss: 0.3858, LR: 0.000001\n",
      "Epoch [31], Batch [100/391], Loss: 0.5515, LR: 0.000001\n",
      "Epoch [31], Batch [150/391], Loss: 0.7871, LR: 0.000001\n",
      "Epoch [31], Batch [200/391], Loss: 0.4080, LR: 0.000001\n",
      "Epoch [31], Batch [250/391], Loss: 0.4394, LR: 0.000001\n",
      "Epoch [31], Batch [300/391], Loss: 1.4461, LR: 0.000001\n",
      "Epoch [31], Batch [350/391], Loss: 2.1500, LR: 0.000001\n",
      "Train set: Epoch: 31, Average loss:1.3536, LR: 0.000001 Top-1 Accuracy: 75.4260%, Top-5 Accuracy: 92.2560%, Time consumed:50.77s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█████████▌                                                                                  | 31/300 [30:00<4:22:35, 58.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 31, Average loss:0.9357, Top-1 Accuracy: 74.4200%, Top-5 Accuracy: 93.3800%, Time consumed:8.96s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [32], Batch [50/391], Loss: 0.4980, LR: 0.000001\n",
      "Epoch [32], Batch [100/391], Loss: 2.9874, LR: 0.000001\n",
      "Epoch [32], Batch [150/391], Loss: 0.4178, LR: 0.000001\n",
      "Epoch [32], Batch [200/391], Loss: 0.3784, LR: 0.000001\n",
      "Epoch [32], Batch [250/391], Loss: 0.3355, LR: 0.000001\n",
      "Epoch [32], Batch [300/391], Loss: 0.3941, LR: 0.000001\n",
      "Epoch [32], Batch [350/391], Loss: 0.4111, LR: 0.000001\n",
      "Train set: Epoch: 32, Average loss:1.2884, LR: 0.000001 Top-1 Accuracy: 76.0000%, Top-5 Accuracy: 92.4560%, Time consumed:48.46s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█████████▊                                                                                  | 32/300 [30:57<4:19:32, 58.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 32, Average loss:0.9470, Top-1 Accuracy: 74.1700%, Top-5 Accuracy: 93.3700%, Time consumed:8.56s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [33], Batch [50/391], Loss: 2.3111, LR: 0.000001\n",
      "Epoch [33], Batch [100/391], Loss: 0.4278, LR: 0.000001\n",
      "Epoch [33], Batch [150/391], Loss: 0.5460, LR: 0.000001\n",
      "Epoch [33], Batch [200/391], Loss: 0.4281, LR: 0.000001\n",
      "Epoch [33], Batch [250/391], Loss: 2.3396, LR: 0.000001\n",
      "Epoch [33], Batch [300/391], Loss: 0.3381, LR: 0.000001\n",
      "Epoch [33], Batch [350/391], Loss: 2.4139, LR: 0.000001\n",
      "Train set: Epoch: 33, Average loss:1.2594, LR: 0.000001 Top-1 Accuracy: 77.0840%, Top-5 Accuracy: 93.1060%, Time consumed:49.52s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|██████████                                                                                  | 33/300 [31:55<4:18:35, 58.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 33, Average loss:0.9254, Top-1 Accuracy: 74.3100%, Top-5 Accuracy: 93.4600%, Time consumed:8.60s\n",
      "\n",
      "EarlyStopping 카운터: 3 / 30\n",
      "Epoch [34], Batch [50/391], Loss: 0.4925, LR: 0.000000\n",
      "Epoch [34], Batch [100/391], Loss: 2.6790, LR: 0.000000\n",
      "Epoch [34], Batch [150/391], Loss: 2.5117, LR: 0.000000\n",
      "Epoch [34], Batch [200/391], Loss: 0.4341, LR: 0.000000\n",
      "Epoch [34], Batch [250/391], Loss: 0.2803, LR: 0.000000\n",
      "Epoch [34], Batch [300/391], Loss: 0.4426, LR: 0.000000\n",
      "Epoch [34], Batch [350/391], Loss: 2.0272, LR: 0.000000\n",
      "Train set: Epoch: 34, Average loss:1.3052, LR: 0.000000 Top-1 Accuracy: 75.3200%, Top-5 Accuracy: 91.9880%, Time consumed:48.09s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|██████████▍                                                                                 | 34/300 [32:53<4:16:41, 57.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 34, Average loss:0.9280, Top-1 Accuracy: 74.1900%, Top-5 Accuracy: 93.4300%, Time consumed:9.31s\n",
      "\n",
      "EarlyStopping 카운터: 4 / 30\n",
      "Epoch [35], Batch [50/391], Loss: 0.4199, LR: 0.000000\n",
      "Epoch [35], Batch [100/391], Loss: 2.6969, LR: 0.000000\n",
      "Epoch [35], Batch [150/391], Loss: 1.8692, LR: 0.000000\n",
      "Epoch [35], Batch [200/391], Loss: 2.5770, LR: 0.000000\n",
      "Epoch [35], Batch [250/391], Loss: 2.8202, LR: 0.000000\n",
      "Epoch [35], Batch [300/391], Loss: 0.2568, LR: 0.000000\n",
      "Epoch [35], Batch [350/391], Loss: 2.2376, LR: 0.000000\n",
      "Train set: Epoch: 35, Average loss:1.3743, LR: 0.000000 Top-1 Accuracy: 75.4100%, Top-5 Accuracy: 92.3760%, Time consumed:47.92s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████▋                                                                                 | 35/300 [33:49<4:13:50, 57.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 35, Average loss:0.9311, Top-1 Accuracy: 74.1300%, Top-5 Accuracy: 93.4800%, Time consumed:8.55s\n",
      "\n",
      "EarlyStopping 카운터: 5 / 30\n",
      "Epoch [36], Batch [50/391], Loss: 0.9634, LR: 0.000000\n",
      "Epoch [36], Batch [100/391], Loss: 0.3336, LR: 0.000000\n",
      "Epoch [36], Batch [150/391], Loss: 0.4175, LR: 0.000000\n",
      "Epoch [36], Batch [200/391], Loss: 2.8957, LR: 0.000000\n",
      "Epoch [36], Batch [250/391], Loss: 1.3535, LR: 0.000000\n",
      "Epoch [36], Batch [300/391], Loss: 0.4990, LR: 0.000000\n",
      "Epoch [36], Batch [350/391], Loss: 0.5615, LR: 0.000000\n",
      "Train set: Epoch: 36, Average loss:1.3182, LR: 0.000000 Top-1 Accuracy: 75.7680%, Top-5 Accuracy: 92.3380%, Time consumed:48.05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|███████████                                                                                 | 36/300 [34:45<4:11:15, 57.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 36, Average loss:0.9249, Top-1 Accuracy: 74.2600%, Top-5 Accuracy: 93.4200%, Time consumed:8.19s\n",
      "\n",
      "EarlyStopping 카운터: 6 / 30\n",
      "Epoch [37], Batch [50/391], Loss: 2.6888, LR: 0.000000\n",
      "Epoch [37], Batch [100/391], Loss: 0.4564, LR: 0.000000\n",
      "Epoch [37], Batch [150/391], Loss: 2.8705, LR: 0.000000\n",
      "Epoch [37], Batch [200/391], Loss: 2.3846, LR: 0.000000\n",
      "Epoch [37], Batch [250/391], Loss: 0.6793, LR: 0.000000\n",
      "Epoch [37], Batch [300/391], Loss: 1.7059, LR: 0.000000\n",
      "Epoch [37], Batch [350/391], Loss: 2.7212, LR: 0.000000\n",
      "Train set: Epoch: 37, Average loss:1.3376, LR: 0.000000 Top-1 Accuracy: 75.3000%, Top-5 Accuracy: 92.1340%, Time consumed:47.81s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|███████████▎                                                                                | 37/300 [35:42<4:09:19, 56.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 37, Average loss:0.9276, Top-1 Accuracy: 74.1400%, Top-5 Accuracy: 93.4800%, Time consumed:8.55s\n",
      "\n",
      "EarlyStopping 카운터: 7 / 30\n",
      "Epoch [38], Batch [50/391], Loss: 0.2915, LR: 0.000000\n",
      "Epoch [38], Batch [100/391], Loss: 0.3504, LR: 0.000000\n",
      "Epoch [38], Batch [150/391], Loss: 2.6833, LR: 0.000000\n",
      "Epoch [38], Batch [200/391], Loss: 0.2966, LR: 0.000000\n",
      "Epoch [38], Batch [250/391], Loss: 0.4470, LR: 0.000000\n",
      "Epoch [38], Batch [300/391], Loss: 0.3894, LR: 0.000000\n",
      "Epoch [38], Batch [350/391], Loss: 2.8061, LR: 0.000000\n",
      "Train set: Epoch: 38, Average loss:1.3080, LR: 0.000000 Top-1 Accuracy: 76.4820%, Top-5 Accuracy: 92.5300%, Time consumed:49.05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|███████████▋                                                                                | 38/300 [36:39<4:09:09, 57.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 38, Average loss:0.9295, Top-1 Accuracy: 74.3700%, Top-5 Accuracy: 93.4600%, Time consumed:8.42s\n",
      "\n",
      "EarlyStopping 카운터: 8 / 30\n",
      "Epoch [39], Batch [50/391], Loss: 1.7163, LR: 0.000000\n",
      "Epoch [39], Batch [100/391], Loss: 1.0613, LR: 0.000000\n",
      "Epoch [39], Batch [150/391], Loss: 1.5312, LR: 0.000000\n",
      "Epoch [39], Batch [200/391], Loss: 0.7654, LR: 0.000000\n",
      "Epoch [39], Batch [250/391], Loss: 0.3542, LR: 0.000000\n",
      "Epoch [39], Batch [300/391], Loss: 0.4966, LR: 0.000000\n",
      "Epoch [39], Batch [350/391], Loss: 0.3354, LR: 0.000000\n",
      "Train set: Epoch: 39, Average loss:1.2454, LR: 0.000000 Top-1 Accuracy: 77.0680%, Top-5 Accuracy: 92.7920%, Time consumed:47.36s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|███████████▉                                                                                | 39/300 [37:35<4:06:17, 56.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 39, Average loss:0.9341, Top-1 Accuracy: 74.1100%, Top-5 Accuracy: 93.3500%, Time consumed:8.22s\n",
      "\n",
      "EarlyStopping 카운터: 9 / 30\n",
      "Epoch [40], Batch [50/391], Loss: 0.4432, LR: 0.000000\n",
      "Epoch [40], Batch [100/391], Loss: 2.7551, LR: 0.000000\n",
      "Epoch [40], Batch [150/391], Loss: 0.3834, LR: 0.000000\n",
      "Epoch [40], Batch [200/391], Loss: 2.6667, LR: 0.000000\n",
      "Epoch [40], Batch [250/391], Loss: 1.4170, LR: 0.000000\n",
      "Epoch [40], Batch [300/391], Loss: 0.3937, LR: 0.000000\n",
      "Epoch [40], Batch [350/391], Loss: 0.4435, LR: 0.000000\n",
      "Train set: Epoch: 40, Average loss:1.2492, LR: 0.000000 Top-1 Accuracy: 77.0740%, Top-5 Accuracy: 92.7240%, Time consumed:48.63s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|████████████▎                                                                               | 40/300 [38:32<4:06:29, 56.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 40, Average loss:0.9318, Top-1 Accuracy: 74.2400%, Top-5 Accuracy: 93.4600%, Time consumed:8.87s\n",
      "\n",
      "EarlyStopping 카운터: 10 / 30\n",
      "Epoch [41], Batch [50/391], Loss: 1.3242, LR: 0.000000\n",
      "Epoch [41], Batch [100/391], Loss: 2.9710, LR: 0.000000\n",
      "Epoch [41], Batch [150/391], Loss: 0.5516, LR: 0.000000\n",
      "Epoch [41], Batch [200/391], Loss: 0.4868, LR: 0.000000\n",
      "Epoch [41], Batch [250/391], Loss: 2.5680, LR: 0.000000\n",
      "Epoch [41], Batch [300/391], Loss: 2.4147, LR: 0.000000\n",
      "Epoch [41], Batch [350/391], Loss: 1.5441, LR: 0.000000\n",
      "Train set: Epoch: 41, Average loss:1.3284, LR: 0.000000 Top-1 Accuracy: 75.7060%, Top-5 Accuracy: 92.3720%, Time consumed:48.41s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████▌                                                                               | 41/300 [39:29<4:05:33, 56.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 41, Average loss:0.9195, Top-1 Accuracy: 74.4100%, Top-5 Accuracy: 93.4900%, Time consumed:8.47s\n",
      "\n",
      "EarlyStopping 카운터: 11 / 30\n",
      "Epoch [42], Batch [50/391], Loss: 0.3430, LR: 0.000000\n",
      "Epoch [42], Batch [100/391], Loss: 2.6795, LR: 0.000000\n",
      "Epoch [42], Batch [150/391], Loss: 2.8371, LR: 0.000000\n",
      "Epoch [42], Batch [200/391], Loss: 1.8828, LR: 0.000000\n",
      "Epoch [42], Batch [250/391], Loss: 0.3880, LR: 0.000000\n",
      "Epoch [42], Batch [300/391], Loss: 2.7243, LR: 0.000000\n",
      "Epoch [42], Batch [350/391], Loss: 0.4338, LR: 0.000000\n",
      "Train set: Epoch: 42, Average loss:1.2462, LR: 0.000000 Top-1 Accuracy: 77.6120%, Top-5 Accuracy: 93.0660%, Time consumed:47.96s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████▉                                                                               | 42/300 [40:25<4:03:49, 56.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 42, Average loss:0.9353, Top-1 Accuracy: 74.2500%, Top-5 Accuracy: 93.4300%, Time consumed:8.31s\n",
      "\n",
      "EarlyStopping 카운터: 12 / 30\n",
      "Epoch [43], Batch [50/391], Loss: 2.1184, LR: 0.000000\n",
      "Epoch [43], Batch [100/391], Loss: 2.1725, LR: 0.000000\n",
      "Epoch [43], Batch [150/391], Loss: 2.1458, LR: 0.000000\n",
      "Epoch [43], Batch [200/391], Loss: 0.3676, LR: 0.000000\n",
      "Epoch [43], Batch [250/391], Loss: 2.4305, LR: 0.000000\n",
      "Epoch [43], Batch [300/391], Loss: 2.9625, LR: 0.000000\n",
      "Epoch [43], Batch [350/391], Loss: 0.6805, LR: 0.000000\n",
      "Train set: Epoch: 43, Average loss:1.3080, LR: 0.000000 Top-1 Accuracy: 76.3480%, Top-5 Accuracy: 92.6560%, Time consumed:48.81s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█████████████▏                                                                              | 43/300 [41:23<4:03:43, 56.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 43, Average loss:0.9446, Top-1 Accuracy: 74.0600%, Top-5 Accuracy: 93.4300%, Time consumed:8.55s\n",
      "\n",
      "EarlyStopping 카운터: 13 / 30\n",
      "Epoch [44], Batch [50/391], Loss: 0.3519, LR: 0.000000\n",
      "Epoch [44], Batch [100/391], Loss: 0.6602, LR: 0.000000\n",
      "Epoch [44], Batch [150/391], Loss: 2.5449, LR: 0.000000\n",
      "Epoch [44], Batch [200/391], Loss: 0.4015, LR: 0.000000\n",
      "Epoch [44], Batch [250/391], Loss: 0.3952, LR: 0.000000\n",
      "Epoch [44], Batch [300/391], Loss: 0.5234, LR: 0.000000\n",
      "Epoch [44], Batch [350/391], Loss: 0.3904, LR: 0.000000\n",
      "Train set: Epoch: 44, Average loss:1.2427, LR: 0.000000 Top-1 Accuracy: 77.0000%, Top-5 Accuracy: 92.9760%, Time consumed:49.67s\n",
      "Test set: Epoch: 44, Average loss:0.9253, Top-1 Accuracy: 74.5700%, Top-5 Accuracy: 93.5000%, Time consumed:8.75s\n",
      "\n",
      "새로운 최고 top-1 정확도: 74.57%, top-5 정확도: 93.50%\n",
      "Accuracy improved (74.43% --> 74.57%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████████████▍                                                                              | 44/300 [42:21<4:05:02, 57.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45], Batch [50/391], Loss: 2.6660, LR: 0.000000\n",
      "Epoch [45], Batch [100/391], Loss: 0.4124, LR: 0.000000\n",
      "Epoch [45], Batch [150/391], Loss: 0.3710, LR: 0.000000\n",
      "Epoch [45], Batch [200/391], Loss: 0.4410, LR: 0.000000\n",
      "Epoch [45], Batch [250/391], Loss: 2.1422, LR: 0.000000\n",
      "Epoch [45], Batch [300/391], Loss: 0.5537, LR: 0.000000\n",
      "Epoch [45], Batch [350/391], Loss: 0.3298, LR: 0.000000\n",
      "Train set: Epoch: 45, Average loss:1.2571, LR: 0.000000 Top-1 Accuracy: 76.6580%, Top-5 Accuracy: 92.7080%, Time consumed:48.75s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████████████▊                                                                              | 45/300 [43:19<4:04:04, 57.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 45, Average loss:0.9217, Top-1 Accuracy: 74.2900%, Top-5 Accuracy: 93.4300%, Time consumed:8.66s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [46], Batch [50/391], Loss: 2.5081, LR: 0.000000\n",
      "Epoch [46], Batch [100/391], Loss: 2.5229, LR: 0.000000\n",
      "Epoch [46], Batch [150/391], Loss: 0.3567, LR: 0.000000\n",
      "Epoch [46], Batch [200/391], Loss: 0.3966, LR: 0.000000\n",
      "Epoch [46], Batch [250/391], Loss: 0.7908, LR: 0.000000\n",
      "Epoch [46], Batch [300/391], Loss: 0.4229, LR: 0.000000\n",
      "Epoch [46], Batch [350/391], Loss: 2.1905, LR: 0.000000\n",
      "Train set: Epoch: 46, Average loss:1.2526, LR: 0.000000 Top-1 Accuracy: 78.2200%, Top-5 Accuracy: 93.6580%, Time consumed:51.50s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|██████████████                                                                              | 46/300 [44:20<4:07:45, 58.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 46, Average loss:0.9259, Top-1 Accuracy: 74.3300%, Top-5 Accuracy: 93.4700%, Time consumed:9.58s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [47], Batch [50/391], Loss: 2.6467, LR: 0.000000\n",
      "Epoch [47], Batch [100/391], Loss: 2.2931, LR: 0.000000\n",
      "Epoch [47], Batch [150/391], Loss: 2.5996, LR: 0.000000\n",
      "Epoch [47], Batch [200/391], Loss: 2.5484, LR: 0.000000\n",
      "Epoch [47], Batch [250/391], Loss: 0.4041, LR: 0.000000\n",
      "Epoch [47], Batch [300/391], Loss: 0.4480, LR: 0.000000\n",
      "Epoch [47], Batch [350/391], Loss: 1.6172, LR: 0.000000\n",
      "Train set: Epoch: 47, Average loss:1.2211, LR: 0.000000 Top-1 Accuracy: 77.8460%, Top-5 Accuracy: 93.3820%, Time consumed:49.73s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████████████▍                                                                             | 47/300 [45:18<4:06:16, 58.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 47, Average loss:0.9231, Top-1 Accuracy: 74.4800%, Top-5 Accuracy: 93.4700%, Time consumed:8.39s\n",
      "\n",
      "EarlyStopping 카운터: 3 / 30\n",
      "Epoch [48], Batch [50/391], Loss: 2.7198, LR: 0.000000\n",
      "Epoch [48], Batch [100/391], Loss: 2.8221, LR: 0.000000\n",
      "Epoch [48], Batch [150/391], Loss: 0.3507, LR: 0.000000\n",
      "Epoch [48], Batch [200/391], Loss: 2.1367, LR: 0.000000\n",
      "Epoch [48], Batch [250/391], Loss: 0.4466, LR: 0.000000\n",
      "Epoch [48], Batch [300/391], Loss: 2.7369, LR: 0.000000\n",
      "Epoch [48], Batch [350/391], Loss: 0.6980, LR: 0.000000\n",
      "Train set: Epoch: 48, Average loss:1.2569, LR: 0.000000 Top-1 Accuracy: 76.0960%, Top-5 Accuracy: 92.0400%, Time consumed:52.13s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████████████▋                                                                             | 48/300 [46:19<4:08:03, 59.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 48, Average loss:0.9434, Top-1 Accuracy: 74.2200%, Top-5 Accuracy: 93.3400%, Time consumed:8.46s\n",
      "\n",
      "EarlyStopping 카운터: 4 / 30\n",
      "Epoch [49], Batch [50/391], Loss: 0.3932, LR: 0.000000\n",
      "Epoch [49], Batch [100/391], Loss: 1.3976, LR: 0.000000\n",
      "Epoch [49], Batch [150/391], Loss: 2.9141, LR: 0.000000\n",
      "Epoch [49], Batch [200/391], Loss: 0.8229, LR: 0.000000\n",
      "Epoch [49], Batch [250/391], Loss: 0.3221, LR: 0.000000\n",
      "Epoch [49], Batch [300/391], Loss: 0.4771, LR: 0.000000\n",
      "Epoch [49], Batch [350/391], Loss: 3.0710, LR: 0.000000\n",
      "Train set: Epoch: 49, Average loss:1.3114, LR: 0.000000 Top-1 Accuracy: 75.9200%, Top-5 Accuracy: 91.9800%, Time consumed:48.47s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|███████████████                                                                             | 49/300 [47:16<4:04:38, 58.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 49, Average loss:0.9264, Top-1 Accuracy: 74.2500%, Top-5 Accuracy: 93.3700%, Time consumed:8.64s\n",
      "\n",
      "EarlyStopping 카운터: 5 / 30\n",
      "Epoch [50], Batch [50/391], Loss: 0.4610, LR: 0.000000\n",
      "Epoch [50], Batch [100/391], Loss: 0.3359, LR: 0.000000\n",
      "Epoch [50], Batch [150/391], Loss: 0.3718, LR: 0.000000\n",
      "Epoch [50], Batch [200/391], Loss: 0.4037, LR: 0.000000\n",
      "Epoch [50], Batch [250/391], Loss: 0.3676, LR: 0.000000\n",
      "Epoch [50], Batch [300/391], Loss: 0.2860, LR: 0.000000\n",
      "Epoch [50], Batch [350/391], Loss: 2.3522, LR: 0.000000\n",
      "Train set: Epoch: 50, Average loss:1.2454, LR: 0.000000 Top-1 Accuracy: 77.2960%, Top-5 Accuracy: 92.9960%, Time consumed:49.49s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████████████▎                                                                            | 50/300 [48:14<4:03:30, 58.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 50, Average loss:0.9312, Top-1 Accuracy: 74.2400%, Top-5 Accuracy: 93.5300%, Time consumed:8.86s\n",
      "\n",
      "EarlyStopping 카운터: 6 / 30\n",
      "Epoch [51], Batch [50/391], Loss: 1.1401, LR: 0.000000\n",
      "Epoch [51], Batch [100/391], Loss: 0.4704, LR: 0.000000\n",
      "Epoch [51], Batch [150/391], Loss: 0.4375, LR: 0.000000\n",
      "Epoch [51], Batch [200/391], Loss: 0.3884, LR: 0.000000\n",
      "Epoch [51], Batch [250/391], Loss: 2.6873, LR: 0.000000\n",
      "Epoch [51], Batch [300/391], Loss: 2.4828, LR: 0.000000\n",
      "Epoch [51], Batch [350/391], Loss: 0.4398, LR: 0.000000\n",
      "Train set: Epoch: 51, Average loss:1.2566, LR: 0.000000 Top-1 Accuracy: 77.7040%, Top-5 Accuracy: 93.2360%, Time consumed:47.76s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████████████▋                                                                            | 51/300 [49:10<3:59:38, 57.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 51, Average loss:0.9156, Top-1 Accuracy: 74.3500%, Top-5 Accuracy: 93.5700%, Time consumed:8.35s\n",
      "\n",
      "새로운 최고 top-5 정확도: 93.57%\n",
      "EarlyStopping 카운터: 7 / 30\n",
      "Epoch [52], Batch [50/391], Loss: 0.4303, LR: 0.000000\n",
      "Epoch [52], Batch [100/391], Loss: 1.7708, LR: 0.000000\n",
      "Epoch [52], Batch [150/391], Loss: 2.6050, LR: 0.000000\n",
      "Epoch [52], Batch [200/391], Loss: 0.3441, LR: 0.000000\n",
      "Epoch [52], Batch [250/391], Loss: 0.4380, LR: 0.000000\n",
      "Epoch [52], Batch [300/391], Loss: 0.5449, LR: 0.000000\n",
      "Epoch [52], Batch [350/391], Loss: 0.3584, LR: 0.000000\n",
      "Train set: Epoch: 52, Average loss:1.3413, LR: 0.000000 Top-1 Accuracy: 75.4140%, Top-5 Accuracy: 92.0440%, Time consumed:48.44s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████████████▉                                                                            | 52/300 [50:07<3:57:53, 57.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 52, Average loss:0.9356, Top-1 Accuracy: 74.2700%, Top-5 Accuracy: 93.5300%, Time consumed:8.66s\n",
      "\n",
      "EarlyStopping 카운터: 8 / 30\n",
      "Epoch [53], Batch [50/391], Loss: 0.3457, LR: 0.000000\n",
      "Epoch [53], Batch [100/391], Loss: 2.2470, LR: 0.000000\n",
      "Epoch [53], Batch [150/391], Loss: 2.7395, LR: 0.000000\n",
      "Epoch [53], Batch [200/391], Loss: 0.9249, LR: 0.000000\n",
      "Epoch [53], Batch [250/391], Loss: 0.3550, LR: 0.000000\n",
      "Epoch [53], Batch [300/391], Loss: 0.3348, LR: 0.000000\n",
      "Epoch [53], Batch [350/391], Loss: 2.2733, LR: 0.000000\n",
      "Train set: Epoch: 53, Average loss:1.2167, LR: 0.000000 Top-1 Accuracy: 77.6800%, Top-5 Accuracy: 93.0660%, Time consumed:49.50s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|████████████████▎                                                                           | 53/300 [51:05<3:57:29, 57.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 53, Average loss:0.9319, Top-1 Accuracy: 74.3000%, Top-5 Accuracy: 93.3900%, Time consumed:8.51s\n",
      "\n",
      "EarlyStopping 카운터: 9 / 30\n",
      "Epoch [54], Batch [50/391], Loss: 0.3219, LR: 0.000000\n",
      "Epoch [54], Batch [100/391], Loss: 1.6300, LR: 0.000000\n",
      "Epoch [54], Batch [150/391], Loss: 1.1359, LR: 0.000000\n",
      "Epoch [54], Batch [200/391], Loss: 2.5234, LR: 0.000000\n",
      "Epoch [54], Batch [250/391], Loss: 0.3378, LR: 0.000000\n",
      "Epoch [54], Batch [300/391], Loss: 0.3698, LR: 0.000000\n",
      "Epoch [54], Batch [350/391], Loss: 0.4378, LR: 0.000000\n",
      "Train set: Epoch: 54, Average loss:1.3436, LR: 0.000000 Top-1 Accuracy: 75.0900%, Top-5 Accuracy: 91.9000%, Time consumed:47.62s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|████████████████▌                                                                           | 54/300 [52:02<3:54:42, 57.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 54, Average loss:0.9276, Top-1 Accuracy: 74.1000%, Top-5 Accuracy: 93.4400%, Time consumed:8.58s\n",
      "\n",
      "EarlyStopping 카운터: 10 / 30\n",
      "Epoch [55], Batch [50/391], Loss: 0.4597, LR: 0.000000\n",
      "Epoch [55], Batch [100/391], Loss: 0.3809, LR: 0.000000\n",
      "Epoch [55], Batch [150/391], Loss: 0.4523, LR: 0.000000\n",
      "Epoch [55], Batch [200/391], Loss: 0.3746, LR: 0.000000\n",
      "Epoch [55], Batch [250/391], Loss: 2.4573, LR: 0.000000\n",
      "Epoch [55], Batch [300/391], Loss: 2.2049, LR: 0.000000\n",
      "Epoch [55], Batch [350/391], Loss: 0.5422, LR: 0.000000\n",
      "Train set: Epoch: 55, Average loss:1.3482, LR: 0.000000 Top-1 Accuracy: 75.6160%, Top-5 Accuracy: 92.1380%, Time consumed:50.06s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|████████████████▊                                                                           | 55/300 [53:01<3:56:16, 57.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 55, Average loss:0.9313, Top-1 Accuracy: 74.2400%, Top-5 Accuracy: 93.3900%, Time consumed:9.24s\n",
      "\n",
      "EarlyStopping 카운터: 11 / 30\n",
      "Epoch [56], Batch [50/391], Loss: 0.3305, LR: 0.000000\n",
      "Epoch [56], Batch [100/391], Loss: 0.3351, LR: 0.000000\n",
      "Epoch [56], Batch [150/391], Loss: 1.2935, LR: 0.000000\n",
      "Epoch [56], Batch [200/391], Loss: 2.3543, LR: 0.000000\n",
      "Epoch [56], Batch [250/391], Loss: 1.5931, LR: 0.000000\n",
      "Epoch [56], Batch [300/391], Loss: 0.3601, LR: 0.000000\n",
      "Epoch [56], Batch [350/391], Loss: 0.4645, LR: 0.000000\n",
      "Train set: Epoch: 56, Average loss:1.3152, LR: 0.000000 Top-1 Accuracy: 76.3180%, Top-5 Accuracy: 92.4580%, Time consumed:47.67s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█████████████████▏                                                                          | 56/300 [53:57<3:52:56, 57.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 56, Average loss:0.9398, Top-1 Accuracy: 74.1600%, Top-5 Accuracy: 93.4100%, Time consumed:8.25s\n",
      "\n",
      "EarlyStopping 카운터: 12 / 30\n",
      "Epoch [57], Batch [50/391], Loss: 0.4696, LR: 0.000000\n",
      "Epoch [57], Batch [100/391], Loss: 1.4570, LR: 0.000000\n",
      "Epoch [57], Batch [150/391], Loss: 2.4296, LR: 0.000000\n",
      "Epoch [57], Batch [200/391], Loss: 2.5941, LR: 0.000000\n",
      "Epoch [57], Batch [250/391], Loss: 0.3999, LR: 0.000000\n",
      "Epoch [57], Batch [300/391], Loss: 2.8532, LR: 0.000000\n",
      "Epoch [57], Batch [350/391], Loss: 2.3527, LR: 0.000000\n",
      "Train set: Epoch: 57, Average loss:1.3026, LR: 0.000000 Top-1 Accuracy: 75.9960%, Top-5 Accuracy: 92.4420%, Time consumed:47.60s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█████████████████▍                                                                          | 57/300 [54:53<3:50:37, 56.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 57, Average loss:0.9376, Top-1 Accuracy: 74.3300%, Top-5 Accuracy: 93.3900%, Time consumed:8.57s\n",
      "\n",
      "EarlyStopping 카운터: 13 / 30\n",
      "Epoch [58], Batch [50/391], Loss: 0.4528, LR: 0.000000\n",
      "Epoch [58], Batch [100/391], Loss: 0.4097, LR: 0.000000\n",
      "Epoch [58], Batch [150/391], Loss: 0.4570, LR: 0.000000\n",
      "Epoch [58], Batch [200/391], Loss: 0.3346, LR: 0.000000\n",
      "Epoch [58], Batch [250/391], Loss: 2.4296, LR: 0.000000\n",
      "Epoch [58], Batch [300/391], Loss: 1.7372, LR: 0.000000\n",
      "Epoch [58], Batch [350/391], Loss: 1.1107, LR: 0.000000\n",
      "Train set: Epoch: 58, Average loss:1.2550, LR: 0.000000 Top-1 Accuracy: 76.8220%, Top-5 Accuracy: 92.5340%, Time consumed:47.48s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█████████████████▊                                                                          | 58/300 [55:49<3:48:38, 56.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 58, Average loss:0.9450, Top-1 Accuracy: 74.1100%, Top-5 Accuracy: 93.2800%, Time consumed:8.60s\n",
      "\n",
      "EarlyStopping 카운터: 14 / 30\n",
      "Epoch [59], Batch [50/391], Loss: 2.4712, LR: 0.000000\n",
      "Epoch [59], Batch [100/391], Loss: 2.5641, LR: 0.000000\n",
      "Epoch [59], Batch [150/391], Loss: 0.4438, LR: 0.000000\n",
      "Epoch [59], Batch [200/391], Loss: 0.3447, LR: 0.000000\n",
      "Epoch [59], Batch [250/391], Loss: 0.4435, LR: 0.000000\n",
      "Epoch [59], Batch [300/391], Loss: 0.4964, LR: 0.000000\n",
      "Epoch [59], Batch [350/391], Loss: 0.3207, LR: 0.000000\n",
      "Train set: Epoch: 59, Average loss:1.3368, LR: 0.000000 Top-1 Accuracy: 74.8840%, Top-5 Accuracy: 91.4420%, Time consumed:47.93s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████████████                                                                          | 59/300 [56:45<3:47:00, 56.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 59, Average loss:0.9276, Top-1 Accuracy: 74.2700%, Top-5 Accuracy: 93.4900%, Time consumed:8.18s\n",
      "\n",
      "EarlyStopping 카운터: 15 / 30\n",
      "Epoch [60], Batch [50/391], Loss: 0.3451, LR: 0.000000\n",
      "Epoch [60], Batch [100/391], Loss: 0.4900, LR: 0.000000\n",
      "Epoch [60], Batch [150/391], Loss: 0.8869, LR: 0.000000\n",
      "Epoch [60], Batch [200/391], Loss: 2.1090, LR: 0.000000\n",
      "Epoch [60], Batch [250/391], Loss: 2.5234, LR: 0.000000\n",
      "Epoch [60], Batch [300/391], Loss: 1.5928, LR: 0.000000\n",
      "Epoch [60], Batch [350/391], Loss: 2.8457, LR: 0.000000\n",
      "Train set: Epoch: 60, Average loss:1.3243, LR: 0.000000 Top-1 Accuracy: 75.8080%, Top-5 Accuracy: 92.1040%, Time consumed:47.53s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████████████▍                                                                         | 60/300 [57:41<3:45:08, 56.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 60, Average loss:0.9282, Top-1 Accuracy: 74.3000%, Top-5 Accuracy: 93.5500%, Time consumed:8.21s\n",
      "\n",
      "EarlyStopping 카운터: 16 / 30\n",
      "Epoch [61], Batch [50/391], Loss: 0.3392, LR: 0.000000\n",
      "Epoch [61], Batch [100/391], Loss: 0.3314, LR: 0.000000\n",
      "Epoch [61], Batch [150/391], Loss: 0.4078, LR: 0.000000\n",
      "Epoch [61], Batch [200/391], Loss: 0.3722, LR: 0.000000\n",
      "Epoch [61], Batch [250/391], Loss: 2.8285, LR: 0.000000\n",
      "Epoch [61], Batch [300/391], Loss: 0.4004, LR: 0.000000\n",
      "Epoch [61], Batch [350/391], Loss: 0.4985, LR: 0.000000\n",
      "Train set: Epoch: 61, Average loss:1.2810, LR: 0.000000 Top-1 Accuracy: 77.2720%, Top-5 Accuracy: 93.1560%, Time consumed:47.91s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████████████▋                                                                         | 61/300 [58:38<3:44:47, 56.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 61, Average loss:0.9380, Top-1 Accuracy: 74.2000%, Top-5 Accuracy: 93.3200%, Time consumed:8.87s\n",
      "\n",
      "EarlyStopping 카운터: 17 / 30\n",
      "Epoch [62], Batch [50/391], Loss: 0.4422, LR: 0.000000\n",
      "Epoch [62], Batch [100/391], Loss: 0.3117, LR: 0.000000\n",
      "Epoch [62], Batch [150/391], Loss: 2.4000, LR: 0.000000\n",
      "Epoch [62], Batch [200/391], Loss: 0.3854, LR: 0.000000\n",
      "Epoch [62], Batch [250/391], Loss: 0.3925, LR: 0.000000\n",
      "Epoch [62], Batch [300/391], Loss: 0.4143, LR: 0.000000\n",
      "Epoch [62], Batch [350/391], Loss: 0.3368, LR: 0.000000\n",
      "Train set: Epoch: 62, Average loss:1.2626, LR: 0.000000 Top-1 Accuracy: 77.3160%, Top-5 Accuracy: 93.1540%, Time consumed:48.07s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|███████████████████                                                                         | 62/300 [59:34<3:43:47, 56.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 62, Average loss:0.9174, Top-1 Accuracy: 74.2700%, Top-5 Accuracy: 93.5500%, Time consumed:8.31s\n",
      "\n",
      "EarlyStopping 카운터: 18 / 30\n",
      "Epoch [63], Batch [50/391], Loss: 0.4338, LR: 0.000000\n",
      "Epoch [63], Batch [100/391], Loss: 1.8375, LR: 0.000000\n",
      "Epoch [63], Batch [150/391], Loss: 2.0063, LR: 0.000000\n",
      "Epoch [63], Batch [200/391], Loss: 0.3743, LR: 0.000000\n",
      "Epoch [63], Batch [250/391], Loss: 0.5745, LR: 0.000000\n",
      "Epoch [63], Batch [300/391], Loss: 1.8625, LR: 0.000000\n",
      "Epoch [63], Batch [350/391], Loss: 0.4041, LR: 0.000000\n",
      "Train set: Epoch: 63, Average loss:1.3016, LR: 0.000000 Top-1 Accuracy: 76.1860%, Top-5 Accuracy: 92.3940%, Time consumed:50.89s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██████████████████▉                                                                       | 63/300 [1:00:33<3:46:21, 57.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 63, Average loss:0.9165, Top-1 Accuracy: 74.2400%, Top-5 Accuracy: 93.5600%, Time consumed:8.48s\n",
      "\n",
      "EarlyStopping 카운터: 19 / 30\n",
      "Epoch [64], Batch [50/391], Loss: 0.2965, LR: 0.000000\n",
      "Epoch [64], Batch [100/391], Loss: 0.4589, LR: 0.000000\n",
      "Epoch [64], Batch [150/391], Loss: 0.3502, LR: 0.000000\n",
      "Epoch [64], Batch [200/391], Loss: 0.9516, LR: 0.000000\n",
      "Epoch [64], Batch [250/391], Loss: 0.3899, LR: 0.000000\n",
      "Epoch [64], Batch [300/391], Loss: 3.0594, LR: 0.000000\n",
      "Epoch [64], Batch [350/391], Loss: 2.6979, LR: 0.000000\n",
      "Train set: Epoch: 64, Average loss:1.2807, LR: 0.000000 Top-1 Accuracy: 76.7540%, Top-5 Accuracy: 92.8440%, Time consumed:50.80s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|███████████████████▏                                                                      | 64/300 [1:01:34<3:48:58, 58.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 64, Average loss:0.9257, Top-1 Accuracy: 74.3400%, Top-5 Accuracy: 93.4800%, Time consumed:9.52s\n",
      "\n",
      "EarlyStopping 카운터: 20 / 30\n",
      "Epoch [65], Batch [50/391], Loss: 0.3441, LR: 0.000000\n",
      "Epoch [65], Batch [100/391], Loss: 1.2058, LR: 0.000000\n",
      "Epoch [65], Batch [150/391], Loss: 0.3784, LR: 0.000000\n",
      "Epoch [65], Batch [200/391], Loss: 0.3530, LR: 0.000000\n",
      "Epoch [65], Batch [250/391], Loss: 0.3769, LR: 0.000000\n",
      "Epoch [65], Batch [300/391], Loss: 0.3504, LR: 0.000000\n",
      "Epoch [65], Batch [350/391], Loss: 0.3704, LR: 0.000000\n",
      "Train set: Epoch: 65, Average loss:1.2747, LR: 0.000000 Top-1 Accuracy: 77.1860%, Top-5 Accuracy: 93.1400%, Time consumed:48.19s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|███████████████████▌                                                                      | 65/300 [1:02:31<3:46:37, 57.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 65, Average loss:0.9259, Top-1 Accuracy: 74.3000%, Top-5 Accuracy: 93.3600%, Time consumed:8.85s\n",
      "\n",
      "EarlyStopping 카운터: 21 / 30\n",
      "Epoch [66], Batch [50/391], Loss: 0.4585, LR: 0.000000\n",
      "Epoch [66], Batch [100/391], Loss: 0.4385, LR: 0.000000\n",
      "Epoch [66], Batch [150/391], Loss: 0.4455, LR: 0.000000\n",
      "Epoch [66], Batch [200/391], Loss: 0.3994, LR: 0.000000\n",
      "Epoch [66], Batch [250/391], Loss: 2.4998, LR: 0.000000\n",
      "Epoch [66], Batch [300/391], Loss: 0.3782, LR: 0.000000\n",
      "Epoch [66], Batch [350/391], Loss: 1.9942, LR: 0.000000\n",
      "Train set: Epoch: 66, Average loss:1.2699, LR: 0.000000 Top-1 Accuracy: 76.8840%, Top-5 Accuracy: 92.9040%, Time consumed:48.58s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|███████████████████▊                                                                      | 66/300 [1:03:28<3:44:43, 57.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 66, Average loss:0.9369, Top-1 Accuracy: 74.1900%, Top-5 Accuracy: 93.3000%, Time consumed:8.47s\n",
      "\n",
      "EarlyStopping 카운터: 22 / 30\n",
      "Epoch [67], Batch [50/391], Loss: 0.4487, LR: 0.000000\n",
      "Epoch [67], Batch [100/391], Loss: 0.2500, LR: 0.000000\n",
      "Epoch [67], Batch [150/391], Loss: 2.7400, LR: 0.000000\n",
      "Epoch [67], Batch [200/391], Loss: 0.4774, LR: 0.000000\n",
      "Epoch [67], Batch [250/391], Loss: 0.4632, LR: 0.000000\n",
      "Epoch [67], Batch [300/391], Loss: 0.3663, LR: 0.000000\n",
      "Epoch [67], Batch [350/391], Loss: 0.5240, LR: 0.000000\n",
      "Train set: Epoch: 67, Average loss:1.2460, LR: 0.000000 Top-1 Accuracy: 76.4120%, Top-5 Accuracy: 92.2360%, Time consumed:49.25s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|████████████████████                                                                      | 67/300 [1:04:26<3:44:31, 57.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 67, Average loss:0.9548, Top-1 Accuracy: 74.0500%, Top-5 Accuracy: 93.2600%, Time consumed:9.03s\n",
      "\n",
      "EarlyStopping 카운터: 23 / 30\n",
      "Epoch [68], Batch [50/391], Loss: 0.3648, LR: 0.000000\n",
      "Epoch [68], Batch [100/391], Loss: 0.4199, LR: 0.000000\n",
      "Epoch [68], Batch [150/391], Loss: 1.5338, LR: 0.000000\n",
      "Epoch [68], Batch [200/391], Loss: 2.4374, LR: 0.000000\n",
      "Epoch [68], Batch [250/391], Loss: 0.3829, LR: 0.000000\n",
      "Epoch [68], Batch [300/391], Loss: 0.3067, LR: 0.000000\n",
      "Epoch [68], Batch [350/391], Loss: 0.4209, LR: 0.000000\n",
      "Train set: Epoch: 68, Average loss:1.2234, LR: 0.000000 Top-1 Accuracy: 77.2300%, Top-5 Accuracy: 92.9640%, Time consumed:48.02s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|████████████████████▍                                                                     | 68/300 [1:05:22<3:41:51, 57.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 68, Average loss:0.9164, Top-1 Accuracy: 74.2900%, Top-5 Accuracy: 93.5200%, Time consumed:8.32s\n",
      "\n",
      "EarlyStopping 카운터: 24 / 30\n",
      "Epoch [69], Batch [50/391], Loss: 0.3450, LR: 0.000000\n",
      "Epoch [69], Batch [100/391], Loss: 0.4552, LR: 0.000000\n",
      "Epoch [69], Batch [150/391], Loss: 0.4483, LR: 0.000000\n",
      "Epoch [69], Batch [200/391], Loss: 2.8553, LR: 0.000000\n",
      "Epoch [69], Batch [250/391], Loss: 2.3056, LR: 0.000000\n",
      "Epoch [69], Batch [300/391], Loss: 2.8837, LR: 0.000000\n",
      "Epoch [69], Batch [350/391], Loss: 0.4320, LR: 0.000000\n",
      "Train set: Epoch: 69, Average loss:1.3229, LR: 0.000000 Top-1 Accuracy: 75.8900%, Top-5 Accuracy: 92.5440%, Time consumed:47.60s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|████████████████████▋                                                                     | 69/300 [1:06:18<3:39:21, 56.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 69, Average loss:0.9405, Top-1 Accuracy: 74.1800%, Top-5 Accuracy: 93.3900%, Time consumed:8.44s\n",
      "\n",
      "EarlyStopping 카운터: 25 / 30\n",
      "Epoch [70], Batch [50/391], Loss: 1.5086, LR: 0.000000\n",
      "Epoch [70], Batch [100/391], Loss: 2.7536, LR: 0.000000\n",
      "Epoch [70], Batch [150/391], Loss: 0.2675, LR: 0.000000\n",
      "Epoch [70], Batch [200/391], Loss: 0.4409, LR: 0.000000\n",
      "Epoch [70], Batch [250/391], Loss: 2.1930, LR: 0.000000\n",
      "Epoch [70], Batch [300/391], Loss: 1.9561, LR: 0.000000\n",
      "Epoch [70], Batch [350/391], Loss: 0.4600, LR: 0.000000\n",
      "Train set: Epoch: 70, Average loss:1.3228, LR: 0.000000 Top-1 Accuracy: 75.1840%, Top-5 Accuracy: 92.1180%, Time consumed:48.38s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|█████████████████████                                                                     | 70/300 [1:07:16<3:38:36, 57.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 70, Average loss:0.9445, Top-1 Accuracy: 74.1200%, Top-5 Accuracy: 93.3800%, Time consumed:8.77s\n",
      "\n",
      "EarlyStopping 카운터: 26 / 30\n",
      "Epoch [71], Batch [50/391], Loss: 1.8461, LR: 0.000000\n",
      "Epoch [71], Batch [100/391], Loss: 2.1134, LR: 0.000000\n",
      "Epoch [71], Batch [150/391], Loss: 0.4324, LR: 0.000000\n",
      "Epoch [71], Batch [200/391], Loss: 2.5017, LR: 0.000000\n",
      "Epoch [71], Batch [250/391], Loss: 1.2749, LR: 0.000000\n",
      "Epoch [71], Batch [300/391], Loss: 0.5484, LR: 0.000000\n",
      "Epoch [71], Batch [350/391], Loss: 0.3822, LR: 0.000000\n",
      "Train set: Epoch: 71, Average loss:1.2429, LR: 0.000000 Top-1 Accuracy: 77.6300%, Top-5 Accuracy: 93.3400%, Time consumed:49.59s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|█████████████████████▎                                                                    | 71/300 [1:08:14<3:38:52, 57.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 71, Average loss:0.9389, Top-1 Accuracy: 74.2200%, Top-5 Accuracy: 93.4600%, Time consumed:8.48s\n",
      "\n",
      "EarlyStopping 카운터: 27 / 30\n",
      "Epoch [72], Batch [50/391], Loss: 2.4252, LR: 0.000000\n",
      "Epoch [72], Batch [100/391], Loss: 2.8174, LR: 0.000000\n",
      "Epoch [72], Batch [150/391], Loss: 0.6340, LR: 0.000000\n",
      "Epoch [72], Batch [200/391], Loss: 0.4791, LR: 0.000000\n",
      "Epoch [72], Batch [250/391], Loss: 1.1597, LR: 0.000000\n",
      "Epoch [72], Batch [300/391], Loss: 0.5779, LR: 0.000000\n",
      "Epoch [72], Batch [350/391], Loss: 2.9034, LR: 0.000000\n",
      "Train set: Epoch: 72, Average loss:1.2718, LR: 0.000000 Top-1 Accuracy: 77.1580%, Top-5 Accuracy: 93.0560%, Time consumed:50.05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|█████████████████████▌                                                                    | 72/300 [1:09:12<3:39:01, 57.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 72, Average loss:0.9261, Top-1 Accuracy: 74.4400%, Top-5 Accuracy: 93.4800%, Time consumed:8.27s\n",
      "\n",
      "EarlyStopping 카운터: 28 / 30\n",
      "Epoch [73], Batch [50/391], Loss: 1.1091, LR: 0.000000\n",
      "Epoch [73], Batch [100/391], Loss: 0.3461, LR: 0.000000\n",
      "Epoch [73], Batch [150/391], Loss: 2.3590, LR: 0.000000\n",
      "Epoch [73], Batch [200/391], Loss: 0.3477, LR: 0.000000\n",
      "Epoch [73], Batch [250/391], Loss: 2.6706, LR: 0.000000\n",
      "Epoch [73], Batch [300/391], Loss: 0.4508, LR: 0.000000\n",
      "Epoch [73], Batch [350/391], Loss: 2.7751, LR: 0.000000\n",
      "Train set: Epoch: 73, Average loss:1.1526, LR: 0.000000 Top-1 Accuracy: 78.6240%, Top-5 Accuracy: 93.6320%, Time consumed:48.31s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|█████████████████████▉                                                                    | 73/300 [1:10:09<3:37:20, 57.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 73, Average loss:0.9178, Top-1 Accuracy: 74.4000%, Top-5 Accuracy: 93.5600%, Time consumed:8.68s\n",
      "\n",
      "EarlyStopping 카운터: 29 / 30\n",
      "Epoch [74], Batch [50/391], Loss: 0.4085, LR: 0.000000\n",
      "Epoch [74], Batch [100/391], Loss: 0.4022, LR: 0.000000\n",
      "Epoch [74], Batch [150/391], Loss: 2.8489, LR: 0.000000\n",
      "Epoch [74], Batch [200/391], Loss: 0.3925, LR: 0.000000\n",
      "Epoch [74], Batch [250/391], Loss: 0.3748, LR: 0.000000\n",
      "Epoch [74], Batch [300/391], Loss: 2.5323, LR: 0.000000\n",
      "Epoch [74], Batch [350/391], Loss: 0.6285, LR: 0.000000\n",
      "Train set: Epoch: 74, Average loss:1.2563, LR: 0.000000 Top-1 Accuracy: 76.5800%, Top-5 Accuracy: 92.4600%, Time consumed:49.81s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|█████████████████████▉                                                                    | 73/300 [1:11:08<3:41:13, 58.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 74, Average loss:0.9297, Top-1 Accuracy: 74.3200%, Top-5 Accuracy: 93.4000%, Time consumed:9.36s\n",
      "\n",
      "EarlyStopping 카운터: 30 / 30\n",
      "에폭 74에서 학습 조기 종료. 최고 성능 에폭: 44\n",
      "테스트 정확도 기준 최고 모델 로드 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 300, Average loss:0.9253, Top-1 Accuracy: 74.5700%, Top-5 Accuracy: 93.5000%, Time consumed:8.26s\n",
      "\n",
      "완료! 최고 테스트 top-1 정확도: 74.57%, 최고 테스트 top-5 정확도: 93.57%\n",
      "최종 테스트 top-1 정확도: 74.57%, 최종 테스트 top-5 정확도: 93.50%\n",
      "전체 학습 시간: 4277.04 초\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇█</td></tr><tr><td>learning_rate</td><td>▂▄▅▇███████▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_accuracy_top1</td><td>▁▂▃▃▄▆▆▆▇▇▇█████████████████████████████</td></tr><tr><td>test_accuracy_top5</td><td>▁▅▆▆▇▇▇▇▇███████████████████████████████</td></tr><tr><td>test_loss</td><td>█▇▆▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>total_training_time</td><td>▁</td></tr><tr><td>train_accuracy_top1</td><td>▁▂▃▃▄▅▅▅▆▆▇▇▇█▇█████████████████████████</td></tr><tr><td>train_accuracy_top5</td><td>▁▂▄▅▆▆▇▇▇███████████████████████████████</td></tr><tr><td>train_loss</td><td>█▇▆▅▄▄▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>44</td></tr><tr><td>best_test_accuracy_top1</td><td>74.57</td></tr><tr><td>best_test_accuracy_top5</td><td>93.57</td></tr><tr><td>early_stopped</td><td>True</td></tr><tr><td>early_stopped_epoch</td><td>74</td></tr><tr><td>epoch</td><td>74</td></tr><tr><td>final_test_accuracy_top1</td><td>74.57</td></tr><tr><td>final_test_accuracy_top5</td><td>93.5</td></tr><tr><td>learning_rate</td><td>0.0</td></tr><tr><td>test_accuracy_top1</td><td>74.32</td></tr><tr><td>test_accuracy_top5</td><td>93.4</td></tr><tr><td>test_loss</td><td>0.9297</td></tr><tr><td>total_training_time</td><td>4277.04283</td></tr><tr><td>train_accuracy_top1</td><td>76.58</td></tr><tr><td>train_accuracy_top5</td><td>92.46</td></tr><tr><td>train_loss</td><td>1.25625</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">resnet18_cfc,warmup,reduce_standard</strong> at: <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/uhx0tl6z' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/uhx0tl6z</a><br> View project at: <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250417_135957-uhx0tl6z/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.v2 as transforms_v2  # CutMix를 위한 v2 transforms 추가\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "from tools.tool import AccuracyEarlyStopping, WarmUpLR  # 수정된 AccuracyEarlyStopping 클래스 임포트\n",
    "from models.resnet import resnet18\n",
    "\n",
    "wandb.login(key=\"ef091b9abcea3186341ddf8995d62bde62d7469e\")\n",
    "wandb.init(project=\"PBL-2\", name=\"resnet18_cfc,warmup,reduce_standard\")  \n",
    "\n",
    "# WandB 설정\n",
    "config = {\n",
    "    \"model\": \"resnet18\",\n",
    "    \"batch_size\": 256,\n",
    "    \"num_epochs\": 300,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"seed\": 2025,\n",
    "    \"deterministic\": False,\n",
    "    \"patience\": 30,  # early stopping patience\n",
    "    \"max_epochs_wait\": float('inf'),  # 최대 30 에폭까지만 기다림\n",
    "    \"cutmix_alpha\": 1.0,  # CutMix 알파 파라미터 추가\n",
    "    \"cutmix_prob\": 0.5,   # CutMix 적용 확률 추가\n",
    "    \"crop_padding\": 4,    # RandomCrop 패딩 크기\n",
    "    \"crop_size\": 32,      # RandomCrop 크기 (CIFAR-100 이미지 크기는 32x32)\n",
    "    \"warmup_epochs\": 5,   # 웜업할 에폭 수 추가\n",
    "}\n",
    "wandb.config.update(config)\n",
    "\n",
    "# CIFAR-100 데이터셋 로드 - 기본 train/test 분할 사용\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(config[\"crop_size\"], padding=config[\"crop_padding\"]),  # 패딩 후 랜덤 크롭\n",
    "    transforms.RandomHorizontalFlip(),  # 수평 뒤집기\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR100(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR100(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "# DataLoader 생성\n",
    "trainloader = DataLoader(trainset, batch_size=config[\"batch_size\"], shuffle=True, num_workers=16)\n",
    "testloader = DataLoader(testset, batch_size=config[\"batch_size\"], shuffle=False, num_workers=16)\n",
    "\n",
    "print(f\"Train set size: {len(trainset)}\")\n",
    "print(f\"Test set size: {len(testset)}\")\n",
    "\n",
    "# CutMix 변환 정의\n",
    "cutmix = transforms_v2.CutMix(alpha=config[\"cutmix_alpha\"], num_classes=100)  # CIFAR-100은 100개 클래스\n",
    "\n",
    "def train(model, trainloader, criterion, optimizer, device, epoch, warmup_scheduler=None, warmup_epochs=5):\n",
    "    \"\"\"\n",
    "    학습 함수 (CutMix 적용)\n",
    "    \"\"\"\n",
    "    model.train()   # 모델을 학습 모드로 설정\n",
    "    start_time = time.time()  # 시간 측정 시작\n",
    "    running_loss = 0.0\n",
    "    correct_top1 = 0\n",
    "    correct_top5 = 0\n",
    "    total = 0\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(trainloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # CutMix 확률적 적용\n",
    "        if random.random() < config[\"cutmix_prob\"]:\n",
    "            inputs, labels = cutmix(inputs, labels)\n",
    "            # 이 경우 labels은 원-핫 인코딩 형태로 변환됨\n",
    "            use_cutmix = True\n",
    "        else:\n",
    "            use_cutmix = False\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # CutMix 적용 여부에 따라 손실 함수 선택\n",
    "        if use_cutmix:\n",
    "            # CutMix가 적용된 경우 (원-핫 인코딩된 레이블)\n",
    "            loss = torch.nn.functional.cross_entropy(outputs, labels)\n",
    "        else:\n",
    "            # 일반적인 경우 (정수 인덱스 레이블)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 학습률 스케줄러 업데이트 - warmup 스케줄러만 여기서 업데이트\n",
    "        if epoch < warmup_epochs and warmup_scheduler is not None:\n",
    "            warmup_scheduler.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # 정확도 계산 - CutMix 적용 여부에 따라 다르게 처리\n",
    "        if use_cutmix:\n",
    "            # 원-핫 인코딩된 레이블에서 argmax를 사용해 가장 큰 값의 인덱스 추출\n",
    "            _, label_idx = labels.max(1)\n",
    "        else:\n",
    "            # 정수 인덱스 레이블 그대로 사용\n",
    "            label_idx = labels\n",
    "            \n",
    "        # top-1 정확도 계산\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += inputs.size(0)\n",
    "        correct_top1 += predicted.eq(label_idx).sum().item()\n",
    "        \n",
    "        # top-5 정확도 계산\n",
    "        _, top5_idx = outputs.topk(5, 1, largest=True, sorted=True)\n",
    "        correct_top5 += sum([1 for i in range(len(label_idx)) if label_idx[i] in top5_idx[i]])\n",
    "        \n",
    "        if (i + 1) % 50 == 0:  # 50 배치마다 출력\n",
    "            print(f'Epoch [{epoch+1}], Batch [{i+1}/{len(trainloader)}], Loss: {loss.item():.4f}, LR: {optimizer.param_groups[0][\"lr\"]:.6f}')\n",
    "    \n",
    "    epoch_loss = running_loss / len(trainloader)\n",
    "    accuracy_top1 = 100.0 * correct_top1 / total\n",
    "    accuracy_top5 = 100.0 * correct_top5 / total\n",
    "    \n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    # 학습 세트에 대한 성능 출력\n",
    "    print(f'Train set: Epoch: {epoch+1}, Average loss:{epoch_loss:.4f}, LR: {optimizer.param_groups[0][\"lr\"]:.6f} '\n",
    "          f'Top-1 Accuracy: {accuracy_top1:.4f}%, Top-5 Accuracy: {accuracy_top5:.4f}%, Time consumed:{train_time:.2f}s')\n",
    "    \n",
    "    return epoch_loss, accuracy_top1, accuracy_top5\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device, epoch, phase=\"test\"):\n",
    "    \"\"\"\n",
    "    평가 함수\n",
    "    \"\"\"\n",
    "    model.eval()  # 모델을 평가 모드로 설정\n",
    "    start_time = time.time()  # 시간 측정 시작\n",
    "    \n",
    "    eval_loss = 0.0\n",
    "    correct_top1 = 0\n",
    "    correct_top5 = 0\n",
    "    total = 0\n",
    "    \n",
    "    # 그래디언트 계산 비활성화\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # 순전파\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # 손실 계산\n",
    "            loss = criterion(outputs, labels)\n",
    "            eval_loss += loss.item()\n",
    "            \n",
    "            # top-1 정확도 계산\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct_top1 += (predicted == labels).sum().item()\n",
    "            \n",
    "            # top-5 정확도 계산\n",
    "            _, top5_idx = outputs.topk(5, 1, largest=True, sorted=True)\n",
    "            correct_top5 += top5_idx.eq(labels.view(-1, 1).expand_as(top5_idx)).sum().item()\n",
    "    \n",
    "    # 평균 손실 및 정확도 계산\n",
    "    eval_loss = eval_loss / len(dataloader)\n",
    "    accuracy_top1 = 100.0 * correct_top1 / total\n",
    "    accuracy_top5 = 100.0 * correct_top5 / total\n",
    "    \n",
    "    # 평가 시간 계산\n",
    "    eval_time = time.time() - start_time\n",
    "    \n",
    "    # 테스트 세트에 대한 성능 출력\n",
    "    print(f'{phase.capitalize()} set: Epoch: {epoch+1}, Average loss:{eval_loss:.4f}, '\n",
    "          f'Top-1 Accuracy: {accuracy_top1:.4f}%, Top-5 Accuracy: {accuracy_top5:.4f}%, Time consumed:{eval_time:.2f}s')\n",
    "    print()\n",
    "    \n",
    "    return eval_loss, accuracy_top1, accuracy_top5\n",
    "\n",
    "# 메인 학습 루프\n",
    "def main_training_loop(model, trainloader, testloader, criterion, optimizer, device, num_epochs, patience, max_epochs_wait, warmup_scheduler=None, main_scheduler=None, warmup_epochs=5):\n",
    "    \"\"\"\n",
    "    메인 학습 루프 (accuracy 기준 early stopping)\n",
    "    \"\"\"\n",
    "    # 정확도 기반 얼리 스토핑 사용\n",
    "    early_stopping = AccuracyEarlyStopping(patience=patience, verbose=True, path='checkpoint.pt', max_epochs=max_epochs_wait)\n",
    "    \n",
    "    best_test_acc_top1 = 0.0\n",
    "    best_test_acc_top5 = 0.0\n",
    "    \n",
    "    # 테스트 정확도 기록을 위한 리스트\n",
    "    test_acc_top1_history = []\n",
    "    \n",
    "    # tqdm을 사용한 진행 상황 표시\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        # 학습\n",
    "        train_loss, train_acc_top1, train_acc_top5 = train(\n",
    "            model, \n",
    "            trainloader, \n",
    "            criterion, \n",
    "            optimizer, \n",
    "            device, \n",
    "            epoch, \n",
    "            warmup_scheduler, \n",
    "            warmup_epochs\n",
    "        )\n",
    "        \n",
    "        # 테스트 데이터로 평가\n",
    "        test_loss, test_acc_top1, test_acc_top5 = evaluate(model, testloader, criterion, device, epoch, phase=\"test\")\n",
    "\n",
    "        # 웜업 이후 ReduceLROnPlateau 스케줄러 업데이트 \n",
    "        if epoch >= warmup_epochs and main_scheduler is not None:\n",
    "            main_scheduler.step(test_acc_top1)  # 테스트 정확도에 따라 학습률 업데이트       \n",
    "            \n",
    "        # 테스트 정확도 기록\n",
    "        test_acc_top1_history.append(test_acc_top1)\n",
    "        \n",
    "        # WandB에 로깅\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_accuracy_top1\": train_acc_top1,\n",
    "            \"train_accuracy_top5\": train_acc_top5,\n",
    "            \"test_loss\": test_loss,\n",
    "            \"test_accuracy_top1\": test_acc_top1,\n",
    "            \"test_accuracy_top5\": test_acc_top5\n",
    "        })\n",
    "            \n",
    "        # 최고 정확도 모델 저장 (top-1 기준)\n",
    "        if test_acc_top1 > best_test_acc_top1:\n",
    "            best_test_acc_top1 = test_acc_top1\n",
    "            best_test_acc_top5_at_best_top1 = test_acc_top5\n",
    "            print(f'새로운 최고 top-1 정확도: {best_test_acc_top1:.2f}%, top-5 정확도: {best_test_acc_top5_at_best_top1:.2f}%')\n",
    "            # 모델 저장\n",
    "            model_path = f'best_model_{wandb.run.name}.pth'\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            \n",
    "            # WandB에 모델 아티팩트 저장\n",
    "            wandb.save(model_path)\n",
    "        \n",
    "        # top-5 accuracy 기록 업데이트\n",
    "        if test_acc_top5 > best_test_acc_top5:\n",
    "            best_test_acc_top5 = test_acc_top5\n",
    "            print(f'새로운 최고 top-5 정확도: {best_test_acc_top5:.2f}%')\n",
    "\n",
    "        # Early stopping 체크 (test_acc_top1 기준)\n",
    "        early_stopping(test_acc_top1, model, epoch)\n",
    "        if early_stopping.early_stop:\n",
    "            print(f\"에폭 {epoch+1}에서 학습 조기 종료. 최고 성능 에폭: {early_stopping.best_epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    # 훈련 완료 후 최고 모델 로드\n",
    "    print(\"테스트 정확도 기준 최고 모델 로드 중...\")\n",
    "    model_path = f'best_model_{wandb.run.name}.pth'\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    # 최종 테스트 세트 평가\n",
    "    final_test_loss, final_test_acc_top1, final_test_acc_top5 = evaluate(model, testloader, criterion, device, num_epochs-1, phase=\"test\")\n",
    "    \n",
    "    print(f'완료! 최고 테스트 top-1 정확도: {best_test_acc_top1:.2f}%, 최고 테스트 top-5 정확도: {best_test_acc_top5:.2f}%')\n",
    "    print(f'최종 테스트 top-1 정확도: {final_test_acc_top1:.2f}%, 최종 테스트 top-5 정확도: {final_test_acc_top5:.2f}%')\n",
    "    \n",
    "    # WandB에 최종 결과 기록\n",
    "    wandb.run.summary[\"best_test_accuracy_top1\"] = best_test_acc_top1\n",
    "    wandb.run.summary[\"best_test_accuracy_top5\"] = best_test_acc_top5\n",
    "    wandb.run.summary[\"final_test_accuracy_top1\"] = final_test_acc_top1\n",
    "    wandb.run.summary[\"final_test_accuracy_top5\"] = final_test_acc_top5\n",
    "\n",
    "    # Early stopping 정보 저장\n",
    "    if early_stopping.early_stop:\n",
    "        wandb.run.summary[\"early_stopped\"] = True\n",
    "        wandb.run.summary[\"early_stopped_epoch\"] = epoch+1\n",
    "        wandb.run.summary[\"best_epoch\"] = early_stopping.best_epoch+1\n",
    "    else:\n",
    "        wandb.run.summary[\"early_stopped\"] = False\n",
    "\n",
    "\n",
    "# 디바이스 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 모델 초기화\n",
    "# 또는 매개변수 커스터마이징\n",
    "model = resnet18().to(device)\n",
    "criterion = nn.CrossEntropyLoss()  # 기본 CrossEntropyLoss 사용 (라벨 스무딩 없음)\n",
    "optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"])  # 옵티마이저 정의\n",
    "\n",
    "# WarmUpLR 스케줄러 초기화\n",
    "# 웜업할 총 iteration 수 계산 (웜업 에폭 × 배치 수)\n",
    "warmup_steps = config[\"warmup_epochs\"] * len(trainloader)\n",
    "warmup_scheduler = WarmUpLR(optimizer, total_iters=warmup_steps)\n",
    "\n",
    "# 웜업 이후 사용할 스케줄러 설정 \n",
    "main_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    mode='max',           # 정확도를 모니터링하므로 'max' 모드 사용\n",
    "    factor=0.1,           # 학습률 감소 비율 (10배 감소)\n",
    "    patience=5,           # 몇 에폭 동안 개선이 없을 때 감소시킬지\n",
    "    verbose=True,         # 학습률 변경 시 출력\n",
    "    threshold=0.01        # 개선으로 간주할 최소 변화량\n",
    ")\n",
    "\n",
    "# WandB에 모델 구조 기록\n",
    "wandb.watch(model, log=\"all\")\n",
    "\n",
    "# GPU 가속\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"{torch.cuda.device_count()}개의 GPU를 사용합니다.\")\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "# 훈련 시작 시간 기록\n",
    "start_time = time.time()\n",
    "\n",
    "# 메인 학습 루프 호출\n",
    "main_training_loop(\n",
    "    model=model,\n",
    "    trainloader=trainloader,\n",
    "    testloader=testloader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    num_epochs=config[\"num_epochs\"],\n",
    "    patience=config[\"patience\"],\n",
    "    max_epochs_wait=config[\"max_epochs_wait\"],\n",
    "    warmup_scheduler=warmup_scheduler,\n",
    "    main_scheduler=main_scheduler,\n",
    "    warmup_epochs=config[\"warmup_epochs\"]\n",
    ")\n",
    "\n",
    "# 훈련 종료 시간 기록 및 출력\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "wandb.log({\"total_training_time\": total_time})\n",
    "\n",
    "print(f\"전체 학습 시간: {total_time:.2f} 초\")\n",
    "\n",
    "# WandB 실행 종료\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57b9218-aa24-4297-bb92-473c215e6767",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
