{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "516f9d5f-6361-4b03-98ee-e1ba4de86b92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/guswls/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msokjh1310\u001b[0m (\u001b[33msokjh1310-hanyang-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/guswls/EEN4015_Intro2ML/pbl-2/wandb/run-20250413_045312-g9yk5gzm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/g9yk5gzm' target=\"_blank\">resnet50_cutmix,flip</a></strong> to <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/g9yk5gzm' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/g9yk5gzm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Train set size: 40000\n",
      "Validation set size: 5000\n",
      "Test set size: 5000\n",
      "Using device: cuda\n",
      "2개의 GPU를 사용합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                       | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Batch [50/313], Loss: 4.3900\n",
      "Epoch [1], Batch [100/313], Loss: 4.1090\n",
      "Epoch [1], Batch [150/313], Loss: 4.1082\n",
      "Epoch [1], Batch [200/313], Loss: 3.9824\n",
      "Epoch [1], Batch [250/313], Loss: 3.8416\n",
      "Epoch [1], Batch [300/313], Loss: 3.5935\n",
      "Train set: Epoch: 1, Average loss:4.2586, LR: 0.001000 Top-1 Accuracy: 6.2600%, Top-5 Accuracy: 22.0675%, Time consumed:80.07s\n",
      "Val set: Epoch: 1, Average loss:3.8159, Top-1 Accuracy: 10.3800%, Top-5 Accuracy: 32.7800%, Time consumed:8.96s\n",
      "\n",
      "New best top-1 accuracy: 10.38%, top-5 accuracy: 32.78%\n",
      "New best top-5 accuracy: 32.78%\n",
      "Validation loss decreased (inf --> 3.815898). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▉                                                                                            | 1/100 [01:29<2:27:44, 89.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], Batch [50/313], Loss: 3.6662\n",
      "Epoch [2], Batch [100/313], Loss: 4.1941\n",
      "Epoch [2], Batch [150/313], Loss: 4.2280\n",
      "Epoch [2], Batch [200/313], Loss: 3.4618\n",
      "Epoch [2], Batch [250/313], Loss: 3.5255\n",
      "Epoch [2], Batch [300/313], Loss: 3.8123\n",
      "Train set: Epoch: 2, Average loss:3.7644, LR: 0.001000 Top-1 Accuracy: 13.6225%, Top-5 Accuracy: 37.7975%, Time consumed:82.50s\n",
      "Val set: Epoch: 2, Average loss:3.3263, Top-1 Accuracy: 19.4800%, Top-5 Accuracy: 48.9200%, Time consumed:9.19s\n",
      "\n",
      "New best top-1 accuracy: 19.48%, top-5 accuracy: 48.92%\n",
      "New best top-5 accuracy: 48.92%\n",
      "Validation loss decreased (3.815898 --> 3.326332). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▊                                                                                           | 2/100 [03:01<2:28:49, 91.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3], Batch [50/313], Loss: 3.7211\n",
      "Epoch [3], Batch [100/313], Loss: 2.9829\n",
      "Epoch [3], Batch [150/313], Loss: 3.7029\n",
      "Epoch [3], Batch [200/313], Loss: 4.0567\n",
      "Epoch [3], Batch [250/313], Loss: 3.4003\n",
      "Epoch [3], Batch [300/313], Loss: 4.0819\n",
      "Train set: Epoch: 3, Average loss:3.2779, LR: 0.001000 Top-1 Accuracy: 22.0100%, Top-5 Accuracy: 51.7000%, Time consumed:79.49s\n",
      "Val set: Epoch: 3, Average loss:2.8930, Top-1 Accuracy: 27.5200%, Top-5 Accuracy: 62.8400%, Time consumed:8.89s\n",
      "\n",
      "New best top-1 accuracy: 27.52%, top-5 accuracy: 62.84%\n",
      "New best top-5 accuracy: 62.84%\n",
      "Validation loss decreased (3.326332 --> 2.893042). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▊                                                                                          | 3/100 [04:30<2:25:41, 90.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4], Batch [50/313], Loss: 3.4523\n",
      "Epoch [4], Batch [100/313], Loss: 2.7672\n",
      "Epoch [4], Batch [150/313], Loss: 3.9901\n",
      "Epoch [4], Batch [200/313], Loss: 2.8880\n",
      "Epoch [4], Batch [250/313], Loss: 2.6688\n",
      "Epoch [4], Batch [300/313], Loss: 2.3404\n",
      "Train set: Epoch: 4, Average loss:3.0017, LR: 0.001000 Top-1 Accuracy: 28.6225%, Top-5 Accuracy: 60.3900%, Time consumed:80.86s\n",
      "Val set: Epoch: 4, Average loss:3.1974, Top-1 Accuracy: 33.9200%, Top-5 Accuracy: 66.0400%, Time consumed:8.60s\n",
      "\n",
      "New best top-1 accuracy: 33.92%, top-5 accuracy: 66.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▋                                                                                         | 4/100 [06:00<2:23:56, 89.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best top-5 accuracy: 66.04%\n",
      "EarlyStopping 카운터: 1 / 10\n",
      "Epoch [5], Batch [50/313], Loss: 3.0353\n",
      "Epoch [5], Batch [100/313], Loss: 2.1680\n",
      "Epoch [5], Batch [150/313], Loss: 2.7582\n",
      "Epoch [5], Batch [200/313], Loss: 2.0622\n",
      "Epoch [5], Batch [250/313], Loss: 2.2801\n",
      "Epoch [5], Batch [300/313], Loss: 2.1226\n",
      "Train set: Epoch: 5, Average loss:2.7399, LR: 0.001000 Top-1 Accuracy: 35.1175%, Top-5 Accuracy: 66.9100%, Time consumed:81.84s\n",
      "Val set: Epoch: 5, Average loss:2.6735, Top-1 Accuracy: 39.2800%, Top-5 Accuracy: 72.0000%, Time consumed:8.62s\n",
      "\n",
      "New best top-1 accuracy: 39.28%, top-5 accuracy: 72.00%\n",
      "New best top-5 accuracy: 72.00%\n",
      "Validation loss decreased (2.893042 --> 2.673488). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▋                                                                                        | 5/100 [07:31<2:23:01, 90.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6], Batch [50/313], Loss: 2.0449\n",
      "Epoch [6], Batch [100/313], Loss: 2.5305\n",
      "Epoch [6], Batch [150/313], Loss: 2.7565\n",
      "Epoch [6], Batch [200/313], Loss: 3.5641\n",
      "Epoch [6], Batch [250/313], Loss: 2.1251\n",
      "Epoch [6], Batch [300/313], Loss: 1.9355\n",
      "Train set: Epoch: 6, Average loss:2.6705, LR: 0.001000 Top-1 Accuracy: 38.2400%, Top-5 Accuracy: 69.6375%, Time consumed:79.04s\n",
      "Val set: Epoch: 6, Average loss:2.7290, Top-1 Accuracy: 42.6600%, Top-5 Accuracy: 74.9000%, Time consumed:8.59s\n",
      "\n",
      "New best top-1 accuracy: 42.66%, top-5 accuracy: 74.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████▌                                                                                       | 6/100 [08:59<2:20:13, 89.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best top-5 accuracy: 74.90%\n",
      "EarlyStopping 카운터: 1 / 10\n",
      "Epoch [7], Batch [50/313], Loss: 3.3097\n",
      "Epoch [7], Batch [100/313], Loss: 2.2907\n",
      "Epoch [7], Batch [150/313], Loss: 2.9435\n",
      "Epoch [7], Batch [200/313], Loss: 1.9167\n",
      "Epoch [7], Batch [250/313], Loss: 1.7236\n",
      "Epoch [7], Batch [300/313], Loss: 1.7637\n",
      "Train set: Epoch: 7, Average loss:2.4306, LR: 0.001000 Top-1 Accuracy: 43.1125%, Top-5 Accuracy: 73.9650%, Time consumed:83.55s\n",
      "Val set: Epoch: 7, Average loss:2.2669, Top-1 Accuracy: 48.1600%, Top-5 Accuracy: 79.4800%, Time consumed:8.31s\n",
      "\n",
      "New best top-1 accuracy: 48.16%, top-5 accuracy: 79.48%\n",
      "New best top-5 accuracy: 79.48%\n",
      "Validation loss decreased (2.673488 --> 2.266854). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████▌                                                                                      | 7/100 [10:31<2:20:11, 90.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8], Batch [50/313], Loss: 1.6513\n",
      "Epoch [8], Batch [100/313], Loss: 1.5053\n",
      "Epoch [8], Batch [150/313], Loss: 3.6494\n",
      "Epoch [8], Batch [200/313], Loss: 1.8956\n",
      "Epoch [8], Batch [250/313], Loss: 2.3423\n",
      "Epoch [8], Batch [300/313], Loss: 1.9236\n",
      "Train set: Epoch: 8, Average loss:2.3246, LR: 0.001000 Top-1 Accuracy: 45.1275%, Top-5 Accuracy: 75.3700%, Time consumed:81.73s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███████▍                                                                                     | 8/100 [12:02<2:18:49, 90.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val set: Epoch: 8, Average loss:2.6984, Top-1 Accuracy: 43.6400%, Top-5 Accuracy: 76.7800%, Time consumed:9.00s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 10\n",
      "Epoch [9], Batch [50/313], Loss: 1.3532\n",
      "Epoch [9], Batch [100/313], Loss: 1.5046\n",
      "Epoch [9], Batch [150/313], Loss: 1.5240\n",
      "Epoch [9], Batch [200/313], Loss: 3.6225\n",
      "Epoch [9], Batch [250/313], Loss: 3.4138\n",
      "Epoch [9], Batch [300/313], Loss: 3.2752\n",
      "Train set: Epoch: 9, Average loss:2.2583, LR: 0.001000 Top-1 Accuracy: 48.0225%, Top-5 Accuracy: 77.3800%, Time consumed:81.56s\n",
      "Val set: Epoch: 9, Average loss:2.3896, Top-1 Accuracy: 51.7000%, Top-5 Accuracy: 81.5600%, Time consumed:8.85s\n",
      "\n",
      "New best top-1 accuracy: 51.70%, top-5 accuracy: 81.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|████████▎                                                                                    | 9/100 [13:33<2:17:23, 90.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best top-5 accuracy: 81.56%\n",
      "EarlyStopping 카운터: 2 / 10\n",
      "Epoch [10], Batch [50/313], Loss: 1.3117\n",
      "Epoch [10], Batch [100/313], Loss: 1.5127\n",
      "Epoch [10], Batch [150/313], Loss: 1.3267\n",
      "Epoch [10], Batch [200/313], Loss: 1.7004\n",
      "Epoch [10], Batch [250/313], Loss: 3.0246\n",
      "Epoch [10], Batch [300/313], Loss: 1.5497\n",
      "Train set: Epoch: 10, Average loss:2.0418, LR: 0.001000 Top-1 Accuracy: 52.6850%, Top-5 Accuracy: 81.2375%, Time consumed:79.38s\n",
      "Val set: Epoch: 10, Average loss:2.3230, Top-1 Accuracy: 54.8400%, Top-5 Accuracy: 82.9200%, Time consumed:8.76s\n",
      "\n",
      "New best top-1 accuracy: 54.84%, top-5 accuracy: 82.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█████████▏                                                                                  | 10/100 [15:01<2:14:52, 89.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best top-5 accuracy: 82.92%\n",
      "EarlyStopping 카운터: 3 / 10\n",
      "Epoch [11], Batch [50/313], Loss: 1.4192\n",
      "Epoch [11], Batch [100/313], Loss: 3.6538\n",
      "Epoch [11], Batch [150/313], Loss: 3.0252\n",
      "Epoch [11], Batch [200/313], Loss: 3.4628\n",
      "Epoch [11], Batch [250/313], Loss: 1.4069\n",
      "Epoch [11], Batch [300/313], Loss: 3.2864\n",
      "Train set: Epoch: 11, Average loss:2.0300, LR: 0.001000 Top-1 Accuracy: 53.7325%, Top-5 Accuracy: 81.2800%, Time consumed:83.48s\n",
      "Val set: Epoch: 11, Average loss:1.7560, Top-1 Accuracy: 53.1400%, Top-5 Accuracy: 83.0200%, Time consumed:9.86s\n",
      "\n",
      "New best top-5 accuracy: 83.02%\n",
      "Validation loss decreased (2.266854 --> 1.756017). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|██████████                                                                                  | 11/100 [16:35<2:15:02, 91.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12], Batch [50/313], Loss: 2.9855\n",
      "Epoch [12], Batch [100/313], Loss: 1.0805\n",
      "Epoch [12], Batch [150/313], Loss: 1.1718\n",
      "Epoch [12], Batch [200/313], Loss: 1.6149\n",
      "Epoch [12], Batch [250/313], Loss: 1.3021\n",
      "Epoch [12], Batch [300/313], Loss: 2.4411\n",
      "Train set: Epoch: 12, Average loss:1.8758, LR: 0.001000 Top-1 Accuracy: 57.3800%, Top-5 Accuracy: 83.5450%, Time consumed:81.29s\n",
      "Val set: Epoch: 12, Average loss:1.5581, Top-1 Accuracy: 57.2200%, Top-5 Accuracy: 85.9600%, Time consumed:9.32s\n",
      "\n",
      "New best top-1 accuracy: 57.22%, top-5 accuracy: 85.96%\n",
      "New best top-5 accuracy: 85.96%\n",
      "Validation loss decreased (1.756017 --> 1.558083). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|███████████                                                                                 | 12/100 [18:06<2:13:34, 91.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13], Batch [50/313], Loss: 2.3695\n",
      "Epoch [13], Batch [100/313], Loss: 0.9344\n",
      "Epoch [13], Batch [150/313], Loss: 1.0876\n",
      "Epoch [13], Batch [200/313], Loss: 2.9033\n",
      "Epoch [13], Batch [250/313], Loss: 0.9727\n",
      "Epoch [13], Batch [300/313], Loss: 1.2209\n",
      "Train set: Epoch: 13, Average loss:1.7977, LR: 0.001000 Top-1 Accuracy: 59.0425%, Top-5 Accuracy: 84.5525%, Time consumed:83.08s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|███████████▉                                                                                | 13/100 [19:37<2:12:17, 91.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val set: Epoch: 13, Average loss:1.6493, Top-1 Accuracy: 57.0600%, Top-5 Accuracy: 85.1400%, Time consumed:8.52s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 10\n",
      "Epoch [14], Batch [50/313], Loss: 3.0402\n",
      "Epoch [14], Batch [100/313], Loss: 2.0803\n",
      "Epoch [14], Batch [150/313], Loss: 1.5297\n",
      "Epoch [14], Batch [200/313], Loss: 0.7293\n",
      "Epoch [14], Batch [250/313], Loss: 2.9598\n",
      "Epoch [14], Batch [300/313], Loss: 0.9774\n",
      "Train set: Epoch: 14, Average loss:1.7306, LR: 0.001000 Top-1 Accuracy: 63.1475%, Top-5 Accuracy: 87.7075%, Time consumed:78.31s\n",
      "Val set: Epoch: 14, Average loss:1.4431, Top-1 Accuracy: 60.2800%, Top-5 Accuracy: 87.3600%, Time consumed:9.08s\n",
      "\n",
      "New best top-1 accuracy: 60.28%, top-5 accuracy: 87.36%\n",
      "New best top-5 accuracy: 87.36%\n",
      "Validation loss decreased (1.558083 --> 1.443097). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████▉                                                                               | 14/100 [21:05<2:09:19, 90.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15], Batch [50/313], Loss: 0.7277\n",
      "Epoch [15], Batch [100/313], Loss: 3.1994\n",
      "Epoch [15], Batch [150/313], Loss: 3.0909\n",
      "Epoch [15], Batch [200/313], Loss: 2.8032\n",
      "Epoch [15], Batch [250/313], Loss: 0.7641\n",
      "Epoch [15], Batch [300/313], Loss: 0.8466\n",
      "Train set: Epoch: 15, Average loss:1.7571, LR: 0.001000 Top-1 Accuracy: 62.4275%, Top-5 Accuracy: 86.9375%, Time consumed:78.71s\n",
      "Val set: Epoch: 15, Average loss:1.4157, Top-1 Accuracy: 61.2200%, Top-5 Accuracy: 87.7800%, Time consumed:8.51s\n",
      "\n",
      "New best top-1 accuracy: 61.22%, top-5 accuracy: 87.78%\n",
      "New best top-5 accuracy: 87.78%\n",
      "Validation loss decreased (1.443097 --> 1.415721). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████████████▊                                                                              | 15/100 [22:33<2:06:45, 89.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16], Batch [50/313], Loss: 2.6627\n",
      "Epoch [16], Batch [100/313], Loss: 2.9572\n",
      "Epoch [16], Batch [150/313], Loss: 2.8578\n",
      "Epoch [16], Batch [200/313], Loss: 2.6315\n",
      "Epoch [16], Batch [250/313], Loss: 0.7596\n",
      "Epoch [16], Batch [300/313], Loss: 2.8270\n",
      "Train set: Epoch: 16, Average loss:1.5652, LR: 0.001000 Top-1 Accuracy: 67.0150%, Top-5 Accuracy: 89.1350%, Time consumed:77.45s\n",
      "Val set: Epoch: 16, Average loss:1.3880, Top-1 Accuracy: 61.2200%, Top-5 Accuracy: 88.4600%, Time consumed:8.77s\n",
      "\n",
      "New best top-5 accuracy: 88.46%\n",
      "Validation loss decreased (1.415721 --> 1.388024). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████████████▋                                                                             | 16/100 [24:00<2:04:00, 88.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17], Batch [50/313], Loss: 2.6770\n",
      "Epoch [17], Batch [100/313], Loss: 2.5186\n",
      "Epoch [17], Batch [150/313], Loss: 0.6497\n",
      "Epoch [17], Batch [200/313], Loss: 2.9644\n",
      "Epoch [17], Batch [250/313], Loss: 0.4711\n",
      "Epoch [17], Batch [300/313], Loss: 2.0107\n",
      "Train set: Epoch: 17, Average loss:1.5145, LR: 0.001000 Top-1 Accuracy: 68.7675%, Top-5 Accuracy: 89.8950%, Time consumed:77.49s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████████████▋                                                                            | 17/100 [25:26<2:01:29, 87.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val set: Epoch: 17, Average loss:1.4378, Top-1 Accuracy: 60.4200%, Top-5 Accuracy: 87.6800%, Time consumed:8.59s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 10\n",
      "Epoch [18], Batch [50/313], Loss: 1.7579\n",
      "Epoch [18], Batch [100/313], Loss: 2.4723\n",
      "Epoch [18], Batch [150/313], Loss: 0.7226\n",
      "Epoch [18], Batch [200/313], Loss: 3.1106\n",
      "Epoch [18], Batch [250/313], Loss: 2.3181\n",
      "Epoch [18], Batch [300/313], Loss: 0.6899\n",
      "Train set: Epoch: 18, Average loss:1.5069, LR: 0.001000 Top-1 Accuracy: 70.0425%, Top-5 Accuracy: 90.3450%, Time consumed:77.68s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|████████████████▌                                                                           | 18/100 [26:52<1:59:25, 87.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val set: Epoch: 18, Average loss:1.4383, Top-1 Accuracy: 60.8000%, Top-5 Accuracy: 87.0600%, Time consumed:8.66s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 10\n",
      "Epoch [19], Batch [50/313], Loss: 2.8707\n",
      "Epoch [19], Batch [100/313], Loss: 0.4202\n",
      "Epoch [19], Batch [150/313], Loss: 0.4152\n",
      "Epoch [19], Batch [200/313], Loss: 0.5902\n",
      "Epoch [19], Batch [250/313], Loss: 0.3313\n",
      "Epoch [19], Batch [300/313], Loss: 2.7965\n",
      "Train set: Epoch: 19, Average loss:1.3506, LR: 0.001000 Top-1 Accuracy: 72.4775%, Top-5 Accuracy: 90.6300%, Time consumed:79.46s\n",
      "Val set: Epoch: 19, Average loss:1.3991, Top-1 Accuracy: 61.8600%, Top-5 Accuracy: 87.6400%, Time consumed:8.56s\n",
      "\n",
      "New best top-1 accuracy: 61.86%, top-5 accuracy: 87.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█████████████████▍                                                                          | 19/100 [28:20<1:58:20, 87.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping 카운터: 3 / 10\n",
      "Epoch [20], Batch [50/313], Loss: 0.3532\n",
      "Epoch [20], Batch [100/313], Loss: 2.2892\n",
      "Epoch [20], Batch [150/313], Loss: 2.6096\n",
      "Epoch [20], Batch [200/313], Loss: 0.4125\n",
      "Epoch [20], Batch [250/313], Loss: 0.4420\n",
      "Epoch [20], Batch [300/313], Loss: 3.0153\n",
      "Train set: Epoch: 20, Average loss:1.3312, LR: 0.001000 Top-1 Accuracy: 75.3125%, Top-5 Accuracy: 92.3600%, Time consumed:78.29s\n",
      "Val set: Epoch: 20, Average loss:1.4065, Top-1 Accuracy: 63.0600%, Top-5 Accuracy: 87.7800%, Time consumed:8.47s\n",
      "\n",
      "New best top-1 accuracy: 63.06%, top-5 accuracy: 87.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████████████▍                                                                         | 20/100 [29:47<1:56:37, 87.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping 카운터: 4 / 10\n",
      "Epoch [21], Batch [50/313], Loss: 0.2979\n",
      "Epoch [21], Batch [100/313], Loss: 0.3211\n",
      "Epoch [21], Batch [150/313], Loss: 1.4220\n",
      "Epoch [21], Batch [200/313], Loss: 1.0082\n",
      "Epoch [21], Batch [250/313], Loss: 2.2436\n",
      "Epoch [21], Batch [300/313], Loss: 2.2936\n",
      "Train set: Epoch: 21, Average loss:1.2560, LR: 0.001000 Top-1 Accuracy: 76.4950%, Top-5 Accuracy: 92.8700%, Time consumed:80.69s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|███████████████████▎                                                                        | 21/100 [31:17<1:55:53, 88.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val set: Epoch: 21, Average loss:1.5282, Top-1 Accuracy: 61.5800%, Top-5 Accuracy: 86.6800%, Time consumed:8.61s\n",
      "\n",
      "EarlyStopping 카운터: 5 / 10\n",
      "Epoch [22], Batch [50/313], Loss: 0.3305\n",
      "Epoch [22], Batch [100/313], Loss: 1.9485\n",
      "Epoch [22], Batch [150/313], Loss: 0.3277\n",
      "Epoch [22], Batch [200/313], Loss: 0.2879\n",
      "Epoch [22], Batch [250/313], Loss: 0.4624\n",
      "Epoch [22], Batch [300/313], Loss: 0.2596\n",
      "Train set: Epoch: 22, Average loss:1.2940, LR: 0.001000 Top-1 Accuracy: 76.4125%, Top-5 Accuracy: 92.8550%, Time consumed:79.16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|████████████████████▏                                                                       | 22/100 [32:44<1:54:11, 87.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val set: Epoch: 22, Average loss:1.3934, Top-1 Accuracy: 63.0600%, Top-5 Accuracy: 87.9200%, Time consumed:8.28s\n",
      "\n",
      "EarlyStopping 카운터: 6 / 10\n",
      "Epoch [23], Batch [50/313], Loss: 2.6959\n",
      "Epoch [23], Batch [100/313], Loss: 0.2118\n",
      "Epoch [23], Batch [150/313], Loss: 2.8110\n",
      "Epoch [23], Batch [200/313], Loss: 2.2972\n",
      "Epoch [23], Batch [250/313], Loss: 0.7375\n",
      "Epoch [23], Batch [300/313], Loss: 2.5713\n",
      "Train set: Epoch: 23, Average loss:1.3152, LR: 0.001000 Top-1 Accuracy: 76.8075%, Top-5 Accuracy: 92.7750%, Time consumed:77.10s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|█████████████████████▏                                                                      | 23/100 [34:10<1:52:02, 87.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val set: Epoch: 23, Average loss:1.6885, Top-1 Accuracy: 62.1600%, Top-5 Accuracy: 87.1400%, Time consumed:8.94s\n",
      "\n",
      "EarlyStopping 카운터: 7 / 10\n",
      "Epoch [24], Batch [50/313], Loss: 0.3064\n",
      "Epoch [24], Batch [100/313], Loss: 0.2254\n",
      "Epoch [24], Batch [150/313], Loss: 2.4513\n",
      "Epoch [24], Batch [200/313], Loss: 0.3027\n",
      "Epoch [24], Batch [250/313], Loss: 2.6531\n",
      "Epoch [24], Batch [300/313], Loss: 2.0898\n",
      "Train set: Epoch: 24, Average loss:1.1562, LR: 0.001000 Top-1 Accuracy: 78.5900%, Top-5 Accuracy: 93.1875%, Time consumed:77.43s\n",
      "Val set: Epoch: 24, Average loss:1.4627, Top-1 Accuracy: 63.1800%, Top-5 Accuracy: 87.3600%, Time consumed:8.33s\n",
      "\n",
      "New best top-1 accuracy: 63.18%, top-5 accuracy: 87.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██████████████████████                                                                      | 24/100 [35:36<1:50:05, 86.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping 카운터: 8 / 10\n",
      "Epoch [25], Batch [50/313], Loss: 2.5090\n",
      "Epoch [25], Batch [100/313], Loss: 0.1510\n",
      "Epoch [25], Batch [150/313], Loss: 0.1405\n",
      "Epoch [25], Batch [200/313], Loss: 0.1938\n",
      "Epoch [25], Batch [250/313], Loss: 0.1619\n",
      "Epoch [25], Batch [300/313], Loss: 2.6490\n",
      "Train set: Epoch: 25, Average loss:1.0438, LR: 0.001000 Top-1 Accuracy: 82.3550%, Top-5 Accuracy: 94.8275%, Time consumed:78.57s\n",
      "Val set: Epoch: 25, Average loss:1.4450, Top-1 Accuracy: 63.2600%, Top-5 Accuracy: 87.6800%, Time consumed:8.65s\n",
      "\n",
      "New best top-1 accuracy: 63.26%, top-5 accuracy: 87.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████████                                                                     | 25/100 [37:04<1:48:52, 87.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping 카운터: 9 / 10\n",
      "Epoch [26], Batch [50/313], Loss: 0.0924\n",
      "Epoch [26], Batch [100/313], Loss: 0.1286\n",
      "Epoch [26], Batch [150/313], Loss: 2.5432\n",
      "Epoch [26], Batch [200/313], Loss: 1.9826\n",
      "Epoch [26], Batch [250/313], Loss: 0.2725\n",
      "Epoch [26], Batch [300/313], Loss: 0.3138\n",
      "Train set: Epoch: 26, Average loss:1.1265, LR: 0.001000 Top-1 Accuracy: 81.6075%, Top-5 Accuracy: 94.4425%, Time consumed:77.54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████████                                                                     | 25/100 [38:29<1:55:29, 92.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val set: Epoch: 26, Average loss:1.5407, Top-1 Accuracy: 61.3600%, Top-5 Accuracy: 86.1800%, Time consumed:8.27s\n",
      "\n",
      "EarlyStopping 카운터: 10 / 10\n",
      "Early stopping triggered. Training stopped.\n",
      "Loading best model from early stopping checkpoint...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 100, Average loss:1.4863, Top-1 Accuracy: 61.6000%, Top-5 Accuracy: 85.7800%, Time consumed:10.06s\n",
      "\n",
      "Finish! Best validation top-1 accuracy: 63.26%, Best validation top-5 accuracy: 88.46%\n",
      "Final test top-1 accuracy: 61.60%, Final test top-5 accuracy: 85.78%\n",
      "Total training time: 2319.96 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▄▅▅▅▅▆▆▆▇▇▇▇███</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_accuracy_top1</td><td>▁</td></tr><tr><td>test_accuracy_top5</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>total_training_time</td><td>▁</td></tr><tr><td>train_accuracy_top1</td><td>▁▂▂▃▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇███</td></tr><tr><td>train_accuracy_top5</td><td>▁▃▄▅▅▆▆▆▆▇▇▇▇▇▇▇██████████</td></tr><tr><td>train_loss</td><td>█▇▆▅▅▅▄▄▄▃▃▃▃▂▃▂▂▂▂▂▁▂▂▁▁▁</td></tr><tr><td>val_accuracy_top1</td><td>▁▂▃▄▅▅▆▅▆▇▇▇▇█████████████</td></tr><tr><td>val_accuracy_top5</td><td>▁▃▅▅▆▆▇▇▇▇▇███████████████</td></tr><tr><td>val_loss</td><td>█▇▅▆▅▅▄▅▄▄▂▁▂▁▁▁▁▁▁▁▁▁▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_accuracy_top1</td><td>63.26</td></tr><tr><td>best_val_accuracy_top5</td><td>88.46</td></tr><tr><td>early_stopped</td><td>True</td></tr><tr><td>early_stopped_epoch</td><td>26</td></tr><tr><td>epoch</td><td>26</td></tr><tr><td>learning_rate</td><td>0.001</td></tr><tr><td>test_accuracy_top1</td><td>61.6</td></tr><tr><td>test_accuracy_top5</td><td>85.78</td></tr><tr><td>test_loss</td><td>1.48629</td></tr><tr><td>total_training_time</td><td>2319.96019</td></tr><tr><td>train_accuracy_top1</td><td>81.6075</td></tr><tr><td>train_accuracy_top5</td><td>94.4425</td></tr><tr><td>train_loss</td><td>1.12653</td></tr><tr><td>val_accuracy_top1</td><td>61.36</td></tr><tr><td>val_accuracy_top5</td><td>86.18</td></tr><tr><td>val_loss</td><td>1.54074</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">resnet50_cutmix,flip</strong> at: <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/g9yk5gzm' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/g9yk5gzm</a><br> View project at: <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250413_045312-g9yk5gzm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.v2 as transforms_v2  # CutMix를 위한 v2 transforms 추가\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from tools.tool import EarlyStopping\n",
    "from models.resnet import resnet18, resnet34, resnet50\n",
    "\n",
    "wandb.login(key=\"ef091b9abcea3186341ddf8995d62bde62d7469e\")\n",
    "wandb.init(project=\"PBL-2\", name=\"resnet50_cutmix,flip\")  # CutMix 적용 실험임을 명시\n",
    "\n",
    "# WandB 설정\n",
    "config = {\n",
    "    \"model\": \"resnet50\",\n",
    "    \"batch_size\": 128,\n",
    "    \"num_epochs\": 100,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"seed\": 2025,\n",
    "    \"deterministic\": False,\n",
    "    \"patience\": 10,  # early stopping patience\n",
    "    \"train_ratio\": 0.8,\n",
    "    \"val_ratio\": 0.1,\n",
    "    \"test_ratio\": 0.1,\n",
    "    \"cutmix_alpha\": 1.0,  # CutMix 알파 파라미터 추가\n",
    "    \"cutmix_prob\": 0.5    # CutMix 적용 확률 추가\n",
    "}\n",
    "wandb.config.update(config)\n",
    "\n",
    "# CIFAR-100 데이터셋 로드\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "])\n",
    "\n",
    "full_trainset = torchvision.datasets.CIFAR100(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR100(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "# Stratified 분할을 위한 준비 (train, validation 나누기)\n",
    "# 모든 라벨을 추출\n",
    "targets = np.array(full_trainset.targets)\n",
    "\n",
    "# StratifiedShuffleSplit을 사용하여 8:1:1 비율로 분할\n",
    "# 먼저 train과 validation을 나눔 (full_trainset에서 8:2)\n",
    "train_val_split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=config[\"seed\"])\n",
    "train_idx, temp_idx = next(train_val_split.split(np.zeros(len(targets)), targets))\n",
    "\n",
    "# 그 다음 validation과 test를 나눔 (temp에서 1:1, 전체로 보면 1:1)\n",
    "val_test_targets = targets[temp_idx]\n",
    "val_test_split = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=config[\"seed\"])\n",
    "val_idx_temp, test_idx_temp = next(val_test_split.split(np.zeros(len(val_test_targets)), val_test_targets))\n",
    "\n",
    "# 원래 인덱스로 매핑\n",
    "val_idx = temp_idx[val_idx_temp]\n",
    "test_idx = temp_idx[test_idx_temp]\n",
    "\n",
    "# Subset 생성\n",
    "trainset = Subset(full_trainset, train_idx)\n",
    "valset = Subset(full_trainset, val_idx)\n",
    "testset_split = Subset(full_trainset, test_idx)  # 원래 테스트셋 대신 stratified split에서 나온 테스트셋 사용\n",
    "\n",
    "# DataLoader 생성\n",
    "trainloader = DataLoader(trainset, batch_size=config[\"batch_size\"], shuffle=True, num_workers=16)\n",
    "valloader = DataLoader(valset, batch_size=config[\"batch_size\"], shuffle=False, num_workers=16)\n",
    "testloader = DataLoader(testset_split, batch_size=config[\"batch_size\"], shuffle=False, num_workers=16)\n",
    "\n",
    "print(f\"Train set size: {len(trainset)}\")\n",
    "print(f\"Validation set size: {len(valset)}\")\n",
    "print(f\"Test set size: {len(testset_split)}\")\n",
    "\n",
    "# 추가: CutMix 변환 정의\n",
    "cutmix = transforms_v2.CutMix(alpha=config[\"cutmix_alpha\"], num_classes=100)  # CIFAR-100은 100개 클래스\n",
    "\n",
    "# CutMix용 손실 함수 정의 (원-핫 인코딩된 레이블 처리)\n",
    "def cutmix_criterion(outputs, targets):\n",
    "    \"\"\"\n",
    "    CutMix로 혼합된 레이블을 처리하기 위한 손실 함수\n",
    "    outputs: 모델 출력\n",
    "    targets: CutMix로 생성된 원-핫 인코딩 레이블\n",
    "    \"\"\"\n",
    "    return torch.nn.functional.cross_entropy(outputs, targets)\n",
    "\n",
    "def train(model, trainloader, criterion, optimizer, device, epoch):\n",
    "    \"\"\"\n",
    "    학습 함수 (CutMix 적용)\n",
    "    \"\"\"\n",
    "    model.train()   # 모델을 학습 모드로 설정\n",
    "    start_time = time.time()  # 시간 측정 시작\n",
    "    running_loss = 0.0\n",
    "    correct_top1 = 0\n",
    "    correct_top5 = 0\n",
    "    total = 0\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(trainloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # CutMix 확률적 적용\n",
    "        if random.random() < config[\"cutmix_prob\"]:\n",
    "            inputs, labels = cutmix(inputs, labels)\n",
    "            # 이 경우 labels은 원-핫 인코딩 형태로 변환됨\n",
    "            use_cutmix = True\n",
    "        else:\n",
    "            use_cutmix = False\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # CutMix 적용 여부에 따라 손실 함수 선택\n",
    "        if use_cutmix:\n",
    "            # CutMix가 적용된 경우 (원-핫 인코딩된 레이블)\n",
    "            loss = torch.nn.functional.cross_entropy(outputs, labels)\n",
    "        else:\n",
    "            # 일반적인 경우 (정수 인덱스 레이블)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # 정확도 계산 - CutMix 적용 여부에 따라 다르게 처리\n",
    "        if use_cutmix:\n",
    "            # 원-핫 인코딩된 레이블에서 argmax를 사용해 가장 큰 값의 인덱스 추출\n",
    "            _, label_idx = labels.max(1)\n",
    "        else:\n",
    "            # 정수 인덱스 레이블 그대로 사용\n",
    "            label_idx = labels\n",
    "            \n",
    "        # top-1 정확도 계산\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += inputs.size(0)\n",
    "        correct_top1 += predicted.eq(label_idx).sum().item()\n",
    "        \n",
    "        # top-5 정확도 계산\n",
    "        _, top5_idx = outputs.topk(5, 1, largest=True, sorted=True)\n",
    "        correct_top5 += sum([1 for i in range(len(label_idx)) if label_idx[i] in top5_idx[i]])\n",
    "        \n",
    "        if (i + 1) % 50 == 0:  # 50 배치마다 출력\n",
    "            print(f'Epoch [{epoch+1}], Batch [{i+1}/{len(trainloader)}], Loss: {loss.item():.4f}')\n",
    "    \n",
    "    epoch_loss = running_loss / len(trainloader)\n",
    "    accuracy_top1 = 100.0 * correct_top1 / total\n",
    "    accuracy_top5 = 100.0 * correct_top5 / total\n",
    "    \n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    # 학습 세트에 대한 성능 출력\n",
    "    print(f'Train set: Epoch: {epoch+1}, Average loss:{epoch_loss:.4f}, LR: {optimizer.param_groups[0][\"lr\"]:.6f} '\n",
    "          f'Top-1 Accuracy: {accuracy_top1:.4f}%, Top-5 Accuracy: {accuracy_top5:.4f}%, Time consumed:{train_time:.2f}s')\n",
    "    \n",
    "    return epoch_loss, accuracy_top1, accuracy_top5\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device, epoch, phase=\"val\"):\n",
    "    \"\"\"\n",
    "    평가 함수\n",
    "    \"\"\"\n",
    "    model.eval()  # 모델을 평가 모드로 설정\n",
    "    start_time = time.time()  # 시간 측정 시작\n",
    "    \n",
    "    eval_loss = 0.0\n",
    "    correct_top1 = 0\n",
    "    correct_top5 = 0\n",
    "    total = 0\n",
    "    \n",
    "    # 그래디언트 계산 비활성화\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # 순전파\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # 손실 계산\n",
    "            loss = criterion(outputs, labels)\n",
    "            eval_loss += loss.item()\n",
    "            \n",
    "            # top-1 정확도 계산\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct_top1 += (predicted == labels).sum().item()\n",
    "            \n",
    "            # top-5 정확도 계산\n",
    "            _, top5_idx = outputs.topk(5, 1, largest=True, sorted=True)\n",
    "            correct_top5 += top5_idx.eq(labels.view(-1, 1).expand_as(top5_idx)).sum().item()\n",
    "    \n",
    "    # 평균 손실 및 정확도 계산\n",
    "    eval_loss = eval_loss / len(dataloader)\n",
    "    accuracy_top1 = 100.0 * correct_top1 / total\n",
    "    accuracy_top5 = 100.0 * correct_top5 / total\n",
    "    \n",
    "    # 평가 시간 계산\n",
    "    eval_time = time.time() - start_time\n",
    "    \n",
    "    # 테스트 세트에 대한 성능 출력\n",
    "    print(f'{phase.capitalize()} set: Epoch: {epoch+1}, Average loss:{eval_loss:.4f}, '\n",
    "          f'Top-1 Accuracy: {accuracy_top1:.4f}%, Top-5 Accuracy: {accuracy_top5:.4f}%, Time consumed:{eval_time:.2f}s')\n",
    "    print()\n",
    "    \n",
    "    return eval_loss, accuracy_top1, accuracy_top5\n",
    "\n",
    "\n",
    "# 메인 학습 루프\n",
    "def main_training_loop(model, trainloader, valloader, testloader, criterion, optimizer, device, num_epochs, patience):\n",
    "    \"\"\"\n",
    "    메인 학습 루프\n",
    "    \"\"\"\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "    \n",
    "    best_acc_top1 = 0.0\n",
    "    best_acc_top5 = 0.0\n",
    "    \n",
    "    # tqdm을 사용한 진행 상황 표시\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        # 학습\n",
    "        train_loss, train_acc_top1, train_acc_top5 = train(model, trainloader, criterion, optimizer, device, epoch)\n",
    "        \n",
    "        # 평가\n",
    "        val_loss, val_acc_top1, val_acc_top5 = evaluate(model, valloader, criterion, device, epoch, phase=\"val\")\n",
    "        \n",
    "        # WandB에 로깅\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_accuracy_top1\": train_acc_top1,\n",
    "            \"train_accuracy_top5\": train_acc_top5,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"val_accuracy_top1\": val_acc_top1,\n",
    "            \"val_accuracy_top5\": val_acc_top5\n",
    "        })\n",
    "            \n",
    "        # 최고 정확도 모델 저장 (top-1 기준)\n",
    "        if val_acc_top1 > best_acc_top1:\n",
    "            best_acc_top1 = val_acc_top1\n",
    "            best_acc_top5_at_best_top1 = val_acc_top5\n",
    "            print(f'New best top-1 accuracy: {best_acc_top1:.2f}%, top-5 accuracy: {best_acc_top5_at_best_top1:.2f}%')\n",
    "            # 모델 저장\n",
    "            model_path = f'best_model_{wandb.run.name}.pth'\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            \n",
    "            # WandB에 모델 아티팩트 저장\n",
    "            wandb.save(model_path)\n",
    "        \n",
    "        # top-5 accuracy 기록 업데이트\n",
    "        if val_acc_top5 > best_acc_top5:\n",
    "            best_acc_top5 = val_acc_top5\n",
    "            print(f'New best top-5 accuracy: {best_acc_top5:.2f}%')\n",
    "\n",
    "        # Early stopping 체크 (validation loss 기준)\n",
    "        early_stopping(val_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered. Training stopped.\")\n",
    "            break\n",
    "    \n",
    "    # 훈련 완료 후 모델 평가 (best model 로드)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Loading best model from early stopping checkpoint...\")\n",
    "    else:\n",
    "        print(\"Loading best model based on validation accuracy...\")\n",
    "        model_path = f'best_model_{wandb.run.name}.pth'\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    # 최종 테스트 세트 평가\n",
    "    test_loss, test_acc_top1, test_acc_top5 = evaluate(model, testloader, criterion, device, num_epochs-1, phase=\"test\")\n",
    "\n",
    "    # 테스트 결과를 wandb 로그에 추가\n",
    "    wandb.log({\n",
    "        \"epoch\": epoch + 1,  # 마지막 에폭 또는 early stopping된 에폭\n",
    "        \"test_loss\": test_loss,\n",
    "        \"test_accuracy_top1\": test_acc_top1,\n",
    "        \"test_accuracy_top5\": test_acc_top5\n",
    "    })\n",
    "        \n",
    "    print(f'Finish! Best validation top-1 accuracy: {best_acc_top1:.2f}%, Best validation top-5 accuracy: {best_acc_top5:.2f}%')\n",
    "    print(f'Final test top-1 accuracy: {test_acc_top1:.2f}%, Final test top-5 accuracy: {test_acc_top5:.2f}%')\n",
    "    \n",
    "    # WandB에 최종 결과 기록\n",
    "    wandb.run.summary[\"best_val_accuracy_top1\"] = best_acc_top1\n",
    "    wandb.run.summary[\"best_val_accuracy_top5\"] = best_acc_top5\n",
    "    wandb.run.summary[\"test_accuracy_top1\"] = test_acc_top1\n",
    "    wandb.run.summary[\"test_accuracy_top5\"] = test_acc_top5\n",
    "\n",
    "    # Early stopping 정보 저장\n",
    "    if early_stopping.early_stop:\n",
    "        wandb.run.summary[\"early_stopped\"] = True\n",
    "        wandb.run.summary[\"early_stopped_epoch\"] = epoch+1\n",
    "    else:\n",
    "        wandb.run.summary[\"early_stopped\"] = False\n",
    "\n",
    "\n",
    "# 디바이스 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 모델 초기화\n",
    "model = resnet50().to(device)  \n",
    "criterion = nn.CrossEntropyLoss()  # 손실 함수 정의\n",
    "optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"])  # 옵티마이저 정의\n",
    "\n",
    "# WandB에 모델 구조 기록\n",
    "wandb.watch(model, log=\"all\")\n",
    "\n",
    "# GPU 가속\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"{torch.cuda.device_count()}개의 GPU를 사용합니다.\")\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "# 훈련 시작 시간 기록\n",
    "start_time = time.time()\n",
    "\n",
    "# 메인 학습 루프 호출\n",
    "main_training_loop(\n",
    "    model=model,\n",
    "    trainloader=trainloader,\n",
    "    valloader=valloader,\n",
    "    testloader=testloader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    num_epochs=config[\"num_epochs\"],\n",
    "    patience=config[\"patience\"]\n",
    ")\n",
    "\n",
    "# 훈련 종료 시간 기록 및 출력\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "wandb.log({\"total_training_time\": total_time})\n",
    "\n",
    "print(f\"Total training time: {total_time:.2f} seconds\")\n",
    "\n",
    "# WandB 실행 종료\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57b9218-aa24-4297-bb92-473c215e6767",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
