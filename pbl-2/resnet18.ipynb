{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "516f9d5f-6361-4b03-98ee-e1ba4de86b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">resnet18-cifar100</strong> at: <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/slehgam7' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/slehgam7</a><br> View project at: <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250411_132855-slehgam7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/guswls/EEN4015_Intro2ML/pbl-2/wandb/run-20250411_141331-vmlea5s2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/vmlea5s2' target=\"_blank\">resnet18-cifar100</a></strong> to <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/vmlea5s2' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/vmlea5s2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Using device: cuda\n",
      "2개의 GPU를 사용합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                        | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Batch [50/391], Loss: 4.0298\n",
      "Epoch [1], Batch [100/391], Loss: 3.9639\n",
      "Epoch [1], Batch [150/391], Loss: 3.7676\n",
      "Epoch [1], Batch [200/391], Loss: 3.7366\n",
      "Epoch [1], Batch [250/391], Loss: 3.1741\n",
      "Epoch [1], Batch [300/391], Loss: 3.3485\n",
      "Epoch [1], Batch [350/391], Loss: 3.0976\n",
      "Train set: Epoch: 1, Average loss:3.6294, LR: 0.001000 Top-1 Accuracy: 14.2620%, Time consumed:136.77s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▊                                                                                          | 1/20 [02:40<50:56, 160.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 1, Average loss:3.3422, Top-1 Accuracy: 19.4200%, Time consumed:24.01s\n",
      "\n",
      "new best accuracy: 19.42%\n",
      "Epoch [2], Batch [50/391], Loss: 3.0490\n",
      "Epoch [2], Batch [100/391], Loss: 2.8896\n",
      "Epoch [2], Batch [150/391], Loss: 2.7912\n",
      "Epoch [2], Batch [200/391], Loss: 2.6927\n",
      "Epoch [2], Batch [250/391], Loss: 2.5435\n",
      "Epoch [2], Batch [300/391], Loss: 2.3125\n",
      "Epoch [2], Batch [350/391], Loss: 2.2837\n",
      "Train set: Epoch: 2, Average loss:2.6827, LR: 0.001000 Top-1 Accuracy: 30.8280%, Time consumed:138.39s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█████████▌                                                                                     | 2/20 [05:25<48:51, 162.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 2, Average loss:2.4428, Top-1 Accuracy: 35.9100%, Time consumed:25.73s\n",
      "\n",
      "new best accuracy: 35.91%\n",
      "Epoch [3], Batch [50/391], Loss: 2.3539\n",
      "Epoch [3], Batch [100/391], Loss: 2.0003\n",
      "Epoch [3], Batch [150/391], Loss: 1.9958\n",
      "Epoch [3], Batch [200/391], Loss: 1.9782\n",
      "Epoch [3], Batch [250/391], Loss: 1.8713\n",
      "Epoch [3], Batch [300/391], Loss: 1.9979\n",
      "Epoch [3], Batch [350/391], Loss: 2.2639\n",
      "Train set: Epoch: 3, Average loss:2.1181, LR: 0.001000 Top-1 Accuracy: 42.7500%, Time consumed:138.80s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|██████████████▎                                                                                | 3/20 [08:08<46:10, 162.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 3, Average loss:2.0910, Top-1 Accuracy: 43.4100%, Time consumed:24.09s\n",
      "\n",
      "new best accuracy: 43.41%\n",
      "Epoch [4], Batch [50/391], Loss: 1.5676\n",
      "Epoch [4], Batch [100/391], Loss: 1.6410\n",
      "Epoch [4], Batch [150/391], Loss: 1.8668\n",
      "Epoch [4], Batch [200/391], Loss: 1.7898\n",
      "Epoch [4], Batch [250/391], Loss: 1.8302\n",
      "Epoch [4], Batch [300/391], Loss: 1.6693\n",
      "Epoch [4], Batch [350/391], Loss: 1.7630\n",
      "Train set: Epoch: 4, Average loss:1.7287, LR: 0.001000 Top-1 Accuracy: 51.8680%, Time consumed:130.59s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████████                                                                            | 4/20 [10:42<42:34, 159.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 4, Average loss:1.8637, Top-1 Accuracy: 48.9400%, Time consumed:23.89s\n",
      "\n",
      "new best accuracy: 48.94%\n",
      "Epoch [5], Batch [50/391], Loss: 1.2933\n",
      "Epoch [5], Batch [100/391], Loss: 1.1365\n",
      "Epoch [5], Batch [150/391], Loss: 1.5346\n",
      "Epoch [5], Batch [200/391], Loss: 1.4484\n",
      "Epoch [5], Batch [250/391], Loss: 1.4076\n",
      "Epoch [5], Batch [300/391], Loss: 1.5290\n",
      "Epoch [5], Batch [350/391], Loss: 1.2781\n",
      "Train set: Epoch: 5, Average loss:1.4041, LR: 0.001000 Top-1 Accuracy: 59.7280%, Time consumed:128.94s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████████▊                                                                       | 5/20 [13:16<39:21, 157.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 5, Average loss:1.7678, Top-1 Accuracy: 51.7100%, Time consumed:24.37s\n",
      "\n",
      "new best accuracy: 51.71%\n",
      "Epoch [6], Batch [50/391], Loss: 1.0433\n",
      "Epoch [6], Batch [100/391], Loss: 0.9669\n",
      "Epoch [6], Batch [150/391], Loss: 1.0686\n",
      "Epoch [6], Batch [200/391], Loss: 1.2374\n",
      "Epoch [6], Batch [250/391], Loss: 1.1422\n",
      "Epoch [6], Batch [300/391], Loss: 1.2711\n",
      "Epoch [6], Batch [350/391], Loss: 1.1228\n",
      "Train set: Epoch: 6, Average loss:1.1068, LR: 0.001000 Top-1 Accuracy: 67.3720%, Time consumed:130.13s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████████▌                                                                  | 6/20 [15:50<36:28, 156.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 6, Average loss:1.7758, Top-1 Accuracy: 52.3200%, Time consumed:23.85s\n",
      "\n",
      "new best accuracy: 52.32%\n",
      "Epoch [7], Batch [50/391], Loss: 0.7637\n",
      "Epoch [7], Batch [100/391], Loss: 0.7555\n",
      "Epoch [7], Batch [150/391], Loss: 0.9019\n",
      "Epoch [7], Batch [200/391], Loss: 0.7866\n",
      "Epoch [7], Batch [250/391], Loss: 0.7748\n",
      "Epoch [7], Batch [300/391], Loss: 0.6968\n",
      "Epoch [7], Batch [350/391], Loss: 0.7676\n",
      "Train set: Epoch: 7, Average loss:0.8081, LR: 0.001000 Top-1 Accuracy: 75.5120%, Time consumed:134.29s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|█████████████████████████████████▎                                                             | 7/20 [18:28<34:01, 157.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 7, Average loss:1.8129, Top-1 Accuracy: 54.1300%, Time consumed:24.08s\n",
      "\n",
      "new best accuracy: 54.13%\n",
      "Epoch [8], Batch [50/391], Loss: 0.3099\n",
      "Epoch [8], Batch [100/391], Loss: 0.4450\n",
      "Epoch [8], Batch [150/391], Loss: 0.4690\n",
      "Epoch [8], Batch [200/391], Loss: 0.5830\n",
      "Epoch [8], Batch [250/391], Loss: 0.5329\n",
      "Epoch [8], Batch [300/391], Loss: 0.6182\n",
      "Epoch [8], Batch [350/391], Loss: 0.4818\n",
      "Train set: Epoch: 8, Average loss:0.5333, LR: 0.001000 Top-1 Accuracy: 83.5440%, Time consumed:141.02s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████████████                                                         | 8/20 [21:13<31:54, 159.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 8, Average loss:2.0310, Top-1 Accuracy: 52.7500%, Time consumed:23.90s\n",
      "\n",
      "Epoch [9], Batch [50/391], Loss: 0.2430\n",
      "Epoch [9], Batch [100/391], Loss: 0.2604\n",
      "Epoch [9], Batch [150/391], Loss: 0.3790\n",
      "Epoch [9], Batch [200/391], Loss: 0.4073\n",
      "Epoch [9], Batch [250/391], Loss: 0.2384\n",
      "Epoch [9], Batch [300/391], Loss: 0.3669\n",
      "Epoch [9], Batch [350/391], Loss: 0.3917\n",
      "Train set: Epoch: 9, Average loss:0.3063, LR: 0.001000 Top-1 Accuracy: 90.6200%, Time consumed:133.58s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|██████████████████████████████████████████▊                                                    | 9/20 [23:52<29:12, 159.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 9, Average loss:2.1112, Top-1 Accuracy: 53.5000%, Time consumed:25.26s\n",
      "\n",
      "Epoch [10], Batch [50/391], Loss: 0.1703\n",
      "Epoch [10], Batch [100/391], Loss: 0.1354\n",
      "Epoch [10], Batch [150/391], Loss: 0.1752\n",
      "Epoch [10], Batch [200/391], Loss: 0.1629\n",
      "Epoch [10], Batch [250/391], Loss: 0.1677\n",
      "Epoch [10], Batch [300/391], Loss: 0.2342\n",
      "Epoch [10], Batch [350/391], Loss: 0.2288\n",
      "Train set: Epoch: 10, Average loss:0.2033, LR: 0.001000 Top-1 Accuracy: 93.8860%, Time consumed:129.89s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████████████████████████████████                                               | 10/20 [26:26<26:16, 157.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 10, Average loss:2.2632, Top-1 Accuracy: 53.2600%, Time consumed:23.90s\n",
      "\n",
      "Epoch [11], Batch [50/391], Loss: 0.1416\n",
      "Epoch [11], Batch [100/391], Loss: 0.1603\n",
      "Epoch [11], Batch [150/391], Loss: 0.1157\n",
      "Epoch [11], Batch [200/391], Loss: 0.1994\n",
      "Epoch [11], Batch [250/391], Loss: 0.1662\n",
      "Epoch [11], Batch [300/391], Loss: 0.1944\n",
      "Epoch [11], Batch [350/391], Loss: 0.1561\n",
      "Train set: Epoch: 11, Average loss:0.1446, LR: 0.001000 Top-1 Accuracy: 95.7680%, Time consumed:131.85s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|███████████████████████████████████████████████████▋                                          | 11/20 [29:02<23:33, 157.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 11, Average loss:2.4521, Top-1 Accuracy: 52.9200%, Time consumed:24.07s\n",
      "\n",
      "Epoch [12], Batch [50/391], Loss: 0.0672\n",
      "Epoch [12], Batch [100/391], Loss: 0.0620\n",
      "Epoch [12], Batch [150/391], Loss: 0.1073\n",
      "Epoch [12], Batch [200/391], Loss: 0.0857\n",
      "Epoch [12], Batch [250/391], Loss: 0.1460\n",
      "Epoch [12], Batch [300/391], Loss: 0.0940\n",
      "Epoch [12], Batch [350/391], Loss: 0.1856\n",
      "Train set: Epoch: 12, Average loss:0.1114, LR: 0.001000 Top-1 Accuracy: 96.7500%, Time consumed:129.64s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|████████████████████████████████████████████████████████▍                                     | 12/20 [31:36<20:48, 156.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 12, Average loss:2.6333, Top-1 Accuracy: 51.2500%, Time consumed:24.10s\n",
      "\n",
      "Epoch [13], Batch [50/391], Loss: 0.0945\n",
      "Epoch [13], Batch [100/391], Loss: 0.0918\n",
      "Epoch [13], Batch [150/391], Loss: 0.1282\n",
      "Epoch [13], Batch [200/391], Loss: 0.0839\n",
      "Epoch [13], Batch [250/391], Loss: 0.2562\n",
      "Epoch [13], Batch [300/391], Loss: 0.1048\n",
      "Epoch [13], Batch [350/391], Loss: 0.2421\n",
      "Train set: Epoch: 13, Average loss:0.1264, LR: 0.001000 Top-1 Accuracy: 96.1020%, Time consumed:132.21s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|█████████████████████████████████████████████████████████████                                 | 13/20 [34:12<18:13, 156.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 13, Average loss:2.5630, Top-1 Accuracy: 52.7700%, Time consumed:24.40s\n",
      "\n",
      "Epoch [14], Batch [50/391], Loss: 0.1036\n",
      "Epoch [14], Batch [100/391], Loss: 0.0856\n",
      "Epoch [14], Batch [150/391], Loss: 0.0892\n",
      "Epoch [14], Batch [200/391], Loss: 0.1525\n",
      "Epoch [14], Batch [250/391], Loss: 0.0806\n",
      "Epoch [14], Batch [300/391], Loss: 0.1718\n",
      "Epoch [14], Batch [350/391], Loss: 0.0603\n",
      "Train set: Epoch: 14, Average loss:0.1229, LR: 0.001000 Top-1 Accuracy: 96.1060%, Time consumed:137.35s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|█████████████████████████████████████████████████████████████████▊                            | 14/20 [36:54<15:47, 157.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 14, Average loss:2.6861, Top-1 Accuracy: 51.9200%, Time consumed:24.47s\n",
      "\n",
      "Epoch [15], Batch [50/391], Loss: 0.0926\n",
      "Epoch [15], Batch [100/391], Loss: 0.0552\n",
      "Epoch [15], Batch [150/391], Loss: 0.1412\n",
      "Epoch [15], Batch [200/391], Loss: 0.1498\n",
      "Epoch [15], Batch [250/391], Loss: 0.1355\n",
      "Epoch [15], Batch [300/391], Loss: 0.1508\n",
      "Epoch [15], Batch [350/391], Loss: 0.0868\n",
      "Train set: Epoch: 15, Average loss:0.1069, LR: 0.001000 Top-1 Accuracy: 96.6020%, Time consumed:137.69s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|██████████████████████████████████████████████████████████████████████▌                       | 15/20 [39:37<13:16, 159.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 15, Average loss:2.7173, Top-1 Accuracy: 52.4200%, Time consumed:24.87s\n",
      "\n",
      "Epoch [16], Batch [50/391], Loss: 0.0767\n",
      "Epoch [16], Batch [100/391], Loss: 0.0825\n",
      "Epoch [16], Batch [150/391], Loss: 0.0949\n",
      "Epoch [16], Batch [200/391], Loss: 0.1012\n",
      "Epoch [16], Batch [250/391], Loss: 0.0909\n",
      "Epoch [16], Batch [300/391], Loss: 0.1295\n",
      "Epoch [16], Batch [350/391], Loss: 0.0936\n",
      "Train set: Epoch: 16, Average loss:0.0909, LR: 0.001000 Top-1 Accuracy: 97.1180%, Time consumed:137.84s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████████████████████████████████████████████████████████████▏                  | 16/20 [42:20<10:42, 160.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 16, Average loss:2.7615, Top-1 Accuracy: 53.2500%, Time consumed:25.77s\n",
      "\n",
      "Epoch [17], Batch [50/391], Loss: 0.0256\n",
      "Epoch [17], Batch [100/391], Loss: 0.1063\n",
      "Epoch [17], Batch [150/391], Loss: 0.0269\n",
      "Epoch [17], Batch [200/391], Loss: 0.1085\n",
      "Epoch [17], Batch [250/391], Loss: 0.0704\n",
      "Epoch [17], Batch [300/391], Loss: 0.0692\n",
      "Epoch [17], Batch [350/391], Loss: 0.0857\n",
      "Train set: Epoch: 17, Average loss:0.0713, LR: 0.001000 Top-1 Accuracy: 97.7360%, Time consumed:133.44s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|███████████████████████████████████████████████████████████████████████████████▉              | 17/20 [45:00<08:00, 160.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 17, Average loss:2.9736, Top-1 Accuracy: 52.3800%, Time consumed:25.91s\n",
      "\n",
      "Epoch [18], Batch [50/391], Loss: 0.0330\n",
      "Epoch [18], Batch [100/391], Loss: 0.0255\n",
      "Epoch [18], Batch [150/391], Loss: 0.0658\n",
      "Epoch [18], Batch [200/391], Loss: 0.0337\n",
      "Epoch [18], Batch [250/391], Loss: 0.0456\n",
      "Epoch [18], Batch [300/391], Loss: 0.1444\n",
      "Epoch [18], Batch [350/391], Loss: 0.0642\n",
      "Train set: Epoch: 18, Average loss:0.0711, LR: 0.001000 Top-1 Accuracy: 97.7980%, Time consumed:137.47s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████████████████████████████████████████████████████████████████████████████████▌         | 18/20 [47:43<05:22, 161.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 18, Average loss:2.9213, Top-1 Accuracy: 52.3500%, Time consumed:25.78s\n",
      "\n",
      "Epoch [19], Batch [50/391], Loss: 0.0498\n",
      "Epoch [19], Batch [100/391], Loss: 0.0939\n",
      "Epoch [19], Batch [150/391], Loss: 0.0565\n",
      "Epoch [19], Batch [200/391], Loss: 0.1902\n",
      "Epoch [19], Batch [250/391], Loss: 0.0587\n",
      "Epoch [19], Batch [300/391], Loss: 0.0331\n",
      "Epoch [19], Batch [350/391], Loss: 0.0870\n",
      "Train set: Epoch: 19, Average loss:0.0896, LR: 0.001000 Top-1 Accuracy: 97.1520%, Time consumed:139.54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████████████████████████████████████████████████████████████████████████████████████▎    | 19/20 [50:26<02:41, 161.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 19, Average loss:3.3095, Top-1 Accuracy: 50.7000%, Time consumed:23.21s\n",
      "\n",
      "Epoch [20], Batch [50/391], Loss: 0.0545\n",
      "Epoch [20], Batch [100/391], Loss: 0.0499\n",
      "Epoch [20], Batch [150/391], Loss: 0.0306\n",
      "Epoch [20], Batch [200/391], Loss: 0.0350\n",
      "Epoch [20], Batch [250/391], Loss: 0.0907\n",
      "Epoch [20], Batch [300/391], Loss: 0.0412\n",
      "Epoch [20], Batch [350/391], Loss: 0.1017\n",
      "Train set: Epoch: 20, Average loss:0.0736, LR: 0.001000 Top-1 Accuracy: 97.6180%, Time consumed:131.23s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [53:09<00:00, 159.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 20, Average loss:2.9964, Top-1 Accuracy: 53.3200%, Time consumed:32.37s\n",
      "\n",
      "finish! best accuracy: 54.13%\n",
      "Total training time: 3189.73 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_accuracy</td><td>▁▄▆▇███████▇██████▇█</td></tr><tr><td>test_loss</td><td>█▄▂▁▁▁▁▂▃▃▄▅▅▅▅▅▆▆█▆</td></tr><tr><td>total_training_time</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▁▂▃▄▅▅▆▇▇███████████</td></tr><tr><td>train_loss</td><td>█▆▅▄▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_accuracy</td><td>54.13</td></tr><tr><td>epoch</td><td>20</td></tr><tr><td>learning_rate</td><td>0.001</td></tr><tr><td>test_accuracy</td><td>53.32</td></tr><tr><td>test_loss</td><td>2.99645</td></tr><tr><td>total_training_time</td><td>3189.73193</td></tr><tr><td>train_accuracy</td><td>97.618</td></tr><tr><td>train_loss</td><td>0.07356</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">resnet18-cifar100</strong> at: <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/vmlea5s2' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/vmlea5s2</a><br> View project at: <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250411_141331-vmlea5s2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "\n",
    "from models.resnet import resnet18, resnet34, resnet50\n",
    "\n",
    "wandb.login(key=\"ef091b9abcea3186341ddf8995d62bde62d7469e\")\n",
    "wandb.init(project=\"PBL-2\", name=\"resnet50-cutmix\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# 학습 재현성 고정\n",
    "def fix_seed(seed, deterministic=False):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    if deterministic:\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "    else:\n",
    "        torch.backends.cudnn.benchmark = True  # 성능 향상을 위해 True로 변경\n",
    "\n",
    "deterministic=True와 benchmark=False는 확실히 학습 속도를 저하시킬 수 있습니다.\n",
    "특히 torch.backends.cudnn.benchmark=False는 CUDA가 최적의 알고리즘을 찾기 위한 \n",
    "벤치마킹을 수행하지 않게 만들어 성능이 떨어질 수 있습니다.\n",
    "# 속도 우선 설정 -> 완벽한 재현성은 보장되지 않음 \n",
    "\n",
    "fix_seed(2025, deterministic=False)\n",
    "\"\"\"\n",
    "\n",
    "# WandB 설정\n",
    "config = {\n",
    "    \"model\": \"resnet50\",\n",
    "    \"batch_size\": 128,\n",
    "    \"num_epochs\": 100,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"seed\": 2025,\n",
    "    \"deterministic\": False,\n",
    "}\n",
    "wandb.config.update(config)\n",
    "\n",
    "# CIFAR-100 데이터셋 로드\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizonalFlip()\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR100(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = DataLoader(trainset, batch_size=config[\"batch_size\"], shuffle=True, num_workers=16)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR100(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = DataLoader(testset, batch_size=config[\"batch_size\"], shuffle=False, num_workers=16)\n",
    "\n",
    "\n",
    "def cutmix(batch, alpha):\n",
    "    data, targets = batch\n",
    "\n",
    "    indices = torch.randperm(data.size(0))\n",
    "    shuffled_data = data[indices]\n",
    "    shuffled_targets = targets[indices]\n",
    "\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "\n",
    "    image_h, image_w = data.shape[2:]\n",
    "    cx = np.random.uniform(0, image_w)\n",
    "    cy = np.random.uniform(0, image_h)\n",
    "    w = image_w * np.sqrt(1 - lam)\n",
    "    h = image_h * np.sqrt(1 - lam)\n",
    "    x0 = int(np.round(max(cx - w / 2, 0)))\n",
    "    x1 = int(np.round(min(cx + w / 2, image_w)))\n",
    "    y0 = int(np.round(max(cy - h / 2, 0)))\n",
    "    y1 = int(np.round(min(cy + h / 2, image_h)))\n",
    "\n",
    "    data[:, :, y0:y1, x0:x1] = shuffled_data[:, :, y0:y1, x0:x1]\n",
    "    targets = (targets, shuffled_targets, lam)\n",
    "\n",
    "    return data, targets\n",
    "\n",
    "\n",
    "class CutMixCollator:\n",
    "    def __init__(self, alpha):\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        batch = torch.utils.data.dataloader.default_collate(batch)\n",
    "        batch = cutmix(batch, self.alpha)\n",
    "        return batch\n",
    "\n",
    "\n",
    "class CutMixCriterion:\n",
    "    def __init__(self, reduction):\n",
    "        self.criterion = nn.CrossEntropyLoss(reduction=reduction)\n",
    "\n",
    "    def __call__(self, preds, targets):\n",
    "        targets1, targets2, lam = targets\n",
    "        return lam * self.criterion(\n",
    "            preds, targets1) + (1 - lam) * self.criterion(preds, targets2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train(model, trainloader, criterion, optimizer, device, epoch):\n",
    "    \"\"\"\n",
    "    학습 함수 - 0.5 확률로 CutMix 적용\n",
    "    \"\"\"\n",
    "    model.train()   # 모델을 학습 모드로 설정\n",
    "    start_time = time.time()  # 시간 측정 시작\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(trainloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # 0.5 확률로 CutMix 적용\n",
    "        r = np.random.rand(1)\n",
    "        if r < 0.5:  # 50% 확률로 CutMix 적용\n",
    "            # CutMix 적용\n",
    "            indices = torch.randperm(inputs.size(0)).to(device)\n",
    "            shuffled_labels = labels[indices]\n",
    "            \n",
    "            # 혼합 비율 결정 (Beta(1,1) = 균등분포)\n",
    "            lam = np.random.beta(1.0, 1.0)\n",
    "            \n",
    "            # 랜덤 박스 좌표 생성\n",
    "            image_h, image_w = inputs.shape[2:]\n",
    "            cx = np.random.uniform(0, image_w)\n",
    "            cy = np.random.uniform(0, image_h)\n",
    "            w = image_w * np.sqrt(1 - lam)\n",
    "            h = image_h * np.sqrt(1 - lam)\n",
    "            x0 = int(np.round(max(cx - w / 2, 0)))\n",
    "            x1 = int(np.round(min(cx + w / 2, image_w)))\n",
    "            y0 = int(np.round(max(cy - h / 2, 0)))\n",
    "            y1 = int(np.round(min(cy + h / 2, image_h)))\n",
    "            \n",
    "            # 이미지 섞기\n",
    "            inputs[:, :, y0:y1, x0:x1] = inputs[indices, :, y0:y1, x0:x1]\n",
    "            \n",
    "            # 실제 혼합 비율 계산 (영역 기반)\n",
    "            lam = 1 - ((y1 - y0) * (x1 - x0) / (image_h * image_w))\n",
    "            \n",
    "            # 모델 순전파\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # CutMix 손실 계산\n",
    "            loss = lam * criterion(outputs, labels) + (1 - lam) * criterion(outputs, shuffled_labels)\n",
    "        else:\n",
    "            # 일반 순전파 및 손실 계산\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # 정확도 계산 (CutMix를 적용했을 때는 원래 레이블로 평가)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        if (i + 1) % 50 == 0:  # 50 배치마다 출력\n",
    "            print(f'Epoch [{epoch+1}], Batch [{i+1}/{len(trainloader)}], Loss: {loss.item():.4f}')\n",
    "    \n",
    "    epoch_loss = running_loss / len(trainloader)\n",
    "    accuracy = 100.0 * correct / total\n",
    "    \n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    # 학습 세트에 대한 성능 출력\n",
    "    print(f'Train set: Epoch: {epoch+1}, Average loss:{epoch_loss:.4f}, LR: {optimizer.param_groups[0][\"lr\"]:.6f} '\n",
    "          f'Top-1 Accuracy: {accuracy:.4f}%, Time consumed:{train_time:.2f}s')\n",
    "    \n",
    "    return epoch_loss, accuracy\n",
    "\n",
    "def evaluate(model, testloader, criterion, device, epoch):\n",
    "    \"\"\"\n",
    "    평가 함수\n",
    "    \"\"\"\n",
    "    model.eval()  # 모델을 평가 모드로 설정\n",
    "    start_time = time.time()  # 시간 측정 시작\n",
    "    \n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # 그래디언트 계산 비활성화\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # 순전파\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # 손실 계산\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            # 정확도 계산\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    # 평균 손실 및 정확도 계산\n",
    "    test_loss = test_loss / len(testloader)\n",
    "    accuracy = 100.0 * correct / total\n",
    "    \n",
    "    # 평가 시간 계산\n",
    "    eval_time = time.time() - start_time\n",
    "    \n",
    "    # 테스트 세트에 대한 성능 출력 (document_7 스타일)\n",
    "    print(f'Test set: Epoch: {epoch+1}, Average loss:{test_loss:.4f}, '\n",
    "          f'Top-1 Accuracy: {accuracy:.4f}%, Time consumed:{eval_time:.2f}s')\n",
    "    print()\n",
    "    \n",
    "    return test_loss, accuracy\n",
    "\n",
    "# 메인 학습 루프\n",
    "def main_training_loop(model, trainloader, testloader, criterion, optimizer, device, num_epochs=10):\n",
    "    \"\"\"\n",
    "    메인 학습 루프\n",
    "    \"\"\"\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    # tqdm을 사용한 진행 상황 표시\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        # 학습\n",
    "        train_loss, train_acc = train(model, trainloader, criterion, optimizer, device, epoch)\n",
    "        \n",
    "        # 평가\n",
    "        test_loss, test_acc = evaluate(model, testloader, criterion, device, epoch)\n",
    "        \n",
    "        # WandB에 로깅\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_accuracy\": train_acc,\n",
    "            \"test_loss\": test_loss,\n",
    "            \"test_accuracy\": test_acc\n",
    "        })\n",
    "            \n",
    "        # 최고 정확도 모델 저장\n",
    "        if test_acc > best_acc:\n",
    "            best_acc = test_acc\n",
    "            print(f'new best accuracy: {best_acc:.2f}%')\n",
    "            \n",
    "            # 모델 저장\n",
    "            model_path = f'best_model_{wandb.run.name}.pth'\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            \n",
    "            # WandB에 모델 아티팩트 저장\n",
    "            wandb.save(model_path)\n",
    "    \n",
    "    print(f'finish! best accuracy: {best_acc:.2f}%')\n",
    "    wandb.run.summary[\"best_accuracy\"] = best_acc\n",
    "\n",
    "# 디바이스 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 모델 초기화\n",
    "model = resnet50().to(device)  \n",
    "criterion = nn.CrossEntropyLoss()  # 손실 함수 정의\n",
    "optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"])  # 옵티마이저 정의\n",
    "\n",
    "# WandB에 모델 구조 기록\n",
    "wandb.watch(model, log=\"all\")\n",
    "\n",
    "# GPU 가속\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"{torch.cuda.device_count()}개의 GPU를 사용합니다.\")\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "# 훈련 시작 시간 기록\n",
    "start_time = time.time()\n",
    "\n",
    "# 메인 학습 루프 호출\n",
    "main_training_loop(\n",
    "    model=model,\n",
    "    trainloader=trainloader,\n",
    "    testloader=testloader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    num_epochs=config[\"num_epochs\"]\n",
    ")\n",
    "\n",
    "# 훈련 종료 시간 기록 및 출력\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "wandb.log({\"total_training_time\": total_time})\n",
    "\n",
    "print(f\"Total training time: {total_time:.2f} seconds\")\n",
    "\n",
    "# WandB 실행 종료\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaaa646-eb14-44be-a97a-fde2ee3adf0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
