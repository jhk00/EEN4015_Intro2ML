{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "516f9d5f-6361-4b03-98ee-e1ba4de86b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">resnet18_cfc,lr=0.01,factor=0.5,SAM_standard</strong> at: <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/seblxl0d' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/seblxl0d</a><br> View project at: <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250418_053512-seblxl0d/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/guswls/EEN4015_Intro2ML/pbl-2/wandb/run-20250418_054151-4n6g8sbn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/4n6g8sbn' target=\"_blank\">resnet18_cfc,lr=0.01,factor=0.5,SAM_standard</a></strong> to <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/4n6g8sbn' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/4n6g8sbn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Train set size: 50000\n",
      "Test set size: 10000\n",
      "Using device: cuda\n",
      "2개의 GPU를 사용합니다."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                       | 0/300 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Batch [50/391], Loss: 4.5961, LR: 0.000256\n",
      "Epoch [1], Batch [100/391], Loss: 4.5056, LR: 0.000512\n",
      "Epoch [1], Batch [150/391], Loss: 4.0830, LR: 0.000767\n",
      "Epoch [1], Batch [200/391], Loss: 4.3724, LR: 0.001023\n",
      "Epoch [1], Batch [250/391], Loss: 3.8148, LR: 0.001279\n",
      "Epoch [1], Batch [300/391], Loss: 3.7220, LR: 0.001535\n",
      "Epoch [1], Batch [350/391], Loss: 4.3313, LR: 0.001790\n",
      "Train set: Epoch: 1, Average loss:4.2361, LR: 0.002000 Top-1 Accuracy: 6.3880%, Top-5 Accuracy: 22.4320%, Time consumed:91.87s\n",
      "Test set: Epoch: 1, Average loss:3.7305, Top-1 Accuracy: 12.6700%, Top-5 Accuracy: 37.2200%, Time consumed:8.16s\n",
      "\n",
      "새로운 최고 top-1 정확도: 12.67%, top-5 정확도: 37.22%\n",
      "새로운 최고 top-5 정확도: 37.22%\n",
      "Accuracy improved (-inf% --> 12.67%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                                           | 1/300 [01:40<8:19:36, 100.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], Batch [50/391], Loss: 3.7938, LR: 0.002256\n",
      "Epoch [2], Batch [100/391], Loss: 3.4379, LR: 0.002512\n",
      "Epoch [2], Batch [150/391], Loss: 3.6116, LR: 0.002767\n",
      "Epoch [2], Batch [200/391], Loss: 3.3739, LR: 0.003023\n",
      "Epoch [2], Batch [250/391], Loss: 3.2603, LR: 0.003279\n",
      "Epoch [2], Batch [300/391], Loss: 3.3991, LR: 0.003535\n",
      "Epoch [2], Batch [350/391], Loss: 3.9479, LR: 0.003790\n",
      "Train set: Epoch: 2, Average loss:3.7179, LR: 0.004000 Top-1 Accuracy: 14.1860%, Top-5 Accuracy: 39.0500%, Time consumed:94.84s\n",
      "Test set: Epoch: 2, Average loss:3.2554, Top-1 Accuracy: 21.3300%, Top-5 Accuracy: 50.4000%, Time consumed:8.05s\n",
      "\n",
      "새로운 최고 top-1 정확도: 21.33%, top-5 정확도: 50.40%\n",
      "새로운 최고 top-5 정확도: 50.40%\n",
      "Accuracy improved (12.67% --> 21.33%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▌                                                                                           | 2/300 [03:23<8:26:26, 101.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3], Batch [50/391], Loss: 3.0326, LR: 0.004256\n",
      "Epoch [3], Batch [100/391], Loss: 3.0342, LR: 0.004512\n",
      "Epoch [3], Batch [150/391], Loss: 4.0415, LR: 0.004767\n",
      "Epoch [3], Batch [200/391], Loss: 3.8093, LR: 0.005023\n",
      "Epoch [3], Batch [250/391], Loss: 2.8377, LR: 0.005279\n",
      "Epoch [3], Batch [300/391], Loss: 2.9366, LR: 0.005535\n",
      "Epoch [3], Batch [350/391], Loss: 2.7980, LR: 0.005790\n",
      "Train set: Epoch: 3, Average loss:3.3317, LR: 0.006000 Top-1 Accuracy: 21.8020%, Top-5 Accuracy: 50.9640%, Time consumed:90.53s\n",
      "Test set: Epoch: 3, Average loss:2.6647, Top-1 Accuracy: 31.7800%, Top-5 Accuracy: 63.8200%, Time consumed:8.10s\n",
      "\n",
      "새로운 최고 top-1 정확도: 31.78%, top-5 정확도: 63.82%\n",
      "새로운 최고 top-5 정확도: 63.82%\n",
      "Accuracy improved (21.33% --> 31.78%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▉                                                                                           | 3/300 [05:02<8:17:54, 100.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4], Batch [50/391], Loss: 3.1691, LR: 0.006256\n",
      "Epoch [4], Batch [100/391], Loss: 2.8669, LR: 0.006512\n",
      "Epoch [4], Batch [150/391], Loss: 2.6220, LR: 0.006767\n",
      "Epoch [4], Batch [200/391], Loss: 2.6368, LR: 0.007023\n",
      "Epoch [4], Batch [250/391], Loss: 3.8379, LR: 0.007279\n",
      "Epoch [4], Batch [300/391], Loss: 3.5700, LR: 0.007535\n",
      "Epoch [4], Batch [350/391], Loss: 2.4219, LR: 0.007790\n",
      "Train set: Epoch: 4, Average loss:2.9721, LR: 0.008000 Top-1 Accuracy: 29.2860%, Top-5 Accuracy: 60.6960%, Time consumed:93.83s\n",
      "Test set: Epoch: 4, Average loss:2.3399, Top-1 Accuracy: 38.1600%, Top-5 Accuracy: 71.0900%, Time consumed:8.36s\n",
      "\n",
      "새로운 최고 top-1 정확도: 38.16%, top-5 정확도: 71.09%\n",
      "새로운 최고 top-5 정확도: 71.09%\n",
      "Accuracy improved (31.78% --> 38.16%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▏                                                                                          | 4/300 [06:44<8:19:49, 101.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5], Batch [50/391], Loss: 3.8390, LR: 0.008256\n",
      "Epoch [5], Batch [100/391], Loss: 3.3550, LR: 0.008512\n",
      "Epoch [5], Batch [150/391], Loss: 2.1009, LR: 0.008767\n",
      "Epoch [5], Batch [200/391], Loss: 3.2485, LR: 0.009023\n",
      "Epoch [5], Batch [250/391], Loss: 2.1393, LR: 0.009279\n",
      "Epoch [5], Batch [300/391], Loss: 2.1440, LR: 0.009535\n",
      "Epoch [5], Batch [350/391], Loss: 2.0353, LR: 0.009790\n",
      "Train set: Epoch: 5, Average loss:2.7229, LR: 0.010000 Top-1 Accuracy: 35.2300%, Top-5 Accuracy: 66.9600%, Time consumed:94.16s\n",
      "Test set: Epoch: 5, Average loss:2.0010, Top-1 Accuracy: 46.0400%, Top-5 Accuracy: 77.8200%, Time consumed:9.04s\n",
      "\n",
      "새로운 최고 top-1 정확도: 46.04%, top-5 정확도: 77.82%\n",
      "새로운 최고 top-5 정확도: 77.82%\n",
      "Accuracy improved (38.16% --> 46.04%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▌                                                                                          | 5/300 [08:28<8:21:56, 102.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6], Batch [50/391], Loss: 2.5787, LR: 0.010000\n",
      "Epoch [6], Batch [100/391], Loss: 1.7364, LR: 0.010000\n",
      "Epoch [6], Batch [150/391], Loss: 3.6242, LR: 0.010000\n",
      "Epoch [6], Batch [200/391], Loss: 3.0872, LR: 0.010000\n",
      "Epoch [6], Batch [250/391], Loss: 2.1317, LR: 0.010000\n",
      "Epoch [6], Batch [300/391], Loss: 1.8930, LR: 0.010000\n",
      "Epoch [6], Batch [350/391], Loss: 2.8879, LR: 0.010000\n",
      "Train set: Epoch: 6, Average loss:2.6331, LR: 0.010000 Top-1 Accuracy: 38.7280%, Top-5 Accuracy: 69.2240%, Time consumed:96.24s\n",
      "Test set: Epoch: 6, Average loss:1.8909, Top-1 Accuracy: 48.8300%, Top-5 Accuracy: 79.4000%, Time consumed:9.13s\n",
      "\n",
      "새로운 최고 top-1 정확도: 48.83%, top-5 정확도: 79.40%\n",
      "새로운 최고 top-5 정확도: 79.40%\n",
      "Accuracy improved (46.04% --> 48.83%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▊                                                                                          | 6/300 [10:13<8:26:07, 103.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7], Batch [50/391], Loss: 3.5995, LR: 0.010000\n",
      "Epoch [7], Batch [100/391], Loss: 3.5471, LR: 0.010000\n",
      "Epoch [7], Batch [150/391], Loss: 1.5324, LR: 0.010000\n",
      "Epoch [7], Batch [200/391], Loss: 1.5266, LR: 0.010000\n",
      "Epoch [7], Batch [250/391], Loss: 3.6060, LR: 0.010000\n",
      "Epoch [7], Batch [300/391], Loss: 3.4678, LR: 0.010000\n",
      "Epoch [7], Batch [350/391], Loss: 2.1975, LR: 0.010000\n",
      "Train set: Epoch: 7, Average loss:2.4396, LR: 0.010000 Top-1 Accuracy: 43.1080%, Top-5 Accuracy: 73.2060%, Time consumed:93.45s\n",
      "Test set: Epoch: 7, Average loss:1.6691, Top-1 Accuracy: 54.1100%, Top-5 Accuracy: 83.2900%, Time consumed:8.50s\n",
      "\n",
      "새로운 최고 top-1 정확도: 54.11%, top-5 정확도: 83.29%\n",
      "새로운 최고 top-5 정확도: 83.29%\n",
      "Accuracy improved (48.83% --> 54.11%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██▏                                                                                         | 7/300 [11:56<8:22:40, 102.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8], Batch [50/391], Loss: 1.6941, LR: 0.010000\n",
      "Epoch [8], Batch [100/391], Loss: 3.5938, LR: 0.010000\n",
      "Epoch [8], Batch [150/391], Loss: 1.4686, LR: 0.010000\n",
      "Epoch [8], Batch [200/391], Loss: 1.6023, LR: 0.010000\n",
      "Epoch [8], Batch [250/391], Loss: 1.5122, LR: 0.010000\n",
      "Epoch [8], Batch [300/391], Loss: 1.4355, LR: 0.010000\n",
      "Epoch [8], Batch [350/391], Loss: 2.4312, LR: 0.010000\n",
      "Train set: Epoch: 8, Average loss:2.3629, LR: 0.010000 Top-1 Accuracy: 45.7120%, Top-5 Accuracy: 75.1420%, Time consumed:90.92s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▍                                                                                         | 8/300 [13:35<8:15:00, 101.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 8, Average loss:1.7279, Top-1 Accuracy: 53.6700%, Top-5 Accuracy: 82.2000%, Time consumed:8.17s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [9], Batch [50/391], Loss: 1.4759, LR: 0.010000\n",
      "Epoch [9], Batch [100/391], Loss: 3.3286, LR: 0.010000\n",
      "Epoch [9], Batch [150/391], Loss: 1.5119, LR: 0.010000\n",
      "Epoch [9], Batch [200/391], Loss: 1.6081, LR: 0.010000\n",
      "Epoch [9], Batch [250/391], Loss: 3.5524, LR: 0.010000\n",
      "Epoch [9], Batch [300/391], Loss: 1.6328, LR: 0.010000\n",
      "Epoch [9], Batch [350/391], Loss: 3.2784, LR: 0.010000\n",
      "Train set: Epoch: 9, Average loss:2.2001, LR: 0.010000 Top-1 Accuracy: 49.3040%, Top-5 Accuracy: 78.0700%, Time consumed:92.98s\n",
      "Test set: Epoch: 9, Average loss:1.6357, Top-1 Accuracy: 55.7000%, Top-5 Accuracy: 83.7000%, Time consumed:8.19s\n",
      "\n",
      "새로운 최고 top-1 정확도: 55.70%, top-5 정확도: 83.70%\n",
      "새로운 최고 top-5 정확도: 83.70%\n",
      "Accuracy improved (54.11% --> 55.70%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▊                                                                                         | 9/300 [15:16<8:12:51, 101.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10], Batch [50/391], Loss: 1.3945, LR: 0.010000\n",
      "Epoch [10], Batch [100/391], Loss: 1.2465, LR: 0.010000\n",
      "Epoch [10], Batch [150/391], Loss: 3.3033, LR: 0.010000\n",
      "Epoch [10], Batch [200/391], Loss: 1.2888, LR: 0.010000\n",
      "Epoch [10], Batch [250/391], Loss: 1.5038, LR: 0.010000\n",
      "Epoch [10], Batch [300/391], Loss: 1.4028, LR: 0.010000\n",
      "Epoch [10], Batch [350/391], Loss: 1.2001, LR: 0.010000\n",
      "Train set: Epoch: 10, Average loss:2.0976, LR: 0.010000 Top-1 Accuracy: 51.9860%, Top-5 Accuracy: 80.2120%, Time consumed:90.05s\n",
      "Test set: Epoch: 10, Average loss:1.6199, Top-1 Accuracy: 56.4500%, Top-5 Accuracy: 84.2300%, Time consumed:8.09s\n",
      "\n",
      "새로운 최고 top-1 정확도: 56.45%, top-5 정확도: 84.23%\n",
      "새로운 최고 top-5 정확도: 84.23%\n",
      "Accuracy improved (55.70% --> 56.45%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|███                                                                                        | 10/300 [16:55<8:06:22, 100.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11], Batch [50/391], Loss: 1.2256, LR: 0.010000\n",
      "Epoch [11], Batch [100/391], Loss: 1.2094, LR: 0.010000\n",
      "Epoch [11], Batch [150/391], Loss: 1.5612, LR: 0.010000\n",
      "Epoch [11], Batch [200/391], Loss: 1.3575, LR: 0.010000\n",
      "Epoch [11], Batch [250/391], Loss: 1.2561, LR: 0.010000\n",
      "Epoch [11], Batch [300/391], Loss: 2.8355, LR: 0.010000\n",
      "Epoch [11], Batch [350/391], Loss: 1.3629, LR: 0.010000\n",
      "Train set: Epoch: 11, Average loss:2.0274, LR: 0.010000 Top-1 Accuracy: 53.9100%, Top-5 Accuracy: 81.4060%, Time consumed:89.04s\n",
      "Test set: Epoch: 11, Average loss:1.4695, Top-1 Accuracy: 59.3900%, Top-5 Accuracy: 85.7000%, Time consumed:8.38s\n",
      "\n",
      "새로운 최고 top-1 정확도: 59.39%, top-5 정확도: 85.70%\n",
      "새로운 최고 top-5 정확도: 85.70%\n",
      "Accuracy improved (56.45% --> 59.39%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▎                                                                                        | 11/300 [18:32<8:00:19, 99.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12], Batch [50/391], Loss: 3.0174, LR: 0.010000\n",
      "Epoch [12], Batch [100/391], Loss: 1.3715, LR: 0.010000\n",
      "Epoch [12], Batch [150/391], Loss: 0.9964, LR: 0.010000\n",
      "Epoch [12], Batch [200/391], Loss: 3.0314, LR: 0.010000\n",
      "Epoch [12], Batch [250/391], Loss: 1.3879, LR: 0.010000\n",
      "Epoch [12], Batch [300/391], Loss: 1.0072, LR: 0.010000\n",
      "Epoch [12], Batch [350/391], Loss: 1.1371, LR: 0.010000\n",
      "Train set: Epoch: 12, Average loss:1.9590, LR: 0.010000 Top-1 Accuracy: 55.5480%, Top-5 Accuracy: 82.4800%, Time consumed:89.18s\n",
      "Test set: Epoch: 12, Average loss:1.3505, Top-1 Accuracy: 62.1400%, Top-5 Accuracy: 87.9800%, Time consumed:8.99s\n",
      "\n",
      "새로운 최고 top-1 정확도: 62.14%, top-5 정확도: 87.98%\n",
      "새로운 최고 top-5 정확도: 87.98%\n",
      "Accuracy improved (59.39% --> 62.14%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▋                                                                                        | 12/300 [20:11<7:56:44, 99.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13], Batch [50/391], Loss: 3.3230, LR: 0.010000\n",
      "Epoch [13], Batch [100/391], Loss: 3.3444, LR: 0.010000\n",
      "Epoch [13], Batch [150/391], Loss: 1.3384, LR: 0.010000\n",
      "Epoch [13], Batch [200/391], Loss: 3.0272, LR: 0.010000\n",
      "Epoch [13], Batch [250/391], Loss: 3.3493, LR: 0.010000\n",
      "Epoch [13], Batch [300/391], Loss: 1.9738, LR: 0.010000\n",
      "Epoch [13], Batch [350/391], Loss: 3.1221, LR: 0.010000\n",
      "Train set: Epoch: 13, Average loss:2.0172, LR: 0.010000 Top-1 Accuracy: 56.0540%, Top-5 Accuracy: 82.3700%, Time consumed:89.19s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▉                                                                                        | 13/300 [21:49<7:53:05, 98.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 13, Average loss:1.4139, Top-1 Accuracy: 61.8000%, Top-5 Accuracy: 87.5000%, Time consumed:8.74s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [14], Batch [50/391], Loss: 2.6200, LR: 0.010000\n",
      "Epoch [14], Batch [100/391], Loss: 0.7389, LR: 0.010000\n",
      "Epoch [14], Batch [150/391], Loss: 1.1539, LR: 0.010000\n",
      "Epoch [14], Batch [200/391], Loss: 2.2253, LR: 0.010000\n",
      "Epoch [14], Batch [250/391], Loss: 2.7622, LR: 0.010000\n",
      "Epoch [14], Batch [300/391], Loss: 1.0358, LR: 0.010000\n",
      "Epoch [14], Batch [350/391], Loss: 3.1959, LR: 0.010000\n",
      "Train set: Epoch: 14, Average loss:1.9088, LR: 0.010000 Top-1 Accuracy: 58.3120%, Top-5 Accuracy: 84.1640%, Time consumed:88.32s\n",
      "Test set: Epoch: 14, Average loss:1.3160, Top-1 Accuracy: 63.7900%, Top-5 Accuracy: 88.6300%, Time consumed:8.22s\n",
      "\n",
      "새로운 최고 top-1 정확도: 63.79%, top-5 정확도: 88.63%\n",
      "새로운 최고 top-5 정확도: 88.63%\n",
      "Accuracy improved (62.14% --> 63.79%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▎                                                                                       | 14/300 [23:25<7:48:23, 98.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15], Batch [50/391], Loss: 1.0252, LR: 0.010000\n",
      "Epoch [15], Batch [100/391], Loss: 2.9919, LR: 0.010000\n",
      "Epoch [15], Batch [150/391], Loss: 1.1158, LR: 0.010000\n",
      "Epoch [15], Batch [200/391], Loss: 2.9001, LR: 0.010000\n",
      "Epoch [15], Batch [250/391], Loss: 2.6305, LR: 0.010000\n",
      "Epoch [15], Batch [300/391], Loss: 0.7260, LR: 0.010000\n",
      "Epoch [15], Batch [350/391], Loss: 1.0409, LR: 0.010000\n",
      "Train set: Epoch: 15, Average loss:1.8724, LR: 0.010000 Top-1 Accuracy: 58.6980%, Top-5 Accuracy: 83.7240%, Time consumed:90.70s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▌                                                                                       | 15/300 [25:04<7:47:44, 98.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 15, Average loss:1.3459, Top-1 Accuracy: 63.4300%, Top-5 Accuracy: 88.0500%, Time consumed:8.25s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [16], Batch [50/391], Loss: 0.9209, LR: 0.010000\n",
      "Epoch [16], Batch [100/391], Loss: 1.0218, LR: 0.010000\n",
      "Epoch [16], Batch [150/391], Loss: 0.9059, LR: 0.010000\n",
      "Epoch [16], Batch [200/391], Loss: 3.3158, LR: 0.010000\n",
      "Epoch [16], Batch [250/391], Loss: 3.1980, LR: 0.010000\n",
      "Epoch [16], Batch [300/391], Loss: 1.0154, LR: 0.010000\n",
      "Epoch [16], Batch [350/391], Loss: 1.0829, LR: 0.010000\n",
      "Train set: Epoch: 16, Average loss:1.8286, LR: 0.010000 Top-1 Accuracy: 59.9980%, Top-5 Accuracy: 84.6520%, Time consumed:87.96s\n",
      "Test set: Epoch: 16, Average loss:1.2242, Top-1 Accuracy: 65.4000%, Top-5 Accuracy: 89.8900%, Time consumed:8.42s\n",
      "\n",
      "새로운 최고 top-1 정확도: 65.40%, top-5 정확도: 89.89%\n",
      "새로운 최고 top-5 정확도: 89.89%\n",
      "Accuracy improved (63.79% --> 65.40%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▉                                                                                       | 16/300 [26:41<7:43:33, 97.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17], Batch [50/391], Loss: 1.6794, LR: 0.010000\n",
      "Epoch [17], Batch [100/391], Loss: 2.0241, LR: 0.010000\n",
      "Epoch [17], Batch [150/391], Loss: 2.6312, LR: 0.010000\n",
      "Epoch [17], Batch [200/391], Loss: 0.8840, LR: 0.010000\n",
      "Epoch [17], Batch [250/391], Loss: 2.7965, LR: 0.010000\n",
      "Epoch [17], Batch [300/391], Loss: 2.7870, LR: 0.010000\n",
      "Epoch [17], Batch [350/391], Loss: 1.4999, LR: 0.010000\n",
      "Train set: Epoch: 17, Average loss:1.7685, LR: 0.010000 Top-1 Accuracy: 60.7520%, Top-5 Accuracy: 84.9500%, Time consumed:88.71s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████▏                                                                                      | 17/300 [28:18<7:40:19, 97.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 17, Average loss:1.2480, Top-1 Accuracy: 65.3900%, Top-5 Accuracy: 89.1400%, Time consumed:8.08s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [18], Batch [50/391], Loss: 0.6875, LR: 0.010000\n",
      "Epoch [18], Batch [100/391], Loss: 0.8873, LR: 0.010000\n",
      "Epoch [18], Batch [150/391], Loss: 2.0307, LR: 0.010000\n",
      "Epoch [18], Batch [200/391], Loss: 0.7984, LR: 0.010000\n",
      "Epoch [18], Batch [250/391], Loss: 3.2986, LR: 0.010000\n",
      "Epoch [18], Batch [300/391], Loss: 2.1950, LR: 0.010000\n",
      "Epoch [18], Batch [350/391], Loss: 2.8187, LR: 0.010000\n",
      "Train set: Epoch: 18, Average loss:1.7113, LR: 0.010000 Top-1 Accuracy: 63.0800%, Top-5 Accuracy: 86.6840%, Time consumed:90.86s\n",
      "Test set: Epoch: 18, Average loss:1.2431, Top-1 Accuracy: 65.6300%, Top-5 Accuracy: 89.6000%, Time consumed:8.03s\n",
      "\n",
      "새로운 최고 top-1 정확도: 65.63%, top-5 정확도: 89.60%\n",
      "Accuracy improved (65.40% --> 65.63%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████▌                                                                                      | 18/300 [29:57<7:40:55, 98.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19], Batch [50/391], Loss: 2.2731, LR: 0.010000\n",
      "Epoch [19], Batch [100/391], Loss: 1.0484, LR: 0.010000\n",
      "Epoch [19], Batch [150/391], Loss: 2.6294, LR: 0.010000\n",
      "Epoch [19], Batch [200/391], Loss: 1.0181, LR: 0.010000\n",
      "Epoch [19], Batch [250/391], Loss: 0.8232, LR: 0.010000\n",
      "Epoch [19], Batch [300/391], Loss: 2.4790, LR: 0.010000\n",
      "Epoch [19], Batch [350/391], Loss: 2.9758, LR: 0.010000\n",
      "Train set: Epoch: 19, Average loss:1.7287, LR: 0.010000 Top-1 Accuracy: 62.4540%, Top-5 Accuracy: 85.9420%, Time consumed:94.42s\n",
      "Test set: Epoch: 19, Average loss:1.2058, Top-1 Accuracy: 66.3000%, Top-5 Accuracy: 90.0400%, Time consumed:8.21s\n",
      "\n",
      "새로운 최고 top-1 정확도: 66.30%, top-5 정확도: 90.04%\n",
      "새로운 최고 top-5 정확도: 90.04%\n",
      "Accuracy improved (65.63% --> 66.30%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████▊                                                                                      | 19/300 [31:40<7:46:05, 99.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20], Batch [50/391], Loss: 0.8161, LR: 0.010000\n",
      "Epoch [20], Batch [100/391], Loss: 0.8804, LR: 0.010000\n",
      "Epoch [20], Batch [150/391], Loss: 1.2676, LR: 0.010000\n",
      "Epoch [20], Batch [200/391], Loss: 0.6969, LR: 0.010000\n",
      "Epoch [20], Batch [250/391], Loss: 0.8443, LR: 0.010000\n",
      "Epoch [20], Batch [300/391], Loss: 1.5636, LR: 0.010000\n",
      "Epoch [20], Batch [350/391], Loss: 2.9584, LR: 0.010000\n",
      "Train set: Epoch: 20, Average loss:1.6785, LR: 0.010000 Top-1 Accuracy: 64.8960%, Top-5 Accuracy: 87.5360%, Time consumed:89.76s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████▏                                                                                     | 20/300 [33:18<7:42:35, 99.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 20, Average loss:1.2607, Top-1 Accuracy: 66.1500%, Top-5 Accuracy: 89.4500%, Time consumed:8.45s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [21], Batch [50/391], Loss: 2.4809, LR: 0.010000\n",
      "Epoch [21], Batch [100/391], Loss: 3.2015, LR: 0.010000\n",
      "Epoch [21], Batch [150/391], Loss: 0.6789, LR: 0.010000\n",
      "Epoch [21], Batch [200/391], Loss: 0.7783, LR: 0.010000\n",
      "Epoch [21], Batch [250/391], Loss: 0.5351, LR: 0.010000\n",
      "Epoch [21], Batch [300/391], Loss: 3.1097, LR: 0.010000\n",
      "Epoch [21], Batch [350/391], Loss: 3.0556, LR: 0.010000\n",
      "Train set: Epoch: 21, Average loss:1.7365, LR: 0.010000 Top-1 Accuracy: 63.4520%, Top-5 Accuracy: 86.3180%, Time consumed:90.19s\n",
      "Test set: Epoch: 21, Average loss:1.1681, Top-1 Accuracy: 67.1400%, Top-5 Accuracy: 90.4600%, Time consumed:8.07s\n",
      "\n",
      "새로운 최고 top-1 정확도: 67.14%, top-5 정확도: 90.46%\n",
      "새로운 최고 top-5 정확도: 90.46%\n",
      "Accuracy improved (66.30% --> 67.14%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████▍                                                                                     | 21/300 [34:57<7:40:08, 98.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22], Batch [50/391], Loss: 2.2588, LR: 0.010000\n",
      "Epoch [22], Batch [100/391], Loss: 0.4932, LR: 0.010000\n",
      "Epoch [22], Batch [150/391], Loss: 2.2418, LR: 0.010000\n",
      "Epoch [22], Batch [200/391], Loss: 0.5837, LR: 0.010000\n",
      "Epoch [22], Batch [250/391], Loss: 0.5170, LR: 0.010000\n",
      "Epoch [22], Batch [300/391], Loss: 2.2442, LR: 0.010000\n",
      "Epoch [22], Batch [350/391], Loss: 2.8448, LR: 0.010000\n",
      "Train set: Epoch: 22, Average loss:1.5761, LR: 0.010000 Top-1 Accuracy: 66.6740%, Top-5 Accuracy: 88.1980%, Time consumed:88.98s\n",
      "Test set: Epoch: 22, Average loss:1.1731, Top-1 Accuracy: 67.5000%, Top-5 Accuracy: 90.5400%, Time consumed:8.16s\n",
      "\n",
      "새로운 최고 top-1 정확도: 67.50%, top-5 정확도: 90.54%\n",
      "새로운 최고 top-5 정확도: 90.54%\n",
      "Accuracy improved (67.14% --> 67.50%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████▋                                                                                     | 22/300 [36:34<7:36:18, 98.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23], Batch [50/391], Loss: 1.0986, LR: 0.010000\n",
      "Epoch [23], Batch [100/391], Loss: 3.4793, LR: 0.010000\n",
      "Epoch [23], Batch [150/391], Loss: 2.5732, LR: 0.010000\n",
      "Epoch [23], Batch [200/391], Loss: 0.6118, LR: 0.010000\n",
      "Epoch [23], Batch [250/391], Loss: 0.5637, LR: 0.010000\n",
      "Epoch [23], Batch [300/391], Loss: 0.5179, LR: 0.010000\n",
      "Epoch [23], Batch [350/391], Loss: 3.1281, LR: 0.010000\n",
      "Train set: Epoch: 23, Average loss:1.5945, LR: 0.010000 Top-1 Accuracy: 67.1180%, Top-5 Accuracy: 88.2780%, Time consumed:94.20s\n",
      "Test set: Epoch: 23, Average loss:1.1823, Top-1 Accuracy: 67.5100%, Top-5 Accuracy: 89.9800%, Time consumed:8.24s\n",
      "\n",
      "새로운 최고 top-1 정확도: 67.51%, top-5 정확도: 89.98%\n",
      "Accuracy improved (67.50% --> 67.51%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███████                                                                                     | 23/300 [38:17<7:40:29, 99.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24], Batch [50/391], Loss: 0.4199, LR: 0.010000\n",
      "Epoch [24], Batch [100/391], Loss: 2.4438, LR: 0.010000\n",
      "Epoch [24], Batch [150/391], Loss: 0.6514, LR: 0.010000\n",
      "Epoch [24], Batch [200/391], Loss: 0.5871, LR: 0.010000\n",
      "Epoch [24], Batch [250/391], Loss: 0.5344, LR: 0.010000\n",
      "Epoch [24], Batch [300/391], Loss: 0.6076, LR: 0.010000\n",
      "Epoch [24], Batch [350/391], Loss: 0.7009, LR: 0.010000\n",
      "Train set: Epoch: 24, Average loss:1.4884, LR: 0.010000 Top-1 Accuracy: 67.7540%, Top-5 Accuracy: 88.2160%, Time consumed:91.67s\n",
      "Test set: Epoch: 24, Average loss:1.1726, Top-1 Accuracy: 67.8800%, Top-5 Accuracy: 90.0300%, Time consumed:8.36s\n",
      "\n",
      "새로운 최고 top-1 정확도: 67.88%, top-5 정확도: 90.03%\n",
      "Accuracy improved (67.51% --> 67.88%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███████▎                                                                                    | 24/300 [39:57<7:39:33, 99.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25], Batch [50/391], Loss: 0.5745, LR: 0.010000\n",
      "Epoch [25], Batch [100/391], Loss: 0.5118, LR: 0.010000\n",
      "Epoch [25], Batch [150/391], Loss: 0.5782, LR: 0.010000\n",
      "Epoch [25], Batch [200/391], Loss: 0.4586, LR: 0.010000\n",
      "Epoch [25], Batch [250/391], Loss: 0.5844, LR: 0.010000\n",
      "Epoch [25], Batch [300/391], Loss: 2.6163, LR: 0.010000\n",
      "Epoch [25], Batch [350/391], Loss: 0.6092, LR: 0.010000\n",
      "Train set: Epoch: 25, Average loss:1.5804, LR: 0.010000 Top-1 Accuracy: 67.3440%, Top-5 Accuracy: 88.2660%, Time consumed:94.32s\n",
      "Test set: Epoch: 25, Average loss:1.1893, Top-1 Accuracy: 67.9000%, Top-5 Accuracy: 90.0100%, Time consumed:8.74s\n",
      "\n",
      "새로운 최고 top-1 정확도: 67.90%, top-5 정확도: 90.01%\n",
      "Accuracy improved (67.88% --> 67.90%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███████▌                                                                                   | 25/300 [41:40<7:42:35, 100.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26], Batch [50/391], Loss: 0.4140, LR: 0.010000\n",
      "Epoch [26], Batch [100/391], Loss: 0.5415, LR: 0.010000\n",
      "Train set: Epoch: 26, Average loss:1.3923, LR: 0.010000 Top-1 Accuracy: 70.9580%, Top-5 Accuracy: 90.4360%, Time consumed:91.79s\n",
      "Test set: Epoch: 26, Average loss:1.1603, Top-1 Accuracy: 68.3500%, Top-5 Accuracy: 90.7400%, Time consumed:8.17s\n",
      "\n",
      "새로운 최고 top-1 정확도: 68.35%, top-5 정확도: 90.74%\n",
      "새로운 최고 top-5 정확도: 90.74%\n",
      "Accuracy improved (67.90% --> 68.35%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███████▉                                                                                   | 26/300 [43:20<7:39:55, 100.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27], Batch [50/391], Loss: 0.9763, LR: 0.010000\n",
      "Epoch [27], Batch [100/391], Loss: 0.3900, LR: 0.010000\n",
      "Epoch [27], Batch [150/391], Loss: 0.5174, LR: 0.010000\n",
      "Epoch [27], Batch [200/391], Loss: 1.3260, LR: 0.010000\n",
      "Epoch [27], Batch [250/391], Loss: 3.0872, LR: 0.010000\n",
      "Epoch [27], Batch [300/391], Loss: 0.6450, LR: 0.010000\n",
      "Epoch [27], Batch [350/391], Loss: 2.7293, LR: 0.010000\n",
      "Train set: Epoch: 27, Average loss:1.4622, LR: 0.010000 Top-1 Accuracy: 70.4680%, Top-5 Accuracy: 89.7620%, Time consumed:89.37s\n",
      "Test set: Epoch: 27, Average loss:1.1444, Top-1 Accuracy: 68.8800%, Top-5 Accuracy: 90.5700%, Time consumed:8.09s\n",
      "\n",
      "새로운 최고 top-1 정확도: 68.88%, top-5 정확도: 90.57%\n",
      "Accuracy improved (68.35% --> 68.88%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|████████▎                                                                                   | 27/300 [44:58<7:34:10, 99.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28], Batch [50/391], Loss: 1.6340, LR: 0.010000\n",
      "Epoch [28], Batch [100/391], Loss: 0.2594, LR: 0.010000\n",
      "Epoch [28], Batch [150/391], Loss: 3.0301, LR: 0.010000\n",
      "Epoch [28], Batch [200/391], Loss: 2.9050, LR: 0.010000\n",
      "Epoch [28], Batch [250/391], Loss: 0.5331, LR: 0.010000\n",
      "Epoch [28], Batch [300/391], Loss: 3.1400, LR: 0.010000\n",
      "Epoch [28], Batch [350/391], Loss: 2.2895, LR: 0.010000\n",
      "Train set: Epoch: 28, Average loss:1.4401, LR: 0.010000 Top-1 Accuracy: 70.4340%, Top-5 Accuracy: 89.6620%, Time consumed:88.38s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|████████▌                                                                                   | 28/300 [46:36<7:29:13, 99.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 28, Average loss:1.1681, Top-1 Accuracy: 68.6200%, Top-5 Accuracy: 90.7400%, Time consumed:9.03s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [29], Batch [50/391], Loss: 0.4821, LR: 0.010000\n",
      "Epoch [29], Batch [100/391], Loss: 0.3249, LR: 0.010000\n",
      "Epoch [29], Batch [150/391], Loss: 0.3401, LR: 0.010000\n",
      "Epoch [29], Batch [200/391], Loss: 0.5419, LR: 0.010000\n",
      "Epoch [29], Batch [250/391], Loss: 0.5635, LR: 0.010000\n",
      "Epoch [29], Batch [300/391], Loss: 3.1223, LR: 0.010000\n",
      "Epoch [29], Batch [350/391], Loss: 3.0911, LR: 0.010000\n",
      "Train set: Epoch: 29, Average loss:1.3092, LR: 0.010000 Top-1 Accuracy: 73.3940%, Top-5 Accuracy: 91.4620%, Time consumed:90.76s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▉                                                                                   | 29/300 [48:15<7:27:24, 99.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 29, Average loss:1.2145, Top-1 Accuracy: 67.8000%, Top-5 Accuracy: 89.6800%, Time consumed:8.20s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [30], Batch [50/391], Loss: 2.1323, LR: 0.010000\n",
      "Epoch [30], Batch [100/391], Loss: 1.8996, LR: 0.010000\n",
      "Epoch [30], Batch [150/391], Loss: 2.8990, LR: 0.010000\n",
      "Epoch [30], Batch [200/391], Loss: 0.3845, LR: 0.010000\n",
      "Epoch [30], Batch [250/391], Loss: 0.2362, LR: 0.010000\n",
      "Epoch [30], Batch [300/391], Loss: 0.4385, LR: 0.010000\n",
      "Epoch [30], Batch [350/391], Loss: 2.9503, LR: 0.010000\n",
      "Train set: Epoch: 30, Average loss:1.3609, LR: 0.010000 Top-1 Accuracy: 73.0080%, Top-5 Accuracy: 91.0020%, Time consumed:94.89s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█████████                                                                                  | 30/300 [49:59<7:32:53, 100.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 30, Average loss:1.2104, Top-1 Accuracy: 68.0700%, Top-5 Accuracy: 90.1400%, Time consumed:9.44s\n",
      "\n",
      "EarlyStopping 카운터: 3 / 30\n",
      "Epoch [31], Batch [50/391], Loss: 2.2309, LR: 0.010000\n",
      "Epoch [31], Batch [100/391], Loss: 0.4192, LR: 0.010000\n",
      "Epoch [31], Batch [150/391], Loss: 1.5141, LR: 0.010000\n",
      "Epoch [31], Batch [200/391], Loss: 0.4636, LR: 0.010000\n",
      "Epoch [31], Batch [250/391], Loss: 2.1346, LR: 0.010000\n",
      "Epoch [31], Batch [300/391], Loss: 0.3681, LR: 0.010000\n",
      "Epoch [31], Batch [350/391], Loss: 0.5009, LR: 0.010000\n",
      "Train set: Epoch: 31, Average loss:1.3407, LR: 0.010000 Top-1 Accuracy: 72.9740%, Top-5 Accuracy: 90.6600%, Time consumed:91.39s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█████████▍                                                                                 | 31/300 [51:39<7:30:20, 100.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 31, Average loss:1.1794, Top-1 Accuracy: 68.7900%, Top-5 Accuracy: 90.2200%, Time consumed:8.60s\n",
      "\n",
      "EarlyStopping 카운터: 4 / 30\n",
      "Epoch [32], Batch [50/391], Loss: 3.1023, LR: 0.010000\n",
      "Epoch [32], Batch [100/391], Loss: 2.8062, LR: 0.010000\n",
      "Epoch [32], Batch [150/391], Loss: 2.8335, LR: 0.010000\n",
      "Epoch [32], Batch [200/391], Loss: 0.4221, LR: 0.010000\n",
      "Epoch [32], Batch [250/391], Loss: 0.4013, LR: 0.010000\n",
      "Epoch [32], Batch [300/391], Loss: 0.3613, LR: 0.010000\n",
      "Epoch [32], Batch [350/391], Loss: 0.7592, LR: 0.010000\n",
      "Train set: Epoch: 32, Average loss:1.3570, LR: 0.010000 Top-1 Accuracy: 74.0960%, Top-5 Accuracy: 91.3200%, Time consumed:95.19s\n",
      "Test set: Epoch: 32, Average loss:1.1134, Top-1 Accuracy: 70.7400%, Top-5 Accuracy: 91.3700%, Time consumed:8.91s\n",
      "\n",
      "새로운 최고 top-1 정확도: 70.74%, top-5 정확도: 91.37%\n",
      "새로운 최고 top-5 정확도: 91.37%\n",
      "Accuracy improved (68.88% --> 70.74%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█████████▋                                                                                 | 32/300 [53:23<7:33:53, 101.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33], Batch [50/391], Loss: 1.9956, LR: 0.010000\n",
      "Epoch [33], Batch [100/391], Loss: 0.2211, LR: 0.010000\n",
      "Epoch [33], Batch [150/391], Loss: 1.7265, LR: 0.010000\n",
      "Epoch [33], Batch [200/391], Loss: 0.3549, LR: 0.010000\n",
      "Epoch [33], Batch [250/391], Loss: 2.3377, LR: 0.010000\n",
      "Epoch [33], Batch [300/391], Loss: 0.3191, LR: 0.010000\n",
      "Epoch [33], Batch [350/391], Loss: 1.6958, LR: 0.010000\n",
      "Train set: Epoch: 33, Average loss:1.2968, LR: 0.010000 Top-1 Accuracy: 74.8480%, Top-5 Accuracy: 91.5980%, Time consumed:95.87s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|██████████                                                                                 | 33/300 [55:07<7:35:34, 102.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 33, Average loss:1.1531, Top-1 Accuracy: 69.0400%, Top-5 Accuracy: 90.4900%, Time consumed:8.28s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [34], Batch [50/391], Loss: 0.3392, LR: 0.010000\n",
      "Epoch [34], Batch [100/391], Loss: 0.3408, LR: 0.010000\n",
      "Epoch [34], Batch [150/391], Loss: 0.3628, LR: 0.010000\n",
      "Epoch [34], Batch [200/391], Loss: 0.2916, LR: 0.010000\n",
      "Epoch [34], Batch [250/391], Loss: 2.7207, LR: 0.010000\n",
      "Epoch [34], Batch [300/391], Loss: 0.3896, LR: 0.010000\n",
      "Epoch [34], Batch [350/391], Loss: 0.3076, LR: 0.010000\n",
      "Train set: Epoch: 34, Average loss:1.3840, LR: 0.010000 Top-1 Accuracy: 72.5280%, Top-5 Accuracy: 90.1580%, Time consumed:91.22s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|██████████▎                                                                                | 34/300 [56:47<7:30:26, 101.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 34, Average loss:1.1529, Top-1 Accuracy: 69.6400%, Top-5 Accuracy: 90.6600%, Time consumed:8.57s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [35], Batch [50/391], Loss: 1.7061, LR: 0.010000\n",
      "Epoch [35], Batch [100/391], Loss: 0.6000, LR: 0.010000\n",
      "Epoch [35], Batch [150/391], Loss: 0.3838, LR: 0.010000\n",
      "Epoch [35], Batch [200/391], Loss: 3.1537, LR: 0.010000\n",
      "Epoch [35], Batch [250/391], Loss: 0.3699, LR: 0.010000\n",
      "Epoch [35], Batch [300/391], Loss: 1.8523, LR: 0.010000\n",
      "Epoch [35], Batch [350/391], Loss: 0.3802, LR: 0.010000\n",
      "Train set: Epoch: 35, Average loss:1.2942, LR: 0.010000 Top-1 Accuracy: 74.7200%, Top-5 Accuracy: 91.1720%, Time consumed:93.77s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████▌                                                                                | 35/300 [58:29<7:29:18, 101.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 35, Average loss:1.1848, Top-1 Accuracy: 68.4800%, Top-5 Accuracy: 90.2100%, Time consumed:8.24s\n",
      "\n",
      "EarlyStopping 카운터: 3 / 30\n",
      "Epoch [36], Batch [50/391], Loss: 2.9579, LR: 0.010000\n",
      "Epoch [36], Batch [100/391], Loss: 1.4247, LR: 0.010000\n",
      "Epoch [36], Batch [150/391], Loss: 1.9915, LR: 0.010000\n",
      "Epoch [36], Batch [200/391], Loss: 1.7044, LR: 0.010000\n",
      "Epoch [36], Batch [250/391], Loss: 0.2187, LR: 0.010000\n",
      "Epoch [36], Batch [300/391], Loss: 0.3220, LR: 0.010000\n",
      "Epoch [36], Batch [350/391], Loss: 0.9650, LR: 0.010000\n",
      "Train set: Epoch: 36, Average loss:1.3486, LR: 0.010000 Top-1 Accuracy: 74.7980%, Top-5 Accuracy: 91.5180%, Time consumed:90.19s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████▋                                                                              | 36/300 [1:00:08<7:23:26, 100.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 36, Average loss:1.1286, Top-1 Accuracy: 69.4400%, Top-5 Accuracy: 91.1400%, Time consumed:8.37s\n",
      "\n",
      "EarlyStopping 카운터: 4 / 30\n",
      "Epoch [37], Batch [50/391], Loss: 2.9919, LR: 0.010000\n",
      "Epoch [37], Batch [100/391], Loss: 0.3037, LR: 0.010000\n",
      "Epoch [37], Batch [150/391], Loss: 0.1697, LR: 0.010000\n",
      "Epoch [37], Batch [200/391], Loss: 0.1362, LR: 0.010000\n",
      "Epoch [37], Batch [250/391], Loss: 0.1836, LR: 0.010000\n",
      "Epoch [37], Batch [300/391], Loss: 2.8880, LR: 0.010000\n",
      "Epoch [37], Batch [350/391], Loss: 0.2791, LR: 0.010000\n",
      "Train set: Epoch: 37, Average loss:1.2056, LR: 0.010000 Top-1 Accuracy: 77.0300%, Top-5 Accuracy: 92.3400%, Time consumed:95.77s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████▉                                                                              | 37/300 [1:01:52<7:26:20, 101.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 37, Average loss:1.2203, Top-1 Accuracy: 68.4600%, Top-5 Accuracy: 90.0400%, Time consumed:8.50s\n",
      "\n",
      "EarlyStopping 카운터: 5 / 30\n",
      "Epoch [38], Batch [50/391], Loss: 3.1652, LR: 0.010000\n",
      "Epoch [38], Batch [100/391], Loss: 0.2576, LR: 0.010000\n",
      "Epoch [38], Batch [150/391], Loss: 0.2990, LR: 0.010000\n",
      "Epoch [38], Batch [200/391], Loss: 2.4007, LR: 0.010000\n",
      "Epoch [38], Batch [250/391], Loss: 0.6051, LR: 0.010000\n",
      "Epoch [38], Batch [300/391], Loss: 2.2668, LR: 0.010000\n",
      "Epoch [38], Batch [350/391], Loss: 1.4625, LR: 0.010000\n",
      "Train set: Epoch: 38, Average loss:1.3702, LR: 0.010000 Top-1 Accuracy: 73.7060%, Top-5 Accuracy: 90.5720%, Time consumed:91.77s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|███████████▎                                                                             | 38/300 [1:03:32<7:21:58, 101.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 38, Average loss:1.2043, Top-1 Accuracy: 68.8800%, Top-5 Accuracy: 90.0200%, Time consumed:8.01s\n",
      "\n",
      "EarlyStopping 카운터: 6 / 30\n",
      "Epoch [39], Batch [50/391], Loss: 0.1213, LR: 0.005000\n",
      "Epoch [39], Batch [100/391], Loss: 2.5409, LR: 0.005000\n",
      "Epoch [39], Batch [150/391], Loss: 2.6989, LR: 0.005000\n",
      "Epoch [39], Batch [200/391], Loss: 1.7086, LR: 0.005000\n",
      "Epoch [39], Batch [250/391], Loss: 0.1890, LR: 0.005000\n",
      "Epoch [39], Batch [300/391], Loss: 0.2470, LR: 0.005000\n",
      "Epoch [39], Batch [350/391], Loss: 0.1255, LR: 0.005000\n",
      "Train set: Epoch: 39, Average loss:1.0280, LR: 0.005000 Top-1 Accuracy: 81.0520%, Top-5 Accuracy: 93.6100%, Time consumed:93.15s\n",
      "Test set: Epoch: 39, Average loss:1.1449, Top-1 Accuracy: 72.8000%, Top-5 Accuracy: 92.2200%, Time consumed:9.33s\n",
      "\n",
      "새로운 최고 top-1 정확도: 72.80%, top-5 정확도: 92.22%\n",
      "새로운 최고 top-5 정확도: 92.22%\n",
      "Accuracy improved (70.74% --> 72.80%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|███████████▌                                                                             | 39/300 [1:05:15<7:22:14, 101.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40], Batch [50/391], Loss: 0.1640, LR: 0.005000\n",
      "Epoch [40], Batch [100/391], Loss: 2.6071, LR: 0.005000\n",
      "Epoch [40], Batch [150/391], Loss: 0.0978, LR: 0.005000\n",
      "Epoch [40], Batch [200/391], Loss: 2.3927, LR: 0.005000\n",
      "Epoch [40], Batch [250/391], Loss: 2.6388, LR: 0.005000\n",
      "Epoch [40], Batch [300/391], Loss: 1.8612, LR: 0.005000\n",
      "Epoch [40], Batch [350/391], Loss: 2.9093, LR: 0.005000\n",
      "Train set: Epoch: 40, Average loss:1.1520, LR: 0.005000 Top-1 Accuracy: 80.1240%, Top-5 Accuracy: 93.1240%, Time consumed:94.02s\n",
      "Test set: Epoch: 40, Average loss:1.0250, Top-1 Accuracy: 72.9300%, Top-5 Accuracy: 91.9700%, Time consumed:8.73s\n",
      "\n",
      "새로운 최고 top-1 정확도: 72.93%, top-5 정확도: 91.97%\n",
      "Accuracy improved (72.80% --> 72.93%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|███████████▊                                                                             | 40/300 [1:06:58<7:22:17, 102.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41], Batch [50/391], Loss: 0.1026, LR: 0.005000\n",
      "Epoch [41], Batch [100/391], Loss: 0.0920, LR: 0.005000\n",
      "Epoch [41], Batch [150/391], Loss: 0.1444, LR: 0.005000\n",
      "Epoch [41], Batch [200/391], Loss: 0.1181, LR: 0.005000\n",
      "Epoch [41], Batch [250/391], Loss: 0.1029, LR: 0.005000\n",
      "Epoch [41], Batch [300/391], Loss: 0.1113, LR: 0.005000\n",
      "Epoch [41], Batch [350/391], Loss: 0.0951, LR: 0.005000\n",
      "Train set: Epoch: 41, Average loss:1.1255, LR: 0.005000 Top-1 Accuracy: 81.3100%, Top-5 Accuracy: 93.8720%, Time consumed:96.60s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████▏                                                                            | 41/300 [1:08:42<7:24:07, 102.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 41, Average loss:1.0444, Top-1 Accuracy: 72.5100%, Top-5 Accuracy: 91.8500%, Time consumed:8.19s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [42], Batch [50/391], Loss: 2.0839, LR: 0.005000\n",
      "Epoch [42], Batch [100/391], Loss: 0.0947, LR: 0.005000\n",
      "Epoch [42], Batch [150/391], Loss: 0.1207, LR: 0.005000\n",
      "Epoch [42], Batch [200/391], Loss: 1.9430, LR: 0.005000\n",
      "Epoch [42], Batch [250/391], Loss: 0.1126, LR: 0.005000\n",
      "Epoch [42], Batch [300/391], Loss: 0.1345, LR: 0.005000\n",
      "Epoch [42], Batch [350/391], Loss: 0.0624, LR: 0.005000\n",
      "Train set: Epoch: 42, Average loss:0.9690, LR: 0.005000 Top-1 Accuracy: 83.8920%, Top-5 Accuracy: 94.8480%, Time consumed:91.39s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████▍                                                                            | 42/300 [1:10:23<7:18:54, 102.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 42, Average loss:1.0486, Top-1 Accuracy: 72.6800%, Top-5 Accuracy: 92.1400%, Time consumed:8.77s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [43], Batch [50/391], Loss: 0.0755, LR: 0.005000\n",
      "Epoch [43], Batch [100/391], Loss: 1.3986, LR: 0.005000\n",
      "Epoch [43], Batch [150/391], Loss: 2.6375, LR: 0.005000\n",
      "Epoch [43], Batch [200/391], Loss: 1.0045, LR: 0.005000\n",
      "Epoch [43], Batch [250/391], Loss: 2.1187, LR: 0.005000\n",
      "Epoch [43], Batch [300/391], Loss: 0.0845, LR: 0.005000\n",
      "Epoch [43], Batch [350/391], Loss: 0.0583, LR: 0.005000\n",
      "Train set: Epoch: 43, Average loss:1.0429, LR: 0.005000 Top-1 Accuracy: 82.1520%, Top-5 Accuracy: 94.1380%, Time consumed:98.41s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████▊                                                                            | 43/300 [1:12:10<7:23:57, 103.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 43, Average loss:1.0581, Top-1 Accuracy: 72.4500%, Top-5 Accuracy: 92.0600%, Time consumed:8.91s\n",
      "\n",
      "EarlyStopping 카운터: 3 / 30\n",
      "Epoch [44], Batch [50/391], Loss: 0.0996, LR: 0.005000\n",
      "Epoch [44], Batch [100/391], Loss: 0.0692, LR: 0.005000\n",
      "Epoch [44], Batch [150/391], Loss: 0.0469, LR: 0.005000\n",
      "Epoch [44], Batch [200/391], Loss: 0.1110, LR: 0.005000\n",
      "Epoch [44], Batch [250/391], Loss: 1.4948, LR: 0.005000\n",
      "Epoch [44], Batch [300/391], Loss: 0.1262, LR: 0.005000\n",
      "Epoch [44], Batch [350/391], Loss: 0.0393, LR: 0.005000\n",
      "Train set: Epoch: 44, Average loss:1.0060, LR: 0.005000 Top-1 Accuracy: 83.6580%, Top-5 Accuracy: 94.6900%, Time consumed:93.78s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████████████                                                                            | 44/300 [1:13:52<7:20:51, 103.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 44, Average loss:1.1118, Top-1 Accuracy: 71.4800%, Top-5 Accuracy: 91.0400%, Time consumed:8.80s\n",
      "\n",
      "EarlyStopping 카운터: 4 / 30\n",
      "Epoch [45], Batch [50/391], Loss: 0.0887, LR: 0.005000\n",
      "Epoch [45], Batch [100/391], Loss: 3.1649, LR: 0.005000\n",
      "Epoch [45], Batch [150/391], Loss: 1.9192, LR: 0.005000\n",
      "Epoch [45], Batch [200/391], Loss: 3.0140, LR: 0.005000\n",
      "Epoch [45], Batch [250/391], Loss: 0.0799, LR: 0.005000\n",
      "Epoch [45], Batch [300/391], Loss: 2.4471, LR: 0.005000\n",
      "Epoch [45], Batch [350/391], Loss: 0.1347, LR: 0.005000\n",
      "Train set: Epoch: 45, Average loss:1.1423, LR: 0.005000 Top-1 Accuracy: 79.5280%, Top-5 Accuracy: 92.5320%, Time consumed:91.27s\n",
      "Test set: Epoch: 45, Average loss:1.0424, Top-1 Accuracy: 73.0400%, Top-5 Accuracy: 92.2200%, Time consumed:8.28s\n",
      "\n",
      "새로운 최고 top-1 정확도: 73.04%, top-5 정확도: 92.22%\n",
      "Accuracy improved (72.93% --> 73.04%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████████████▎                                                                           | 45/300 [1:15:32<7:14:38, 102.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46], Batch [50/391], Loss: 1.4046, LR: 0.002500\n",
      "Epoch [46], Batch [100/391], Loss: 0.0492, LR: 0.002500\n",
      "Epoch [46], Batch [150/391], Loss: 0.0303, LR: 0.002500\n",
      "Epoch [46], Batch [200/391], Loss: 2.4180, LR: 0.002500\n",
      "Epoch [46], Batch [250/391], Loss: 2.8368, LR: 0.002500\n",
      "Epoch [46], Batch [300/391], Loss: 0.0706, LR: 0.002500\n",
      "Epoch [46], Batch [350/391], Loss: 2.7088, LR: 0.002500\n",
      "Train set: Epoch: 46, Average loss:0.9947, LR: 0.002500 Top-1 Accuracy: 83.8360%, Top-5 Accuracy: 94.6560%, Time consumed:90.45s\n",
      "Test set: Epoch: 46, Average loss:0.9830, Top-1 Accuracy: 74.1400%, Top-5 Accuracy: 92.4500%, Time consumed:8.26s\n",
      "\n",
      "새로운 최고 top-1 정확도: 74.14%, top-5 정확도: 92.45%\n",
      "새로운 최고 top-5 정확도: 92.45%\n",
      "Accuracy improved (73.04% --> 74.14%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████████████▋                                                                           | 46/300 [1:17:11<7:08:43, 101.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47], Batch [50/391], Loss: 2.3473, LR: 0.002500\n",
      "Epoch [47], Batch [100/391], Loss: 2.7292, LR: 0.002500\n",
      "Epoch [47], Batch [150/391], Loss: 0.0475, LR: 0.002500\n",
      "Epoch [47], Batch [200/391], Loss: 0.0682, LR: 0.002500\n",
      "Epoch [47], Batch [250/391], Loss: 1.2329, LR: 0.002500\n",
      "Epoch [47], Batch [300/391], Loss: 2.6472, LR: 0.002500\n",
      "Epoch [47], Batch [350/391], Loss: 0.0485, LR: 0.002500\n",
      "Train set: Epoch: 47, Average loss:1.1290, LR: 0.002500 Top-1 Accuracy: 81.0340%, Top-5 Accuracy: 93.5540%, Time consumed:95.22s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█████████████▉                                                                           | 47/300 [1:18:55<7:09:41, 101.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 47, Average loss:1.0573, Top-1 Accuracy: 73.8900%, Top-5 Accuracy: 92.4600%, Time consumed:8.14s\n",
      "\n",
      "새로운 최고 top-5 정확도: 92.46%\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [48], Batch [50/391], Loss: 0.0763, LR: 0.002500\n",
      "Epoch [48], Batch [100/391], Loss: 2.5134, LR: 0.002500\n",
      "Epoch [48], Batch [150/391], Loss: 2.6889, LR: 0.002500\n",
      "Epoch [48], Batch [200/391], Loss: 0.0683, LR: 0.002500\n",
      "Epoch [48], Batch [250/391], Loss: 2.3646, LR: 0.002500\n",
      "Epoch [48], Batch [300/391], Loss: 0.0375, LR: 0.002500\n",
      "Epoch [48], Batch [350/391], Loss: 0.0436, LR: 0.002500\n",
      "Train set: Epoch: 48, Average loss:1.0731, LR: 0.002500 Top-1 Accuracy: 83.2000%, Top-5 Accuracy: 94.4840%, Time consumed:88.91s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████████████▏                                                                          | 48/300 [1:20:33<7:03:31, 100.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 48, Average loss:1.0049, Top-1 Accuracy: 74.1100%, Top-5 Accuracy: 92.6200%, Time consumed:9.44s\n",
      "\n",
      "새로운 최고 top-5 정확도: 92.62%\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [49], Batch [50/391], Loss: 0.0885, LR: 0.002500\n",
      "Epoch [49], Batch [100/391], Loss: 0.0329, LR: 0.002500\n",
      "Epoch [49], Batch [150/391], Loss: 2.5809, LR: 0.002500\n",
      "Epoch [49], Batch [200/391], Loss: 2.2618, LR: 0.002500\n",
      "Epoch [49], Batch [250/391], Loss: 2.8448, LR: 0.002500\n",
      "Epoch [49], Batch [300/391], Loss: 2.7128, LR: 0.002500\n",
      "Epoch [49], Batch [350/391], Loss: 2.8228, LR: 0.002500\n",
      "Train set: Epoch: 49, Average loss:1.1134, LR: 0.002500 Top-1 Accuracy: 81.2240%, Top-5 Accuracy: 93.4420%, Time consumed:93.46s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████████████▌                                                                          | 49/300 [1:22:15<7:03:02, 101.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 49, Average loss:1.0026, Top-1 Accuracy: 73.7900%, Top-5 Accuracy: 92.1200%, Time consumed:8.32s\n",
      "\n",
      "EarlyStopping 카운터: 3 / 30\n",
      "Epoch [50], Batch [50/391], Loss: 2.5222, LR: 0.002500\n",
      "Epoch [50], Batch [100/391], Loss: 2.8340, LR: 0.002500\n",
      "Epoch [50], Batch [150/391], Loss: 0.0558, LR: 0.002500\n",
      "Epoch [50], Batch [200/391], Loss: 0.0642, LR: 0.002500\n",
      "Epoch [50], Batch [250/391], Loss: 0.9560, LR: 0.002500\n",
      "Epoch [50], Batch [300/391], Loss: 0.0352, LR: 0.002500\n",
      "Epoch [50], Batch [350/391], Loss: 1.1567, LR: 0.002500\n",
      "Train set: Epoch: 50, Average loss:0.9902, LR: 0.002500 Top-1 Accuracy: 83.6320%, Top-5 Accuracy: 94.7480%, Time consumed:90.09s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████████████▊                                                                          | 50/300 [1:23:53<6:58:08, 100.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 50, Average loss:1.0228, Top-1 Accuracy: 73.5000%, Top-5 Accuracy: 92.0800%, Time consumed:8.46s\n",
      "\n",
      "EarlyStopping 카운터: 4 / 30\n",
      "Epoch [51], Batch [50/391], Loss: 1.5081, LR: 0.002500\n",
      "Epoch [51], Batch [100/391], Loss: 0.0439, LR: 0.002500\n",
      "Epoch [51], Batch [150/391], Loss: 0.0511, LR: 0.002500\n",
      "Epoch [51], Batch [200/391], Loss: 1.8416, LR: 0.002500\n",
      "Epoch [51], Batch [250/391], Loss: 0.0406, LR: 0.002500\n",
      "Epoch [51], Batch [300/391], Loss: 2.5977, LR: 0.002500\n",
      "Epoch [51], Batch [350/391], Loss: 2.4893, LR: 0.002500\n",
      "Train set: Epoch: 51, Average loss:1.0084, LR: 0.002500 Top-1 Accuracy: 83.0860%, Top-5 Accuracy: 94.0500%, Time consumed:93.97s\n",
      "Test set: Epoch: 51, Average loss:0.9679, Top-1 Accuracy: 74.4400%, Top-5 Accuracy: 92.8700%, Time consumed:8.52s\n",
      "\n",
      "새로운 최고 top-1 정확도: 74.44%, top-5 정확도: 92.87%\n",
      "새로운 최고 top-5 정확도: 92.87%\n",
      "Accuracy improved (74.14% --> 74.44%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████████████▏                                                                         | 51/300 [1:25:36<6:59:24, 101.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52], Batch [50/391], Loss: 0.0653, LR: 0.002500\n",
      "Epoch [52], Batch [100/391], Loss: 2.2942, LR: 0.002500\n",
      "Epoch [52], Batch [150/391], Loss: 2.5068, LR: 0.002500\n",
      "Epoch [52], Batch [200/391], Loss: 1.8490, LR: 0.002500\n",
      "Epoch [52], Batch [250/391], Loss: 0.0390, LR: 0.002500\n",
      "Epoch [52], Batch [300/391], Loss: 2.5961, LR: 0.002500\n",
      "Epoch [52], Batch [350/391], Loss: 0.0266, LR: 0.002500\n",
      "Train set: Epoch: 52, Average loss:0.8959, LR: 0.002500 Top-1 Accuracy: 85.7540%, Top-5 Accuracy: 95.5200%, Time consumed:92.84s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████████████▍                                                                         | 52/300 [1:27:17<6:57:57, 101.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 52, Average loss:0.9937, Top-1 Accuracy: 74.2600%, Top-5 Accuracy: 92.8600%, Time consumed:8.40s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [53], Batch [50/391], Loss: 0.0877, LR: 0.001250\n",
      "Epoch [53], Batch [100/391], Loss: 2.0723, LR: 0.001250\n",
      "Epoch [53], Batch [150/391], Loss: 2.3290, LR: 0.001250\n",
      "Epoch [53], Batch [200/391], Loss: 0.0183, LR: 0.001250\n",
      "Epoch [53], Batch [250/391], Loss: 0.0431, LR: 0.001250\n",
      "Epoch [53], Batch [300/391], Loss: 0.0402, LR: 0.001250\n",
      "Epoch [53], Batch [350/391], Loss: 0.0483, LR: 0.001250\n",
      "Train set: Epoch: 53, Average loss:0.9100, LR: 0.001250 Top-1 Accuracy: 86.5180%, Top-5 Accuracy: 95.7780%, Time consumed:91.97s\n",
      "Test set: Epoch: 53, Average loss:0.9919, Top-1 Accuracy: 74.6300%, Top-5 Accuracy: 92.8300%, Time consumed:8.63s\n",
      "\n",
      "새로운 최고 top-1 정확도: 74.63%, top-5 정확도: 92.83%\n",
      "Accuracy improved (74.44% --> 74.63%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████████████▋                                                                         | 53/300 [1:28:58<6:55:57, 101.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54], Batch [50/391], Loss: 0.0418, LR: 0.001250\n",
      "Epoch [54], Batch [100/391], Loss: 0.0151, LR: 0.001250\n",
      "Epoch [54], Batch [150/391], Loss: 1.2106, LR: 0.001250\n",
      "Epoch [54], Batch [200/391], Loss: 0.0238, LR: 0.001250\n",
      "Epoch [54], Batch [250/391], Loss: 2.5639, LR: 0.001250\n",
      "Epoch [54], Batch [300/391], Loss: 0.0384, LR: 0.001250\n",
      "Epoch [54], Batch [350/391], Loss: 2.5159, LR: 0.001250\n",
      "Train set: Epoch: 54, Average loss:0.9381, LR: 0.001250 Top-1 Accuracy: 85.8200%, Top-5 Accuracy: 95.4000%, Time consumed:96.01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|████████████████                                                                         | 54/300 [1:30:42<6:58:06, 101.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 54, Average loss:0.9666, Top-1 Accuracy: 74.4300%, Top-5 Accuracy: 92.8500%, Time consumed:8.15s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [55], Batch [50/391], Loss: 2.5806, LR: 0.001250\n",
      "Epoch [55], Batch [100/391], Loss: 0.0273, LR: 0.001250\n",
      "Epoch [55], Batch [150/391], Loss: 1.9453, LR: 0.001250\n",
      "Epoch [55], Batch [200/391], Loss: 0.0217, LR: 0.001250\n",
      "Epoch [55], Batch [250/391], Loss: 0.0182, LR: 0.001250\n",
      "Epoch [55], Batch [300/391], Loss: 0.0576, LR: 0.001250\n",
      "Epoch [55], Batch [350/391], Loss: 1.6711, LR: 0.001250\n",
      "Train set: Epoch: 55, Average loss:0.9077, LR: 0.001250 Top-1 Accuracy: 86.0940%, Top-5 Accuracy: 95.4960%, Time consumed:90.23s\n",
      "Test set: Epoch: 55, Average loss:1.0224, Top-1 Accuracy: 74.7000%, Top-5 Accuracy: 93.0900%, Time consumed:8.04s\n",
      "\n",
      "새로운 최고 top-1 정확도: 74.70%, top-5 정확도: 93.09%\n",
      "새로운 최고 top-5 정확도: 93.09%\n",
      "Accuracy improved (74.63% --> 74.70%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|████████████████▎                                                                        | 55/300 [1:32:21<6:52:12, 100.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56], Batch [50/391], Loss: 0.0712, LR: 0.001250\n",
      "Epoch [56], Batch [100/391], Loss: 0.0191, LR: 0.001250\n",
      "Epoch [56], Batch [150/391], Loss: 0.0173, LR: 0.001250\n",
      "Epoch [56], Batch [200/391], Loss: 0.0768, LR: 0.001250\n",
      "Epoch [56], Batch [250/391], Loss: 2.2842, LR: 0.001250\n",
      "Epoch [56], Batch [300/391], Loss: 0.0174, LR: 0.001250\n",
      "Epoch [56], Batch [350/391], Loss: 0.0362, LR: 0.001250\n",
      "Train set: Epoch: 56, Average loss:1.0369, LR: 0.001250 Top-1 Accuracy: 84.0000%, Top-5 Accuracy: 94.8220%, Time consumed:91.16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|████████████████▌                                                                        | 56/300 [1:34:00<6:48:27, 100.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 56, Average loss:0.9862, Top-1 Accuracy: 74.6600%, Top-5 Accuracy: 92.9100%, Time consumed:8.09s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [57], Batch [50/391], Loss: 0.0180, LR: 0.001250\n",
      "Epoch [57], Batch [100/391], Loss: 0.0373, LR: 0.001250\n",
      "Epoch [57], Batch [150/391], Loss: 1.4330, LR: 0.001250\n",
      "Epoch [57], Batch [200/391], Loss: 2.3518, LR: 0.001250\n",
      "Epoch [57], Batch [250/391], Loss: 1.0610, LR: 0.001250\n",
      "Epoch [57], Batch [300/391], Loss: 2.4188, LR: 0.001250\n",
      "Epoch [57], Batch [350/391], Loss: 0.0548, LR: 0.001250\n",
      "Train set: Epoch: 57, Average loss:1.0558, LR: 0.001250 Top-1 Accuracy: 82.7000%, Top-5 Accuracy: 94.3000%, Time consumed:88.11s\n",
      "Test set: Epoch: 57, Average loss:0.9689, Top-1 Accuracy: 74.7800%, Top-5 Accuracy: 92.8200%, Time consumed:8.03s\n",
      "\n",
      "새로운 최고 top-1 정확도: 74.78%, top-5 정확도: 92.82%\n",
      "Accuracy improved (74.70% --> 74.78%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█████████████████                                                                         | 57/300 [1:35:36<6:41:50, 99.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58], Batch [50/391], Loss: 0.0441, LR: 0.001250\n",
      "Epoch [58], Batch [100/391], Loss: 2.5372, LR: 0.001250\n",
      "Epoch [58], Batch [150/391], Loss: 0.4990, LR: 0.001250\n",
      "Epoch [58], Batch [200/391], Loss: 2.3957, LR: 0.001250\n",
      "Epoch [58], Batch [250/391], Loss: 2.6539, LR: 0.001250\n",
      "Epoch [58], Batch [300/391], Loss: 2.6301, LR: 0.001250\n",
      "Epoch [58], Batch [350/391], Loss: 2.7403, LR: 0.001250\n",
      "Train set: Epoch: 58, Average loss:0.9866, LR: 0.001250 Top-1 Accuracy: 84.4420%, Top-5 Accuracy: 94.7420%, Time consumed:89.81s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█████████████████▍                                                                        | 58/300 [1:37:14<6:38:28, 98.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 58, Average loss:1.1474, Top-1 Accuracy: 74.5700%, Top-5 Accuracy: 92.7700%, Time consumed:8.00s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [59], Batch [50/391], Loss: 0.0285, LR: 0.000625\n",
      "Epoch [59], Batch [100/391], Loss: 1.6600, LR: 0.000625\n",
      "Epoch [59], Batch [150/391], Loss: 0.0357, LR: 0.000625\n",
      "Epoch [59], Batch [200/391], Loss: 2.4603, LR: 0.000625\n",
      "Epoch [59], Batch [250/391], Loss: 2.2007, LR: 0.000625\n",
      "Epoch [59], Batch [300/391], Loss: 0.0159, LR: 0.000625\n",
      "Epoch [59], Batch [350/391], Loss: 0.7557, LR: 0.000625\n",
      "Train set: Epoch: 59, Average loss:0.8837, LR: 0.000625 Top-1 Accuracy: 87.2940%, Top-5 Accuracy: 96.1200%, Time consumed:93.00s\n",
      "Test set: Epoch: 59, Average loss:0.9720, Top-1 Accuracy: 74.9600%, Top-5 Accuracy: 92.8100%, Time consumed:8.10s\n",
      "\n",
      "새로운 최고 top-1 정확도: 74.96%, top-5 정확도: 92.81%\n",
      "Accuracy improved (74.78% --> 74.96%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█████████████████▋                                                                        | 59/300 [1:38:56<6:39:53, 99.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60], Batch [50/391], Loss: 0.0084, LR: 0.000625\n",
      "Epoch [60], Batch [100/391], Loss: 0.0227, LR: 0.000625\n",
      "Epoch [60], Batch [150/391], Loss: 0.0293, LR: 0.000625\n",
      "Epoch [60], Batch [200/391], Loss: 0.0258, LR: 0.000625\n",
      "Epoch [60], Batch [250/391], Loss: 2.9004, LR: 0.000625\n",
      "Epoch [60], Batch [300/391], Loss: 2.5694, LR: 0.000625\n",
      "Epoch [60], Batch [350/391], Loss: 2.5029, LR: 0.000625\n",
      "Train set: Epoch: 60, Average loss:0.9127, LR: 0.000625 Top-1 Accuracy: 85.1800%, Top-5 Accuracy: 94.8780%, Time consumed:89.68s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████████████                                                                        | 60/300 [1:40:34<6:36:18, 99.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 60, Average loss:0.9763, Top-1 Accuracy: 74.8300%, Top-5 Accuracy: 92.7400%, Time consumed:8.26s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [61], Batch [50/391], Loss: 1.5482, LR: 0.000625\n",
      "Epoch [61], Batch [100/391], Loss: 2.1858, LR: 0.000625\n",
      "Epoch [61], Batch [150/391], Loss: 2.2249, LR: 0.000625\n",
      "Epoch [61], Batch [200/391], Loss: 0.0299, LR: 0.000625\n",
      "Epoch [61], Batch [250/391], Loss: 2.5760, LR: 0.000625\n",
      "Epoch [61], Batch [300/391], Loss: 0.0233, LR: 0.000625\n",
      "Epoch [61], Batch [350/391], Loss: 1.6291, LR: 0.000625\n",
      "Train set: Epoch: 61, Average loss:0.9653, LR: 0.000625 Top-1 Accuracy: 84.6720%, Top-5 Accuracy: 94.8160%, Time consumed:92.22s\n",
      "Test set: Epoch: 61, Average loss:0.9637, Top-1 Accuracy: 74.9900%, Top-5 Accuracy: 92.8800%, Time consumed:9.04s\n",
      "\n",
      "새로운 최고 top-1 정확도: 74.99%, top-5 정확도: 92.88%\n",
      "Accuracy improved (74.96% --> 74.99%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████████████▎                                                                       | 61/300 [1:42:15<6:37:32, 99.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [62], Batch [50/391], Loss: 0.0195, LR: 0.000625\n",
      "Epoch [62], Batch [100/391], Loss: 0.0272, LR: 0.000625\n",
      "Epoch [62], Batch [150/391], Loss: 0.0142, LR: 0.000625\n",
      "Epoch [62], Batch [200/391], Loss: 0.0264, LR: 0.000625\n",
      "Epoch [62], Batch [250/391], Loss: 2.5102, LR: 0.000625\n",
      "Epoch [62], Batch [300/391], Loss: 0.0178, LR: 0.000625\n",
      "Epoch [62], Batch [350/391], Loss: 1.9664, LR: 0.000625\n",
      "Train set: Epoch: 62, Average loss:0.9643, LR: 0.000625 Top-1 Accuracy: 85.2720%, Top-5 Accuracy: 95.4240%, Time consumed:90.02s\n",
      "Test set: Epoch: 62, Average loss:1.0145, Top-1 Accuracy: 75.0300%, Top-5 Accuracy: 92.9300%, Time consumed:8.63s\n",
      "\n",
      "새로운 최고 top-1 정확도: 75.03%, top-5 정확도: 92.93%\n",
      "Accuracy improved (74.99% --> 75.03%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██████████████████▌                                                                       | 62/300 [1:43:54<6:34:50, 99.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [63], Batch [50/391], Loss: 2.5308, LR: 0.000625\n",
      "Epoch [63], Batch [100/391], Loss: 0.0260, LR: 0.000625\n",
      "Epoch [63], Batch [150/391], Loss: 1.5931, LR: 0.000625\n",
      "Epoch [63], Batch [200/391], Loss: 0.0169, LR: 0.000625\n",
      "Epoch [63], Batch [250/391], Loss: 0.0353, LR: 0.000625\n",
      "Epoch [63], Batch [300/391], Loss: 2.2223, LR: 0.000625\n",
      "Epoch [63], Batch [350/391], Loss: 0.0128, LR: 0.000625\n",
      "Train set: Epoch: 63, Average loss:0.9898, LR: 0.000625 Top-1 Accuracy: 84.9800%, Top-5 Accuracy: 95.3960%, Time consumed:95.39s\n",
      "Test set: Epoch: 63, Average loss:0.9722, Top-1 Accuracy: 75.1400%, Top-5 Accuracy: 92.8400%, Time consumed:8.63s\n",
      "\n",
      "새로운 최고 top-1 정확도: 75.14%, top-5 정확도: 92.84%\n",
      "Accuracy improved (75.03% --> 75.14%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██████████████████▋                                                                      | 63/300 [1:45:38<6:38:47, 100.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [64], Batch [50/391], Loss: 0.0116, LR: 0.000625\n",
      "Epoch [64], Batch [100/391], Loss: 1.9684, LR: 0.000625\n",
      "Epoch [64], Batch [150/391], Loss: 2.6041, LR: 0.000625\n",
      "Epoch [64], Batch [200/391], Loss: 0.0123, LR: 0.000625\n",
      "Epoch [64], Batch [250/391], Loss: 1.8302, LR: 0.000625\n",
      "Epoch [64], Batch [300/391], Loss: 0.0194, LR: 0.000625\n",
      "Epoch [64], Batch [350/391], Loss: 0.0438, LR: 0.000625\n",
      "Train set: Epoch: 64, Average loss:0.9873, LR: 0.000625 Top-1 Accuracy: 84.7160%, Top-5 Accuracy: 95.2140%, Time consumed:95.30s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██████████████████▉                                                                      | 64/300 [1:47:22<6:39:55, 101.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 64, Average loss:0.9856, Top-1 Accuracy: 74.9600%, Top-5 Accuracy: 92.7700%, Time consumed:8.03s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [65], Batch [50/391], Loss: 0.0127, LR: 0.000625\n",
      "Epoch [65], Batch [100/391], Loss: 0.0107, LR: 0.000625\n",
      "Epoch [65], Batch [150/391], Loss: 2.3863, LR: 0.000625\n",
      "Epoch [65], Batch [200/391], Loss: 0.0249, LR: 0.000625\n",
      "Epoch [65], Batch [250/391], Loss: 2.0141, LR: 0.000625\n",
      "Epoch [65], Batch [300/391], Loss: 0.0424, LR: 0.000625\n",
      "Epoch [65], Batch [350/391], Loss: 1.4057, LR: 0.000625\n",
      "Train set: Epoch: 65, Average loss:0.9104, LR: 0.000625 Top-1 Accuracy: 86.6000%, Top-5 Accuracy: 95.7780%, Time consumed:94.16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|███████████████████▎                                                                     | 65/300 [1:49:04<6:38:57, 101.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 65, Average loss:0.9701, Top-1 Accuracy: 74.9200%, Top-5 Accuracy: 92.7500%, Time consumed:8.13s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [66], Batch [50/391], Loss: 1.2192, LR: 0.000312\n",
      "Epoch [66], Batch [100/391], Loss: 0.0250, LR: 0.000312\n",
      "Epoch [66], Batch [150/391], Loss: 1.9244, LR: 0.000312\n",
      "Epoch [66], Batch [200/391], Loss: 0.0253, LR: 0.000312\n",
      "Epoch [66], Batch [250/391], Loss: 0.0115, LR: 0.000312\n",
      "Epoch [66], Batch [300/391], Loss: 1.5015, LR: 0.000312\n",
      "Epoch [66], Batch [350/391], Loss: 0.0410, LR: 0.000312\n",
      "Train set: Epoch: 66, Average loss:0.8964, LR: 0.000312 Top-1 Accuracy: 86.2240%, Top-5 Accuracy: 95.6140%, Time consumed:93.41s\n",
      "Test set: Epoch: 66, Average loss:0.9674, Top-1 Accuracy: 75.4400%, Top-5 Accuracy: 93.2500%, Time consumed:8.20s\n",
      "\n",
      "새로운 최고 top-1 정확도: 75.44%, top-5 정확도: 93.25%\n",
      "새로운 최고 top-5 정확도: 93.25%\n",
      "Accuracy improved (75.14% --> 75.44%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|███████████████████▌                                                                     | 66/300 [1:50:46<6:37:16, 101.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [67], Batch [50/391], Loss: 1.9800, LR: 0.000312\n",
      "Epoch [67], Batch [100/391], Loss: 2.2464, LR: 0.000312\n",
      "Epoch [67], Batch [150/391], Loss: 2.5915, LR: 0.000312\n",
      "Epoch [67], Batch [200/391], Loss: 0.0105, LR: 0.000312\n",
      "Epoch [67], Batch [250/391], Loss: 0.0086, LR: 0.000312\n",
      "Epoch [67], Batch [300/391], Loss: 0.0116, LR: 0.000312\n",
      "Epoch [67], Batch [350/391], Loss: 2.6581, LR: 0.000312\n",
      "Train set: Epoch: 67, Average loss:1.0292, LR: 0.000312 Top-1 Accuracy: 84.6500%, Top-5 Accuracy: 95.4040%, Time consumed:90.69s\n",
      "Test set: Epoch: 67, Average loss:0.9544, Top-1 Accuracy: 75.4500%, Top-5 Accuracy: 92.8300%, Time consumed:8.52s\n",
      "\n",
      "새로운 최고 top-1 정확도: 75.45%, top-5 정확도: 92.83%\n",
      "Accuracy improved (75.44% --> 75.45%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|███████████████████▉                                                                     | 67/300 [1:52:25<6:32:45, 101.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [68], Batch [50/391], Loss: 0.0191, LR: 0.000312\n",
      "Epoch [68], Batch [100/391], Loss: 0.0169, LR: 0.000312\n",
      "Epoch [68], Batch [150/391], Loss: 1.7265, LR: 0.000312\n",
      "Epoch [68], Batch [200/391], Loss: 0.7057, LR: 0.000312\n",
      "Epoch [68], Batch [250/391], Loss: 0.0199, LR: 0.000312\n",
      "Epoch [68], Batch [300/391], Loss: 0.0225, LR: 0.000312\n",
      "Epoch [68], Batch [350/391], Loss: 2.5424, LR: 0.000312\n",
      "Train set: Epoch: 68, Average loss:0.9020, LR: 0.000312 Top-1 Accuracy: 85.9700%, Top-5 Accuracy: 95.5420%, Time consumed:88.45s\n",
      "Test set: Epoch: 68, Average loss:0.9577, Top-1 Accuracy: 75.6900%, Top-5 Accuracy: 93.1200%, Time consumed:8.20s\n",
      "\n",
      "새로운 최고 top-1 정확도: 75.69%, top-5 정확도: 93.12%\n",
      "Accuracy improved (75.45% --> 75.69%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|████████████████████▍                                                                     | 68/300 [1:54:02<6:26:08, 99.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [69], Batch [50/391], Loss: 0.0116, LR: 0.000312\n",
      "Epoch [69], Batch [100/391], Loss: 0.0160, LR: 0.000312\n",
      "Epoch [69], Batch [150/391], Loss: 0.0347, LR: 0.000312\n",
      "Epoch [69], Batch [200/391], Loss: 0.8557, LR: 0.000312\n",
      "Epoch [69], Batch [250/391], Loss: 0.8053, LR: 0.000312\n",
      "Epoch [69], Batch [300/391], Loss: 0.0113, LR: 0.000312\n",
      "Epoch [69], Batch [350/391], Loss: 0.0224, LR: 0.000312\n",
      "Train set: Epoch: 69, Average loss:0.9401, LR: 0.000312 Top-1 Accuracy: 85.8340%, Top-5 Accuracy: 95.6380%, Time consumed:95.85s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|████████████████████▍                                                                    | 69/300 [1:55:46<6:29:26, 101.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 69, Average loss:0.9467, Top-1 Accuracy: 75.2500%, Top-5 Accuracy: 92.9600%, Time consumed:8.31s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [70], Batch [50/391], Loss: 2.5265, LR: 0.000312\n",
      "Epoch [70], Batch [100/391], Loss: 1.5660, LR: 0.000312\n",
      "Epoch [70], Batch [150/391], Loss: 1.9362, LR: 0.000312\n",
      "Epoch [70], Batch [200/391], Loss: 0.0196, LR: 0.000312\n",
      "Epoch [70], Batch [250/391], Loss: 2.7892, LR: 0.000312\n",
      "Epoch [70], Batch [300/391], Loss: 1.7071, LR: 0.000312\n",
      "Epoch [70], Batch [350/391], Loss: 0.0209, LR: 0.000312\n",
      "Train set: Epoch: 70, Average loss:0.8880, LR: 0.000312 Top-1 Accuracy: 86.5200%, Top-5 Accuracy: 95.8000%, Time consumed:89.83s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|████████████████████▊                                                                    | 70/300 [1:57:25<6:25:06, 100.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 70, Average loss:1.0776, Top-1 Accuracy: 75.3300%, Top-5 Accuracy: 93.1000%, Time consumed:9.02s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [71], Batch [50/391], Loss: 1.4750, LR: 0.000312\n",
      "Epoch [71], Batch [100/391], Loss: 2.2419, LR: 0.000312\n",
      "Epoch [71], Batch [150/391], Loss: 1.5911, LR: 0.000312\n",
      "Epoch [71], Batch [200/391], Loss: 0.0107, LR: 0.000312\n",
      "Epoch [71], Batch [250/391], Loss: 2.3121, LR: 0.000312\n",
      "Epoch [71], Batch [300/391], Loss: 0.0230, LR: 0.000312\n",
      "Epoch [71], Batch [350/391], Loss: 1.9958, LR: 0.000312\n",
      "Train set: Epoch: 71, Average loss:1.0006, LR: 0.000312 Top-1 Accuracy: 84.0120%, Top-5 Accuracy: 95.0480%, Time consumed:89.10s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|█████████████████████▎                                                                    | 71/300 [1:59:02<6:19:38, 99.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 71, Average loss:0.9900, Top-1 Accuracy: 75.4200%, Top-5 Accuracy: 92.8300%, Time consumed:8.04s\n",
      "\n",
      "EarlyStopping 카운터: 3 / 30\n",
      "Epoch [72], Batch [50/391], Loss: 2.3781, LR: 0.000156\n",
      "Epoch [72], Batch [100/391], Loss: 0.0271, LR: 0.000156\n",
      "Epoch [72], Batch [150/391], Loss: 1.0806, LR: 0.000156\n",
      "Epoch [72], Batch [200/391], Loss: 0.0337, LR: 0.000156\n",
      "Epoch [72], Batch [250/391], Loss: 2.5969, LR: 0.000156\n",
      "Epoch [72], Batch [300/391], Loss: 2.2001, LR: 0.000156\n",
      "Epoch [72], Batch [350/391], Loss: 2.5714, LR: 0.000156\n",
      "Train set: Epoch: 72, Average loss:0.9107, LR: 0.000156 Top-1 Accuracy: 86.1180%, Top-5 Accuracy: 95.7120%, Time consumed:92.87s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|█████████████████████▌                                                                    | 72/300 [2:00:43<6:19:47, 99.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 72, Average loss:0.9413, Top-1 Accuracy: 75.5000%, Top-5 Accuracy: 93.1100%, Time consumed:8.18s\n",
      "\n",
      "EarlyStopping 카운터: 4 / 30\n",
      "Epoch [73], Batch [50/391], Loss: 0.0113, LR: 0.000156\n",
      "Epoch [73], Batch [100/391], Loss: 0.0089, LR: 0.000156\n",
      "Epoch [73], Batch [150/391], Loss: 0.0367, LR: 0.000156\n",
      "Epoch [73], Batch [200/391], Loss: 0.0475, LR: 0.000156\n",
      "Epoch [73], Batch [250/391], Loss: 0.0077, LR: 0.000156\n",
      "Epoch [73], Batch [300/391], Loss: 0.0075, LR: 0.000156\n",
      "Epoch [73], Batch [350/391], Loss: 0.2456, LR: 0.000156\n",
      "Train set: Epoch: 73, Average loss:0.8878, LR: 0.000156 Top-1 Accuracy: 87.0500%, Top-5 Accuracy: 96.1020%, Time consumed:90.27s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|█████████████████████▉                                                                    | 73/300 [2:02:22<6:17:00, 99.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 73, Average loss:0.9686, Top-1 Accuracy: 75.2200%, Top-5 Accuracy: 93.0500%, Time consumed:8.68s\n",
      "\n",
      "EarlyStopping 카운터: 5 / 30\n",
      "Epoch [74], Batch [50/391], Loss: 1.2037, LR: 0.000156\n",
      "Epoch [74], Batch [100/391], Loss: 2.4002, LR: 0.000156\n",
      "Epoch [74], Batch [150/391], Loss: 0.0201, LR: 0.000156\n",
      "Epoch [74], Batch [200/391], Loss: 2.0367, LR: 0.000156\n",
      "Epoch [74], Batch [250/391], Loss: 0.2384, LR: 0.000156\n",
      "Epoch [74], Batch [300/391], Loss: 0.0143, LR: 0.000156\n",
      "Epoch [74], Batch [350/391], Loss: 0.0126, LR: 0.000156\n",
      "Train set: Epoch: 74, Average loss:0.9439, LR: 0.000156 Top-1 Accuracy: 85.6120%, Top-5 Accuracy: 95.6400%, Time consumed:90.44s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██████████████████████▏                                                                   | 74/300 [2:04:01<6:14:18, 99.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 74, Average loss:0.9434, Top-1 Accuracy: 75.4400%, Top-5 Accuracy: 92.9000%, Time consumed:8.29s\n",
      "\n",
      "EarlyStopping 카운터: 6 / 30\n",
      "Epoch [75], Batch [50/391], Loss: 0.0214, LR: 0.000156\n",
      "Epoch [75], Batch [100/391], Loss: 0.0213, LR: 0.000156\n",
      "Epoch [75], Batch [150/391], Loss: 1.9146, LR: 0.000156\n",
      "Epoch [75], Batch [200/391], Loss: 1.1490, LR: 0.000156\n",
      "Epoch [75], Batch [250/391], Loss: 0.0071, LR: 0.000156\n",
      "Epoch [75], Batch [300/391], Loss: 0.0087, LR: 0.000156\n",
      "Epoch [75], Batch [350/391], Loss: 0.0162, LR: 0.000156\n",
      "Train set: Epoch: 75, Average loss:1.0092, LR: 0.000156 Top-1 Accuracy: 84.7600%, Top-5 Accuracy: 95.3680%, Time consumed:95.15s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██████████████████████▎                                                                  | 75/300 [2:05:44<6:17:06, 100.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 75, Average loss:0.9563, Top-1 Accuracy: 75.3900%, Top-5 Accuracy: 92.9000%, Time consumed:8.18s\n",
      "\n",
      "EarlyStopping 카운터: 7 / 30\n",
      "Epoch [76], Batch [50/391], Loss: 0.0129, LR: 0.000156\n",
      "Epoch [76], Batch [100/391], Loss: 0.0398, LR: 0.000156\n",
      "Epoch [76], Batch [150/391], Loss: 2.3154, LR: 0.000156\n",
      "Epoch [76], Batch [200/391], Loss: 0.0050, LR: 0.000156\n",
      "Epoch [76], Batch [250/391], Loss: 2.5152, LR: 0.000156\n",
      "Epoch [76], Batch [300/391], Loss: 0.0180, LR: 0.000156\n",
      "Epoch [76], Batch [350/391], Loss: 2.5485, LR: 0.000156\n",
      "Train set: Epoch: 76, Average loss:0.9212, LR: 0.000156 Top-1 Accuracy: 85.6540%, Top-5 Accuracy: 95.4680%, Time consumed:92.16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██████████████████████▌                                                                  | 76/300 [2:07:25<6:15:04, 100.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 76, Average loss:1.0003, Top-1 Accuracy: 75.3700%, Top-5 Accuracy: 92.9800%, Time consumed:8.08s\n",
      "\n",
      "EarlyStopping 카운터: 8 / 30\n",
      "Epoch [77], Batch [50/391], Loss: 0.0177, LR: 0.000156\n",
      "Epoch [77], Batch [100/391], Loss: 0.0064, LR: 0.000156\n",
      "Epoch [77], Batch [150/391], Loss: 1.3514, LR: 0.000156\n",
      "Epoch [77], Batch [200/391], Loss: 1.1468, LR: 0.000156\n",
      "Epoch [77], Batch [250/391], Loss: 0.6781, LR: 0.000156\n",
      "Epoch [77], Batch [300/391], Loss: 0.0157, LR: 0.000156\n",
      "Epoch [77], Batch [350/391], Loss: 2.2292, LR: 0.000156\n",
      "Train set: Epoch: 77, Average loss:0.9798, LR: 0.000156 Top-1 Accuracy: 85.1000%, Top-5 Accuracy: 95.2400%, Time consumed:93.16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██████████████████████▊                                                                  | 77/300 [2:09:07<6:15:02, 100.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 77, Average loss:0.9565, Top-1 Accuracy: 75.2500%, Top-5 Accuracy: 92.9500%, Time consumed:8.76s\n",
      "\n",
      "EarlyStopping 카운터: 9 / 30\n",
      "Epoch [78], Batch [50/391], Loss: 1.5044, LR: 0.000078\n",
      "Epoch [78], Batch [100/391], Loss: 0.0239, LR: 0.000078\n",
      "Epoch [78], Batch [150/391], Loss: 1.7570, LR: 0.000078\n",
      "Epoch [78], Batch [200/391], Loss: 1.7950, LR: 0.000078\n",
      "Epoch [78], Batch [250/391], Loss: 0.0174, LR: 0.000078\n",
      "Epoch [78], Batch [300/391], Loss: 1.6296, LR: 0.000078\n",
      "Epoch [78], Batch [350/391], Loss: 2.5173, LR: 0.000078\n",
      "Train set: Epoch: 78, Average loss:0.9967, LR: 0.000078 Top-1 Accuracy: 85.4560%, Top-5 Accuracy: 95.7360%, Time consumed:91.67s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|███████████████████████▏                                                                 | 78/300 [2:10:47<6:12:35, 100.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 78, Average loss:0.9503, Top-1 Accuracy: 75.3400%, Top-5 Accuracy: 93.0800%, Time consumed:8.54s\n",
      "\n",
      "EarlyStopping 카운터: 10 / 30\n",
      "Epoch [79], Batch [50/391], Loss: 0.0137, LR: 0.000078\n",
      "Epoch [79], Batch [100/391], Loss: 2.6464, LR: 0.000078\n",
      "Epoch [79], Batch [150/391], Loss: 0.0144, LR: 0.000078\n",
      "Epoch [79], Batch [200/391], Loss: 0.0107, LR: 0.000078\n",
      "Epoch [79], Batch [250/391], Loss: 2.1214, LR: 0.000078\n",
      "Epoch [79], Batch [300/391], Loss: 0.0215, LR: 0.000078\n",
      "Epoch [79], Batch [350/391], Loss: 1.0330, LR: 0.000078\n",
      "Train set: Epoch: 79, Average loss:0.9837, LR: 0.000078 Top-1 Accuracy: 86.3940%, Top-5 Accuracy: 96.1840%, Time consumed:94.52s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|███████████████████████▍                                                                 | 79/300 [2:12:30<6:14:07, 101.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 79, Average loss:1.0429, Top-1 Accuracy: 74.8200%, Top-5 Accuracy: 92.3900%, Time consumed:9.09s\n",
      "\n",
      "EarlyStopping 카운터: 11 / 30\n",
      "Epoch [80], Batch [50/391], Loss: 0.0091, LR: 0.000078\n",
      "Epoch [80], Batch [100/391], Loss: 0.8165, LR: 0.000078\n",
      "Epoch [80], Batch [150/391], Loss: 0.0188, LR: 0.000078\n",
      "Epoch [80], Batch [200/391], Loss: 0.0154, LR: 0.000078\n",
      "Epoch [80], Batch [250/391], Loss: 0.0199, LR: 0.000078\n",
      "Epoch [80], Batch [300/391], Loss: 2.5933, LR: 0.000078\n",
      "Epoch [80], Batch [350/391], Loss: 0.0078, LR: 0.000078\n",
      "Train set: Epoch: 80, Average loss:0.8638, LR: 0.000078 Top-1 Accuracy: 87.7040%, Top-5 Accuracy: 96.1860%, Time consumed:97.85s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|███████████████████████▋                                                                 | 80/300 [2:14:16<6:17:24, 102.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 80, Average loss:1.0009, Top-1 Accuracy: 74.8100%, Top-5 Accuracy: 92.4300%, Time consumed:8.24s\n",
      "\n",
      "EarlyStopping 카운터: 12 / 30\n",
      "Epoch [81], Batch [50/391], Loss: 2.4938, LR: 0.000078\n",
      "Epoch [81], Batch [100/391], Loss: 1.8241, LR: 0.000078\n",
      "Epoch [81], Batch [150/391], Loss: 1.6817, LR: 0.000078\n",
      "Epoch [81], Batch [200/391], Loss: 0.5918, LR: 0.000078\n",
      "Epoch [81], Batch [250/391], Loss: 2.4933, LR: 0.000078\n",
      "Epoch [81], Batch [300/391], Loss: 0.0102, LR: 0.000078\n",
      "Epoch [81], Batch [350/391], Loss: 2.0503, LR: 0.000078\n",
      "Train set: Epoch: 81, Average loss:0.8926, LR: 0.000078 Top-1 Accuracy: 86.6100%, Top-5 Accuracy: 95.7960%, Time consumed:91.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|████████████████████████                                                                 | 81/300 [2:15:56<6:12:13, 101.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 81, Average loss:1.0086, Top-1 Accuracy: 75.3100%, Top-5 Accuracy: 93.0000%, Time consumed:8.74s\n",
      "\n",
      "EarlyStopping 카운터: 13 / 30\n",
      "Epoch [82], Batch [50/391], Loss: 0.0246, LR: 0.000078\n",
      "Epoch [82], Batch [100/391], Loss: 0.4171, LR: 0.000078\n",
      "Epoch [82], Batch [150/391], Loss: 0.0210, LR: 0.000078\n",
      "Epoch [82], Batch [200/391], Loss: 0.7541, LR: 0.000078\n",
      "Epoch [82], Batch [250/391], Loss: 2.1777, LR: 0.000078\n",
      "Epoch [82], Batch [300/391], Loss: 0.0130, LR: 0.000078\n",
      "Epoch [82], Batch [350/391], Loss: 2.5447, LR: 0.000078\n",
      "Train set: Epoch: 82, Average loss:0.9032, LR: 0.000078 Top-1 Accuracy: 86.5780%, Top-5 Accuracy: 95.7040%, Time consumed:91.18s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|████████████████████████▎                                                                | 82/300 [2:17:36<6:08:03, 101.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 82, Average loss:0.9872, Top-1 Accuracy: 75.0700%, Top-5 Accuracy: 92.5600%, Time consumed:8.53s\n",
      "\n",
      "EarlyStopping 카운터: 14 / 30\n",
      "Epoch [83], Batch [50/391], Loss: 0.0121, LR: 0.000078\n",
      "Epoch [83], Batch [100/391], Loss: 0.0160, LR: 0.000078\n",
      "Epoch [83], Batch [150/391], Loss: 1.8234, LR: 0.000078\n",
      "Epoch [83], Batch [200/391], Loss: 2.3545, LR: 0.000078\n",
      "Epoch [83], Batch [250/391], Loss: 0.0111, LR: 0.000078\n",
      "Epoch [83], Batch [300/391], Loss: 0.0170, LR: 0.000078\n",
      "Epoch [83], Batch [350/391], Loss: 0.2447, LR: 0.000078\n",
      "Train set: Epoch: 83, Average loss:0.9458, LR: 0.000078 Top-1 Accuracy: 86.2080%, Top-5 Accuracy: 95.8180%, Time consumed:91.38s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|████████████████████████▌                                                                | 83/300 [2:19:15<6:04:28, 100.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 83, Average loss:0.9522, Top-1 Accuracy: 75.4900%, Top-5 Accuracy: 92.7100%, Time consumed:8.17s\n",
      "\n",
      "EarlyStopping 카운터: 15 / 30\n",
      "Epoch [84], Batch [50/391], Loss: 0.0208, LR: 0.000039\n",
      "Epoch [84], Batch [100/391], Loss: 2.3269, LR: 0.000039\n",
      "Epoch [84], Batch [150/391], Loss: 0.0108, LR: 0.000039\n",
      "Epoch [84], Batch [200/391], Loss: 1.6662, LR: 0.000039\n",
      "Epoch [84], Batch [250/391], Loss: 0.0223, LR: 0.000039\n",
      "Epoch [84], Batch [300/391], Loss: 2.3529, LR: 0.000039\n",
      "Epoch [84], Batch [350/391], Loss: 0.0082, LR: 0.000039\n",
      "Train set: Epoch: 84, Average loss:0.8900, LR: 0.000039 Top-1 Accuracy: 86.6240%, Top-5 Accuracy: 95.9780%, Time consumed:94.48s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|████████████████████████▉                                                                | 84/300 [2:20:59<6:05:30, 101.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 84, Average loss:1.0015, Top-1 Accuracy: 75.0400%, Top-5 Accuracy: 92.4400%, Time consumed:8.80s\n",
      "\n",
      "EarlyStopping 카운터: 16 / 30\n",
      "Epoch [85], Batch [50/391], Loss: 0.0080, LR: 0.000039\n",
      "Epoch [85], Batch [100/391], Loss: 0.0125, LR: 0.000039\n",
      "Epoch [85], Batch [150/391], Loss: 2.1108, LR: 0.000039\n",
      "Epoch [85], Batch [200/391], Loss: 2.0309, LR: 0.000039\n",
      "Epoch [85], Batch [250/391], Loss: 2.1157, LR: 0.000039\n",
      "Epoch [85], Batch [300/391], Loss: 0.0173, LR: 0.000039\n",
      "Epoch [85], Batch [350/391], Loss: 1.5739, LR: 0.000039\n",
      "Train set: Epoch: 85, Average loss:0.9119, LR: 0.000039 Top-1 Accuracy: 86.6000%, Top-5 Accuracy: 95.9700%, Time consumed:91.36s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|█████████████████████████▏                                                               | 85/300 [2:22:39<6:02:22, 101.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 85, Average loss:0.9488, Top-1 Accuracy: 75.5400%, Top-5 Accuracy: 93.0800%, Time consumed:8.81s\n",
      "\n",
      "EarlyStopping 카운터: 17 / 30\n",
      "Epoch [86], Batch [50/391], Loss: 0.0226, LR: 0.000039\n",
      "Epoch [86], Batch [100/391], Loss: 0.0120, LR: 0.000039\n",
      "Epoch [86], Batch [150/391], Loss: 2.6601, LR: 0.000039\n",
      "Epoch [86], Batch [200/391], Loss: 0.0165, LR: 0.000039\n",
      "Epoch [86], Batch [250/391], Loss: 0.5971, LR: 0.000039\n",
      "Epoch [86], Batch [300/391], Loss: 1.9071, LR: 0.000039\n",
      "Epoch [86], Batch [350/391], Loss: 2.2287, LR: 0.000039\n",
      "Train set: Epoch: 86, Average loss:0.9143, LR: 0.000039 Top-1 Accuracy: 86.3940%, Top-5 Accuracy: 95.9180%, Time consumed:94.40s\n",
      "Test set: Epoch: 86, Average loss:0.9739, Top-1 Accuracy: 75.7500%, Top-5 Accuracy: 93.3200%, Time consumed:8.78s\n",
      "\n",
      "새로운 최고 top-1 정확도: 75.75%, top-5 정확도: 93.32%\n",
      "새로운 최고 top-5 정확도: 93.32%\n",
      "Accuracy improved (75.69% --> 75.75%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|█████████████████████████▌                                                               | 86/300 [2:24:22<6:03:07, 101.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [87], Batch [50/391], Loss: 0.0521, LR: 0.000039\n",
      "Epoch [87], Batch [100/391], Loss: 0.0238, LR: 0.000039\n",
      "Epoch [87], Batch [150/391], Loss: 0.0181, LR: 0.000039\n",
      "Epoch [87], Batch [200/391], Loss: 2.3565, LR: 0.000039\n",
      "Epoch [87], Batch [250/391], Loss: 1.7104, LR: 0.000039\n",
      "Epoch [87], Batch [300/391], Loss: 0.0147, LR: 0.000039\n",
      "Epoch [87], Batch [350/391], Loss: 2.4683, LR: 0.000039\n",
      "Train set: Epoch: 87, Average loss:0.9547, LR: 0.000039 Top-1 Accuracy: 85.6800%, Top-5 Accuracy: 95.7240%, Time consumed:91.72s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|█████████████████████████▊                                                               | 87/300 [2:26:02<5:59:31, 101.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 87, Average loss:0.9896, Top-1 Accuracy: 75.6700%, Top-5 Accuracy: 93.1500%, Time consumed:8.30s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [88], Batch [50/391], Loss: 0.4558, LR: 0.000039\n",
      "Epoch [88], Batch [100/391], Loss: 2.2877, LR: 0.000039\n",
      "Epoch [88], Batch [150/391], Loss: 0.0089, LR: 0.000039\n",
      "Epoch [88], Batch [200/391], Loss: 0.0054, LR: 0.000039\n",
      "Epoch [88], Batch [250/391], Loss: 2.4361, LR: 0.000039\n",
      "Epoch [88], Batch [300/391], Loss: 0.0261, LR: 0.000039\n",
      "Epoch [88], Batch [350/391], Loss: 0.0121, LR: 0.000039\n",
      "Train set: Epoch: 88, Average loss:0.9503, LR: 0.000039 Top-1 Accuracy: 84.4600%, Top-5 Accuracy: 95.0200%, Time consumed:94.42s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██████████████████████████                                                               | 88/300 [2:27:45<5:59:26, 101.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 88, Average loss:0.9486, Top-1 Accuracy: 75.6800%, Top-5 Accuracy: 92.9500%, Time consumed:8.35s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [89], Batch [50/391], Loss: 0.0289, LR: 0.000039\n",
      "Epoch [89], Batch [100/391], Loss: 0.0240, LR: 0.000039\n",
      "Epoch [89], Batch [150/391], Loss: 0.1804, LR: 0.000039\n",
      "Epoch [89], Batch [200/391], Loss: 2.6116, LR: 0.000039\n",
      "Epoch [89], Batch [250/391], Loss: 2.1028, LR: 0.000039\n",
      "Epoch [89], Batch [300/391], Loss: 0.0089, LR: 0.000039\n",
      "Epoch [89], Batch [350/391], Loss: 0.0168, LR: 0.000039\n",
      "Train set: Epoch: 89, Average loss:0.8792, LR: 0.000039 Top-1 Accuracy: 87.0460%, Top-5 Accuracy: 96.2380%, Time consumed:95.58s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██████████████████████████▍                                                              | 89/300 [2:29:29<6:00:06, 102.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 89, Average loss:0.9590, Top-1 Accuracy: 75.3900%, Top-5 Accuracy: 92.8200%, Time consumed:8.38s\n",
      "\n",
      "EarlyStopping 카운터: 3 / 30\n",
      "Epoch [90], Batch [50/391], Loss: 0.0200, LR: 0.000039\n",
      "Epoch [90], Batch [100/391], Loss: 0.0181, LR: 0.000039\n",
      "Epoch [90], Batch [150/391], Loss: 2.0658, LR: 0.000039\n",
      "Epoch [90], Batch [200/391], Loss: 0.0083, LR: 0.000039\n",
      "Epoch [90], Batch [250/391], Loss: 0.0130, LR: 0.000039\n",
      "Epoch [90], Batch [300/391], Loss: 2.0316, LR: 0.000039\n",
      "Epoch [90], Batch [350/391], Loss: 1.2368, LR: 0.000039\n",
      "Train set: Epoch: 90, Average loss:0.8791, LR: 0.000039 Top-1 Accuracy: 86.5640%, Top-5 Accuracy: 95.8800%, Time consumed:92.70s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██████████████████████████▋                                                              | 90/300 [2:31:10<5:57:13, 102.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 90, Average loss:0.9670, Top-1 Accuracy: 75.5800%, Top-5 Accuracy: 92.9600%, Time consumed:8.58s\n",
      "\n",
      "EarlyStopping 카운터: 4 / 30\n",
      "Epoch [91], Batch [50/391], Loss: 0.0108, LR: 0.000039\n",
      "Epoch [91], Batch [100/391], Loss: 0.0125, LR: 0.000039\n",
      "Epoch [91], Batch [150/391], Loss: 2.3303, LR: 0.000039\n",
      "Epoch [91], Batch [200/391], Loss: 0.0157, LR: 0.000039\n",
      "Epoch [91], Batch [250/391], Loss: 2.9332, LR: 0.000039\n",
      "Epoch [91], Batch [300/391], Loss: 0.0190, LR: 0.000039\n",
      "Epoch [91], Batch [350/391], Loss: 0.0128, LR: 0.000039\n",
      "Train set: Epoch: 91, Average loss:0.9649, LR: 0.000039 Top-1 Accuracy: 84.9000%, Top-5 Accuracy: 95.0160%, Time consumed:95.17s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██████████████████████████▉                                                              | 91/300 [2:32:54<5:57:14, 102.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 91, Average loss:0.9598, Top-1 Accuracy: 75.3300%, Top-5 Accuracy: 92.7300%, Time consumed:8.54s\n",
      "\n",
      "EarlyStopping 카운터: 5 / 30\n",
      "Epoch [92], Batch [50/391], Loss: 0.0147, LR: 0.000039\n",
      "Epoch [92], Batch [100/391], Loss: 0.0132, LR: 0.000039\n",
      "Epoch [92], Batch [150/391], Loss: 2.6869, LR: 0.000039\n",
      "Epoch [92], Batch [200/391], Loss: 0.0090, LR: 0.000039\n",
      "Epoch [92], Batch [250/391], Loss: 1.0442, LR: 0.000039\n",
      "Epoch [92], Batch [300/391], Loss: 2.2622, LR: 0.000039\n",
      "Epoch [92], Batch [350/391], Loss: 1.8770, LR: 0.000039\n",
      "Train set: Epoch: 92, Average loss:0.9550, LR: 0.000039 Top-1 Accuracy: 85.7020%, Top-5 Accuracy: 95.7900%, Time consumed:90.99s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███████████████████████████▎                                                             | 92/300 [2:34:35<5:53:17, 101.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 92, Average loss:0.9599, Top-1 Accuracy: 75.5700%, Top-5 Accuracy: 93.0700%, Time consumed:9.40s\n",
      "\n",
      "EarlyStopping 카운터: 6 / 30\n",
      "Epoch [93], Batch [50/391], Loss: 0.0261, LR: 0.000020\n",
      "Epoch [93], Batch [100/391], Loss: 2.4054, LR: 0.000020\n",
      "Epoch [93], Batch [150/391], Loss: 0.0096, LR: 0.000020\n",
      "Epoch [93], Batch [200/391], Loss: 2.2473, LR: 0.000020\n",
      "Epoch [93], Batch [250/391], Loss: 0.0212, LR: 0.000020\n",
      "Epoch [93], Batch [300/391], Loss: 0.0199, LR: 0.000020\n",
      "Epoch [93], Batch [350/391], Loss: 0.0086, LR: 0.000020\n",
      "Train set: Epoch: 93, Average loss:0.9499, LR: 0.000020 Top-1 Accuracy: 84.4400%, Top-5 Accuracy: 95.0540%, Time consumed:91.57s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███████████████████████████▌                                                             | 93/300 [2:36:15<5:49:50, 101.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 93, Average loss:0.9400, Top-1 Accuracy: 75.7100%, Top-5 Accuracy: 93.0700%, Time consumed:8.65s\n",
      "\n",
      "EarlyStopping 카운터: 7 / 30\n",
      "Epoch [94], Batch [50/391], Loss: 0.0218, LR: 0.000020\n",
      "Epoch [94], Batch [100/391], Loss: 0.0050, LR: 0.000020\n",
      "Epoch [94], Batch [150/391], Loss: 2.4889, LR: 0.000020\n",
      "Epoch [94], Batch [200/391], Loss: 2.3796, LR: 0.000020\n",
      "Epoch [94], Batch [250/391], Loss: 0.0202, LR: 0.000020\n",
      "Epoch [94], Batch [300/391], Loss: 0.0214, LR: 0.000020\n",
      "Epoch [94], Batch [350/391], Loss: 0.0127, LR: 0.000020\n",
      "Train set: Epoch: 94, Average loss:0.8623, LR: 0.000020 Top-1 Accuracy: 87.6380%, Top-5 Accuracy: 96.2580%, Time consumed:94.68s\n",
      "Test set: Epoch: 94, Average loss:0.9383, Top-1 Accuracy: 75.8500%, Top-5 Accuracy: 93.0500%, Time consumed:8.67s\n",
      "\n",
      "새로운 최고 top-1 정확도: 75.85%, top-5 정확도: 93.05%\n",
      "Accuracy improved (75.75% --> 75.85%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███████████████████████████▉                                                             | 94/300 [2:37:58<5:50:24, 102.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [95], Batch [50/391], Loss: 1.2919, LR: 0.000020\n",
      "Epoch [95], Batch [100/391], Loss: 0.0109, LR: 0.000020\n",
      "Epoch [95], Batch [150/391], Loss: 0.0322, LR: 0.000020\n",
      "Epoch [95], Batch [200/391], Loss: 0.5532, LR: 0.000020\n",
      "Epoch [95], Batch [250/391], Loss: 1.4686, LR: 0.000020\n",
      "Epoch [95], Batch [300/391], Loss: 0.0071, LR: 0.000020\n",
      "Epoch [95], Batch [350/391], Loss: 0.0086, LR: 0.000020\n",
      "Train set: Epoch: 95, Average loss:0.9543, LR: 0.000020 Top-1 Accuracy: 85.2560%, Top-5 Accuracy: 95.5900%, Time consumed:94.81s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|████████████████████████████▏                                                            | 95/300 [2:39:42<5:50:50, 102.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 95, Average loss:0.9495, Top-1 Accuracy: 75.4100%, Top-5 Accuracy: 92.9500%, Time consumed:9.33s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [96], Batch [50/391], Loss: 2.2446, LR: 0.000020\n",
      "Epoch [96], Batch [100/391], Loss: 2.3004, LR: 0.000020\n",
      "Epoch [96], Batch [150/391], Loss: 0.0230, LR: 0.000020\n",
      "Epoch [96], Batch [200/391], Loss: 1.5989, LR: 0.000020\n",
      "Epoch [96], Batch [250/391], Loss: 1.4184, LR: 0.000020\n",
      "Epoch [96], Batch [300/391], Loss: 2.0632, LR: 0.000020\n",
      "Epoch [96], Batch [350/391], Loss: 2.5749, LR: 0.000020\n",
      "Train set: Epoch: 96, Average loss:0.9070, LR: 0.000020 Top-1 Accuracy: 85.1760%, Top-5 Accuracy: 95.1340%, Time consumed:91.66s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|████████████████████████████▍                                                            | 96/300 [2:41:23<5:46:36, 101.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 96, Average loss:0.9518, Top-1 Accuracy: 75.3500%, Top-5 Accuracy: 92.8500%, Time consumed:8.53s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [97], Batch [50/391], Loss: 1.4990, LR: 0.000020\n",
      "Epoch [97], Batch [100/391], Loss: 1.9737, LR: 0.000020\n",
      "Epoch [97], Batch [150/391], Loss: 0.7031, LR: 0.000020\n",
      "Epoch [97], Batch [200/391], Loss: 1.8470, LR: 0.000020\n",
      "Epoch [97], Batch [250/391], Loss: 0.0358, LR: 0.000020\n",
      "Epoch [97], Batch [300/391], Loss: 0.0080, LR: 0.000020\n",
      "Epoch [97], Batch [350/391], Loss: 1.8632, LR: 0.000020\n",
      "Train set: Epoch: 97, Average loss:0.8762, LR: 0.000020 Top-1 Accuracy: 86.5300%, Top-5 Accuracy: 95.9500%, Time consumed:91.95s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|████████████████████████████▊                                                            | 97/300 [2:43:04<5:44:27, 101.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 97, Average loss:0.9652, Top-1 Accuracy: 75.2500%, Top-5 Accuracy: 92.6800%, Time consumed:9.55s\n",
      "\n",
      "EarlyStopping 카운터: 3 / 30\n",
      "Epoch [98], Batch [50/391], Loss: 0.0161, LR: 0.000020\n",
      "Epoch [98], Batch [100/391], Loss: 0.0131, LR: 0.000020\n",
      "Epoch [98], Batch [150/391], Loss: 0.0088, LR: 0.000020\n",
      "Epoch [98], Batch [200/391], Loss: 2.3970, LR: 0.000020\n",
      "Epoch [98], Batch [250/391], Loss: 0.0146, LR: 0.000020\n",
      "Epoch [98], Batch [300/391], Loss: 0.0094, LR: 0.000020\n",
      "Epoch [98], Batch [350/391], Loss: 2.1880, LR: 0.000020\n",
      "Train set: Epoch: 98, Average loss:0.8993, LR: 0.000020 Top-1 Accuracy: 86.5140%, Top-5 Accuracy: 95.9040%, Time consumed:92.39s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|█████████████████████████████                                                            | 98/300 [2:44:45<5:41:48, 101.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 98, Average loss:0.9570, Top-1 Accuracy: 75.3500%, Top-5 Accuracy: 92.8600%, Time consumed:8.46s\n",
      "\n",
      "EarlyStopping 카운터: 4 / 30\n",
      "Epoch [99], Batch [50/391], Loss: 1.8269, LR: 0.000010\n",
      "Epoch [99], Batch [100/391], Loss: 2.4343, LR: 0.000010\n",
      "Epoch [99], Batch [150/391], Loss: 1.7302, LR: 0.000010\n",
      "Epoch [99], Batch [200/391], Loss: 1.1654, LR: 0.000010\n",
      "Epoch [99], Batch [250/391], Loss: 0.0077, LR: 0.000010\n",
      "Epoch [99], Batch [300/391], Loss: 1.3546, LR: 0.000010\n",
      "Epoch [99], Batch [350/391], Loss: 0.0138, LR: 0.000010\n",
      "Train set: Epoch: 99, Average loss:0.8749, LR: 0.000010 Top-1 Accuracy: 87.1820%, Top-5 Accuracy: 96.1440%, Time consumed:95.10s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|█████████████████████████████▎                                                           | 99/300 [2:46:29<5:42:12, 102.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 99, Average loss:0.9712, Top-1 Accuracy: 75.6300%, Top-5 Accuracy: 93.0300%, Time consumed:8.50s\n",
      "\n",
      "EarlyStopping 카운터: 5 / 30\n",
      "Epoch [100], Batch [50/391], Loss: 2.1635, LR: 0.000010\n",
      "Epoch [100], Batch [100/391], Loss: 2.5042, LR: 0.000010\n",
      "Epoch [100], Batch [150/391], Loss: 0.0366, LR: 0.000010\n",
      "Epoch [100], Batch [200/391], Loss: 0.0127, LR: 0.000010\n",
      "Epoch [100], Batch [250/391], Loss: 0.0086, LR: 0.000010\n",
      "Epoch [100], Batch [300/391], Loss: 2.4054, LR: 0.000010\n",
      "Epoch [100], Batch [350/391], Loss: 2.6160, LR: 0.000010\n",
      "Train set: Epoch: 100, Average loss:0.9283, LR: 0.000010 Top-1 Accuracy: 85.9060%, Top-5 Accuracy: 95.6740%, Time consumed:93.11s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|█████████████████████████████▎                                                          | 100/300 [2:48:10<5:39:53, 101.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 100, Average loss:0.9837, Top-1 Accuracy: 75.5200%, Top-5 Accuracy: 93.1900%, Time consumed:8.43s\n",
      "\n",
      "EarlyStopping 카운터: 6 / 30\n",
      "Epoch [101], Batch [50/391], Loss: 0.0400, LR: 0.000010\n",
      "Epoch [101], Batch [100/391], Loss: 0.0162, LR: 0.000010\n",
      "Epoch [101], Batch [150/391], Loss: 0.0158, LR: 0.000010\n",
      "Epoch [101], Batch [200/391], Loss: 0.4857, LR: 0.000010\n",
      "Epoch [101], Batch [250/391], Loss: 0.0216, LR: 0.000010\n",
      "Epoch [101], Batch [300/391], Loss: 0.0393, LR: 0.000010\n",
      "Epoch [101], Batch [350/391], Loss: 0.0112, LR: 0.000010\n",
      "Train set: Epoch: 101, Average loss:0.9079, LR: 0.000010 Top-1 Accuracy: 86.1260%, Top-5 Accuracy: 95.7540%, Time consumed:92.58s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|█████████████████████████████▋                                                          | 101/300 [2:49:51<5:37:12, 101.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 101, Average loss:0.9487, Top-1 Accuracy: 75.5500%, Top-5 Accuracy: 92.9500%, Time consumed:8.39s\n",
      "\n",
      "EarlyStopping 카운터: 7 / 30\n",
      "Epoch [102], Batch [50/391], Loss: 2.6661, LR: 0.000010\n",
      "Epoch [102], Batch [100/391], Loss: 2.3594, LR: 0.000010\n",
      "Epoch [102], Batch [150/391], Loss: 2.5682, LR: 0.000010\n",
      "Epoch [102], Batch [200/391], Loss: 0.0190, LR: 0.000010\n",
      "Epoch [102], Batch [250/391], Loss: 0.0102, LR: 0.000010\n",
      "Epoch [102], Batch [300/391], Loss: 0.0076, LR: 0.000010\n",
      "Epoch [102], Batch [350/391], Loss: 0.0182, LR: 0.000010\n",
      "Train set: Epoch: 102, Average loss:0.9653, LR: 0.000010 Top-1 Accuracy: 84.6540%, Top-5 Accuracy: 94.9160%, Time consumed:98.44s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|█████████████████████████████▉                                                          | 102/300 [2:51:39<5:41:07, 103.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 102, Average loss:0.9407, Top-1 Accuracy: 75.5900%, Top-5 Accuracy: 93.0600%, Time consumed:8.90s\n",
      "\n",
      "EarlyStopping 카운터: 8 / 30\n",
      "Epoch [103], Batch [50/391], Loss: 0.0118, LR: 0.000010\n",
      "Epoch [103], Batch [100/391], Loss: 0.0378, LR: 0.000010\n",
      "Epoch [103], Batch [150/391], Loss: 0.0097, LR: 0.000010\n",
      "Epoch [103], Batch [200/391], Loss: 0.4833, LR: 0.000010\n",
      "Epoch [103], Batch [250/391], Loss: 0.0180, LR: 0.000010\n",
      "Epoch [103], Batch [300/391], Loss: 1.8864, LR: 0.000010\n",
      "Epoch [103], Batch [350/391], Loss: 0.0247, LR: 0.000010\n",
      "Train set: Epoch: 103, Average loss:0.8804, LR: 0.000010 Top-1 Accuracy: 86.3520%, Top-5 Accuracy: 95.8140%, Time consumed:90.51s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|██████████████████████████████▏                                                         | 103/300 [2:53:18<5:35:46, 102.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 103, Average loss:0.9637, Top-1 Accuracy: 75.3600%, Top-5 Accuracy: 92.9800%, Time consumed:9.18s\n",
      "\n",
      "EarlyStopping 카운터: 9 / 30\n",
      "Epoch [104], Batch [50/391], Loss: 0.0081, LR: 0.000010\n",
      "Epoch [104], Batch [100/391], Loss: 0.0122, LR: 0.000010\n",
      "Epoch [104], Batch [150/391], Loss: 2.5802, LR: 0.000010\n",
      "Epoch [104], Batch [200/391], Loss: 2.3958, LR: 0.000010\n",
      "Epoch [104], Batch [250/391], Loss: 0.0489, LR: 0.000010\n",
      "Epoch [104], Batch [300/391], Loss: 0.0239, LR: 0.000010\n",
      "Epoch [104], Batch [350/391], Loss: 1.6769, LR: 0.000010\n",
      "Train set: Epoch: 104, Average loss:0.9886, LR: 0.000010 Top-1 Accuracy: 84.8220%, Top-5 Accuracy: 95.2500%, Time consumed:93.19s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|██████████████████████████████▌                                                         | 104/300 [2:55:00<5:33:35, 102.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 104, Average loss:0.9452, Top-1 Accuracy: 75.6600%, Top-5 Accuracy: 92.8300%, Time consumed:8.58s\n",
      "\n",
      "EarlyStopping 카운터: 10 / 30\n",
      "Epoch [105], Batch [50/391], Loss: 0.0173, LR: 0.000005\n",
      "Epoch [105], Batch [100/391], Loss: 2.2835, LR: 0.000005\n",
      "Epoch [105], Batch [150/391], Loss: 1.5089, LR: 0.000005\n",
      "Epoch [105], Batch [200/391], Loss: 0.0271, LR: 0.000005\n",
      "Epoch [105], Batch [250/391], Loss: 0.0106, LR: 0.000005\n",
      "Epoch [105], Batch [300/391], Loss: 0.0117, LR: 0.000005\n",
      "Epoch [105], Batch [350/391], Loss: 0.0197, LR: 0.000005\n",
      "Train set: Epoch: 105, Average loss:0.9858, LR: 0.000005 Top-1 Accuracy: 84.2720%, Top-5 Accuracy: 94.9340%, Time consumed:91.95s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|██████████████████████████████▊                                                         | 105/300 [2:56:40<5:29:54, 101.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 105, Average loss:0.9608, Top-1 Accuracy: 75.1900%, Top-5 Accuracy: 92.8900%, Time consumed:8.14s\n",
      "\n",
      "EarlyStopping 카운터: 11 / 30\n",
      "Epoch [106], Batch [50/391], Loss: 0.9599, LR: 0.000005\n",
      "Epoch [106], Batch [100/391], Loss: 0.0155, LR: 0.000005\n",
      "Epoch [106], Batch [150/391], Loss: 0.0194, LR: 0.000005\n",
      "Epoch [106], Batch [200/391], Loss: 0.0198, LR: 0.000005\n",
      "Epoch [106], Batch [250/391], Loss: 0.0114, LR: 0.000005\n",
      "Epoch [106], Batch [300/391], Loss: 0.0198, LR: 0.000005\n",
      "Epoch [106], Batch [350/391], Loss: 0.0180, LR: 0.000005\n",
      "Train set: Epoch: 106, Average loss:0.9107, LR: 0.000005 Top-1 Accuracy: 86.1140%, Top-5 Accuracy: 95.5340%, Time consumed:93.03s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███████████████████████████████                                                         | 106/300 [2:58:21<5:27:50, 101.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 106, Average loss:0.9958, Top-1 Accuracy: 75.5500%, Top-5 Accuracy: 93.2200%, Time consumed:8.08s\n",
      "\n",
      "EarlyStopping 카운터: 12 / 30\n",
      "Epoch [107], Batch [50/391], Loss: 1.9591, LR: 0.000005\n",
      "Epoch [107], Batch [100/391], Loss: 1.5631, LR: 0.000005\n",
      "Epoch [107], Batch [150/391], Loss: 1.8123, LR: 0.000005\n",
      "Epoch [107], Batch [200/391], Loss: 0.0204, LR: 0.000005\n",
      "Epoch [107], Batch [250/391], Loss: 0.0179, LR: 0.000005\n",
      "Epoch [107], Batch [300/391], Loss: 2.5832, LR: 0.000005\n",
      "Epoch [107], Batch [350/391], Loss: 0.0133, LR: 0.000005\n",
      "Train set: Epoch: 107, Average loss:0.8092, LR: 0.000005 Top-1 Accuracy: 88.2120%, Top-5 Accuracy: 96.5360%, Time consumed:93.29s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███████████████████████████████▍                                                        | 107/300 [3:00:03<5:26:13, 101.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 107, Average loss:0.9588, Top-1 Accuracy: 75.5900%, Top-5 Accuracy: 92.8000%, Time consumed:8.17s\n",
      "\n",
      "EarlyStopping 카운터: 13 / 30\n",
      "Epoch [108], Batch [50/391], Loss: 0.0175, LR: 0.000005\n",
      "Epoch [108], Batch [100/391], Loss: 0.0110, LR: 0.000005\n",
      "Epoch [108], Batch [150/391], Loss: 1.7427, LR: 0.000005\n",
      "Epoch [108], Batch [200/391], Loss: 0.0304, LR: 0.000005\n",
      "Epoch [108], Batch [250/391], Loss: 2.1636, LR: 0.000005\n",
      "Epoch [108], Batch [300/391], Loss: 2.5115, LR: 0.000005\n",
      "Epoch [108], Batch [350/391], Loss: 2.6247, LR: 0.000005\n",
      "Train set: Epoch: 108, Average loss:0.9142, LR: 0.000005 Top-1 Accuracy: 85.6080%, Top-5 Accuracy: 95.4740%, Time consumed:94.06s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███████████████████████████████▋                                                        | 108/300 [3:01:46<5:26:06, 101.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 108, Average loss:0.9872, Top-1 Accuracy: 74.9000%, Top-5 Accuracy: 92.5600%, Time consumed:8.99s\n",
      "\n",
      "EarlyStopping 카운터: 14 / 30\n",
      "Epoch [109], Batch [50/391], Loss: 2.6256, LR: 0.000005\n",
      "Epoch [109], Batch [100/391], Loss: 2.1503, LR: 0.000005\n",
      "Epoch [109], Batch [150/391], Loss: 2.4878, LR: 0.000005\n",
      "Epoch [109], Batch [200/391], Loss: 2.3119, LR: 0.000005\n",
      "Epoch [109], Batch [250/391], Loss: 0.0182, LR: 0.000005\n",
      "Epoch [109], Batch [300/391], Loss: 2.5258, LR: 0.000005\n",
      "Epoch [109], Batch [350/391], Loss: 2.2280, LR: 0.000005\n",
      "Train set: Epoch: 109, Average loss:0.9261, LR: 0.000005 Top-1 Accuracy: 86.7740%, Top-5 Accuracy: 95.9640%, Time consumed:93.04s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███████████████████████████████▉                                                        | 109/300 [3:03:28<5:24:26, 101.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 109, Average loss:0.9983, Top-1 Accuracy: 75.0500%, Top-5 Accuracy: 92.5700%, Time consumed:8.90s\n",
      "\n",
      "EarlyStopping 카운터: 15 / 30\n",
      "Epoch [110], Batch [50/391], Loss: 2.3153, LR: 0.000005\n",
      "Epoch [110], Batch [100/391], Loss: 2.4078, LR: 0.000005\n",
      "Epoch [110], Batch [150/391], Loss: 2.3443, LR: 0.000005\n",
      "Epoch [110], Batch [200/391], Loss: 0.0122, LR: 0.000005\n",
      "Epoch [110], Batch [250/391], Loss: 1.6505, LR: 0.000005\n",
      "Epoch [110], Batch [300/391], Loss: 2.6709, LR: 0.000005\n",
      "Epoch [110], Batch [350/391], Loss: 0.0105, LR: 0.000005\n",
      "Train set: Epoch: 110, Average loss:0.9954, LR: 0.000005 Top-1 Accuracy: 83.9920%, Top-5 Accuracy: 94.7860%, Time consumed:91.80s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|████████████████████████████████▎                                                       | 110/300 [3:05:08<5:20:53, 101.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 110, Average loss:0.9704, Top-1 Accuracy: 75.1500%, Top-5 Accuracy: 92.6900%, Time consumed:8.16s\n",
      "\n",
      "EarlyStopping 카운터: 16 / 30\n",
      "Epoch [111], Batch [50/391], Loss: 2.3485, LR: 0.000002\n",
      "Epoch [111], Batch [100/391], Loss: 0.0123, LR: 0.000002\n",
      "Epoch [111], Batch [150/391], Loss: 2.3238, LR: 0.000002\n",
      "Epoch [111], Batch [200/391], Loss: 2.4507, LR: 0.000002\n",
      "Epoch [111], Batch [250/391], Loss: 0.0103, LR: 0.000002\n",
      "Epoch [111], Batch [300/391], Loss: 2.5991, LR: 0.000002\n",
      "Epoch [111], Batch [350/391], Loss: 0.0108, LR: 0.000002\n",
      "Train set: Epoch: 111, Average loss:0.8491, LR: 0.000002 Top-1 Accuracy: 86.7700%, Top-5 Accuracy: 95.9340%, Time consumed:91.08s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|████████████████████████████████▌                                                       | 111/300 [3:06:47<5:17:28, 100.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 111, Average loss:0.9550, Top-1 Accuracy: 75.6900%, Top-5 Accuracy: 93.0700%, Time consumed:8.42s\n",
      "\n",
      "EarlyStopping 카운터: 17 / 30\n",
      "Epoch [112], Batch [50/391], Loss: 0.0209, LR: 0.000002\n",
      "Epoch [112], Batch [100/391], Loss: 2.4248, LR: 0.000002\n",
      "Epoch [112], Batch [150/391], Loss: 0.0197, LR: 0.000002\n",
      "Epoch [112], Batch [200/391], Loss: 2.2071, LR: 0.000002\n",
      "Epoch [112], Batch [250/391], Loss: 0.0080, LR: 0.000002\n",
      "Epoch [112], Batch [300/391], Loss: 1.0425, LR: 0.000002\n",
      "Epoch [112], Batch [350/391], Loss: 0.9744, LR: 0.000002\n",
      "Train set: Epoch: 112, Average loss:0.9308, LR: 0.000002 Top-1 Accuracy: 85.4680%, Top-5 Accuracy: 95.3380%, Time consumed:91.12s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|████████████████████████████████▊                                                       | 112/300 [3:08:27<5:14:44, 100.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 112, Average loss:0.9584, Top-1 Accuracy: 75.2700%, Top-5 Accuracy: 93.0100%, Time consumed:8.55s\n",
      "\n",
      "EarlyStopping 카운터: 18 / 30\n",
      "Epoch [113], Batch [50/391], Loss: 0.0092, LR: 0.000002\n",
      "Epoch [113], Batch [100/391], Loss: 1.9570, LR: 0.000002\n",
      "Epoch [113], Batch [150/391], Loss: 0.0401, LR: 0.000002\n",
      "Epoch [113], Batch [200/391], Loss: 0.2414, LR: 0.000002\n",
      "Epoch [113], Batch [250/391], Loss: 0.9478, LR: 0.000002\n",
      "Epoch [113], Batch [300/391], Loss: 1.5843, LR: 0.000002\n",
      "Epoch [113], Batch [350/391], Loss: 0.4680, LR: 0.000002\n",
      "Train set: Epoch: 113, Average loss:0.8987, LR: 0.000002 Top-1 Accuracy: 87.6460%, Top-5 Accuracy: 96.3720%, Time consumed:96.90s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|█████████████████████████████████▏                                                      | 113/300 [3:10:12<5:17:23, 101.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 113, Average loss:0.9567, Top-1 Accuracy: 75.4100%, Top-5 Accuracy: 92.8100%, Time consumed:8.16s\n",
      "\n",
      "EarlyStopping 카운터: 19 / 30\n",
      "Epoch [114], Batch [50/391], Loss: 0.0183, LR: 0.000002\n",
      "Epoch [114], Batch [100/391], Loss: 0.0185, LR: 0.000002\n",
      "Epoch [114], Batch [150/391], Loss: 2.3959, LR: 0.000002\n",
      "Epoch [114], Batch [200/391], Loss: 0.0074, LR: 0.000002\n",
      "Epoch [114], Batch [250/391], Loss: 0.8938, LR: 0.000002\n",
      "Epoch [114], Batch [300/391], Loss: 1.9358, LR: 0.000002\n",
      "Epoch [114], Batch [350/391], Loss: 2.4301, LR: 0.000002\n",
      "Train set: Epoch: 114, Average loss:0.9394, LR: 0.000002 Top-1 Accuracy: 85.3040%, Top-5 Accuracy: 95.4200%, Time consumed:95.61s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|█████████████████████████████████▍                                                      | 114/300 [3:11:56<5:17:29, 102.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 114, Average loss:1.0252, Top-1 Accuracy: 75.4700%, Top-5 Accuracy: 93.0500%, Time consumed:8.15s\n",
      "\n",
      "EarlyStopping 카운터: 20 / 30\n",
      "Epoch [115], Batch [50/391], Loss: 0.0254, LR: 0.000002\n",
      "Epoch [115], Batch [100/391], Loss: 2.4317, LR: 0.000002\n",
      "Epoch [115], Batch [150/391], Loss: 0.0212, LR: 0.000002\n",
      "Epoch [115], Batch [200/391], Loss: 0.0198, LR: 0.000002\n",
      "Epoch [115], Batch [250/391], Loss: 0.0161, LR: 0.000002\n",
      "Epoch [115], Batch [300/391], Loss: 0.0115, LR: 0.000002\n",
      "Epoch [115], Batch [350/391], Loss: 2.2980, LR: 0.000002\n",
      "Train set: Epoch: 115, Average loss:0.9309, LR: 0.000002 Top-1 Accuracy: 85.8400%, Top-5 Accuracy: 95.5240%, Time consumed:92.78s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|█████████████████████████████████▋                                                      | 115/300 [3:13:37<5:15:01, 102.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 115, Average loss:0.9635, Top-1 Accuracy: 75.0800%, Top-5 Accuracy: 92.9300%, Time consumed:8.82s\n",
      "\n",
      "EarlyStopping 카운터: 21 / 30\n",
      "Epoch [116], Batch [50/391], Loss: 2.2989, LR: 0.000002\n",
      "Epoch [116], Batch [100/391], Loss: 0.0185, LR: 0.000002\n",
      "Epoch [116], Batch [150/391], Loss: 0.4569, LR: 0.000002\n",
      "Epoch [116], Batch [200/391], Loss: 1.6037, LR: 0.000002\n",
      "Epoch [116], Batch [250/391], Loss: 0.0335, LR: 0.000002\n",
      "Epoch [116], Batch [300/391], Loss: 0.0266, LR: 0.000002\n",
      "Epoch [116], Batch [350/391], Loss: 0.0195, LR: 0.000002\n",
      "Train set: Epoch: 116, Average loss:0.7595, LR: 0.000002 Top-1 Accuracy: 89.0720%, Top-5 Accuracy: 96.9500%, Time consumed:89.35s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|██████████████████████████████████                                                      | 116/300 [3:15:15<5:08:56, 100.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 116, Average loss:0.9525, Top-1 Accuracy: 75.6300%, Top-5 Accuracy: 92.9900%, Time consumed:8.05s\n",
      "\n",
      "EarlyStopping 카운터: 22 / 30\n",
      "Epoch [117], Batch [50/391], Loss: 1.7550, LR: 0.000001\n",
      "Epoch [117], Batch [100/391], Loss: 2.2325, LR: 0.000001\n",
      "Epoch [117], Batch [150/391], Loss: 0.0455, LR: 0.000001\n",
      "Epoch [117], Batch [200/391], Loss: 0.0247, LR: 0.000001\n",
      "Epoch [117], Batch [250/391], Loss: 1.0132, LR: 0.000001\n",
      "Epoch [117], Batch [300/391], Loss: 2.2056, LR: 0.000001\n",
      "Epoch [117], Batch [350/391], Loss: 0.0065, LR: 0.000001\n",
      "Train set: Epoch: 117, Average loss:0.9198, LR: 0.000001 Top-1 Accuracy: 86.5560%, Top-5 Accuracy: 95.9280%, Time consumed:88.98s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|██████████████████████████████████▋                                                      | 117/300 [3:16:52<5:04:03, 99.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 117, Average loss:0.9664, Top-1 Accuracy: 75.3400%, Top-5 Accuracy: 93.0600%, Time consumed:8.25s\n",
      "\n",
      "EarlyStopping 카운터: 23 / 30\n",
      "Epoch [118], Batch [50/391], Loss: 2.0803, LR: 0.000001\n",
      "Epoch [118], Batch [100/391], Loss: 1.1566, LR: 0.000001\n",
      "Epoch [118], Batch [150/391], Loss: 0.0106, LR: 0.000001\n",
      "Epoch [118], Batch [200/391], Loss: 0.0105, LR: 0.000001\n",
      "Epoch [118], Batch [250/391], Loss: 2.2024, LR: 0.000001\n",
      "Epoch [118], Batch [300/391], Loss: 1.9411, LR: 0.000001\n",
      "Epoch [118], Batch [350/391], Loss: 0.0227, LR: 0.000001\n",
      "Train set: Epoch: 118, Average loss:0.9466, LR: 0.000001 Top-1 Accuracy: 85.5620%, Top-5 Accuracy: 95.4260%, Time consumed:88.36s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███████████████████████████████████                                                      | 118/300 [3:18:30<5:00:30, 99.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 118, Average loss:0.9555, Top-1 Accuracy: 75.4300%, Top-5 Accuracy: 92.9600%, Time consumed:9.26s\n",
      "\n",
      "EarlyStopping 카운터: 24 / 30\n",
      "Epoch [119], Batch [50/391], Loss: 0.0104, LR: 0.000001\n",
      "Epoch [119], Batch [100/391], Loss: 0.0117, LR: 0.000001\n",
      "Epoch [119], Batch [150/391], Loss: 2.4131, LR: 0.000001\n",
      "Epoch [119], Batch [200/391], Loss: 0.0127, LR: 0.000001\n",
      "Epoch [119], Batch [250/391], Loss: 0.0227, LR: 0.000001\n",
      "Epoch [119], Batch [300/391], Loss: 0.0127, LR: 0.000001\n",
      "Epoch [119], Batch [350/391], Loss: 1.5514, LR: 0.000001\n",
      "Train set: Epoch: 119, Average loss:0.8121, LR: 0.000001 Top-1 Accuracy: 86.7260%, Top-5 Accuracy: 95.5980%, Time consumed:95.78s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████████▉                                                     | 119/300 [3:20:14<5:03:49, 100.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 119, Average loss:0.9556, Top-1 Accuracy: 75.3400%, Top-5 Accuracy: 92.9600%, Time consumed:8.77s\n",
      "\n",
      "EarlyStopping 카운터: 25 / 30\n",
      "Epoch [120], Batch [50/391], Loss: 0.8764, LR: 0.000001\n",
      "Epoch [120], Batch [100/391], Loss: 0.0074, LR: 0.000001\n",
      "Epoch [120], Batch [150/391], Loss: 2.2300, LR: 0.000001\n",
      "Epoch [120], Batch [200/391], Loss: 0.0099, LR: 0.000001\n",
      "Epoch [120], Batch [250/391], Loss: 0.0124, LR: 0.000001\n",
      "Epoch [120], Batch [300/391], Loss: 0.0063, LR: 0.000001\n",
      "Epoch [120], Batch [350/391], Loss: 1.8315, LR: 0.000001\n",
      "Train set: Epoch: 120, Average loss:0.8860, LR: 0.000001 Top-1 Accuracy: 87.5320%, Top-5 Accuracy: 96.4060%, Time consumed:91.34s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███████████████████████████████████▏                                                    | 120/300 [3:21:54<5:01:17, 100.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 120, Average loss:0.9548, Top-1 Accuracy: 75.7100%, Top-5 Accuracy: 93.0600%, Time consumed:8.41s\n",
      "\n",
      "EarlyStopping 카운터: 26 / 30\n",
      "Epoch [121], Batch [50/391], Loss: 2.2951, LR: 0.000001\n",
      "Epoch [121], Batch [100/391], Loss: 2.2685, LR: 0.000001\n",
      "Epoch [121], Batch [150/391], Loss: 1.2010, LR: 0.000001\n",
      "Epoch [121], Batch [200/391], Loss: 0.0053, LR: 0.000001\n",
      "Epoch [121], Batch [250/391], Loss: 1.6448, LR: 0.000001\n",
      "Epoch [121], Batch [300/391], Loss: 2.3614, LR: 0.000001\n",
      "Epoch [121], Batch [350/391], Loss: 0.0060, LR: 0.000001\n",
      "Train set: Epoch: 121, Average loss:0.9104, LR: 0.000001 Top-1 Accuracy: 86.7160%, Top-5 Accuracy: 95.8800%, Time consumed:90.76s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███████████████████████████████████▍                                                    | 121/300 [3:23:33<4:58:49, 100.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 121, Average loss:0.9546, Top-1 Accuracy: 75.4400%, Top-5 Accuracy: 92.9400%, Time consumed:8.79s\n",
      "\n",
      "EarlyStopping 카운터: 27 / 30\n",
      "Epoch [122], Batch [50/391], Loss: 1.0300, LR: 0.000001\n",
      "Epoch [122], Batch [100/391], Loss: 0.0084, LR: 0.000001\n",
      "Epoch [122], Batch [150/391], Loss: 2.4917, LR: 0.000001\n",
      "Epoch [122], Batch [200/391], Loss: 0.0444, LR: 0.000001\n",
      "Epoch [122], Batch [250/391], Loss: 1.9619, LR: 0.000001\n",
      "Epoch [122], Batch [300/391], Loss: 2.8035, LR: 0.000001\n",
      "Epoch [122], Batch [350/391], Loss: 0.0151, LR: 0.000001\n",
      "Train set: Epoch: 122, Average loss:0.9067, LR: 0.000001 Top-1 Accuracy: 86.2420%, Top-5 Accuracy: 95.7580%, Time consumed:92.07s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|███████████████████████████████████▊                                                    | 122/300 [3:25:14<4:57:39, 100.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 122, Average loss:0.9689, Top-1 Accuracy: 75.7000%, Top-5 Accuracy: 93.1900%, Time consumed:8.64s\n",
      "\n",
      "EarlyStopping 카운터: 28 / 30\n",
      "Epoch [123], Batch [50/391], Loss: 0.0229, LR: 0.000001\n",
      "Epoch [123], Batch [100/391], Loss: 2.0949, LR: 0.000001\n",
      "Epoch [123], Batch [150/391], Loss: 0.0154, LR: 0.000001\n",
      "Epoch [123], Batch [200/391], Loss: 0.0185, LR: 0.000001\n",
      "Epoch [123], Batch [250/391], Loss: 0.0114, LR: 0.000001\n",
      "Epoch [123], Batch [300/391], Loss: 2.6696, LR: 0.000001\n",
      "Epoch [123], Batch [350/391], Loss: 0.0154, LR: 0.000001\n",
      "Train set: Epoch: 123, Average loss:0.9517, LR: 0.000001 Top-1 Accuracy: 85.2860%, Top-5 Accuracy: 95.3320%, Time consumed:90.11s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████████████████████████████████████▍                                                    | 123/300 [3:26:53<4:54:23, 99.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 123, Average loss:0.9841, Top-1 Accuracy: 75.1700%, Top-5 Accuracy: 92.5700%, Time consumed:8.42s\n",
      "\n",
      "EarlyStopping 카운터: 29 / 30\n",
      "Epoch [124], Batch [50/391], Loss: 2.2283, LR: 0.000001\n",
      "Epoch [124], Batch [100/391], Loss: 2.5652, LR: 0.000001\n",
      "Epoch [124], Batch [150/391], Loss: 0.0148, LR: 0.000001\n",
      "Epoch [124], Batch [200/391], Loss: 1.6099, LR: 0.000001\n",
      "Epoch [124], Batch [250/391], Loss: 2.4758, LR: 0.000001\n",
      "Epoch [124], Batch [300/391], Loss: 2.6284, LR: 0.000001\n",
      "Epoch [124], Batch [350/391], Loss: 0.0833, LR: 0.000001\n",
      "Train set: Epoch: 124, Average loss:0.8672, LR: 0.000001 Top-1 Accuracy: 86.9500%, Top-5 Accuracy: 96.0700%, Time consumed:93.20s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████████████████████████████████████                                                    | 123/300 [3:28:34<5:00:08, 101.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 124, Average loss:0.9624, Top-1 Accuracy: 75.3900%, Top-5 Accuracy: 92.9600%, Time consumed:8.36s\n",
      "\n",
      "EarlyStopping 카운터: 30 / 30\n",
      "에폭 124에서 학습 조기 종료. 최고 성능 에폭: 94\n",
      "테스트 정확도 기준 최고 모델 로드 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 300, Average loss:0.9383, Top-1 Accuracy: 75.8500%, Top-5 Accuracy: 93.0500%, Time consumed:8.45s\n",
      "\n",
      "완료! 최고 테스트 top-1 정확도: 75.85%, 최고 테스트 top-5 정확도: 93.32%\n",
      "최종 테스트 top-1 정확도: 75.85%, 최종 테스트 top-5 정확도: 93.05%\n",
      "전체 학습 시간: 12523.25 초\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>learning_rate</td><td>▂▄██████████▄▄▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_accuracy_top1</td><td>▁▂▆▆▆▇▇▇▇▇▇▇▇▇▇█████████████████████████</td></tr><tr><td>test_accuracy_top5</td><td>▁▄▅▇▇▇▇▇████████████████████████████████</td></tr><tr><td>test_loss</td><td>█▆▅▃▃▂▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>total_training_time</td><td>▁</td></tr><tr><td>train_accuracy_top1</td><td>▁▂▄▄▅▅▆▆▆▇██▇███████████████████████████</td></tr><tr><td>train_accuracy_top5</td><td>▁▄▅▆▇▇▇█████████████████████████████████</td></tr><tr><td>train_loss</td><td>█▆▆▄▄▄▃▃▃▃▃▂▂▂▂▁▂▁▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>94</td></tr><tr><td>best_test_accuracy_top1</td><td>75.85</td></tr><tr><td>best_test_accuracy_top5</td><td>93.32</td></tr><tr><td>early_stopped</td><td>True</td></tr><tr><td>early_stopped_epoch</td><td>124</td></tr><tr><td>epoch</td><td>124</td></tr><tr><td>final_test_accuracy_top1</td><td>75.85</td></tr><tr><td>final_test_accuracy_top5</td><td>93.05</td></tr><tr><td>learning_rate</td><td>0.0</td></tr><tr><td>test_accuracy_top1</td><td>75.39</td></tr><tr><td>test_accuracy_top5</td><td>92.96</td></tr><tr><td>test_loss</td><td>0.96237</td></tr><tr><td>total_training_time</td><td>12523.24785</td></tr><tr><td>train_accuracy_top1</td><td>86.95</td></tr><tr><td>train_accuracy_top5</td><td>96.07</td></tr><tr><td>train_loss</td><td>0.8672</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">resnet18_cfc,lr=0.01,factor=0.5,SAM_standard</strong> at: <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/4n6g8sbn' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/4n6g8sbn</a><br> View project at: <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250418_054151-4n6g8sbn/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.v2 as transforms_v2  # CutMix를 위한 v2 transforms 추가\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "from tools.tool import AccuracyEarlyStopping, WarmUpLR, SAM  # 수정된 AccuracyEarlyStopping 클래스 임포트\n",
    "from models.resnet import resnet18\n",
    "\n",
    "wandb.login(key=\"ef091b9abcea3186341ddf8995d62bde62d7469e\")\n",
    "wandb.init(project=\"PBL-2\", name=\"resnet18_cfc,lr=0.01,factor=0.5,SGD_standard\")  \n",
    "\n",
    "# WandB 설정\n",
    "config = {\n",
    "    \"model\": \"resnet18\",\n",
    "    \"batch_size\": 128,\n",
    "    \"num_epochs\": 300,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"optimizer\": \"SGD\",\n",
    "    \"seed\": 2025,\n",
    "    \"deterministic\": False,\n",
    "    \"patience\": 30,  # early stopping patience\n",
    "    \"max_epochs_wait\": float('inf'),  # 최대 30 에폭까지만 기다림\n",
    "    \"cutmix_alpha\": 1.0,  # CutMix 알파 파라미터 추가\n",
    "    \"cutmix_prob\": 0.5,   # CutMix 적용 확률 추가\n",
    "    \"crop_padding\": 4,    # RandomCrop 패딩 크기\n",
    "    \"crop_size\": 32,      # RandomCrop 크기 (CIFAR-100 이미지 크기는 32x32)\n",
    "    \"warmup_epochs\": 5,   # 웜업할 에폭 수 추가\n",
    "}\n",
    "wandb.config.update(config)\n",
    "\n",
    "# CIFAR-100 데이터셋 로드 - 기본 train/test 분할 사용\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(config[\"crop_size\"], padding=config[\"crop_padding\"]),  # 패딩 후 랜덤 크롭\n",
    "    transforms.RandomHorizontalFlip(),  # 수평 뒤집기\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR100(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR100(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "# DataLoader 생성\n",
    "trainloader = DataLoader(trainset, batch_size=config[\"batch_size\"], shuffle=True, num_workers=16)\n",
    "testloader = DataLoader(testset, batch_size=config[\"batch_size\"], shuffle=False, num_workers=16)\n",
    "\n",
    "print(f\"Train set size: {len(trainset)}\")\n",
    "print(f\"Test set size: {len(testset)}\")\n",
    "\n",
    "# CutMix 변환 정의\n",
    "cutmix = transforms_v2.CutMix(alpha=config[\"cutmix_alpha\"], num_classes=100)  # CIFAR-100은 100개 클래스\n",
    "\n",
    "def train(model, trainloader, criterion, optimizer, device, epoch, warmup_scheduler=None, warmup_epochs=5):\n",
    "    \"\"\"\n",
    "    학습 함수 (CutMix 적용)\n",
    "    \"\"\"\n",
    "    model.train()   # 모델을 학습 모드로 설정\n",
    "    start_time = time.time()  # 시간 측정 시작\n",
    "    running_loss = 0.0\n",
    "    correct_top1 = 0\n",
    "    correct_top5 = 0\n",
    "    total = 0\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(trainloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # CutMix 확률적 적용\n",
    "        if random.random() < config[\"cutmix_prob\"]:\n",
    "            inputs, labels = cutmix(inputs, labels)\n",
    "            # 이 경우 labels은 원-핫 인코딩 형태로 변환됨\n",
    "            use_cutmix = True\n",
    "        else:\n",
    "            use_cutmix = False\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # CutMix 적용 여부에 따라 손실 함수 선택\n",
    "        if use_cutmix:\n",
    "            # CutMix가 적용된 경우 (원-핫 인코딩된 레이블)\n",
    "            loss = torch.nn.functional.cross_entropy(outputs, labels)\n",
    "        else:\n",
    "            # 일반적인 경우 (정수 인덱스 레이블)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "        loss.backward()\n",
    "        optimizer.first_step(zero_grad=True)\n",
    "\n",
    "\n",
    "        \n",
    "        # 두 번째 forward-backward 패스\n",
    "        if use_cutmix:\n",
    "            # 새로운 forward 패스 필요\n",
    "            outputs = model(inputs)\n",
    "            loss = torch.nn.functional.cross_entropy(outputs, labels)\n",
    "        else:\n",
    "            # 새로운 forward 패스 필요\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.second_step(zero_grad=True)\n",
    "\n",
    "        # 학습률 스케줄러 업데이트 - warmup 스케줄러만 여기서 업데이트\n",
    "        if epoch < warmup_epochs and warmup_scheduler is not None:\n",
    "            warmup_scheduler.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # 정확도 계산 - CutMix 적용 여부에 따라 다르게 처리\n",
    "        if use_cutmix:\n",
    "            # 원-핫 인코딩된 레이블에서 argmax를 사용해 가장 큰 값의 인덱스 추출\n",
    "            _, label_idx = labels.max(1)\n",
    "        else:\n",
    "            # 정수 인덱스 레이블 그대로 사용\n",
    "            label_idx = labels\n",
    "        \n",
    "    \n",
    "        # top-1 정확도 계산\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += inputs.size(0)\n",
    "        correct_top1 += predicted.eq(label_idx).sum().item()\n",
    "        \n",
    "        # top-5 정확도 계산\n",
    "        _, top5_idx = outputs.topk(5, 1, largest=True, sorted=True)\n",
    "        correct_top5 += sum([1 for i in range(len(label_idx)) if label_idx[i] in top5_idx[i]])\n",
    "        \n",
    "        if (i + 1) % 50 == 0:  # 50 배치마다 출력\n",
    "            print(f'Epoch [{epoch+1}], Batch [{i+1}/{len(trainloader)}], Loss: {loss.item():.4f}, LR: {optimizer.param_groups[0][\"lr\"]:.6f}')\n",
    "    \n",
    "    epoch_loss = running_loss / len(trainloader)\n",
    "    accuracy_top1 = 100.0 * correct_top1 / total\n",
    "    accuracy_top5 = 100.0 * correct_top5 / total\n",
    "    \n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    # 학습 세트에 대한 성능 출력\n",
    "    print(f'Train set: Epoch: {epoch+1}, Average loss:{epoch_loss:.4f}, LR: {optimizer.param_groups[0][\"lr\"]:.6f} '\n",
    "          f'Top-1 Accuracy: {accuracy_top1:.4f}%, Top-5 Accuracy: {accuracy_top5:.4f}%, Time consumed:{train_time:.2f}s')\n",
    "    \n",
    "    return epoch_loss, accuracy_top1, accuracy_top5\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device, epoch, phase=\"test\"):\n",
    "    \"\"\"\n",
    "    평가 함수\n",
    "    \"\"\"\n",
    "    model.eval()  # 모델을 평가 모드로 설정\n",
    "    start_time = time.time()  # 시간 측정 시작\n",
    "    \n",
    "    eval_loss = 0.0\n",
    "    correct_top1 = 0\n",
    "    correct_top5 = 0\n",
    "    total = 0\n",
    "    \n",
    "    # 그래디언트 계산 비활성화\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # 순전파\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # 손실 계산\n",
    "            loss = criterion(outputs, labels)\n",
    "            eval_loss += loss.item()\n",
    "            \n",
    "            # top-1 정확도 계산\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct_top1 += (predicted == labels).sum().item()\n",
    "            \n",
    "            # top-5 정확도 계산\n",
    "            _, top5_idx = outputs.topk(5, 1, largest=True, sorted=True)\n",
    "            correct_top5 += top5_idx.eq(labels.view(-1, 1).expand_as(top5_idx)).sum().item()\n",
    "    \n",
    "    # 평균 손실 및 정확도 계산\n",
    "    eval_loss = eval_loss / len(dataloader)\n",
    "    accuracy_top1 = 100.0 * correct_top1 / total\n",
    "    accuracy_top5 = 100.0 * correct_top5 / total\n",
    "    \n",
    "    # 평가 시간 계산\n",
    "    eval_time = time.time() - start_time\n",
    "    \n",
    "    # 테스트 세트에 대한 성능 출력\n",
    "    print(f'{phase.capitalize()} set: Epoch: {epoch+1}, Average loss:{eval_loss:.4f}, '\n",
    "          f'Top-1 Accuracy: {accuracy_top1:.4f}%, Top-5 Accuracy: {accuracy_top5:.4f}%, Time consumed:{eval_time:.2f}s')\n",
    "    print()\n",
    "    \n",
    "    return eval_loss, accuracy_top1, accuracy_top5\n",
    "\n",
    "# 메인 학습 루프\n",
    "def main_training_loop(model, trainloader, testloader, criterion, optimizer, device, num_epochs, patience, max_epochs_wait, warmup_scheduler=None, main_scheduler=None, warmup_epochs=5):\n",
    "    \"\"\"\n",
    "    메인 학습 루프 (accuracy 기준 early stopping)\n",
    "    \"\"\"\n",
    "    # 정확도 기반 얼리 스토핑 사용\n",
    "    early_stopping = AccuracyEarlyStopping(patience=patience, verbose=True, path='checkpoint.pt', max_epochs=max_epochs_wait)\n",
    "    \n",
    "    best_test_acc_top1 = 0.0\n",
    "    best_test_acc_top5 = 0.0\n",
    "    \n",
    "    # 테스트 정확도 기록을 위한 리스트\n",
    "    test_acc_top1_history = []\n",
    "    \n",
    "    # tqdm을 사용한 진행 상황 표시\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        # 학습\n",
    "        train_loss, train_acc_top1, train_acc_top5 = train(\n",
    "            model, \n",
    "            trainloader, \n",
    "            criterion, \n",
    "            optimizer, \n",
    "            device, \n",
    "            epoch, \n",
    "            warmup_scheduler, \n",
    "            warmup_epochs\n",
    "        )\n",
    "        \n",
    "        # 테스트 데이터로 평가\n",
    "        test_loss, test_acc_top1, test_acc_top5 = evaluate(model, testloader, criterion, device, epoch, phase=\"test\")\n",
    "\n",
    "        # 웜업 이후 ReduceLROnPlateau 스케줄러 업데이트 \n",
    "        if epoch >= warmup_epochs and main_scheduler is not None:\n",
    "            main_scheduler.step(test_acc_top1)  # 테스트 정확도에 따라 학습률 업데이트       \n",
    "            \n",
    "        # 테스트 정확도 기록\n",
    "        test_acc_top1_history.append(test_acc_top1)\n",
    "        \n",
    "        # WandB에 로깅\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_accuracy_top1\": train_acc_top1,\n",
    "            \"train_accuracy_top5\": train_acc_top5,\n",
    "            \"test_loss\": test_loss,\n",
    "            \"test_accuracy_top1\": test_acc_top1,\n",
    "            \"test_accuracy_top5\": test_acc_top5\n",
    "        })\n",
    "            \n",
    "        # 최고 정확도 모델 저장 (top-1 기준)\n",
    "        if test_acc_top1 > best_test_acc_top1:\n",
    "            best_test_acc_top1 = test_acc_top1\n",
    "            best_test_acc_top5_at_best_top1 = test_acc_top5\n",
    "            print(f'새로운 최고 top-1 정확도: {best_test_acc_top1:.2f}%, top-5 정확도: {best_test_acc_top5_at_best_top1:.2f}%')\n",
    "            # 모델 저장\n",
    "            model_path = f'best_model_{wandb.run.name}.pth'\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            \n",
    "            # WandB에 모델 아티팩트 저장\n",
    "            wandb.save(model_path)\n",
    "        \n",
    "        # top-5 accuracy 기록 업데이트\n",
    "        if test_acc_top5 > best_test_acc_top5:\n",
    "            best_test_acc_top5 = test_acc_top5\n",
    "            print(f'새로운 최고 top-5 정확도: {best_test_acc_top5:.2f}%')\n",
    "\n",
    "        # Early stopping 체크 (test_acc_top1 기준)\n",
    "        early_stopping(test_acc_top1, model, epoch)\n",
    "        if early_stopping.early_stop:\n",
    "            print(f\"에폭 {epoch+1}에서 학습 조기 종료. 최고 성능 에폭: {early_stopping.best_epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    # 훈련 완료 후 최고 모델 로드\n",
    "    print(\"테스트 정확도 기준 최고 모델 로드 중...\")\n",
    "    model_path = f'best_model_{wandb.run.name}.pth'\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    # 최종 테스트 세트 평가\n",
    "    final_test_loss, final_test_acc_top1, final_test_acc_top5 = evaluate(model, testloader, criterion, device, num_epochs-1, phase=\"test\")\n",
    "    \n",
    "    print(f'완료! 최고 테스트 top-1 정확도: {best_test_acc_top1:.2f}%, 최고 테스트 top-5 정확도: {best_test_acc_top5:.2f}%')\n",
    "    print(f'최종 테스트 top-1 정확도: {final_test_acc_top1:.2f}%, 최종 테스트 top-5 정확도: {final_test_acc_top5:.2f}%')\n",
    "    \n",
    "    # WandB에 최종 결과 기록\n",
    "    wandb.run.summary[\"best_test_accuracy_top1\"] = best_test_acc_top1\n",
    "    wandb.run.summary[\"best_test_accuracy_top5\"] = best_test_acc_top5\n",
    "    wandb.run.summary[\"final_test_accuracy_top1\"] = final_test_acc_top1\n",
    "    wandb.run.summary[\"final_test_accuracy_top5\"] = final_test_acc_top5\n",
    "\n",
    "    # Early stopping 정보 저장\n",
    "    if early_stopping.early_stop:\n",
    "        wandb.run.summary[\"early_stopped\"] = True\n",
    "        wandb.run.summary[\"early_stopped_epoch\"] = epoch+1\n",
    "        wandb.run.summary[\"best_epoch\"] = early_stopping.best_epoch+1\n",
    "    else:\n",
    "        wandb.run.summary[\"early_stopped\"] = False\n",
    "\n",
    "\n",
    "# 디바이스 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 모델 초기화\n",
    "# 또는 매개변수 커스터마이징\n",
    "model = resnet18().to(device)\n",
    "criterion = nn.CrossEntropyLoss()  # 기본 CrossEntropyLoss 사용 (라벨 스무딩 없음)\n",
    "base_optimizer = optim.Adam\n",
    "optimizer = SAM(model.parameters(), base_optimizer, lr=config[\"learning_rate\"])\n",
    "\n",
    "# WarmUpLR 스케줄러 초기화\n",
    "# 웜업할 총 iteration 수 계산 (웜업 에폭 × 배치 수)\n",
    "warmup_steps = config[\"warmup_epochs\"] * len(trainloader)\n",
    "warmup_scheduler = WarmUpLR(optimizer, total_iters=warmup_steps)\n",
    "\n",
    "# 웜업 이후 사용할 스케줄러 설정 \n",
    "main_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    mode='max',           # 정확도를 모니터링하므로 'max' 모드 사용\n",
    "    factor=0.5,           # 학습률 감소 비율 (5배 감소)\n",
    "    patience=5,           # 몇 에폭 동안 개선이 없을 때 감소시킬지\n",
    "    verbose=True,         # 학습률 변경 시 출력\n",
    "    threshold=0.01,        # 개선으로 간주할 최소 변화량\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "# WandB에 모델 구조 기록\n",
    "wandb.watch(model, log=\"all\")\n",
    "\n",
    "# GPU 가속\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"{torch.cuda.device_count()}개의 GPU를 사용합니다.\")\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "# 훈련 시작 시간 기록\n",
    "start_time = time.time()\n",
    "\n",
    "# 메인 학습 루프 호출\n",
    "main_training_loop(\n",
    "    model=model,\n",
    "    trainloader=trainloader,\n",
    "    testloader=testloader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    num_epochs=config[\"num_epochs\"],\n",
    "    patience=config[\"patience\"],\n",
    "    max_epochs_wait=config[\"max_epochs_wait\"],\n",
    "    warmup_scheduler=warmup_scheduler,\n",
    "    main_scheduler=main_scheduler,\n",
    "    warmup_epochs=config[\"warmup_epochs\"]\n",
    ")\n",
    "\n",
    "# 훈련 종료 시간 기록 및 출력\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "wandb.log({\"total_training_time\": total_time})\n",
    "\n",
    "print(f\"전체 학습 시간: {total_time:.2f} 초\")\n",
    "\n",
    "# WandB 실행 종료\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
