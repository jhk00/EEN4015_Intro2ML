{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "516f9d5f-6361-4b03-98ee-e1ba4de86b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/guswls/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/guswls/EEN4015_Intro2ML/pbl-2/wandb/run-20250415_080503-ws3cfeaq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/ws3cfeaq' target=\"_blank\">resnet18_cutmix_standard</a></strong> to <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/ws3cfeaq' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/ws3cfeaq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Train set size: 50000\n",
      "Test set size: 10000\n",
      "Using device: cuda\n",
      "2개의 GPU를 사용합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                       | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Batch [50/391], Loss: 4.2820\n",
      "Epoch [1], Batch [100/391], Loss: 4.0357\n",
      "Epoch [1], Batch [150/391], Loss: 4.2454\n",
      "Epoch [1], Batch [200/391], Loss: 4.2672\n",
      "Epoch [1], Batch [250/391], Loss: 4.1416\n",
      "Epoch [1], Batch [300/391], Loss: 3.4667\n",
      "Epoch [1], Batch [350/391], Loss: 4.3060\n",
      "Train set: Epoch: 1, Average loss:3.9793, LR: 0.001000 Top-1 Accuracy: 10.4180%, Top-5 Accuracy: 30.2480%, Time consumed:50.66s\n",
      "Test set: Epoch: 1, Average loss:3.3190, Top-1 Accuracy: 19.1700%, Top-5 Accuracy: 48.0700%, Time consumed:7.94s\n",
      "\n",
      "New best top-1 accuracy: 19.17%, top-5 accuracy: 48.07%\n",
      "New best top-5 accuracy: 48.07%\n",
      "Validation loss decreased (inf --> 3.318960). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▉                                                                                            | 1/100 [00:58<1:37:02, 58.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], Batch [50/391], Loss: 3.0688\n",
      "Epoch [2], Batch [100/391], Loss: 3.0776\n",
      "Epoch [2], Batch [150/391], Loss: 2.9705\n",
      "Epoch [2], Batch [200/391], Loss: 2.7344\n",
      "Epoch [2], Batch [250/391], Loss: 3.6421\n",
      "Epoch [2], Batch [300/391], Loss: 3.9342\n",
      "Epoch [2], Batch [350/391], Loss: 2.8977\n",
      "Train set: Epoch: 2, Average loss:3.3729, LR: 0.001000 Top-1 Accuracy: 21.2400%, Top-5 Accuracy: 49.5580%, Time consumed:48.02s\n",
      "Test set: Epoch: 2, Average loss:2.7337, Top-1 Accuracy: 29.8600%, Top-5 Accuracy: 62.5300%, Time consumed:8.45s\n",
      "\n",
      "New best top-1 accuracy: 29.86%, top-5 accuracy: 62.53%\n",
      "New best top-5 accuracy: 62.53%\n",
      "Validation loss decreased (3.318960 --> 2.733703). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▊                                                                                           | 2/100 [01:55<1:34:01, 57.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3], Batch [50/391], Loss: 2.7153\n",
      "Epoch [3], Batch [100/391], Loss: 2.3433\n",
      "Epoch [3], Batch [150/391], Loss: 3.8826\n",
      "Epoch [3], Batch [200/391], Loss: 3.2005\n",
      "Epoch [3], Batch [250/391], Loss: 2.4208\n",
      "Epoch [3], Batch [300/391], Loss: 2.2677\n",
      "Epoch [3], Batch [350/391], Loss: 3.7596\n",
      "Train set: Epoch: 3, Average loss:2.9755, LR: 0.001000 Top-1 Accuracy: 30.2240%, Top-5 Accuracy: 60.8220%, Time consumed:46.17s\n",
      "Test set: Epoch: 3, Average loss:2.3225, Top-1 Accuracy: 39.0500%, Top-5 Accuracy: 71.2900%, Time consumed:7.91s\n",
      "\n",
      "New best top-1 accuracy: 39.05%, top-5 accuracy: 71.29%\n",
      "New best top-5 accuracy: 71.29%\n",
      "Validation loss decreased (2.733703 --> 2.322519). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▊                                                                                          | 3/100 [02:49<1:30:40, 56.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4], Batch [50/391], Loss: 2.0658\n",
      "Epoch [4], Batch [100/391], Loss: 2.0399\n",
      "Epoch [4], Batch [150/391], Loss: 2.0022\n",
      "Epoch [4], Batch [200/391], Loss: 2.2514\n",
      "Epoch [4], Batch [250/391], Loss: 2.9656\n",
      "Epoch [4], Batch [300/391], Loss: 2.1870\n",
      "Epoch [4], Batch [350/391], Loss: 2.1274\n",
      "Train set: Epoch: 4, Average loss:2.6978, LR: 0.001000 Top-1 Accuracy: 36.7460%, Top-5 Accuracy: 67.4260%, Time consumed:49.37s\n",
      "Test set: Epoch: 4, Average loss:1.9907, Top-1 Accuracy: 46.3900%, Top-5 Accuracy: 77.8300%, Time consumed:8.54s\n",
      "\n",
      "New best top-1 accuracy: 46.39%, top-5 accuracy: 77.83%\n",
      "New best top-5 accuracy: 77.83%\n",
      "Validation loss decreased (2.322519 --> 1.990737). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▋                                                                                         | 4/100 [03:47<1:31:02, 56.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5], Batch [50/391], Loss: 2.1341\n",
      "Epoch [5], Batch [100/391], Loss: 3.5979\n",
      "Epoch [5], Batch [150/391], Loss: 1.7224\n",
      "Epoch [5], Batch [200/391], Loss: 1.6158\n",
      "Epoch [5], Batch [250/391], Loss: 2.6380\n",
      "Epoch [5], Batch [300/391], Loss: 3.3729\n",
      "Epoch [5], Batch [350/391], Loss: 1.9994\n",
      "Train set: Epoch: 5, Average loss:2.3660, LR: 0.001000 Top-1 Accuracy: 44.7180%, Top-5 Accuracy: 74.9000%, Time consumed:49.75s\n",
      "Test set: Epoch: 5, Average loss:1.8919, Top-1 Accuracy: 48.7700%, Top-5 Accuracy: 79.0200%, Time consumed:8.47s\n",
      "\n",
      "New best top-1 accuracy: 48.77%, top-5 accuracy: 79.02%\n",
      "New best top-5 accuracy: 79.02%\n",
      "Validation loss decreased (1.990737 --> 1.891899). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▋                                                                                        | 5/100 [04:46<1:31:00, 57.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6], Batch [50/391], Loss: 2.4953\n",
      "Epoch [6], Batch [100/391], Loss: 1.5123\n",
      "Epoch [6], Batch [150/391], Loss: 1.3866\n",
      "Epoch [6], Batch [200/391], Loss: 1.5338\n",
      "Epoch [6], Batch [250/391], Loss: 3.5192\n",
      "Epoch [6], Batch [300/391], Loss: 1.5669\n",
      "Epoch [6], Batch [350/391], Loss: 3.4043\n",
      "Train set: Epoch: 6, Average loss:2.1482, LR: 0.001000 Top-1 Accuracy: 50.7140%, Top-5 Accuracy: 79.5740%, Time consumed:49.54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████▌                                                                                       | 6/100 [05:45<1:30:52, 58.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 6, Average loss:1.8982, Top-1 Accuracy: 49.2200%, Top-5 Accuracy: 79.3500%, Time consumed:9.39s\n",
      "\n",
      "New best top-1 accuracy: 49.22%, top-5 accuracy: 79.35%\n",
      "New best top-5 accuracy: 79.35%\n",
      "EarlyStopping 카운터: 1 / 10\n",
      "Epoch [7], Batch [50/391], Loss: 1.2246\n",
      "Epoch [7], Batch [100/391], Loss: 3.3284\n",
      "Epoch [7], Batch [150/391], Loss: 1.1608\n",
      "Epoch [7], Batch [200/391], Loss: 1.3105\n",
      "Epoch [7], Batch [250/391], Loss: 1.2808\n",
      "Epoch [7], Batch [300/391], Loss: 1.3254\n",
      "Epoch [7], Batch [350/391], Loss: 3.4367\n",
      "Train set: Epoch: 7, Average loss:2.0452, LR: 0.001000 Top-1 Accuracy: 54.5800%, Top-5 Accuracy: 81.9160%, Time consumed:48.48s\n",
      "Test set: Epoch: 7, Average loss:1.6489, Top-1 Accuracy: 55.2800%, Top-5 Accuracy: 83.2400%, Time consumed:8.55s\n",
      "\n",
      "New best top-1 accuracy: 55.28%, top-5 accuracy: 83.24%\n",
      "New best top-5 accuracy: 83.24%\n",
      "Validation loss decreased (1.891899 --> 1.648907). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████▌                                                                                      | 7/100 [06:42<1:29:32, 57.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8], Batch [50/391], Loss: 1.6055\n",
      "Epoch [8], Batch [100/391], Loss: 0.9525\n",
      "Epoch [8], Batch [150/391], Loss: 1.0719\n",
      "Epoch [8], Batch [200/391], Loss: 2.5954\n",
      "Epoch [8], Batch [250/391], Loss: 1.8320\n",
      "Epoch [8], Batch [300/391], Loss: 0.9618\n",
      "Epoch [8], Batch [350/391], Loss: 1.0475\n",
      "Train set: Epoch: 8, Average loss:1.9179, LR: 0.001000 Top-1 Accuracy: 58.4680%, Top-5 Accuracy: 83.9700%, Time consumed:48.40s\n",
      "Test set: Epoch: 8, Average loss:1.6268, Top-1 Accuracy: 55.4000%, Top-5 Accuracy: 83.9000%, Time consumed:8.57s\n",
      "\n",
      "New best top-1 accuracy: 55.40%, top-5 accuracy: 83.90%\n",
      "New best top-5 accuracy: 83.90%\n",
      "Validation loss decreased (1.648907 --> 1.626841). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███████▍                                                                                     | 8/100 [07:39<1:28:17, 57.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9], Batch [50/391], Loss: 0.7217\n",
      "Epoch [9], Batch [100/391], Loss: 2.9188\n",
      "Epoch [9], Batch [150/391], Loss: 0.7113\n",
      "Epoch [9], Batch [200/391], Loss: 0.6771\n",
      "Epoch [9], Batch [250/391], Loss: 1.3344\n",
      "Epoch [9], Batch [300/391], Loss: 3.5350\n",
      "Epoch [9], Batch [350/391], Loss: 3.1845\n",
      "Train set: Epoch: 9, Average loss:1.6787, LR: 0.001000 Top-1 Accuracy: 64.2120%, Top-5 Accuracy: 87.3880%, Time consumed:49.60s\n",
      "Test set: Epoch: 9, Average loss:1.5578, Top-1 Accuracy: 57.3400%, Top-5 Accuracy: 84.7000%, Time consumed:8.49s\n",
      "\n",
      "New best top-1 accuracy: 57.34%, top-5 accuracy: 84.70%\n",
      "New best top-5 accuracy: 84.70%\n",
      "Validation loss decreased (1.626841 --> 1.557810). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|████████▎                                                                                    | 9/100 [08:38<1:27:42, 57.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10], Batch [50/391], Loss: 2.9598\n",
      "Epoch [10], Batch [100/391], Loss: 2.7575\n",
      "Epoch [10], Batch [150/391], Loss: 0.8347\n",
      "Epoch [10], Batch [200/391], Loss: 2.5835\n",
      "Epoch [10], Batch [250/391], Loss: 0.6736\n",
      "Epoch [10], Batch [300/391], Loss: 0.8516\n",
      "Epoch [10], Batch [350/391], Loss: 2.7367\n",
      "Train set: Epoch: 10, Average loss:1.5474, LR: 0.001000 Top-1 Accuracy: 68.4500%, Top-5 Accuracy: 88.9560%, Time consumed:49.03s\n",
      "Test set: Epoch: 10, Average loss:1.5421, Top-1 Accuracy: 58.6100%, Top-5 Accuracy: 84.8000%, Time consumed:8.85s\n",
      "\n",
      "New best top-1 accuracy: 58.61%, top-5 accuracy: 84.80%\n",
      "New best top-5 accuracy: 84.80%\n",
      "Validation loss decreased (1.557810 --> 1.542109). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█████████▏                                                                                  | 10/100 [09:36<1:26:52, 57.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11], Batch [50/391], Loss: 0.3923\n",
      "Epoch [11], Batch [100/391], Loss: 0.4398\n",
      "Epoch [11], Batch [150/391], Loss: 0.4196\n",
      "Epoch [11], Batch [200/391], Loss: 2.3513\n",
      "Epoch [11], Batch [250/391], Loss: 0.5378\n",
      "Epoch [11], Batch [300/391], Loss: 1.3654\n",
      "Epoch [11], Batch [350/391], Loss: 0.4913\n",
      "Train set: Epoch: 11, Average loss:1.5514, LR: 0.001000 Top-1 Accuracy: 70.1120%, Top-5 Accuracy: 88.9020%, Time consumed:51.58s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|██████████                                                                                  | 11/100 [10:36<1:26:58, 58.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 11, Average loss:1.5441, Top-1 Accuracy: 58.9300%, Top-5 Accuracy: 84.8500%, Time consumed:8.55s\n",
      "\n",
      "New best top-1 accuracy: 58.93%, top-5 accuracy: 84.85%\n",
      "New best top-5 accuracy: 84.85%\n",
      "EarlyStopping 카운터: 1 / 10\n",
      "Epoch [12], Batch [50/391], Loss: 2.8579\n",
      "Epoch [12], Batch [100/391], Loss: 0.4777\n",
      "Epoch [12], Batch [150/391], Loss: 0.4827\n",
      "Epoch [12], Batch [200/391], Loss: 3.0543\n",
      "Epoch [12], Batch [250/391], Loss: 1.6270\n",
      "Epoch [12], Batch [300/391], Loss: 2.6925\n",
      "Epoch [12], Batch [350/391], Loss: 0.3700\n",
      "Train set: Epoch: 12, Average loss:1.3994, LR: 0.001000 Top-1 Accuracy: 74.5360%, Top-5 Accuracy: 91.3320%, Time consumed:49.54s\n",
      "Test set: Epoch: 12, Average loss:1.5154, Top-1 Accuracy: 59.1100%, Top-5 Accuracy: 85.1900%, Time consumed:8.81s\n",
      "\n",
      "New best top-1 accuracy: 59.11%, top-5 accuracy: 85.19%\n",
      "New best top-5 accuracy: 85.19%\n",
      "Validation loss decreased (1.542109 --> 1.515363). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|███████████                                                                                 | 12/100 [11:35<1:25:58, 58.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13], Batch [50/391], Loss: 0.3670\n",
      "Epoch [13], Batch [100/391], Loss: 2.5420\n",
      "Epoch [13], Batch [150/391], Loss: 0.2995\n",
      "Epoch [13], Batch [200/391], Loss: 0.2195\n",
      "Epoch [13], Batch [250/391], Loss: 2.9169\n",
      "Epoch [13], Batch [300/391], Loss: 0.3081\n",
      "Epoch [13], Batch [350/391], Loss: 2.1786\n",
      "Train set: Epoch: 13, Average loss:1.3093, LR: 0.001000 Top-1 Accuracy: 77.0320%, Top-5 Accuracy: 92.0360%, Time consumed:49.23s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|███████████▉                                                                                | 13/100 [12:33<1:24:36, 58.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 13, Average loss:1.5652, Top-1 Accuracy: 58.6700%, Top-5 Accuracy: 84.5600%, Time consumed:8.49s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 10\n",
      "Epoch [14], Batch [50/391], Loss: 2.9104\n",
      "Epoch [14], Batch [100/391], Loss: 0.5759\n",
      "Epoch [14], Batch [150/391], Loss: 0.2018\n",
      "Epoch [14], Batch [200/391], Loss: 0.2496\n",
      "Epoch [14], Batch [250/391], Loss: 0.2012\n",
      "Epoch [14], Batch [300/391], Loss: 0.3020\n",
      "Epoch [14], Batch [350/391], Loss: 0.1919\n",
      "Train set: Epoch: 14, Average loss:1.1702, LR: 0.001000 Top-1 Accuracy: 81.7760%, Top-5 Accuracy: 94.2160%, Time consumed:48.23s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████▉                                                                               | 14/100 [13:29<1:22:58, 57.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 14, Average loss:1.5748, Top-1 Accuracy: 58.6000%, Top-5 Accuracy: 84.2300%, Time consumed:8.57s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 10\n",
      "Epoch [15], Batch [50/391], Loss: 2.8073\n",
      "Epoch [15], Batch [100/391], Loss: 2.2634\n",
      "Epoch [15], Batch [150/391], Loss: 2.9555\n",
      "Epoch [15], Batch [200/391], Loss: 0.1392\n",
      "Epoch [15], Batch [250/391], Loss: 2.6652\n",
      "Epoch [15], Batch [300/391], Loss: 0.1997\n",
      "Epoch [15], Batch [350/391], Loss: 2.7118\n",
      "Train set: Epoch: 15, Average loss:1.2246, LR: 0.001000 Top-1 Accuracy: 81.0720%, Top-5 Accuracy: 93.6560%, Time consumed:53.43s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████████████▊                                                                              | 15/100 [14:32<1:24:08, 59.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 15, Average loss:1.5785, Top-1 Accuracy: 58.8700%, Top-5 Accuracy: 84.2600%, Time consumed:9.46s\n",
      "\n",
      "EarlyStopping 카운터: 3 / 10\n",
      "Epoch [16], Batch [50/391], Loss: 0.1197\n",
      "Epoch [16], Batch [100/391], Loss: 0.1226\n",
      "Epoch [16], Batch [150/391], Loss: 0.4178\n",
      "Epoch [16], Batch [200/391], Loss: 0.6343\n",
      "Epoch [16], Batch [250/391], Loss: 0.1396\n",
      "Epoch [16], Batch [300/391], Loss: 0.1801\n",
      "Epoch [16], Batch [350/391], Loss: 0.1975\n",
      "Train set: Epoch: 16, Average loss:1.0700, LR: 0.001000 Top-1 Accuracy: 83.3160%, Top-5 Accuracy: 94.3460%, Time consumed:49.12s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████████████▋                                                                             | 16/100 [15:30<1:22:35, 59.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 16, Average loss:1.6033, Top-1 Accuracy: 58.9700%, Top-5 Accuracy: 84.3700%, Time consumed:8.94s\n",
      "\n",
      "EarlyStopping 카운터: 4 / 10\n",
      "Epoch [17], Batch [50/391], Loss: 0.1658\n",
      "Epoch [17], Batch [100/391], Loss: 0.1230\n",
      "Epoch [17], Batch [150/391], Loss: 2.7558\n",
      "Epoch [17], Batch [200/391], Loss: 2.7526\n",
      "Epoch [17], Batch [250/391], Loss: 0.1119\n",
      "Epoch [17], Batch [300/391], Loss: 1.3956\n",
      "Epoch [17], Batch [350/391], Loss: 1.4490\n",
      "Train set: Epoch: 17, Average loss:1.0656, LR: 0.001000 Top-1 Accuracy: 84.2420%, Top-5 Accuracy: 94.7680%, Time consumed:49.48s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████████████▋                                                                            | 17/100 [16:29<1:21:36, 59.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 17, Average loss:1.5520, Top-1 Accuracy: 60.2000%, Top-5 Accuracy: 85.0600%, Time consumed:9.37s\n",
      "\n",
      "New best top-1 accuracy: 60.20%, top-5 accuracy: 85.06%\n",
      "EarlyStopping 카운터: 5 / 10\n",
      "Epoch [18], Batch [50/391], Loss: 0.5344\n",
      "Epoch [18], Batch [100/391], Loss: 2.6277\n",
      "Epoch [18], Batch [150/391], Loss: 2.7987\n",
      "Epoch [18], Batch [200/391], Loss: 1.1195\n",
      "Epoch [18], Batch [250/391], Loss: 0.0895\n",
      "Epoch [18], Batch [300/391], Loss: 0.1598\n",
      "Epoch [18], Batch [350/391], Loss: 0.1039\n",
      "Train set: Epoch: 18, Average loss:1.0289, LR: 0.001000 Top-1 Accuracy: 83.9340%, Top-5 Accuracy: 94.0400%, Time consumed:49.25s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|████████████████▌                                                                           | 18/100 [17:27<1:20:05, 58.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 18, Average loss:1.5780, Top-1 Accuracy: 59.8000%, Top-5 Accuracy: 84.6100%, Time consumed:8.42s\n",
      "\n",
      "EarlyStopping 카운터: 6 / 10\n",
      "Epoch [19], Batch [50/391], Loss: 1.8817\n",
      "Epoch [19], Batch [100/391], Loss: 0.1048\n",
      "Epoch [19], Batch [150/391], Loss: 0.0660\n",
      "Epoch [19], Batch [200/391], Loss: 2.0704\n",
      "Epoch [19], Batch [250/391], Loss: 1.6276\n",
      "Epoch [19], Batch [300/391], Loss: 0.0939\n",
      "Epoch [19], Batch [350/391], Loss: 1.4908\n",
      "Train set: Epoch: 19, Average loss:1.1082, LR: 0.001000 Top-1 Accuracy: 83.6480%, Top-5 Accuracy: 94.8160%, Time consumed:49.11s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█████████████████▍                                                                          | 19/100 [18:25<1:18:44, 58.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 19, Average loss:1.6366, Top-1 Accuracy: 59.2900%, Top-5 Accuracy: 83.2500%, Time consumed:8.56s\n",
      "\n",
      "EarlyStopping 카운터: 7 / 10\n",
      "Epoch [20], Batch [50/391], Loss: 0.4599\n",
      "Epoch [20], Batch [100/391], Loss: 0.0826\n",
      "Epoch [20], Batch [150/391], Loss: 0.1060\n",
      "Epoch [20], Batch [200/391], Loss: 2.4471\n",
      "Epoch [20], Batch [250/391], Loss: 0.1154\n",
      "Epoch [20], Batch [300/391], Loss: 0.0908\n",
      "Epoch [20], Batch [350/391], Loss: 0.1099\n",
      "Train set: Epoch: 20, Average loss:1.1075, LR: 0.001000 Top-1 Accuracy: 84.7480%, Top-5 Accuracy: 95.2840%, Time consumed:48.63s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████████████▍                                                                         | 20/100 [19:21<1:17:08, 57.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 20, Average loss:1.6158, Top-1 Accuracy: 59.0800%, Top-5 Accuracy: 83.6100%, Time consumed:8.13s\n",
      "\n",
      "EarlyStopping 카운터: 8 / 10\n",
      "Epoch [21], Batch [50/391], Loss: 0.4706\n",
      "Epoch [21], Batch [100/391], Loss: 0.9742\n",
      "Epoch [21], Batch [150/391], Loss: 0.0681\n",
      "Epoch [21], Batch [200/391], Loss: 2.5538\n",
      "Epoch [21], Batch [250/391], Loss: 0.0687\n",
      "Epoch [21], Batch [300/391], Loss: 0.0672\n",
      "Epoch [21], Batch [350/391], Loss: 2.9195\n",
      "Train set: Epoch: 21, Average loss:0.9618, LR: 0.001000 Top-1 Accuracy: 85.7800%, Top-5 Accuracy: 95.1360%, Time consumed:49.50s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|███████████████████▎                                                                        | 21/100 [20:20<1:16:34, 58.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 21, Average loss:1.6134, Top-1 Accuracy: 59.3900%, Top-5 Accuracy: 83.4700%, Time consumed:9.36s\n",
      "\n",
      "EarlyStopping 카운터: 9 / 10\n",
      "Epoch [22], Batch [50/391], Loss: 2.4643\n",
      "Epoch [22], Batch [100/391], Loss: 2.0788\n",
      "Epoch [22], Batch [150/391], Loss: 1.2459\n",
      "Epoch [22], Batch [200/391], Loss: 1.6774\n",
      "Epoch [22], Batch [250/391], Loss: 0.0786\n",
      "Epoch [22], Batch [300/391], Loss: 2.6005\n",
      "Epoch [22], Batch [350/391], Loss: 0.0645\n",
      "Train set: Epoch: 22, Average loss:0.9922, LR: 0.001000 Top-1 Accuracy: 86.6860%, Top-5 Accuracy: 96.0740%, Time consumed:48.61s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|███████████████████▎                                                                        | 21/100 [21:18<1:20:08, 60.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 22, Average loss:1.5816, Top-1 Accuracy: 59.9100%, Top-5 Accuracy: 83.7300%, Time consumed:8.83s\n",
      "\n",
      "EarlyStopping 카운터: 10 / 10\n",
      "Early stopping triggered. Training stopped.\n",
      "Loading best model from early stopping checkpoint...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 100, Average loss:1.5154, Top-1 Accuracy: 59.1100%, Top-5 Accuracy: 85.1900%, Time consumed:8.45s\n",
      "\n",
      "Finish! Best test top-1 accuracy: 60.20%, Best test top-5 accuracy: 85.19%\n",
      "Final test top-1 accuracy: 59.11%, Final test top-5 accuracy: 85.19%\n",
      "Total training time: 1286.77 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▃▄▄▄▅▅▅▆▆▆▇▇▇██</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_accuracy_top1</td><td>▁▃▄▆▆▆▇▇██████████████</td></tr><tr><td>test_accuracy_top5</td><td>▁▄▅▇▇▇████████████████</td></tr><tr><td>test_loss</td><td>█▆▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>total_training_time</td><td>▁</td></tr><tr><td>train_accuracy_top1</td><td>▁▂▃▃▄▅▅▅▆▆▆▇▇█▇███████</td></tr><tr><td>train_accuracy_top5</td><td>▁▃▄▅▆▆▆▇▇▇▇▇██████████</td></tr><tr><td>train_loss</td><td>█▇▆▅▄▄▄▃▃▂▂▂▂▁▂▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_test_accuracy_top1</td><td>60.2</td></tr><tr><td>best_test_accuracy_top5</td><td>85.19</td></tr><tr><td>early_stopped</td><td>True</td></tr><tr><td>early_stopped_epoch</td><td>22</td></tr><tr><td>epoch</td><td>22</td></tr><tr><td>final_test_accuracy_top1</td><td>59.11</td></tr><tr><td>final_test_accuracy_top5</td><td>85.19</td></tr><tr><td>learning_rate</td><td>0.001</td></tr><tr><td>test_accuracy_top1</td><td>59.91</td></tr><tr><td>test_accuracy_top5</td><td>83.73</td></tr><tr><td>test_loss</td><td>1.58164</td></tr><tr><td>total_training_time</td><td>1286.77148</td></tr><tr><td>train_accuracy_top1</td><td>86.686</td></tr><tr><td>train_accuracy_top5</td><td>96.074</td></tr><tr><td>train_loss</td><td>0.99218</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">resnet18_cutmix_standard</strong> at: <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/ws3cfeaq' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/ws3cfeaq</a><br> View project at: <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250415_080503-ws3cfeaq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.v2 as transforms_v2  # CutMix를 위한 v2 transforms\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "from models.resnet import resnet18, resnet34, resnet50\n",
    "from tools.tool import EarlyStopping  # EarlyStopping 클래스 가져오기\n",
    "\n",
    "wandb.login(key=\"ef091b9abcea3186341ddf8995d62bde62d7469e\")\n",
    "wandb.init(project=\"PBL-2\", name=\"resnet18_cutmix_standard\")  # 실험 이름 변경\n",
    "\n",
    "# WandB 설정\n",
    "config = {\n",
    "    \"model\": \"resnet18\",\n",
    "    \"batch_size\": 128,\n",
    "    \"num_epochs\": 100,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"seed\": 2025,\n",
    "    \"deterministic\": False,\n",
    "    \"patience\": 10,  # early stopping patience\n",
    "    \"cutmix_alpha\": 1.0,  # CutMix 알파 파라미터\n",
    "    \"cutmix_prob\": 0.5    # CutMix 적용 확률\n",
    "}\n",
    "wandb.config.update(config)\n",
    "\n",
    "# CIFAR-100 데이터셋 로드 - 기본 train/test 분할 사용\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR100(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR100(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "# DataLoader 생성\n",
    "trainloader = DataLoader(trainset, batch_size=config[\"batch_size\"], shuffle=True, num_workers=16)\n",
    "testloader = DataLoader(testset, batch_size=config[\"batch_size\"], shuffle=False, num_workers=16)\n",
    "\n",
    "print(f\"Train set size: {len(trainset)}\")\n",
    "print(f\"Test set size: {len(testset)}\")\n",
    "\n",
    "# CutMix 변환 정의\n",
    "cutmix = transforms_v2.CutMix(alpha=config[\"cutmix_alpha\"], num_classes=100)  # CIFAR-100은 100개 클래스\n",
    "\n",
    "def train(model, trainloader, criterion, optimizer, device, epoch):\n",
    "    \"\"\"\n",
    "    학습 함수 (CutMix 적용)\n",
    "    \"\"\"\n",
    "    model.train()   # 모델을 학습 모드로 설정\n",
    "    start_time = time.time()  # 시간 측정 시작\n",
    "    running_loss = 0.0\n",
    "    correct_top1 = 0\n",
    "    correct_top5 = 0\n",
    "    total = 0\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(trainloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # CutMix 확률적 적용\n",
    "        if random.random() < config[\"cutmix_prob\"]:\n",
    "            inputs, labels = cutmix(inputs, labels)\n",
    "            # 이 경우 labels은 원-핫 인코딩 형태로 변환됨\n",
    "            use_cutmix = True\n",
    "        else:\n",
    "            use_cutmix = False\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # CutMix 적용 여부에 따라 손실 함수 선택\n",
    "        if use_cutmix:\n",
    "            # CutMix가 적용된 경우 (원-핫 인코딩된 레이블)\n",
    "            loss = torch.nn.functional.cross_entropy(outputs, labels)\n",
    "        else:\n",
    "            # 일반적인 경우 (정수 인덱스 레이블)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # 정확도 계산 - CutMix 적용 여부에 따라 다르게 처리\n",
    "        if use_cutmix:\n",
    "            # 원-핫 인코딩된 레이블에서 argmax를 사용해 가장 큰 값의 인덱스 추출\n",
    "            _, label_idx = labels.max(1)\n",
    "        else:\n",
    "            # 정수 인덱스 레이블 그대로 사용\n",
    "            label_idx = labels\n",
    "            \n",
    "        # top-1 정확도 계산\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += inputs.size(0)\n",
    "        correct_top1 += predicted.eq(label_idx).sum().item()\n",
    "        \n",
    "        # top-5 정확도 계산\n",
    "        _, top5_idx = outputs.topk(5, 1, largest=True, sorted=True)\n",
    "        correct_top5 += sum([1 for i in range(len(label_idx)) if label_idx[i] in top5_idx[i]])\n",
    "        \n",
    "        if (i + 1) % 50 == 0:  # 50 배치마다 출력\n",
    "            print(f'Epoch [{epoch+1}], Batch [{i+1}/{len(trainloader)}], Loss: {loss.item():.4f}')\n",
    "    \n",
    "    epoch_loss = running_loss / len(trainloader)\n",
    "    accuracy_top1 = 100.0 * correct_top1 / total\n",
    "    accuracy_top5 = 100.0 * correct_top5 / total\n",
    "    \n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    # 학습 세트에 대한 성능 출력\n",
    "    print(f'Train set: Epoch: {epoch+1}, Average loss:{epoch_loss:.4f}, LR: {optimizer.param_groups[0][\"lr\"]:.6f} '\n",
    "          f'Top-1 Accuracy: {accuracy_top1:.4f}%, Top-5 Accuracy: {accuracy_top5:.4f}%, Time consumed:{train_time:.2f}s')\n",
    "    \n",
    "    return epoch_loss, accuracy_top1, accuracy_top5\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device, epoch, phase=\"test\"):\n",
    "    \"\"\"\n",
    "    평가 함수\n",
    "    \"\"\"\n",
    "    model.eval()  # 모델을 평가 모드로 설정\n",
    "    start_time = time.time()  # 시간 측정 시작\n",
    "    \n",
    "    eval_loss = 0.0\n",
    "    correct_top1 = 0\n",
    "    correct_top5 = 0\n",
    "    total = 0\n",
    "    \n",
    "    # 그래디언트 계산 비활성화\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # 순전파\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # 손실 계산\n",
    "            loss = criterion(outputs, labels)\n",
    "            eval_loss += loss.item()\n",
    "            \n",
    "            # top-1 정확도 계산\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct_top1 += (predicted == labels).sum().item()\n",
    "            \n",
    "            # top-5 정확도 계산\n",
    "            _, top5_idx = outputs.topk(5, 1, largest=True, sorted=True)\n",
    "            correct_top5 += top5_idx.eq(labels.view(-1, 1).expand_as(top5_idx)).sum().item()\n",
    "    \n",
    "    # 평균 손실 및 정확도 계산\n",
    "    eval_loss = eval_loss / len(dataloader)\n",
    "    accuracy_top1 = 100.0 * correct_top1 / total\n",
    "    accuracy_top5 = 100.0 * correct_top5 / total\n",
    "    \n",
    "    # 평가 시간 계산\n",
    "    eval_time = time.time() - start_time\n",
    "    \n",
    "    # 테스트 세트에 대한 성능 출력\n",
    "    print(f'{phase.capitalize()} set: Epoch: {epoch+1}, Average loss:{eval_loss:.4f}, '\n",
    "          f'Top-1 Accuracy: {accuracy_top1:.4f}%, Top-5 Accuracy: {accuracy_top5:.4f}%, Time consumed:{eval_time:.2f}s')\n",
    "    print()\n",
    "    \n",
    "    return eval_loss, accuracy_top1, accuracy_top5\n",
    "\n",
    "# EarlyStopping 클래스는 이제 tools.tool에서 가져오기 때문에 제거\n",
    "\n",
    "\n",
    "# 메인 학습 루프\n",
    "def main_training_loop(model, trainloader, testloader, criterion, optimizer, device, num_epochs, patience):\n",
    "    \"\"\"\n",
    "    메인 학습 루프 (validation 없이)\n",
    "    \"\"\"\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=True, path='checkpoint.pt')\n",
    "    \n",
    "    best_test_acc_top1 = 0.0\n",
    "    best_test_acc_top5 = 0.0\n",
    "    \n",
    "    # tqdm을 사용한 진행 상황 표시\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        # 학습\n",
    "        train_loss, train_acc_top1, train_acc_top5 = train(model, trainloader, criterion, optimizer, device, epoch)\n",
    "        \n",
    "        # 테스트 데이터로 평가\n",
    "        test_loss, test_acc_top1, test_acc_top5 = evaluate(model, testloader, criterion, device, epoch, phase=\"test\")\n",
    "        \n",
    "        # WandB에 로깅\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_accuracy_top1\": train_acc_top1,\n",
    "            \"train_accuracy_top5\": train_acc_top5,\n",
    "            \"test_loss\": test_loss,\n",
    "            \"test_accuracy_top1\": test_acc_top1,\n",
    "            \"test_accuracy_top5\": test_acc_top5\n",
    "        })\n",
    "            \n",
    "        # 최고 정확도 모델 저장 (top-1 기준)\n",
    "        if test_acc_top1 > best_test_acc_top1:\n",
    "            best_test_acc_top1 = test_acc_top1\n",
    "            best_test_acc_top5_at_best_top1 = test_acc_top5\n",
    "            print(f'New best top-1 accuracy: {best_test_acc_top1:.2f}%, top-5 accuracy: {best_test_acc_top5_at_best_top1:.2f}%')\n",
    "            # 모델 저장\n",
    "            model_path = f'best_model_{wandb.run.name}.pth'\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            \n",
    "            # WandB에 모델 아티팩트 저장\n",
    "            wandb.save(model_path)\n",
    "        \n",
    "        # top-5 accuracy 기록 업데이트\n",
    "        if test_acc_top5 > best_test_acc_top5:\n",
    "            best_test_acc_top5 = test_acc_top5\n",
    "            print(f'New best top-5 accuracy: {best_test_acc_top5:.2f}%')\n",
    "\n",
    "        # Early stopping 체크 (test loss 기준)\n",
    "        early_stopping(test_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered. Training stopped.\")\n",
    "            break\n",
    "    \n",
    "    # 훈련 완료 후 최고 모델 로드\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Loading best model from early stopping checkpoint...\")\n",
    "        model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "    else:\n",
    "        print(\"Loading best model based on test accuracy...\")\n",
    "        model_path = f'best_model_{wandb.run.name}.pth'\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    # 최종 테스트 세트 평가\n",
    "    final_test_loss, final_test_acc_top1, final_test_acc_top5 = evaluate(model, testloader, criterion, device, num_epochs-1, phase=\"test\")\n",
    "    \n",
    "    print(f'Finish! Best test top-1 accuracy: {best_test_acc_top1:.2f}%, Best test top-5 accuracy: {best_test_acc_top5:.2f}%')\n",
    "    print(f'Final test top-1 accuracy: {final_test_acc_top1:.2f}%, Final test top-5 accuracy: {final_test_acc_top5:.2f}%')\n",
    "    \n",
    "    # WandB에 최종 결과 기록\n",
    "    wandb.run.summary[\"best_test_accuracy_top1\"] = best_test_acc_top1\n",
    "    wandb.run.summary[\"best_test_accuracy_top5\"] = best_test_acc_top5\n",
    "    wandb.run.summary[\"final_test_accuracy_top1\"] = final_test_acc_top1\n",
    "    wandb.run.summary[\"final_test_accuracy_top5\"] = final_test_acc_top5\n",
    "\n",
    "    # Early stopping 정보 저장\n",
    "    if early_stopping.early_stop:\n",
    "        wandb.run.summary[\"early_stopped\"] = True\n",
    "        wandb.run.summary[\"early_stopped_epoch\"] = epoch+1\n",
    "    else:\n",
    "        wandb.run.summary[\"early_stopped\"] = False\n",
    "\n",
    "\n",
    "# 디바이스 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 모델 초기화\n",
    "model = resnet18().to(device)  \n",
    "criterion = nn.CrossEntropyLoss()  # 손실 함수 정의\n",
    "optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"])  # 옵티마이저 정의\n",
    "\n",
    "# WandB에 모델 구조 기록\n",
    "wandb.watch(model, log=\"all\")\n",
    "\n",
    "# GPU 가속\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"{torch.cuda.device_count()}개의 GPU를 사용합니다.\")\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "# 훈련 시작 시간 기록\n",
    "start_time = time.time()\n",
    "\n",
    "# 메인 학습 루프 호출\n",
    "main_training_loop(\n",
    "    model=model,\n",
    "    trainloader=trainloader,\n",
    "    testloader=testloader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    num_epochs=config[\"num_epochs\"],\n",
    "    patience=config[\"patience\"]\n",
    ")\n",
    "\n",
    "# 훈련 종료 시간 기록 및 출력\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "wandb.log({\"total_training_time\": total_time})\n",
    "\n",
    "print(f\"Total training time: {total_time:.2f} seconds\")\n",
    "\n",
    "# WandB 실행 종료\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57b9218-aa24-4297-bb92-473c215e6767",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
