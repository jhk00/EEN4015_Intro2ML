{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516f9d5f-6361-4b03-98ee-e1ba4de86b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/guswls/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msokjh1310\u001b[0m (\u001b[33msokjh1310-hanyang-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/guswls/EEN4015_Intro2ML/pbl-2/wandb/run-20250429_151512-ur3jin8m</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/ur3jin8m' target=\"_blank\">efficientnet-b0,lr=0.005,factor=0.5,SAM_SGD,crossentropy</a></strong> to <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/ur3jin8m' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/ur3jin8m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Train set size: 50000\n",
      "Test set size: 10000\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2개의 GPU를 사용합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                       | 0/300 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a CuDNNError: cuDNN error: CUDNN_STATUS_BAD_PARAM\n",
      "Exception raised from run_conv_plan at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:374 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7f471008a897 in /usr/local/lib/python3.11/dist-packages/torch/lib/libc10.so)\n",
      "frame #1: <unknown function> + 0xe1c861 (0x7f46a55ef861 in /usr/local/lib/python3.11/dist-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #2: <unknown function> + 0x1095d83 (0x7f46a5868d83 in /usr/local/lib/python3.11/dist-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #3: <unknown function> + 0x1097c2c (0x7f46a586ac2c in /usr/local/lib/python3.11/dist-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #4: <unknown function> + 0x109832b (0x7f46a586b32b in /usr/local/lib/python3.11/dist-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #5: <unknown function> + 0x107c8bd (0x7f46a584f8bd in /usr/local/lib/python3.11/dist-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #6: <unknown function> + 0x107e7d3 (0x7f46a58517d3 in /usr/local/lib/python3.11/dist-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #7: at::native::convolution_backward(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::OptionalArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, bool, c10::ArrayRef<long>, long, std::array<bool, 3ul>) + 0x27e0 (0x7f46da2fc770 in /usr/local/lib/python3.11/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #8: <unknown function> + 0x32e15f5 (0x7f46a7ab45f5 in /usr/local/lib/python3.11/dist-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #9: <unknown function> + 0x32e96a2 (0x7f46a7abc6a2 in /usr/local/lib/python3.11/dist-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #10: at::_ops::convolution_backward::redispatch(c10::DispatchKeySet, at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::OptionalArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt, std::array<bool, 3ul>) + 0x26b (0x7f46db1ca72b in /usr/local/lib/python3.11/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #11: <unknown function> + 0x48caf13 (0x7f46dcf50f13 in /usr/local/lib/python3.11/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #12: <unknown function> + 0x48ccac3 (0x7f46dcf52ac3 in /usr/local/lib/python3.11/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #13: at::_ops::convolution_backward::call(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::OptionalArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, c10::ArrayRef<c10::SymInt>, bool, c10::ArrayRef<c10::SymInt>, c10::SymInt, std::array<bool, 3ul>) + 0x3a3 (0x7f46db1f0de3 in /usr/local/lib/python3.11/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #14: <unknown function> + 0x19bdad1 (0x7f46da043ad1 in /usr/local/lib/python3.11/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #15: torch::autograd::generated::ConvolutionBackward0::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x300 (0x7f46dca628b0 in /usr/local/lib/python3.11/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #16: <unknown function> + 0x513f9cb (0x7f46dd7c59cb in /usr/local/lib/python3.11/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #17: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1526 (0x7f46dd7bfac6 in /usr/local/lib/python3.11/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #18: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x698 (0x7f46dd7c0728 in /usr/local/lib/python3.11/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #19: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x13f (0x7f46dd7b765f in /usr/local/lib/python3.11/dist-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #20: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x5c (0x7f46f98e355c in /usr/local/lib/python3.11/dist-packages/torch/lib/libtorch_python.so)\n",
      "frame #21: <unknown function> + 0xd6df4 (0x7f4724211df4 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)\n",
      "frame #22: <unknown function> + 0x8609 (0x7f4724c27609 in /usr/lib/x86_64-linux-gnu/libpthread.so.0)\n",
      "frame #23: clone + 0x43 (0x7f4724d61133 in /usr/lib/x86_64-linux-gnu/libc.so.6)\n",
      " (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:921.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Batch [50/391], Loss: 4.7574, LR: 0.000064\n",
      "Epoch [1], Batch [100/391], Loss: 4.7204, LR: 0.000128\n",
      "Epoch [1], Batch [150/391], Loss: 4.7192, LR: 0.000192\n",
      "Epoch [1], Batch [200/391], Loss: 4.6701, LR: 0.000256\n",
      "Epoch [1], Batch [250/391], Loss: 4.6574, LR: 0.000320\n",
      "Epoch [1], Batch [300/391], Loss: 4.7041, LR: 0.000384\n",
      "Epoch [1], Batch [350/391], Loss: 4.6690, LR: 0.000448\n",
      "Train set: Epoch: 1, Average loss:4.6930, LR: 0.000500 Top-1 Accuracy: 0.6120%, Top-5 Accuracy: 3.4000%, Time consumed:211.19s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                                          | 1/300 [03:50<19:09:51, 230.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 1, Average loss:4.5776, Top-1 Accuracy: 1.6600%, Top-5 Accuracy: 6.7600%, Time consumed:19.40s\n",
      "\n",
      "새로운 최고 top-1 정확도: 1.66%, top-5 정확도: 6.76%\n",
      "새로운 최고 top-5 정확도: 6.76%\n",
      "Accuracy improved (-inf% --> 1.66%). Saving model ...\n",
      "Epoch [2], Batch [50/391], Loss: 4.6587, LR: 0.000564\n",
      "Epoch [2], Batch [100/391], Loss: 4.6117, LR: 0.000628\n",
      "Epoch [2], Batch [150/391], Loss: 4.6312, LR: 0.000692\n",
      "Epoch [2], Batch [200/391], Loss: 4.5966, LR: 0.000756\n",
      "Epoch [2], Batch [250/391], Loss: 4.6562, LR: 0.000820\n",
      "Epoch [2], Batch [300/391], Loss: 4.6437, LR: 0.000884\n",
      "Epoch [2], Batch [350/391], Loss: 4.5720, LR: 0.000948\n",
      "Train set: Epoch: 2, Average loss:4.6292, LR: 0.001000 Top-1 Accuracy: 0.8560%, Top-5 Accuracy: 4.9980%, Time consumed:209.29s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▌                                                                                          | 2/300 [07:39<19:00:58, 229.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 2, Average loss:4.5513, Top-1 Accuracy: 2.4900%, Top-5 Accuracy: 10.4300%, Time consumed:19.57s\n",
      "\n",
      "새로운 최고 top-1 정확도: 2.49%, top-5 정확도: 10.43%\n",
      "새로운 최고 top-5 정확도: 10.43%\n",
      "Accuracy improved (1.66% --> 2.49%). Saving model ...\n",
      "Epoch [3], Batch [50/391], Loss: 4.5629, LR: 0.001064\n",
      "Epoch [3], Batch [100/391], Loss: 4.5683, LR: 0.001128\n",
      "Epoch [3], Batch [150/391], Loss: 4.6711, LR: 0.001192\n",
      "Epoch [3], Batch [200/391], Loss: 4.4433, LR: 0.001256\n",
      "Epoch [3], Batch [250/391], Loss: 4.5657, LR: 0.001320\n",
      "Epoch [3], Batch [300/391], Loss: 4.5749, LR: 0.001384\n",
      "Epoch [3], Batch [350/391], Loss: 4.3907, LR: 0.001448\n",
      "Train set: Epoch: 3, Average loss:4.5227, LR: 0.001500 Top-1 Accuracy: 1.6800%, Top-5 Accuracy: 9.3000%, Time consumed:217.83s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▉                                                                                          | 3/300 [11:36<19:13:32, 233.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 3, Average loss:4.2598, Top-1 Accuracy: 5.2000%, Top-5 Accuracy: 17.9300%, Time consumed:18.98s\n",
      "\n",
      "새로운 최고 top-1 정확도: 5.20%, top-5 정확도: 17.93%\n",
      "새로운 최고 top-5 정확도: 17.93%\n",
      "Accuracy improved (2.49% --> 5.20%). Saving model ...\n",
      "Epoch [4], Batch [50/391], Loss: 4.3488, LR: 0.001564\n",
      "Epoch [4], Batch [100/391], Loss: 4.3021, LR: 0.001628\n",
      "Epoch [4], Batch [150/391], Loss: 4.2627, LR: 0.001692\n",
      "Epoch [4], Batch [200/391], Loss: 4.2898, LR: 0.001756\n",
      "Epoch [4], Batch [250/391], Loss: 4.4788, LR: 0.001820\n",
      "Epoch [4], Batch [300/391], Loss: 4.5476, LR: 0.001884\n",
      "Epoch [4], Batch [350/391], Loss: 4.0435, LR: 0.001948\n",
      "Train set: Epoch: 4, Average loss:4.3268, LR: 0.002000 Top-1 Accuracy: 4.1040%, Top-5 Accuracy: 17.7420%, Time consumed:217.83s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▏                                                                                         | 4/300 [15:33<19:16:41, 234.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 4, Average loss:3.9690, Top-1 Accuracy: 7.9200%, Top-5 Accuracy: 27.8900%, Time consumed:18.67s\n",
      "\n",
      "새로운 최고 top-1 정확도: 7.92%, top-5 정확도: 27.89%\n",
      "새로운 최고 top-5 정확도: 27.89%\n",
      "Accuracy improved (5.20% --> 7.92%). Saving model ...\n",
      "Epoch [5], Batch [50/391], Loss: 4.3698, LR: 0.002064\n",
      "Epoch [5], Batch [100/391], Loss: 4.0407, LR: 0.002128\n",
      "Epoch [5], Batch [150/391], Loss: 4.1731, LR: 0.002192\n",
      "Epoch [5], Batch [200/391], Loss: 4.4182, LR: 0.002256\n",
      "Epoch [5], Batch [250/391], Loss: 4.0112, LR: 0.002320\n",
      "Epoch [5], Batch [300/391], Loss: 3.9362, LR: 0.002384\n",
      "Epoch [5], Batch [350/391], Loss: 4.2894, LR: 0.002448\n",
      "Train set: Epoch: 5, Average loss:4.1399, LR: 0.002500 Top-1 Accuracy: 7.0820%, Top-5 Accuracy: 24.1840%, Time consumed:203.25s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▌                                                                                         | 5/300 [19:14<18:49:14, 229.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 5, Average loss:3.7240, Top-1 Accuracy: 11.8800%, Top-5 Accuracy: 34.5800%, Time consumed:17.79s\n",
      "\n",
      "새로운 최고 top-1 정확도: 11.88%, top-5 정확도: 34.58%\n",
      "새로운 최고 top-5 정확도: 34.58%\n",
      "Accuracy improved (7.92% --> 11.88%). Saving model ...\n",
      "Epoch [6], Batch [50/391], Loss: 4.4074, LR: 0.002564\n",
      "Epoch [6], Batch [100/391], Loss: 3.7403, LR: 0.002628\n",
      "Epoch [6], Batch [150/391], Loss: 4.0228, LR: 0.002692\n",
      "Epoch [6], Batch [200/391], Loss: 4.3901, LR: 0.002756\n",
      "Epoch [6], Batch [250/391], Loss: 3.9295, LR: 0.002820\n",
      "Epoch [6], Batch [300/391], Loss: 4.2358, LR: 0.002884\n",
      "Epoch [6], Batch [350/391], Loss: 4.1760, LR: 0.002948\n",
      "Train set: Epoch: 6, Average loss:4.0297, LR: 0.003000 Top-1 Accuracy: 8.7740%, Top-5 Accuracy: 28.3480%, Time consumed:208.93s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▊                                                                                         | 6/300 [23:01<18:41:19, 228.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 6, Average loss:3.5931, Top-1 Accuracy: 13.4600%, Top-5 Accuracy: 39.2400%, Time consumed:18.12s\n",
      "\n",
      "새로운 최고 top-1 정확도: 13.46%, top-5 정확도: 39.24%\n",
      "새로운 최고 top-5 정확도: 39.24%\n",
      "Accuracy improved (11.88% --> 13.46%). Saving model ...\n",
      "Epoch [7], Batch [50/391], Loss: 3.7995, LR: 0.003064\n",
      "Epoch [7], Batch [100/391], Loss: 3.8127, LR: 0.003128\n",
      "Epoch [7], Batch [150/391], Loss: 4.0129, LR: 0.003192\n",
      "Epoch [7], Batch [200/391], Loss: 3.5168, LR: 0.003256\n",
      "Epoch [7], Batch [250/391], Loss: 3.7774, LR: 0.003320\n",
      "Epoch [7], Batch [300/391], Loss: 4.0681, LR: 0.003384\n",
      "Epoch [7], Batch [350/391], Loss: 4.2695, LR: 0.003448\n",
      "Train set: Epoch: 7, Average loss:3.9375, LR: 0.003500 Top-1 Accuracy: 10.3080%, Top-5 Accuracy: 31.6340%, Time consumed:203.16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██                                                                                         | 7/300 [26:44<18:27:43, 226.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 7, Average loss:3.4116, Top-1 Accuracy: 16.5000%, Top-5 Accuracy: 44.4400%, Time consumed:19.37s\n",
      "\n",
      "새로운 최고 top-1 정확도: 16.50%, top-5 정확도: 44.44%\n",
      "새로운 최고 top-5 정확도: 44.44%\n",
      "Accuracy improved (13.46% --> 16.50%). Saving model ...\n",
      "Epoch [8], Batch [50/391], Loss: 4.2761, LR: 0.003564\n",
      "Epoch [8], Batch [100/391], Loss: 3.4455, LR: 0.003628\n",
      "Epoch [8], Batch [150/391], Loss: 3.6684, LR: 0.003692\n",
      "Epoch [8], Batch [200/391], Loss: 3.5879, LR: 0.003756\n",
      "Epoch [8], Batch [250/391], Loss: 3.4954, LR: 0.003820\n",
      "Epoch [8], Batch [300/391], Loss: 4.1572, LR: 0.003884\n",
      "Epoch [8], Batch [350/391], Loss: 4.3091, LR: 0.003948\n",
      "Train set: Epoch: 8, Average loss:3.8218, LR: 0.004000 Top-1 Accuracy: 12.3960%, Top-5 Accuracy: 35.5660%, Time consumed:207.76s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▍                                                                                        | 8/300 [30:31<18:23:51, 226.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 8, Average loss:3.2133, Top-1 Accuracy: 20.8200%, Top-5 Accuracy: 50.4900%, Time consumed:18.84s\n",
      "\n",
      "새로운 최고 top-1 정확도: 20.82%, top-5 정확도: 50.49%\n",
      "새로운 최고 top-5 정확도: 50.49%\n",
      "Accuracy improved (16.50% --> 20.82%). Saving model ...\n",
      "Epoch [9], Batch [50/391], Loss: 3.4500, LR: 0.004064\n",
      "Epoch [9], Batch [100/391], Loss: 3.3667, LR: 0.004128\n",
      "Epoch [9], Batch [150/391], Loss: 3.4266, LR: 0.004192\n",
      "Epoch [9], Batch [200/391], Loss: 3.3507, LR: 0.004256\n",
      "Epoch [9], Batch [250/391], Loss: 3.4994, LR: 0.004320\n",
      "Epoch [9], Batch [300/391], Loss: 3.3452, LR: 0.004384\n",
      "Epoch [9], Batch [350/391], Loss: 3.2922, LR: 0.004448\n",
      "Train set: Epoch: 9, Average loss:3.7117, LR: 0.004500 Top-1 Accuracy: 14.7400%, Top-5 Accuracy: 39.4440%, Time consumed:207.61s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▋                                                                                        | 9/300 [34:17<18:19:33, 226.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 9, Average loss:3.1581, Top-1 Accuracy: 22.2000%, Top-5 Accuracy: 51.3400%, Time consumed:18.71s\n",
      "\n",
      "새로운 최고 top-1 정확도: 22.20%, top-5 정확도: 51.34%\n",
      "새로운 최고 top-5 정확도: 51.34%\n",
      "Accuracy improved (20.82% --> 22.20%). Saving model ...\n",
      "Epoch [10], Batch [50/391], Loss: 3.2763, LR: 0.004564\n",
      "Epoch [10], Batch [100/391], Loss: 3.2738, LR: 0.004628\n",
      "Epoch [10], Batch [150/391], Loss: 3.7499, LR: 0.004692\n",
      "Epoch [10], Batch [200/391], Loss: 3.2568, LR: 0.004756\n",
      "Epoch [10], Batch [250/391], Loss: 3.5149, LR: 0.004820\n",
      "Epoch [10], Batch [300/391], Loss: 3.1679, LR: 0.004884\n",
      "Epoch [10], Batch [350/391], Loss: 4.3376, LR: 0.004948\n",
      "Train set: Epoch: 10, Average loss:3.6191, LR: 0.005000 Top-1 Accuracy: 16.7580%, Top-5 Accuracy: 43.0700%, Time consumed:207.39s\n",
      "Test set: Epoch: 10, Average loss:2.9638, Top-1 Accuracy: 25.7200%, Top-5 Accuracy: 56.7900%, Time consumed:17.99s\n",
      "\n",
      "새로운 최고 top-1 정확도: 25.72%, top-5 정확도: 56.79%\n",
      "새로운 최고 top-5 정확도: 56.79%\n",
      "Accuracy improved (22.20% --> 25.72%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|███                                                                                       | 10/300 [38:03<18:14:06, 226.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11], Batch [50/391], Loss: 4.1667, LR: 0.005000\n",
      "Epoch [11], Batch [100/391], Loss: 3.4894, LR: 0.005000\n",
      "Epoch [11], Batch [150/391], Loss: 3.1021, LR: 0.005000\n",
      "Epoch [11], Batch [200/391], Loss: 4.1986, LR: 0.005000\n",
      "Epoch [11], Batch [250/391], Loss: 3.1438, LR: 0.005000\n",
      "Epoch [11], Batch [300/391], Loss: 4.2184, LR: 0.005000\n",
      "Epoch [11], Batch [350/391], Loss: 4.2112, LR: 0.005000\n",
      "Train set: Epoch: 11, Average loss:3.5000, LR: 0.005000 Top-1 Accuracy: 18.8240%, Top-5 Accuracy: 46.2040%, Time consumed:202.75s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▎                                                                                      | 11/300 [41:45<18:03:29, 224.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 11, Average loss:2.8118, Top-1 Accuracy: 28.5200%, Top-5 Accuracy: 61.0700%, Time consumed:18.81s\n",
      "\n",
      "새로운 최고 top-1 정확도: 28.52%, top-5 정확도: 61.07%\n",
      "새로운 최고 top-5 정확도: 61.07%\n",
      "Accuracy improved (25.72% --> 28.52%). Saving model ...\n",
      "Epoch [12], Batch [50/391], Loss: 2.9489, LR: 0.005000\n",
      "Epoch [12], Batch [100/391], Loss: 3.8397, LR: 0.005000\n",
      "Epoch [12], Batch [150/391], Loss: 3.3874, LR: 0.005000\n",
      "Epoch [12], Batch [200/391], Loss: 4.0431, LR: 0.005000\n",
      "Epoch [12], Batch [250/391], Loss: 4.1732, LR: 0.005000\n",
      "Epoch [12], Batch [300/391], Loss: 4.2452, LR: 0.005000\n",
      "Epoch [12], Batch [350/391], Loss: 2.8785, LR: 0.005000\n",
      "Train set: Epoch: 12, Average loss:3.4309, LR: 0.005000 Top-1 Accuracy: 20.8420%, Top-5 Accuracy: 48.5320%, Time consumed:205.67s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▌                                                                                      | 12/300 [45:30<18:00:44, 225.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 12, Average loss:2.6538, Top-1 Accuracy: 32.3600%, Top-5 Accuracy: 64.7400%, Time consumed:19.81s\n",
      "\n",
      "새로운 최고 top-1 정확도: 32.36%, top-5 정확도: 64.74%\n",
      "새로운 최고 top-5 정확도: 64.74%\n",
      "Accuracy improved (28.52% --> 32.36%). Saving model ...\n",
      "Epoch [13], Batch [50/391], Loss: 3.7949, LR: 0.005000\n",
      "Epoch [13], Batch [100/391], Loss: 2.7192, LR: 0.005000\n",
      "Epoch [13], Batch [150/391], Loss: 2.7159, LR: 0.005000\n",
      "Epoch [13], Batch [200/391], Loss: 3.5791, LR: 0.005000\n",
      "Epoch [13], Batch [250/391], Loss: 2.6455, LR: 0.005000\n",
      "Epoch [13], Batch [300/391], Loss: 2.5668, LR: 0.005000\n",
      "Epoch [13], Batch [350/391], Loss: 2.7841, LR: 0.005000\n",
      "Train set: Epoch: 13, Average loss:3.2985, LR: 0.005000 Top-1 Accuracy: 23.1180%, Top-5 Accuracy: 52.2020%, Time consumed:202.08s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▉                                                                                      | 13/300 [49:11<17:51:08, 223.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 13, Average loss:2.5447, Top-1 Accuracy: 34.2500%, Top-5 Accuracy: 66.9900%, Time consumed:18.88s\n",
      "\n",
      "새로운 최고 top-1 정확도: 34.25%, top-5 정확도: 66.99%\n",
      "새로운 최고 top-5 정확도: 66.99%\n",
      "Accuracy improved (32.36% --> 34.25%). Saving model ...\n",
      "Epoch [14], Batch [50/391], Loss: 2.5723, LR: 0.005000\n",
      "Epoch [14], Batch [100/391], Loss: 2.5734, LR: 0.005000\n",
      "Epoch [14], Batch [150/391], Loss: 4.2290, LR: 0.005000\n",
      "Epoch [14], Batch [200/391], Loss: 4.0463, LR: 0.005000\n",
      "Epoch [14], Batch [250/391], Loss: 3.6566, LR: 0.005000\n",
      "Epoch [14], Batch [300/391], Loss: 2.6902, LR: 0.005000\n",
      "Epoch [14], Batch [350/391], Loss: 4.2717, LR: 0.005000\n",
      "Train set: Epoch: 14, Average loss:3.2376, LR: 0.005000 Top-1 Accuracy: 24.7900%, Top-5 Accuracy: 54.2460%, Time consumed:201.79s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▏                                                                                     | 14/300 [52:51<17:41:34, 222.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 14, Average loss:2.4814, Top-1 Accuracy: 36.1400%, Top-5 Accuracy: 68.3300%, Time consumed:17.92s\n",
      "\n",
      "새로운 최고 top-1 정확도: 36.14%, top-5 정확도: 68.33%\n",
      "새로운 최고 top-5 정확도: 68.33%\n",
      "Accuracy improved (34.25% --> 36.14%). Saving model ...\n",
      "Epoch [15], Batch [50/391], Loss: 3.5111, LR: 0.005000\n",
      "Epoch [15], Batch [100/391], Loss: 2.5062, LR: 0.005000\n",
      "Epoch [15], Batch [150/391], Loss: 2.7808, LR: 0.005000\n",
      "Epoch [15], Batch [200/391], Loss: 4.0220, LR: 0.005000\n",
      "Epoch [15], Batch [250/391], Loss: 3.8727, LR: 0.005000\n",
      "Epoch [15], Batch [300/391], Loss: 2.6950, LR: 0.005000\n",
      "Epoch [15], Batch [350/391], Loss: 3.6920, LR: 0.005000\n",
      "Train set: Epoch: 15, Average loss:3.1665, LR: 0.005000 Top-1 Accuracy: 26.2120%, Top-5 Accuracy: 56.3920%, Time consumed:203.54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▌                                                                                     | 15/300 [56:34<17:37:57, 222.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 15, Average loss:2.3461, Top-1 Accuracy: 38.6000%, Top-5 Accuracy: 71.2100%, Time consumed:19.05s\n",
      "\n",
      "새로운 최고 top-1 정확도: 38.60%, top-5 정확도: 71.21%\n",
      "새로운 최고 top-5 정확도: 71.21%\n",
      "Accuracy improved (36.14% --> 38.60%). Saving model ...\n",
      "Epoch [16], Batch [50/391], Loss: 3.9140, LR: 0.005000\n",
      "Epoch [16], Batch [100/391], Loss: 2.3563, LR: 0.005000\n",
      "Epoch [16], Batch [150/391], Loss: 2.5579, LR: 0.005000\n",
      "Epoch [16], Batch [200/391], Loss: 3.5390, LR: 0.005000\n",
      "Epoch [16], Batch [250/391], Loss: 2.4808, LR: 0.005000\n",
      "Epoch [16], Batch [300/391], Loss: 3.8841, LR: 0.005000\n",
      "Epoch [16], Batch [350/391], Loss: 4.0677, LR: 0.005000\n",
      "Train set: Epoch: 16, Average loss:3.0333, LR: 0.005000 Top-1 Accuracy: 28.4780%, Top-5 Accuracy: 58.7960%, Time consumed:221.14s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▋                                                                                   | 16/300 [1:00:33<17:57:45, 227.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 16, Average loss:2.3222, Top-1 Accuracy: 39.5400%, Top-5 Accuracy: 71.6200%, Time consumed:17.94s\n",
      "\n",
      "새로운 최고 top-1 정확도: 39.54%, top-5 정확도: 71.62%\n",
      "새로운 최고 top-5 정확도: 71.62%\n",
      "Accuracy improved (38.60% --> 39.54%). Saving model ...\n",
      "Epoch [17], Batch [50/391], Loss: 4.1141, LR: 0.005000\n",
      "Epoch [17], Batch [100/391], Loss: 3.9979, LR: 0.005000\n",
      "Epoch [17], Batch [150/391], Loss: 2.5778, LR: 0.005000\n",
      "Epoch [17], Batch [200/391], Loss: 2.3072, LR: 0.005000\n",
      "Epoch [17], Batch [250/391], Loss: 2.3403, LR: 0.005000\n",
      "Epoch [17], Batch [300/391], Loss: 3.8942, LR: 0.005000\n",
      "Epoch [17], Batch [350/391], Loss: 4.0343, LR: 0.005000\n",
      "Train set: Epoch: 17, Average loss:3.1028, LR: 0.005000 Top-1 Accuracy: 28.2120%, Top-5 Accuracy: 57.8660%, Time consumed:205.03s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▉                                                                                   | 17/300 [1:04:18<17:50:08, 226.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 17, Average loss:2.2296, Top-1 Accuracy: 41.7000%, Top-5 Accuracy: 73.1300%, Time consumed:19.82s\n",
      "\n",
      "새로운 최고 top-1 정확도: 41.70%, top-5 정확도: 73.13%\n",
      "새로운 최고 top-5 정확도: 73.13%\n",
      "Accuracy improved (39.54% --> 41.70%). Saving model ...\n",
      "Epoch [18], Batch [50/391], Loss: 2.4785, LR: 0.005000\n",
      "Epoch [18], Batch [100/391], Loss: 2.3778, LR: 0.005000\n",
      "Epoch [18], Batch [150/391], Loss: 2.3507, LR: 0.005000\n",
      "Epoch [18], Batch [200/391], Loss: 2.4199, LR: 0.005000\n",
      "Epoch [18], Batch [250/391], Loss: 3.3350, LR: 0.005000\n",
      "Epoch [18], Batch [300/391], Loss: 3.1644, LR: 0.005000\n",
      "Epoch [18], Batch [350/391], Loss: 4.0575, LR: 0.005000\n",
      "Train set: Epoch: 18, Average loss:2.9576, LR: 0.005000 Top-1 Accuracy: 30.6020%, Top-5 Accuracy: 60.8280%, Time consumed:217.05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████▎                                                                                  | 18/300 [1:08:14<17:58:29, 229.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 18, Average loss:2.1229, Top-1 Accuracy: 43.4800%, Top-5 Accuracy: 75.4500%, Time consumed:18.28s\n",
      "\n",
      "새로운 최고 top-1 정확도: 43.48%, top-5 정확도: 75.45%\n",
      "새로운 최고 top-5 정확도: 75.45%\n",
      "Accuracy improved (41.70% --> 43.48%). Saving model ...\n",
      "Epoch [19], Batch [50/391], Loss: 2.1084, LR: 0.005000\n",
      "Epoch [19], Batch [100/391], Loss: 3.3308, LR: 0.005000\n",
      "Epoch [19], Batch [150/391], Loss: 3.9188, LR: 0.005000\n",
      "Epoch [19], Batch [200/391], Loss: 2.4255, LR: 0.005000\n",
      "Epoch [19], Batch [250/391], Loss: 2.2784, LR: 0.005000\n",
      "Epoch [19], Batch [300/391], Loss: 4.1809, LR: 0.005000\n",
      "Epoch [19], Batch [350/391], Loss: 2.5353, LR: 0.005000\n",
      "Train set: Epoch: 19, Average loss:2.9165, LR: 0.005000 Top-1 Accuracy: 32.0920%, Top-5 Accuracy: 62.7320%, Time consumed:202.81s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████▌                                                                                  | 19/300 [1:11:55<17:42:36, 226.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 19, Average loss:2.0663, Top-1 Accuracy: 45.8000%, Top-5 Accuracy: 76.6700%, Time consumed:17.92s\n",
      "\n",
      "새로운 최고 top-1 정확도: 45.80%, top-5 정확도: 76.67%\n",
      "새로운 최고 top-5 정확도: 76.67%\n",
      "Accuracy improved (43.48% --> 45.80%). Saving model ...\n",
      "Epoch [20], Batch [50/391], Loss: 4.0914, LR: 0.005000\n",
      "Epoch [20], Batch [100/391], Loss: 2.1057, LR: 0.005000\n",
      "Epoch [20], Batch [150/391], Loss: 2.0948, LR: 0.005000\n",
      "Epoch [20], Batch [200/391], Loss: 2.3510, LR: 0.005000\n",
      "Epoch [20], Batch [250/391], Loss: 2.1733, LR: 0.005000\n",
      "Epoch [20], Batch [300/391], Loss: 2.2358, LR: 0.005000\n",
      "Epoch [20], Batch [350/391], Loss: 3.0709, LR: 0.005000\n",
      "Train set: Epoch: 20, Average loss:2.8968, LR: 0.005000 Top-1 Accuracy: 33.0080%, Top-5 Accuracy: 62.8440%, Time consumed:206.59s\n",
      "Test set: Epoch: 20, Average loss:2.0167, Top-1 Accuracy: 45.9200%, Top-5 Accuracy: 77.6600%, Time consumed:18.69s\n",
      "\n",
      "새로운 최고 top-1 정확도: 45.92%, top-5 정확도: 77.66%\n",
      "새로운 최고 top-5 정확도: 77.66%\n",
      "Accuracy improved (45.80% --> 45.92%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████▊                                                                                  | 20/300 [1:15:40<17:36:51, 226.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21], Batch [50/391], Loss: 3.4198, LR: 0.005000\n",
      "Epoch [21], Batch [100/391], Loss: 2.2336, LR: 0.005000\n",
      "Epoch [21], Batch [150/391], Loss: 3.7407, LR: 0.005000\n",
      "Epoch [21], Batch [200/391], Loss: 2.0499, LR: 0.005000\n",
      "Epoch [21], Batch [250/391], Loss: 2.0505, LR: 0.005000\n",
      "Epoch [21], Batch [300/391], Loss: 2.3405, LR: 0.005000\n",
      "Epoch [21], Batch [350/391], Loss: 2.1037, LR: 0.005000\n",
      "Train set: Epoch: 21, Average loss:2.8293, LR: 0.005000 Top-1 Accuracy: 34.1220%, Top-5 Accuracy: 64.3100%, Time consumed:204.69s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████▏                                                                                 | 21/300 [1:19:23<17:28:40, 225.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 21, Average loss:1.9918, Top-1 Accuracy: 46.9800%, Top-5 Accuracy: 78.2100%, Time consumed:18.47s\n",
      "\n",
      "새로운 최고 top-1 정확도: 46.98%, top-5 정확도: 78.21%\n",
      "새로운 최고 top-5 정확도: 78.21%\n",
      "Accuracy improved (45.92% --> 46.98%). Saving model ...\n",
      "Epoch [22], Batch [50/391], Loss: 2.1530, LR: 0.005000\n",
      "Epoch [22], Batch [100/391], Loss: 2.3044, LR: 0.005000\n",
      "Epoch [22], Batch [150/391], Loss: 2.1425, LR: 0.005000\n",
      "Epoch [22], Batch [200/391], Loss: 2.3223, LR: 0.005000\n",
      "Epoch [22], Batch [250/391], Loss: 3.8756, LR: 0.005000\n",
      "Epoch [22], Batch [300/391], Loss: 2.6949, LR: 0.005000\n",
      "Epoch [22], Batch [350/391], Loss: 3.6767, LR: 0.005000\n",
      "Train set: Epoch: 22, Average loss:2.7565, LR: 0.005000 Top-1 Accuracy: 35.9120%, Top-5 Accuracy: 66.4780%, Time consumed:205.53s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████▍                                                                                 | 22/300 [1:23:09<17:24:54, 225.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 22, Average loss:1.9738, Top-1 Accuracy: 47.3200%, Top-5 Accuracy: 78.0500%, Time consumed:19.84s\n",
      "\n",
      "새로운 최고 top-1 정확도: 47.32%, top-5 정확도: 78.05%\n",
      "Accuracy improved (46.98% --> 47.32%). Saving model ...\n",
      "Epoch [23], Batch [50/391], Loss: 3.8604, LR: 0.005000\n",
      "Epoch [23], Batch [100/391], Loss: 2.6295, LR: 0.005000\n",
      "Epoch [23], Batch [150/391], Loss: 1.9432, LR: 0.005000\n",
      "Epoch [23], Batch [200/391], Loss: 2.0661, LR: 0.005000\n",
      "Epoch [23], Batch [250/391], Loss: 1.8796, LR: 0.005000\n",
      "Epoch [23], Batch [300/391], Loss: 2.0580, LR: 0.005000\n",
      "Epoch [23], Batch [350/391], Loss: 3.4203, LR: 0.005000\n",
      "Train set: Epoch: 23, Average loss:2.7222, LR: 0.005000 Top-1 Accuracy: 36.4260%, Top-5 Accuracy: 66.8600%, Time consumed:215.69s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▋                                                                                 | 23/300 [1:27:03<17:32:40, 228.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 23, Average loss:1.9031, Top-1 Accuracy: 49.4000%, Top-5 Accuracy: 79.7300%, Time consumed:17.99s\n",
      "\n",
      "새로운 최고 top-1 정확도: 49.40%, top-5 정확도: 79.73%\n",
      "새로운 최고 top-5 정확도: 79.73%\n",
      "Accuracy improved (47.32% --> 49.40%). Saving model ...\n",
      "Epoch [24], Batch [50/391], Loss: 3.9700, LR: 0.005000\n",
      "Epoch [24], Batch [100/391], Loss: 1.9126, LR: 0.005000\n",
      "Epoch [24], Batch [150/391], Loss: 2.0757, LR: 0.005000\n",
      "Epoch [24], Batch [200/391], Loss: 2.2916, LR: 0.005000\n",
      "Epoch [24], Batch [250/391], Loss: 3.5930, LR: 0.005000\n",
      "Epoch [24], Batch [300/391], Loss: 3.4677, LR: 0.005000\n",
      "Epoch [24], Batch [350/391], Loss: 1.8851, LR: 0.005000\n",
      "Train set: Epoch: 24, Average loss:2.7123, LR: 0.005000 Top-1 Accuracy: 37.2940%, Top-5 Accuracy: 67.2860%, Time consumed:205.21s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███████                                                                                 | 24/300 [1:30:46<17:22:15, 226.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 24, Average loss:1.8638, Top-1 Accuracy: 50.5700%, Top-5 Accuracy: 80.7100%, Time consumed:17.81s\n",
      "\n",
      "새로운 최고 top-1 정확도: 50.57%, top-5 정확도: 80.71%\n",
      "새로운 최고 top-5 정확도: 80.71%\n",
      "Accuracy improved (49.40% --> 50.57%). Saving model ...\n",
      "Epoch [25], Batch [50/391], Loss: 3.8780, LR: 0.005000\n",
      "Epoch [25], Batch [100/391], Loss: 2.1068, LR: 0.005000\n",
      "Epoch [25], Batch [150/391], Loss: 2.0169, LR: 0.005000\n",
      "Epoch [25], Batch [200/391], Loss: 3.8937, LR: 0.005000\n",
      "Epoch [25], Batch [250/391], Loss: 2.1114, LR: 0.005000\n",
      "Epoch [25], Batch [300/391], Loss: 3.2682, LR: 0.005000\n",
      "Epoch [25], Batch [350/391], Loss: 1.7648, LR: 0.005000\n",
      "Train set: Epoch: 25, Average loss:2.6238, LR: 0.005000 Top-1 Accuracy: 38.6520%, Top-5 Accuracy: 68.9600%, Time consumed:203.46s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███████▎                                                                                | 25/300 [1:34:28<17:12:39, 225.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 25, Average loss:1.8583, Top-1 Accuracy: 50.4600%, Top-5 Accuracy: 80.1000%, Time consumed:18.86s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [26], Batch [50/391], Loss: 1.9843, LR: 0.005000\n",
      "Epoch [26], Batch [100/391], Loss: 3.2648, LR: 0.005000\n",
      "Epoch [26], Batch [150/391], Loss: 2.9815, LR: 0.005000\n",
      "Epoch [26], Batch [200/391], Loss: 3.7979, LR: 0.005000\n",
      "Epoch [26], Batch [250/391], Loss: 3.9351, LR: 0.005000\n",
      "Epoch [26], Batch [300/391], Loss: 2.4972, LR: 0.005000\n",
      "Epoch [26], Batch [350/391], Loss: 3.6233, LR: 0.005000\n",
      "Train set: Epoch: 26, Average loss:2.7776, LR: 0.005000 Top-1 Accuracy: 36.9480%, Top-5 Accuracy: 67.3500%, Time consumed:208.18s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███████▋                                                                                | 26/300 [1:38:17<17:12:53, 226.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 26, Average loss:1.9110, Top-1 Accuracy: 50.2900%, Top-5 Accuracy: 79.8800%, Time consumed:20.04s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [27], Batch [50/391], Loss: 1.9428, LR: 0.005000\n",
      "Epoch [27], Batch [100/391], Loss: 3.9328, LR: 0.005000\n",
      "Epoch [27], Batch [150/391], Loss: 3.9287, LR: 0.005000\n",
      "Epoch [27], Batch [200/391], Loss: 3.7555, LR: 0.005000\n",
      "Epoch [27], Batch [250/391], Loss: 1.8237, LR: 0.005000\n",
      "Epoch [27], Batch [300/391], Loss: 2.1470, LR: 0.005000\n",
      "Epoch [27], Batch [350/391], Loss: 3.5324, LR: 0.005000\n",
      "Train set: Epoch: 27, Average loss:2.6764, LR: 0.005000 Top-1 Accuracy: 38.1400%, Top-5 Accuracy: 67.6120%, Time consumed:201.67s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███████▉                                                                                | 27/300 [1:41:56<17:00:21, 224.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 27, Average loss:1.7857, Top-1 Accuracy: 52.1400%, Top-5 Accuracy: 82.3300%, Time consumed:17.93s\n",
      "\n",
      "새로운 최고 top-1 정확도: 52.14%, top-5 정확도: 82.33%\n",
      "새로운 최고 top-5 정확도: 82.33%\n",
      "Accuracy improved (50.57% --> 52.14%). Saving model ...\n",
      "Epoch [28], Batch [50/391], Loss: 3.4501, LR: 0.005000\n",
      "Epoch [28], Batch [100/391], Loss: 3.2570, LR: 0.005000\n",
      "Epoch [28], Batch [150/391], Loss: 2.2343, LR: 0.005000\n",
      "Epoch [28], Batch [200/391], Loss: 1.9856, LR: 0.005000\n",
      "Epoch [28], Batch [250/391], Loss: 3.8472, LR: 0.005000\n",
      "Epoch [28], Batch [300/391], Loss: 3.1419, LR: 0.005000\n",
      "Epoch [28], Batch [350/391], Loss: 2.0300, LR: 0.005000\n",
      "Train set: Epoch: 28, Average loss:2.6095, LR: 0.005000 Top-1 Accuracy: 39.3880%, Top-5 Accuracy: 69.0220%, Time consumed:201.45s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|████████▏                                                                               | 28/300 [1:45:36<16:49:53, 222.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 28, Average loss:1.7642, Top-1 Accuracy: 52.7800%, Top-5 Accuracy: 81.8900%, Time consumed:17.71s\n",
      "\n",
      "새로운 최고 top-1 정확도: 52.78%, top-5 정확도: 81.89%\n",
      "Accuracy improved (52.14% --> 52.78%). Saving model ...\n",
      "Epoch [29], Batch [50/391], Loss: 2.0100, LR: 0.005000\n",
      "Epoch [29], Batch [100/391], Loss: 1.9211, LR: 0.005000\n",
      "Epoch [29], Batch [150/391], Loss: 1.7632, LR: 0.005000\n",
      "Epoch [29], Batch [200/391], Loss: 3.8100, LR: 0.005000\n",
      "Epoch [29], Batch [250/391], Loss: 1.8972, LR: 0.005000\n",
      "Epoch [29], Batch [300/391], Loss: 1.7431, LR: 0.005000\n",
      "Epoch [29], Batch [350/391], Loss: 3.2023, LR: 0.005000\n",
      "Train set: Epoch: 29, Average loss:2.5440, LR: 0.005000 Top-1 Accuracy: 40.9920%, Top-5 Accuracy: 70.9780%, Time consumed:205.78s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▌                                                                               | 29/300 [1:49:21<16:49:21, 223.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 29, Average loss:1.6948, Top-1 Accuracy: 54.4600%, Top-5 Accuracy: 83.2500%, Time consumed:19.17s\n",
      "\n",
      "새로운 최고 top-1 정확도: 54.46%, top-5 정확도: 83.25%\n",
      "새로운 최고 top-5 정확도: 83.25%\n",
      "Accuracy improved (52.78% --> 54.46%). Saving model ...\n",
      "Epoch [30], Batch [50/391], Loss: 1.6203, LR: 0.005000\n",
      "Epoch [30], Batch [100/391], Loss: 3.8045, LR: 0.005000\n",
      "Epoch [30], Batch [150/391], Loss: 2.7738, LR: 0.005000\n",
      "Epoch [30], Batch [200/391], Loss: 1.6180, LR: 0.005000\n",
      "Epoch [30], Batch [250/391], Loss: 3.8058, LR: 0.005000\n",
      "Epoch [30], Batch [300/391], Loss: 1.6519, LR: 0.005000\n",
      "Epoch [30], Batch [350/391], Loss: 3.8912, LR: 0.005000\n",
      "Train set: Epoch: 30, Average loss:2.5584, LR: 0.005000 Top-1 Accuracy: 41.4480%, Top-5 Accuracy: 71.2880%, Time consumed:203.22s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▊                                                                               | 30/300 [1:53:02<16:42:23, 222.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 30, Average loss:1.7048, Top-1 Accuracy: 54.1600%, Top-5 Accuracy: 83.1300%, Time consumed:17.84s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [31], Batch [50/391], Loss: 3.8276, LR: 0.002500\n",
      "Epoch [31], Batch [100/391], Loss: 1.7162, LR: 0.002500\n",
      "Epoch [31], Batch [150/391], Loss: 3.7501, LR: 0.002500\n",
      "Epoch [31], Batch [200/391], Loss: 3.1384, LR: 0.002500\n",
      "Epoch [31], Batch [250/391], Loss: 1.6213, LR: 0.002500\n",
      "Epoch [31], Batch [300/391], Loss: 3.7186, LR: 0.002500\n",
      "Epoch [31], Batch [350/391], Loss: 3.0499, LR: 0.002500\n",
      "Train set: Epoch: 31, Average loss:2.4969, LR: 0.002500 Top-1 Accuracy: 43.2100%, Top-5 Accuracy: 72.6340%, Time consumed:213.00s\n",
      "Test set: Epoch: 31, Average loss:1.6157, Top-1 Accuracy: 56.5800%, Top-5 Accuracy: 84.3900%, Time consumed:19.15s\n",
      "\n",
      "새로운 최고 top-1 정확도: 56.58%, top-5 정확도: 84.39%\n",
      "새로운 최고 top-5 정확도: 84.39%\n",
      "Accuracy improved (54.46% --> 56.58%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█████████                                                                               | 31/300 [1:56:54<16:51:36, 225.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32], Batch [50/391], Loss: 3.9741, LR: 0.002500\n",
      "Epoch [32], Batch [100/391], Loss: 1.4188, LR: 0.002500\n",
      "Epoch [32], Batch [150/391], Loss: 3.1766, LR: 0.002500\n",
      "Epoch [32], Batch [200/391], Loss: 3.7666, LR: 0.002500\n",
      "Epoch [32], Batch [250/391], Loss: 1.7597, LR: 0.002500\n",
      "Epoch [32], Batch [300/391], Loss: 1.7106, LR: 0.002500\n",
      "Epoch [32], Batch [350/391], Loss: 1.9269, LR: 0.002500\n",
      "Train set: Epoch: 32, Average loss:2.4739, LR: 0.002500 Top-1 Accuracy: 43.3780%, Top-5 Accuracy: 72.8460%, Time consumed:208.40s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█████████▍                                                                              | 32/300 [2:00:41<16:48:51, 225.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 32, Average loss:1.6085, Top-1 Accuracy: 56.3200%, Top-5 Accuracy: 84.4500%, Time consumed:17.98s\n",
      "\n",
      "새로운 최고 top-5 정확도: 84.45%\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [33], Batch [50/391], Loss: 1.6117, LR: 0.002500\n",
      "Epoch [33], Batch [100/391], Loss: 2.2678, LR: 0.002500\n",
      "Epoch [33], Batch [150/391], Loss: 1.7026, LR: 0.002500\n",
      "Epoch [33], Batch [200/391], Loss: 3.3906, LR: 0.002500\n",
      "Epoch [33], Batch [250/391], Loss: 1.6353, LR: 0.002500\n",
      "Epoch [33], Batch [300/391], Loss: 1.8609, LR: 0.002500\n",
      "Epoch [33], Batch [350/391], Loss: 3.8078, LR: 0.002500\n",
      "Train set: Epoch: 33, Average loss:2.3738, LR: 0.002500 Top-1 Accuracy: 45.0980%, Top-5 Accuracy: 74.4180%, Time consumed:203.27s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█████████▋                                                                              | 33/300 [2:04:23<16:40:24, 224.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 33, Average loss:1.6496, Top-1 Accuracy: 55.6900%, Top-5 Accuracy: 83.7800%, Time consumed:19.08s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [34], Batch [50/391], Loss: 2.0948, LR: 0.002500\n",
      "Epoch [34], Batch [100/391], Loss: 1.5523, LR: 0.002500\n",
      "Epoch [34], Batch [150/391], Loss: 1.7171, LR: 0.002500\n",
      "Epoch [34], Batch [200/391], Loss: 3.7216, LR: 0.002500\n",
      "Epoch [34], Batch [250/391], Loss: 2.6520, LR: 0.002500\n",
      "Epoch [34], Batch [300/391], Loss: 3.4297, LR: 0.002500\n",
      "Epoch [34], Batch [350/391], Loss: 1.5513, LR: 0.002500\n",
      "Train set: Epoch: 34, Average loss:2.4376, LR: 0.002500 Top-1 Accuracy: 44.4280%, Top-5 Accuracy: 73.6220%, Time consumed:206.22s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█████████▉                                                                              | 34/300 [2:08:08<16:37:06, 224.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 34, Average loss:1.5768, Top-1 Accuracy: 57.3000%, Top-5 Accuracy: 84.9700%, Time consumed:18.75s\n",
      "\n",
      "새로운 최고 top-1 정확도: 57.30%, top-5 정확도: 84.97%\n",
      "새로운 최고 top-5 정확도: 84.97%\n",
      "Accuracy improved (56.58% --> 57.30%). Saving model ...\n",
      "Epoch [35], Batch [50/391], Loss: 1.8413, LR: 0.002500\n",
      "Epoch [35], Batch [100/391], Loss: 1.6147, LR: 0.002500\n",
      "Epoch [35], Batch [150/391], Loss: 3.5008, LR: 0.002500\n",
      "Epoch [35], Batch [200/391], Loss: 3.3763, LR: 0.002500\n",
      "Epoch [35], Batch [250/391], Loss: 1.9169, LR: 0.002500\n",
      "Epoch [35], Batch [300/391], Loss: 1.7788, LR: 0.002500\n",
      "Epoch [35], Batch [350/391], Loss: 1.6628, LR: 0.002500\n",
      "Train set: Epoch: 35, Average loss:2.4693, LR: 0.002500 Top-1 Accuracy: 44.1500%, Top-5 Accuracy: 73.2560%, Time consumed:208.03s\n",
      "Test set: Epoch: 35, Average loss:1.5871, Top-1 Accuracy: 57.4000%, Top-5 Accuracy: 85.0100%, Time consumed:18.96s\n",
      "\n",
      "새로운 최고 top-1 정확도: 57.40%, top-5 정확도: 85.01%\n",
      "새로운 최고 top-5 정확도: 85.01%\n",
      "Accuracy improved (57.30% --> 57.40%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████▎                                                                             | 35/300 [2:11:55<16:36:22, 225.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36], Batch [50/391], Loss: 3.5604, LR: 0.002500\n",
      "Epoch [36], Batch [100/391], Loss: 3.6635, LR: 0.002500\n",
      "Epoch [36], Batch [150/391], Loss: 2.9295, LR: 0.002500\n",
      "Epoch [36], Batch [200/391], Loss: 2.5485, LR: 0.002500\n",
      "Epoch [36], Batch [250/391], Loss: 3.8670, LR: 0.002500\n",
      "Epoch [36], Batch [300/391], Loss: 1.5441, LR: 0.002500\n",
      "Epoch [36], Batch [350/391], Loss: 1.8222, LR: 0.002500\n",
      "Train set: Epoch: 36, Average loss:2.3375, LR: 0.002500 Top-1 Accuracy: 46.1620%, Top-5 Accuracy: 75.2000%, Time consumed:203.15s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████▌                                                                             | 36/300 [2:15:37<16:27:39, 224.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 36, Average loss:1.5792, Top-1 Accuracy: 57.9000%, Top-5 Accuracy: 84.7300%, Time consumed:18.47s\n",
      "\n",
      "새로운 최고 top-1 정확도: 57.90%, top-5 정확도: 84.73%\n",
      "Accuracy improved (57.40% --> 57.90%). Saving model ...\n",
      "Epoch [37], Batch [50/391], Loss: 1.5975, LR: 0.002500\n",
      "Epoch [37], Batch [100/391], Loss: 3.7901, LR: 0.002500\n",
      "Epoch [37], Batch [150/391], Loss: 1.8412, LR: 0.002500\n",
      "Epoch [37], Batch [200/391], Loss: 1.8714, LR: 0.002500\n",
      "Epoch [37], Batch [250/391], Loss: 3.7710, LR: 0.002500\n",
      "Epoch [37], Batch [300/391], Loss: 3.8675, LR: 0.002500\n",
      "Epoch [37], Batch [350/391], Loss: 3.2414, LR: 0.002500\n",
      "Train set: Epoch: 37, Average loss:2.4346, LR: 0.002500 Top-1 Accuracy: 44.8160%, Top-5 Accuracy: 73.7740%, Time consumed:203.26s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████▊                                                                             | 37/300 [2:19:20<16:21:19, 223.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 37, Average loss:1.5929, Top-1 Accuracy: 58.1900%, Top-5 Accuracy: 84.6200%, Time consumed:19.07s\n",
      "\n",
      "새로운 최고 top-1 정확도: 58.19%, top-5 정확도: 84.62%\n",
      "Accuracy improved (57.90% --> 58.19%). Saving model ...\n",
      "Epoch [38], Batch [50/391], Loss: 1.5467, LR: 0.001250\n",
      "Epoch [38], Batch [100/391], Loss: 1.6037, LR: 0.001250\n",
      "Epoch [38], Batch [150/391], Loss: 1.6004, LR: 0.001250\n",
      "Epoch [38], Batch [200/391], Loss: 3.5859, LR: 0.001250\n",
      "Epoch [38], Batch [250/391], Loss: 3.6526, LR: 0.001250\n",
      "Epoch [38], Batch [300/391], Loss: 1.6637, LR: 0.001250\n",
      "Epoch [38], Batch [350/391], Loss: 1.7751, LR: 0.001250\n",
      "Train set: Epoch: 38, Average loss:2.3579, LR: 0.001250 Top-1 Accuracy: 46.2960%, Top-5 Accuracy: 74.6440%, Time consumed:208.77s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|███████████▏                                                                            | 38/300 [2:23:07<16:21:38, 224.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 38, Average loss:1.5364, Top-1 Accuracy: 58.9400%, Top-5 Accuracy: 85.6500%, Time consumed:18.05s\n",
      "\n",
      "새로운 최고 top-1 정확도: 58.94%, top-5 정확도: 85.65%\n",
      "새로운 최고 top-5 정확도: 85.65%\n",
      "Accuracy improved (58.19% --> 58.94%). Saving model ...\n",
      "Epoch [39], Batch [50/391], Loss: 1.4967, LR: 0.001250\n",
      "Epoch [39], Batch [100/391], Loss: 3.7140, LR: 0.001250\n",
      "Epoch [39], Batch [150/391], Loss: 1.5554, LR: 0.001250\n",
      "Epoch [39], Batch [200/391], Loss: 1.5292, LR: 0.001250\n",
      "Epoch [39], Batch [250/391], Loss: 1.5450, LR: 0.001250\n",
      "Epoch [39], Batch [300/391], Loss: 3.0604, LR: 0.001250\n",
      "Epoch [39], Batch [350/391], Loss: 3.7978, LR: 0.001250\n",
      "Train set: Epoch: 39, Average loss:2.2536, LR: 0.001250 Top-1 Accuracy: 48.3300%, Top-5 Accuracy: 76.6800%, Time consumed:208.49s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|███████████▍                                                                            | 39/300 [2:26:56<16:24:12, 226.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 39, Average loss:1.5354, Top-1 Accuracy: 58.6200%, Top-5 Accuracy: 85.5800%, Time consumed:21.13s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [40], Batch [50/391], Loss: 3.7494, LR: 0.001250\n",
      "Epoch [40], Batch [100/391], Loss: 1.5229, LR: 0.001250\n",
      "Epoch [40], Batch [150/391], Loss: 1.3945, LR: 0.001250\n",
      "Epoch [40], Batch [200/391], Loss: 2.4413, LR: 0.001250\n",
      "Epoch [40], Batch [250/391], Loss: 3.5146, LR: 0.001250\n",
      "Epoch [40], Batch [300/391], Loss: 1.4510, LR: 0.001250\n",
      "Epoch [40], Batch [350/391], Loss: 1.5364, LR: 0.001250\n",
      "Train set: Epoch: 40, Average loss:2.3297, LR: 0.001250 Top-1 Accuracy: 47.2900%, Top-5 Accuracy: 75.6060%, Time consumed:216.94s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|███████████▋                                                                            | 40/300 [2:30:51<16:31:50, 228.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 40, Average loss:1.5154, Top-1 Accuracy: 59.0400%, Top-5 Accuracy: 85.9400%, Time consumed:17.94s\n",
      "\n",
      "새로운 최고 top-1 정확도: 59.04%, top-5 정확도: 85.94%\n",
      "새로운 최고 top-5 정확도: 85.94%\n",
      "Accuracy improved (58.94% --> 59.04%). Saving model ...\n",
      "Epoch [41], Batch [50/391], Loss: 1.2133, LR: 0.001250\n",
      "Epoch [41], Batch [100/391], Loss: 3.6284, LR: 0.001250\n",
      "Epoch [41], Batch [150/391], Loss: 1.5752, LR: 0.001250\n",
      "Epoch [41], Batch [200/391], Loss: 2.9688, LR: 0.001250\n",
      "Epoch [41], Batch [250/391], Loss: 3.0508, LR: 0.001250\n",
      "Epoch [41], Batch [300/391], Loss: 3.6485, LR: 0.001250\n",
      "Epoch [41], Batch [350/391], Loss: 2.5415, LR: 0.001250\n",
      "Train set: Epoch: 41, Average loss:2.2955, LR: 0.001250 Top-1 Accuracy: 47.5820%, Top-5 Accuracy: 75.8400%, Time consumed:209.11s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████                                                                            | 41/300 [2:34:40<16:28:13, 228.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 41, Average loss:1.5229, Top-1 Accuracy: 59.3900%, Top-5 Accuracy: 85.9100%, Time consumed:19.78s\n",
      "\n",
      "새로운 최고 top-1 정확도: 59.39%, top-5 정확도: 85.91%\n",
      "Accuracy improved (59.04% --> 59.39%). Saving model ...\n",
      "Epoch [42], Batch [50/391], Loss: 1.5688, LR: 0.001250\n",
      "Epoch [42], Batch [100/391], Loss: 1.5062, LR: 0.001250\n",
      "Epoch [42], Batch [150/391], Loss: 1.4924, LR: 0.001250\n",
      "Epoch [42], Batch [200/391], Loss: 1.4275, LR: 0.001250\n",
      "Epoch [42], Batch [250/391], Loss: 1.4726, LR: 0.001250\n",
      "Epoch [42], Batch [300/391], Loss: 1.5097, LR: 0.001250\n",
      "Epoch [42], Batch [350/391], Loss: 3.6192, LR: 0.001250\n",
      "Train set: Epoch: 42, Average loss:2.3540, LR: 0.001250 Top-1 Accuracy: 46.6860%, Top-5 Accuracy: 75.0060%, Time consumed:215.09s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████▎                                                                           | 42/300 [2:38:34<16:30:24, 230.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 42, Average loss:1.5459, Top-1 Accuracy: 58.5600%, Top-5 Accuracy: 85.2700%, Time consumed:18.48s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [43], Batch [50/391], Loss: 1.4116, LR: 0.001250\n",
      "Epoch [43], Batch [100/391], Loss: 3.7983, LR: 0.001250\n",
      "Epoch [43], Batch [150/391], Loss: 3.8831, LR: 0.001250\n",
      "Epoch [43], Batch [200/391], Loss: 2.2455, LR: 0.001250\n",
      "Epoch [43], Batch [250/391], Loss: 3.8433, LR: 0.001250\n",
      "Epoch [43], Batch [300/391], Loss: 1.7486, LR: 0.001250\n",
      "Epoch [43], Batch [350/391], Loss: 1.5260, LR: 0.001250\n",
      "Train set: Epoch: 43, Average loss:2.3066, LR: 0.001250 Top-1 Accuracy: 47.1340%, Top-5 Accuracy: 75.3240%, Time consumed:203.24s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████▌                                                                           | 43/300 [2:42:15<16:15:06, 227.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 43, Average loss:1.5187, Top-1 Accuracy: 59.1600%, Top-5 Accuracy: 85.8200%, Time consumed:18.17s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [44], Batch [50/391], Loss: 1.4910, LR: 0.000625\n",
      "Epoch [44], Batch [100/391], Loss: 2.5559, LR: 0.000625\n",
      "Epoch [44], Batch [150/391], Loss: 1.5619, LR: 0.000625\n",
      "Epoch [44], Batch [200/391], Loss: 2.5369, LR: 0.000625\n",
      "Epoch [44], Batch [250/391], Loss: 3.4332, LR: 0.000625\n",
      "Epoch [44], Batch [300/391], Loss: 3.7665, LR: 0.000625\n",
      "Epoch [44], Batch [350/391], Loss: 2.7318, LR: 0.000625\n",
      "Train set: Epoch: 44, Average loss:2.2572, LR: 0.000625 Top-1 Accuracy: 48.4200%, Top-5 Accuracy: 76.8480%, Time consumed:204.52s\n",
      "Test set: Epoch: 44, Average loss:1.4898, Top-1 Accuracy: 59.6600%, Top-5 Accuracy: 86.2300%, Time consumed:18.29s\n",
      "\n",
      "새로운 최고 top-1 정확도: 59.66%, top-5 정확도: 86.23%\n",
      "새로운 최고 top-5 정확도: 86.23%\n",
      "Accuracy improved (59.39% --> 59.66%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████████████▉                                                                           | 44/300 [2:45:58<16:05:23, 226.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45], Batch [50/391], Loss: 1.3629, LR: 0.000625\n",
      "Epoch [45], Batch [100/391], Loss: 1.5530, LR: 0.000625\n",
      "Epoch [45], Batch [150/391], Loss: 3.8043, LR: 0.000625\n",
      "Epoch [45], Batch [200/391], Loss: 1.3015, LR: 0.000625\n",
      "Epoch [45], Batch [250/391], Loss: 1.4624, LR: 0.000625\n",
      "Epoch [45], Batch [300/391], Loss: 1.4569, LR: 0.000625\n",
      "Epoch [45], Batch [350/391], Loss: 1.5653, LR: 0.000625\n",
      "Train set: Epoch: 45, Average loss:2.2561, LR: 0.000625 Top-1 Accuracy: 48.9900%, Top-5 Accuracy: 77.2960%, Time consumed:208.69s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████████████▏                                                                          | 45/300 [2:49:47<16:04:50, 227.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 45, Average loss:1.4816, Top-1 Accuracy: 59.7100%, Top-5 Accuracy: 86.4600%, Time consumed:19.95s\n",
      "\n",
      "새로운 최고 top-1 정확도: 59.71%, top-5 정확도: 86.46%\n",
      "새로운 최고 top-5 정확도: 86.46%\n",
      "Accuracy improved (59.66% --> 59.71%). Saving model ...\n",
      "Epoch [46], Batch [50/391], Loss: 1.2664, LR: 0.000625\n",
      "Epoch [46], Batch [100/391], Loss: 1.5100, LR: 0.000625\n",
      "Epoch [46], Batch [150/391], Loss: 1.4272, LR: 0.000625\n",
      "Epoch [46], Batch [200/391], Loss: 1.4807, LR: 0.000625\n",
      "Epoch [46], Batch [250/391], Loss: 1.4030, LR: 0.000625\n",
      "Epoch [46], Batch [300/391], Loss: 1.8872, LR: 0.000625\n",
      "Epoch [46], Batch [350/391], Loss: 3.5135, LR: 0.000625\n",
      "Train set: Epoch: 46, Average loss:2.1936, LR: 0.000625 Top-1 Accuracy: 49.3140%, Top-5 Accuracy: 77.0120%, Time consumed:202.42s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████████████▍                                                                          | 46/300 [2:53:28<15:53:22, 225.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 46, Average loss:1.4712, Top-1 Accuracy: 60.4800%, Top-5 Accuracy: 86.3600%, Time consumed:18.38s\n",
      "\n",
      "새로운 최고 top-1 정확도: 60.48%, top-5 정확도: 86.36%\n",
      "Accuracy improved (59.71% --> 60.48%). Saving model ...\n",
      "Epoch [47], Batch [50/391], Loss: 1.4052, LR: 0.000625\n",
      "Epoch [47], Batch [100/391], Loss: 1.2252, LR: 0.000625\n",
      "Epoch [47], Batch [150/391], Loss: 3.4294, LR: 0.000625\n",
      "Epoch [47], Batch [200/391], Loss: 1.3874, LR: 0.000625\n",
      "Epoch [47], Batch [250/391], Loss: 2.9776, LR: 0.000625\n",
      "Epoch [47], Batch [300/391], Loss: 1.3128, LR: 0.000625\n",
      "Epoch [47], Batch [350/391], Loss: 1.5006, LR: 0.000625\n",
      "Train set: Epoch: 47, Average loss:2.2165, LR: 0.000625 Top-1 Accuracy: 49.2000%, Top-5 Accuracy: 76.8940%, Time consumed:203.13s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█████████████▊                                                                          | 47/300 [2:57:09<15:43:52, 223.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 47, Average loss:1.4860, Top-1 Accuracy: 60.3100%, Top-5 Accuracy: 86.3000%, Time consumed:17.53s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [48], Batch [50/391], Loss: 1.7384, LR: 0.000625\n",
      "Epoch [48], Batch [100/391], Loss: 1.4979, LR: 0.000625\n",
      "Epoch [48], Batch [150/391], Loss: 1.4917, LR: 0.000625\n",
      "Epoch [48], Batch [200/391], Loss: 1.3519, LR: 0.000625\n",
      "Epoch [48], Batch [250/391], Loss: 1.5415, LR: 0.000625\n",
      "Epoch [48], Batch [300/391], Loss: 1.4380, LR: 0.000625\n",
      "Epoch [48], Batch [350/391], Loss: 1.6926, LR: 0.000625\n",
      "Train set: Epoch: 48, Average loss:2.3025, LR: 0.000625 Top-1 Accuracy: 48.2500%, Top-5 Accuracy: 76.5980%, Time consumed:206.57s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████████████                                                                          | 48/300 [3:00:53<15:40:42, 223.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 48, Average loss:1.4919, Top-1 Accuracy: 59.9500%, Top-5 Accuracy: 86.3600%, Time consumed:17.70s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [49], Batch [50/391], Loss: 3.0185, LR: 0.000625\n",
      "Epoch [49], Batch [100/391], Loss: 3.0074, LR: 0.000625\n",
      "Epoch [49], Batch [150/391], Loss: 3.6049, LR: 0.000625\n",
      "Epoch [49], Batch [200/391], Loss: 3.0167, LR: 0.000625\n",
      "Epoch [49], Batch [250/391], Loss: 2.6960, LR: 0.000625\n",
      "Epoch [49], Batch [300/391], Loss: 1.9676, LR: 0.000625\n",
      "Epoch [49], Batch [350/391], Loss: 3.4946, LR: 0.000625\n",
      "Train set: Epoch: 49, Average loss:2.2785, LR: 0.000625 Top-1 Accuracy: 48.7000%, Top-5 Accuracy: 76.9460%, Time consumed:205.44s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████████████▎                                                                         | 49/300 [3:04:37<15:36:47, 223.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 49, Average loss:1.4717, Top-1 Accuracy: 60.0900%, Top-5 Accuracy: 86.7700%, Time consumed:18.39s\n",
      "\n",
      "새로운 최고 top-5 정확도: 86.77%\n",
      "EarlyStopping 카운터: 3 / 30\n",
      "Epoch [50], Batch [50/391], Loss: 2.9953, LR: 0.000312\n",
      "Epoch [50], Batch [100/391], Loss: 1.3459, LR: 0.000312\n",
      "Epoch [50], Batch [150/391], Loss: 1.4960, LR: 0.000312\n",
      "Epoch [50], Batch [200/391], Loss: 1.9737, LR: 0.000312\n",
      "Epoch [50], Batch [250/391], Loss: 1.5785, LR: 0.000312\n",
      "Epoch [50], Batch [300/391], Loss: 1.5876, LR: 0.000312\n",
      "Epoch [50], Batch [350/391], Loss: 1.4211, LR: 0.000312\n",
      "Train set: Epoch: 50, Average loss:2.1995, LR: 0.000312 Top-1 Accuracy: 50.1120%, Top-5 Accuracy: 77.9560%, Time consumed:210.50s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████████████▋                                                                         | 50/300 [3:08:25<15:38:17, 225.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 50, Average loss:1.4855, Top-1 Accuracy: 60.0000%, Top-5 Accuracy: 86.6300%, Time consumed:17.61s\n",
      "\n",
      "EarlyStopping 카운터: 4 / 30\n",
      "Epoch [51], Batch [50/391], Loss: 1.5068, LR: 0.000312\n",
      "Epoch [51], Batch [100/391], Loss: 3.7116, LR: 0.000312\n",
      "Epoch [51], Batch [150/391], Loss: 1.4215, LR: 0.000312\n",
      "Epoch [51], Batch [200/391], Loss: 3.5224, LR: 0.000312\n",
      "Epoch [51], Batch [250/391], Loss: 1.3464, LR: 0.000312\n",
      "Epoch [51], Batch [300/391], Loss: 1.3617, LR: 0.000312\n",
      "Epoch [51], Batch [350/391], Loss: 1.3318, LR: 0.000312\n",
      "Train set: Epoch: 51, Average loss:2.1208, LR: 0.000312 Top-1 Accuracy: 51.0240%, Top-5 Accuracy: 78.6680%, Time consumed:203.50s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████████████▉                                                                         | 51/300 [3:12:07<15:30:32, 224.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 51, Average loss:1.4487, Top-1 Accuracy: 60.4700%, Top-5 Accuracy: 86.9000%, Time consumed:18.47s\n",
      "\n",
      "새로운 최고 top-5 정확도: 86.90%\n",
      "EarlyStopping 카운터: 5 / 30\n",
      "Epoch [52], Batch [50/391], Loss: 2.3247, LR: 0.000312\n",
      "Epoch [52], Batch [100/391], Loss: 1.2653, LR: 0.000312\n",
      "Epoch [52], Batch [150/391], Loss: 1.5124, LR: 0.000312\n",
      "Epoch [52], Batch [200/391], Loss: 1.5090, LR: 0.000312\n",
      "Epoch [52], Batch [250/391], Loss: 3.4991, LR: 0.000312\n",
      "Epoch [52], Batch [300/391], Loss: 2.3964, LR: 0.000312\n",
      "Epoch [52], Batch [350/391], Loss: 1.3668, LR: 0.000312\n",
      "Train set: Epoch: 52, Average loss:2.1776, LR: 0.000312 Top-1 Accuracy: 50.2320%, Top-5 Accuracy: 77.9460%, Time consumed:205.41s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████████████▎                                                                        | 52/300 [3:15:51<15:26:47, 224.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 52, Average loss:1.4624, Top-1 Accuracy: 60.6000%, Top-5 Accuracy: 86.8200%, Time consumed:18.65s\n",
      "\n",
      "새로운 최고 top-1 정확도: 60.60%, top-5 정확도: 86.82%\n",
      "Accuracy improved (60.48% --> 60.60%). Saving model ...\n",
      "Epoch [53], Batch [50/391], Loss: 1.3785, LR: 0.000312\n",
      "Epoch [53], Batch [100/391], Loss: 3.5757, LR: 0.000312\n",
      "Epoch [53], Batch [150/391], Loss: 3.4831, LR: 0.000312\n",
      "Epoch [53], Batch [200/391], Loss: 1.5244, LR: 0.000312\n",
      "Epoch [53], Batch [250/391], Loss: 1.3426, LR: 0.000312\n",
      "Epoch [53], Batch [300/391], Loss: 3.4764, LR: 0.000312\n",
      "Epoch [53], Batch [350/391], Loss: 1.3744, LR: 0.000312\n",
      "Train set: Epoch: 53, Average loss:2.2428, LR: 0.000312 Top-1 Accuracy: 49.2260%, Top-5 Accuracy: 76.8080%, Time consumed:203.61s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████████████▌                                                                        | 53/300 [3:19:33<15:19:35, 223.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 53, Average loss:1.4513, Top-1 Accuracy: 60.5500%, Top-5 Accuracy: 86.9800%, Time consumed:17.80s\n",
      "\n",
      "새로운 최고 top-5 정확도: 86.98%\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [54], Batch [50/391], Loss: 3.6821, LR: 0.000312\n",
      "Epoch [54], Batch [100/391], Loss: 1.6094, LR: 0.000312\n",
      "Epoch [54], Batch [150/391], Loss: 2.1907, LR: 0.000312\n",
      "Epoch [54], Batch [200/391], Loss: 1.5059, LR: 0.000312\n",
      "Epoch [54], Batch [250/391], Loss: 1.4381, LR: 0.000312\n",
      "Epoch [54], Batch [300/391], Loss: 3.6796, LR: 0.000312\n",
      "Epoch [54], Batch [350/391], Loss: 3.6376, LR: 0.000312\n",
      "Train set: Epoch: 54, Average loss:2.1497, LR: 0.000312 Top-1 Accuracy: 50.9900%, Top-5 Accuracy: 78.7020%, Time consumed:209.54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████████████▊                                                                        | 54/300 [3:23:20<15:21:15, 224.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 54, Average loss:1.4376, Top-1 Accuracy: 60.8400%, Top-5 Accuracy: 87.0100%, Time consumed:18.06s\n",
      "\n",
      "새로운 최고 top-1 정확도: 60.84%, top-5 정확도: 87.01%\n",
      "새로운 최고 top-5 정확도: 87.01%\n",
      "Accuracy improved (60.60% --> 60.84%). Saving model ...\n",
      "Epoch [55], Batch [50/391], Loss: 3.6378, LR: 0.000312\n",
      "Epoch [55], Batch [100/391], Loss: 3.1297, LR: 0.000312\n",
      "Epoch [55], Batch [150/391], Loss: 2.6362, LR: 0.000312\n",
      "Epoch [55], Batch [200/391], Loss: 1.3845, LR: 0.000312\n",
      "Epoch [55], Batch [250/391], Loss: 1.1730, LR: 0.000312\n",
      "Epoch [55], Batch [300/391], Loss: 1.3757, LR: 0.000312\n",
      "Epoch [55], Batch [350/391], Loss: 3.6185, LR: 0.000312\n",
      "Train set: Epoch: 55, Average loss:2.0909, LR: 0.000312 Top-1 Accuracy: 51.5300%, Top-5 Accuracy: 79.2720%, Time consumed:202.79s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|████████████████▏                                                                       | 55/300 [3:27:01<15:13:13, 223.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 55, Average loss:1.4398, Top-1 Accuracy: 60.7700%, Top-5 Accuracy: 87.0900%, Time consumed:18.40s\n",
      "\n",
      "새로운 최고 top-5 정확도: 87.09%\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [56], Batch [50/391], Loss: 1.3441, LR: 0.000156\n",
      "Epoch [56], Batch [100/391], Loss: 2.1273, LR: 0.000156\n",
      "Epoch [56], Batch [150/391], Loss: 3.6984, LR: 0.000156\n",
      "Epoch [56], Batch [200/391], Loss: 1.3881, LR: 0.000156\n",
      "Epoch [56], Batch [250/391], Loss: 3.1431, LR: 0.000156\n",
      "Epoch [56], Batch [300/391], Loss: 3.2105, LR: 0.000156\n",
      "Epoch [56], Batch [350/391], Loss: 2.7808, LR: 0.000156\n",
      "Train set: Epoch: 56, Average loss:2.1461, LR: 0.000156 Top-1 Accuracy: 50.5240%, Top-5 Accuracy: 78.6740%, Time consumed:205.43s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|████████████████▍                                                                       | 56/300 [3:30:46<15:10:40, 223.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 56, Average loss:1.4499, Top-1 Accuracy: 60.5500%, Top-5 Accuracy: 86.8300%, Time consumed:19.16s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [57], Batch [50/391], Loss: 1.4010, LR: 0.000156\n",
      "Epoch [57], Batch [100/391], Loss: 1.4768, LR: 0.000156\n",
      "Epoch [57], Batch [150/391], Loss: 1.4527, LR: 0.000156\n",
      "Epoch [57], Batch [200/391], Loss: 1.5398, LR: 0.000156\n",
      "Epoch [57], Batch [250/391], Loss: 2.0932, LR: 0.000156\n",
      "Epoch [57], Batch [300/391], Loss: 2.3611, LR: 0.000156\n",
      "Epoch [57], Batch [350/391], Loss: 2.8519, LR: 0.000156\n",
      "Train set: Epoch: 57, Average loss:2.2429, LR: 0.000156 Top-1 Accuracy: 49.4760%, Top-5 Accuracy: 77.4120%, Time consumed:214.27s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|████████████████▋                                                                       | 57/300 [3:34:40<15:18:59, 226.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 57, Average loss:1.4674, Top-1 Accuracy: 60.1300%, Top-5 Accuracy: 86.5900%, Time consumed:19.57s\n",
      "\n",
      "EarlyStopping 카운터: 3 / 30\n",
      "Epoch [58], Batch [50/391], Loss: 3.4415, LR: 0.000156\n",
      "Epoch [58], Batch [100/391], Loss: 1.4458, LR: 0.000156\n",
      "Epoch [58], Batch [150/391], Loss: 1.5504, LR: 0.000156\n",
      "Epoch [58], Batch [200/391], Loss: 3.5659, LR: 0.000156\n",
      "Epoch [58], Batch [250/391], Loss: 3.6162, LR: 0.000156\n",
      "Epoch [58], Batch [300/391], Loss: 1.3992, LR: 0.000156\n",
      "Epoch [58], Batch [350/391], Loss: 2.2089, LR: 0.000156\n",
      "Train set: Epoch: 58, Average loss:2.2265, LR: 0.000156 Top-1 Accuracy: 49.8460%, Top-5 Accuracy: 77.5920%, Time consumed:207.01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█████████████████                                                                       | 58/300 [3:38:26<15:13:38, 226.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 58, Average loss:1.4570, Top-1 Accuracy: 60.8800%, Top-5 Accuracy: 86.7000%, Time consumed:18.43s\n",
      "\n",
      "새로운 최고 top-1 정확도: 60.88%, top-5 정확도: 86.70%\n",
      "Accuracy improved (60.84% --> 60.88%). Saving model ...\n",
      "Epoch [59], Batch [50/391], Loss: 3.5297, LR: 0.000156\n",
      "Epoch [59], Batch [100/391], Loss: 1.2756, LR: 0.000156\n",
      "Epoch [59], Batch [150/391], Loss: 3.4397, LR: 0.000156\n",
      "Epoch [59], Batch [200/391], Loss: 1.8644, LR: 0.000156\n",
      "Epoch [59], Batch [250/391], Loss: 3.5770, LR: 0.000156\n",
      "Epoch [59], Batch [300/391], Loss: 1.5327, LR: 0.000156\n",
      "Epoch [59], Batch [350/391], Loss: 1.9783, LR: 0.000156\n",
      "Train set: Epoch: 59, Average loss:2.1839, LR: 0.000156 Top-1 Accuracy: 50.6460%, Top-5 Accuracy: 78.8440%, Time consumed:204.63s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█████████████████▎                                                                      | 59/300 [3:42:08<15:05:04, 225.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 59, Average loss:1.4585, Top-1 Accuracy: 60.7300%, Top-5 Accuracy: 86.9200%, Time consumed:17.91s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [60], Batch [50/391], Loss: 3.1523, LR: 0.000156\n",
      "Epoch [60], Batch [100/391], Loss: 1.3882, LR: 0.000156\n",
      "Epoch [60], Batch [150/391], Loss: 1.4139, LR: 0.000156\n",
      "Epoch [60], Batch [200/391], Loss: 1.5405, LR: 0.000156\n",
      "Epoch [60], Batch [250/391], Loss: 1.9552, LR: 0.000156\n",
      "Epoch [60], Batch [300/391], Loss: 1.5240, LR: 0.000156\n",
      "Epoch [60], Batch [350/391], Loss: 3.5876, LR: 0.000156\n",
      "Train set: Epoch: 60, Average loss:2.2294, LR: 0.000156 Top-1 Accuracy: 49.4060%, Top-5 Accuracy: 77.1520%, Time consumed:203.44s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█████████████████▌                                                                      | 60/300 [3:45:50<14:57:13, 224.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 60, Average loss:1.4445, Top-1 Accuracy: 60.8600%, Top-5 Accuracy: 87.0000%, Time consumed:18.46s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [61], Batch [50/391], Loss: 2.8101, LR: 0.000156\n",
      "Epoch [61], Batch [100/391], Loss: 1.3276, LR: 0.000156\n",
      "Epoch [61], Batch [150/391], Loss: 1.3173, LR: 0.000156\n",
      "Epoch [61], Batch [200/391], Loss: 3.8142, LR: 0.000156\n",
      "Epoch [61], Batch [250/391], Loss: 1.5295, LR: 0.000156\n",
      "Epoch [61], Batch [300/391], Loss: 1.5628, LR: 0.000156\n",
      "Epoch [61], Batch [350/391], Loss: 1.3698, LR: 0.000156\n",
      "Train set: Epoch: 61, Average loss:2.1650, LR: 0.000156 Top-1 Accuracy: 50.4900%, Top-5 Accuracy: 78.3740%, Time consumed:205.98s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█████████████████▉                                                                      | 61/300 [3:49:35<14:54:18, 224.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 61, Average loss:1.4485, Top-1 Accuracy: 60.7300%, Top-5 Accuracy: 87.0000%, Time consumed:19.00s\n",
      "\n",
      "EarlyStopping 카운터: 3 / 30\n",
      "Epoch [62], Batch [50/391], Loss: 3.3301, LR: 0.000078\n",
      "Epoch [62], Batch [100/391], Loss: 1.4008, LR: 0.000078\n",
      "Epoch [62], Batch [150/391], Loss: 1.4837, LR: 0.000078\n",
      "Epoch [62], Batch [200/391], Loss: 2.1693, LR: 0.000078\n",
      "Epoch [62], Batch [250/391], Loss: 3.7477, LR: 0.000078\n",
      "Epoch [62], Batch [300/391], Loss: 1.5104, LR: 0.000078\n",
      "Epoch [62], Batch [350/391], Loss: 1.4439, LR: 0.000078\n",
      "Train set: Epoch: 62, Average loss:2.1678, LR: 0.000078 Top-1 Accuracy: 50.5060%, Top-5 Accuracy: 78.2320%, Time consumed:204.92s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██████████████████▏                                                                     | 62/300 [3:53:18<14:48:50, 224.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 62, Average loss:1.4388, Top-1 Accuracy: 60.7800%, Top-5 Accuracy: 87.2700%, Time consumed:18.13s\n",
      "\n",
      "새로운 최고 top-5 정확도: 87.27%\n",
      "EarlyStopping 카운터: 4 / 30\n",
      "Epoch [63], Batch [50/391], Loss: 1.6701, LR: 0.000078\n",
      "Epoch [63], Batch [100/391], Loss: 3.0812, LR: 0.000078\n",
      "Epoch [63], Batch [150/391], Loss: 1.2962, LR: 0.000078\n",
      "Epoch [63], Batch [200/391], Loss: 2.2973, LR: 0.000078\n",
      "Epoch [63], Batch [250/391], Loss: 1.4260, LR: 0.000078\n",
      "Epoch [63], Batch [300/391], Loss: 1.4875, LR: 0.000078\n",
      "Epoch [63], Batch [350/391], Loss: 1.4222, LR: 0.000078\n",
      "Train set: Epoch: 63, Average loss:2.1942, LR: 0.000078 Top-1 Accuracy: 49.9860%, Top-5 Accuracy: 77.7000%, Time consumed:215.10s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██████████████████▍                                                                     | 63/300 [3:57:11<14:55:42, 226.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 63, Average loss:1.4833, Top-1 Accuracy: 59.7300%, Top-5 Accuracy: 86.6100%, Time consumed:17.92s\n",
      "\n",
      "EarlyStopping 카운터: 5 / 30\n",
      "Epoch [64], Batch [50/391], Loss: 3.7736, LR: 0.000078\n",
      "Epoch [64], Batch [100/391], Loss: 2.7450, LR: 0.000078\n",
      "Epoch [64], Batch [150/391], Loss: 3.7729, LR: 0.000078\n",
      "Epoch [64], Batch [200/391], Loss: 1.4651, LR: 0.000078\n",
      "Epoch [64], Batch [250/391], Loss: 3.1236, LR: 0.000078\n",
      "Epoch [64], Batch [300/391], Loss: 1.5403, LR: 0.000078\n",
      "Epoch [64], Batch [350/391], Loss: 3.6566, LR: 0.000078\n",
      "Train set: Epoch: 64, Average loss:2.1816, LR: 0.000078 Top-1 Accuracy: 50.9140%, Top-5 Accuracy: 78.4960%, Time consumed:202.38s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██████████████████▊                                                                     | 64/300 [4:00:52<14:44:56, 224.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 64, Average loss:1.4299, Top-1 Accuracy: 61.0400%, Top-5 Accuracy: 87.1000%, Time consumed:18.32s\n",
      "\n",
      "새로운 최고 top-1 정확도: 61.04%, top-5 정확도: 87.10%\n",
      "Accuracy improved (60.88% --> 61.04%). Saving model ...\n",
      "Epoch [65], Batch [50/391], Loss: 1.4229, LR: 0.000078\n",
      "Epoch [65], Batch [100/391], Loss: 3.4291, LR: 0.000078\n",
      "Epoch [65], Batch [150/391], Loss: 3.9011, LR: 0.000078\n",
      "Epoch [65], Batch [200/391], Loss: 1.4501, LR: 0.000078\n",
      "Epoch [65], Batch [250/391], Loss: 1.4333, LR: 0.000078\n",
      "Epoch [65], Batch [300/391], Loss: 3.7849, LR: 0.000078\n",
      "Epoch [65], Batch [350/391], Loss: 3.5741, LR: 0.000078\n",
      "Train set: Epoch: 65, Average loss:2.2503, LR: 0.000078 Top-1 Accuracy: 49.1520%, Top-5 Accuracy: 76.7840%, Time consumed:201.91s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|███████████████████                                                                     | 65/300 [4:04:32<14:35:12, 223.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 65, Average loss:1.4326, Top-1 Accuracy: 60.6000%, Top-5 Accuracy: 86.9400%, Time consumed:17.97s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [66], Batch [50/391], Loss: 1.6064, LR: 0.000078\n",
      "Epoch [66], Batch [100/391], Loss: 2.8496, LR: 0.000078\n",
      "Epoch [66], Batch [150/391], Loss: 3.6001, LR: 0.000078\n",
      "Epoch [66], Batch [200/391], Loss: 1.5600, LR: 0.000078\n",
      "Epoch [66], Batch [250/391], Loss: 1.3980, LR: 0.000078\n",
      "Epoch [66], Batch [300/391], Loss: 3.3689, LR: 0.000078\n",
      "Epoch [66], Batch [350/391], Loss: 1.6017, LR: 0.000078\n",
      "Train set: Epoch: 66, Average loss:2.2283, LR: 0.000078 Top-1 Accuracy: 49.3660%, Top-5 Accuracy: 77.4040%, Time consumed:210.47s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|███████████████████▎                                                                    | 66/300 [4:08:20<14:37:09, 224.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 66, Average loss:1.4456, Top-1 Accuracy: 60.8000%, Top-5 Accuracy: 87.1300%, Time consumed:17.84s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [67], Batch [50/391], Loss: 3.5304, LR: 0.000078\n",
      "Epoch [67], Batch [100/391], Loss: 2.3275, LR: 0.000078\n",
      "Epoch [67], Batch [150/391], Loss: 1.2713, LR: 0.000078\n",
      "Epoch [67], Batch [200/391], Loss: 1.3799, LR: 0.000078\n",
      "Epoch [67], Batch [250/391], Loss: 1.5587, LR: 0.000078\n",
      "Epoch [67], Batch [300/391], Loss: 2.9190, LR: 0.000078\n",
      "Epoch [67], Batch [350/391], Loss: 3.7685, LR: 0.000078\n",
      "Train set: Epoch: 67, Average loss:2.1041, LR: 0.000078 Top-1 Accuracy: 51.6540%, Top-5 Accuracy: 79.3660%, Time consumed:202.51s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|███████████████████▋                                                                    | 67/300 [4:12:01<14:28:35, 223.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 67, Average loss:1.4373, Top-1 Accuracy: 60.9600%, Top-5 Accuracy: 86.9800%, Time consumed:18.26s\n",
      "\n",
      "EarlyStopping 카운터: 3 / 30\n",
      "Epoch [68], Batch [50/391], Loss: 1.4590, LR: 0.000039\n",
      "Epoch [68], Batch [100/391], Loss: 1.3883, LR: 0.000039\n",
      "Epoch [68], Batch [150/391], Loss: 1.5110, LR: 0.000039\n",
      "Epoch [68], Batch [200/391], Loss: 3.4627, LR: 0.000039\n",
      "Epoch [68], Batch [250/391], Loss: 1.4599, LR: 0.000039\n",
      "Epoch [68], Batch [300/391], Loss: 1.4407, LR: 0.000039\n",
      "Epoch [68], Batch [350/391], Loss: 2.1888, LR: 0.000039\n",
      "Train set: Epoch: 68, Average loss:2.2420, LR: 0.000039 Top-1 Accuracy: 49.5380%, Top-5 Accuracy: 77.0920%, Time consumed:205.66s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|███████████████████▉                                                                    | 68/300 [4:15:44<14:24:43, 223.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 68, Average loss:1.4603, Top-1 Accuracy: 60.5200%, Top-5 Accuracy: 86.9400%, Time consumed:17.88s\n",
      "\n",
      "EarlyStopping 카운터: 4 / 30\n",
      "Epoch [69], Batch [50/391], Loss: 3.6682, LR: 0.000039\n",
      "Epoch [69], Batch [100/391], Loss: 3.4232, LR: 0.000039\n",
      "Epoch [69], Batch [150/391], Loss: 3.4561, LR: 0.000039\n",
      "Epoch [69], Batch [200/391], Loss: 2.5446, LR: 0.000039\n",
      "Epoch [69], Batch [250/391], Loss: 2.5069, LR: 0.000039\n",
      "Epoch [69], Batch [300/391], Loss: 1.4500, LR: 0.000039\n",
      "Epoch [69], Batch [350/391], Loss: 1.4381, LR: 0.000039\n",
      "Train set: Epoch: 69, Average loss:2.2164, LR: 0.000039 Top-1 Accuracy: 49.9640%, Top-5 Accuracy: 78.0020%, Time consumed:202.21s\n",
      "Test set: Epoch: 69, Average loss:1.4295, Top-1 Accuracy: 61.0800%, Top-5 Accuracy: 87.1800%, Time consumed:18.25s\n",
      "\n",
      "새로운 최고 top-1 정확도: 61.08%, top-5 정확도: 87.18%\n",
      "Accuracy improved (61.04% --> 61.08%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|████████████████████▏                                                                   | 69/300 [4:19:25<14:17:34, 222.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [70], Batch [50/391], Loss: 1.4477, LR: 0.000039\n",
      "Epoch [70], Batch [100/391], Loss: 1.3727, LR: 0.000039\n",
      "Epoch [70], Batch [150/391], Loss: 1.6350, LR: 0.000039\n",
      "Epoch [70], Batch [200/391], Loss: 1.3261, LR: 0.000039\n",
      "Epoch [70], Batch [250/391], Loss: 3.0861, LR: 0.000039\n",
      "Epoch [70], Batch [300/391], Loss: 1.5002, LR: 0.000039\n",
      "Epoch [70], Batch [350/391], Loss: 3.0550, LR: 0.000039\n",
      "Train set: Epoch: 70, Average loss:2.2372, LR: 0.000039 Top-1 Accuracy: 49.4380%, Top-5 Accuracy: 76.6580%, Time consumed:203.34s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|████████████████████▌                                                                   | 70/300 [4:23:07<14:12:29, 222.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 70, Average loss:1.4602, Top-1 Accuracy: 60.4000%, Top-5 Accuracy: 86.8700%, Time consumed:18.19s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [71], Batch [50/391], Loss: 3.6228, LR: 0.000039\n",
      "Epoch [71], Batch [100/391], Loss: 1.3050, LR: 0.000039\n",
      "Epoch [71], Batch [150/391], Loss: 1.5434, LR: 0.000039\n",
      "Epoch [71], Batch [200/391], Loss: 1.2708, LR: 0.000039\n",
      "Epoch [71], Batch [250/391], Loss: 2.9493, LR: 0.000039\n",
      "Epoch [71], Batch [300/391], Loss: 3.4898, LR: 0.000039\n",
      "Epoch [71], Batch [350/391], Loss: 4.0518, LR: 0.000039\n",
      "Train set: Epoch: 71, Average loss:2.2168, LR: 0.000039 Top-1 Accuracy: 49.7640%, Top-5 Accuracy: 77.4080%, Time consumed:204.01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|████████████████████▊                                                                   | 71/300 [4:26:49<14:08:24, 222.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 71, Average loss:1.4428, Top-1 Accuracy: 60.9200%, Top-5 Accuracy: 86.9700%, Time consumed:18.04s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [72], Batch [50/391], Loss: 1.3864, LR: 0.000039\n",
      "Epoch [72], Batch [100/391], Loss: 3.6067, LR: 0.000039\n",
      "Epoch [72], Batch [150/391], Loss: 1.7019, LR: 0.000039\n",
      "Epoch [72], Batch [200/391], Loss: 1.6348, LR: 0.000039\n",
      "Epoch [72], Batch [250/391], Loss: 3.0623, LR: 0.000039\n",
      "Epoch [72], Batch [300/391], Loss: 1.2631, LR: 0.000039\n",
      "Epoch [72], Batch [350/391], Loss: 1.5358, LR: 0.000039\n",
      "Train set: Epoch: 72, Average loss:2.2346, LR: 0.000039 Top-1 Accuracy: 49.5700%, Top-5 Accuracy: 77.1980%, Time consumed:204.30s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|█████████████████████                                                                   | 72/300 [4:30:32<14:06:05, 222.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 72, Average loss:1.4478, Top-1 Accuracy: 61.0100%, Top-5 Accuracy: 87.0500%, Time consumed:19.19s\n",
      "\n",
      "EarlyStopping 카운터: 3 / 30\n",
      "Epoch [73], Batch [50/391], Loss: 1.5651, LR: 0.000039\n",
      "Epoch [73], Batch [100/391], Loss: 1.4249, LR: 0.000039\n",
      "Epoch [73], Batch [150/391], Loss: 3.5069, LR: 0.000039\n",
      "Epoch [73], Batch [200/391], Loss: 1.2886, LR: 0.000039\n",
      "Epoch [73], Batch [250/391], Loss: 2.1012, LR: 0.000039\n",
      "Epoch [73], Batch [300/391], Loss: 1.4810, LR: 0.000039\n",
      "Epoch [73], Batch [350/391], Loss: 2.1890, LR: 0.000039\n",
      "Train set: Epoch: 73, Average loss:2.1677, LR: 0.000039 Top-1 Accuracy: 50.6760%, Top-5 Accuracy: 78.0420%, Time consumed:212.56s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|█████████████████████▍                                                                  | 73/300 [4:34:24<14:12:48, 225.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 73, Average loss:1.4528, Top-1 Accuracy: 60.8300%, Top-5 Accuracy: 86.8800%, Time consumed:19.29s\n",
      "\n",
      "EarlyStopping 카운터: 4 / 30\n",
      "Epoch [74], Batch [50/391], Loss: 1.3770, LR: 0.000020\n",
      "Epoch [74], Batch [100/391], Loss: 3.4133, LR: 0.000020\n",
      "Epoch [74], Batch [150/391], Loss: 3.4858, LR: 0.000020\n",
      "Epoch [74], Batch [200/391], Loss: 3.5494, LR: 0.000020\n",
      "Epoch [74], Batch [250/391], Loss: 1.4261, LR: 0.000020\n",
      "Epoch [74], Batch [300/391], Loss: 1.4752, LR: 0.000020\n",
      "Epoch [74], Batch [350/391], Loss: 3.7635, LR: 0.000020\n",
      "Train set: Epoch: 74, Average loss:2.1728, LR: 0.000020 Top-1 Accuracy: 50.9180%, Top-5 Accuracy: 78.6040%, Time consumed:207.89s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|█████████████████████▋                                                                  | 74/300 [4:38:11<14:10:21, 225.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 74, Average loss:1.4343, Top-1 Accuracy: 61.1200%, Top-5 Accuracy: 87.1100%, Time consumed:18.46s\n",
      "\n",
      "새로운 최고 top-1 정확도: 61.12%, top-5 정확도: 87.11%\n",
      "Accuracy improved (61.08% --> 61.12%). Saving model ...\n",
      "Epoch [75], Batch [50/391], Loss: 1.8177, LR: 0.000020\n",
      "Epoch [75], Batch [100/391], Loss: 1.3860, LR: 0.000020\n",
      "Epoch [75], Batch [150/391], Loss: 1.2474, LR: 0.000020\n",
      "Epoch [75], Batch [200/391], Loss: 3.3917, LR: 0.000020\n",
      "Epoch [75], Batch [250/391], Loss: 1.3970, LR: 0.000020\n",
      "Epoch [75], Batch [300/391], Loss: 1.4032, LR: 0.000020\n",
      "Epoch [75], Batch [350/391], Loss: 1.1698, LR: 0.000020\n",
      "Train set: Epoch: 75, Average loss:2.1775, LR: 0.000020 Top-1 Accuracy: 50.1540%, Top-5 Accuracy: 77.4040%, Time consumed:206.20s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██████████████████████                                                                  | 75/300 [4:41:55<14:04:51, 225.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 75, Average loss:1.4508, Top-1 Accuracy: 61.0500%, Top-5 Accuracy: 86.7000%, Time consumed:18.01s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [76], Batch [50/391], Loss: 1.7056, LR: 0.000020\n",
      "Epoch [76], Batch [100/391], Loss: 1.4274, LR: 0.000020\n",
      "Epoch [76], Batch [150/391], Loss: 3.5899, LR: 0.000020\n",
      "Epoch [76], Batch [200/391], Loss: 1.2806, LR: 0.000020\n",
      "Epoch [76], Batch [250/391], Loss: 4.0545, LR: 0.000020\n",
      "Epoch [76], Batch [300/391], Loss: 1.4494, LR: 0.000020\n",
      "Epoch [76], Batch [350/391], Loss: 3.6745, LR: 0.000020\n",
      "Train set: Epoch: 76, Average loss:2.2488, LR: 0.000020 Top-1 Accuracy: 49.4800%, Top-5 Accuracy: 76.9720%, Time consumed:202.16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██████████████████████▎                                                                 | 76/300 [4:45:36<13:56:54, 224.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 76, Average loss:1.4487, Top-1 Accuracy: 60.8600%, Top-5 Accuracy: 87.0300%, Time consumed:19.36s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [77], Batch [50/391], Loss: 2.3064, LR: 0.000020\n",
      "Epoch [77], Batch [100/391], Loss: 1.2626, LR: 0.000020\n",
      "Epoch [77], Batch [150/391], Loss: 2.6073, LR: 0.000020\n",
      "Epoch [77], Batch [200/391], Loss: 1.6602, LR: 0.000020\n",
      "Epoch [77], Batch [250/391], Loss: 1.2463, LR: 0.000020\n",
      "Epoch [77], Batch [300/391], Loss: 2.7575, LR: 0.000020\n",
      "Epoch [77], Batch [350/391], Loss: 1.8575, LR: 0.000020\n",
      "Train set: Epoch: 77, Average loss:2.2006, LR: 0.000020 Top-1 Accuracy: 50.1900%, Top-5 Accuracy: 77.8520%, Time consumed:204.69s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██████████████████████▌                                                                 | 77/300 [4:49:19<13:51:40, 223.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 77, Average loss:1.4440, Top-1 Accuracy: 60.7200%, Top-5 Accuracy: 86.9100%, Time consumed:18.13s\n",
      "\n",
      "EarlyStopping 카운터: 3 / 30\n",
      "Epoch [78], Batch [50/391], Loss: 1.5649, LR: 0.000020\n",
      "Epoch [78], Batch [100/391], Loss: 2.4684, LR: 0.000020\n",
      "Epoch [78], Batch [150/391], Loss: 1.3049, LR: 0.000020\n",
      "Epoch [78], Batch [200/391], Loss: 3.2822, LR: 0.000020\n",
      "Epoch [78], Batch [250/391], Loss: 2.8031, LR: 0.000020\n",
      "Epoch [78], Batch [300/391], Loss: 1.2456, LR: 0.000020\n",
      "Epoch [78], Batch [350/391], Loss: 1.5390, LR: 0.000020\n",
      "Train set: Epoch: 78, Average loss:2.2388, LR: 0.000020 Top-1 Accuracy: 50.1520%, Top-5 Accuracy: 78.1260%, Time consumed:202.43s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██████████████████████▉                                                                 | 78/300 [4:52:59<13:43:41, 222.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 78, Average loss:1.4457, Top-1 Accuracy: 61.0300%, Top-5 Accuracy: 87.2300%, Time consumed:17.51s\n",
      "\n",
      "EarlyStopping 카운터: 4 / 30\n",
      "Epoch [79], Batch [50/391], Loss: 1.2948, LR: 0.000020\n",
      "Epoch [79], Batch [100/391], Loss: 3.8110, LR: 0.000020\n",
      "Epoch [79], Batch [150/391], Loss: 1.3950, LR: 0.000020\n",
      "Epoch [79], Batch [200/391], Loss: 1.3064, LR: 0.000020\n",
      "Epoch [79], Batch [250/391], Loss: 1.3811, LR: 0.000020\n",
      "Epoch [79], Batch [300/391], Loss: 1.4351, LR: 0.000020\n",
      "Epoch [79], Batch [350/391], Loss: 1.3623, LR: 0.000020\n",
      "Train set: Epoch: 79, Average loss:2.1956, LR: 0.000020 Top-1 Accuracy: 50.2140%, Top-5 Accuracy: 77.9900%, Time consumed:203.67s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|███████████████████████▏                                                                | 79/300 [4:56:41<13:39:06, 222.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 79, Average loss:1.4622, Top-1 Accuracy: 60.5600%, Top-5 Accuracy: 86.7700%, Time consumed:18.15s\n",
      "\n",
      "EarlyStopping 카운터: 5 / 30\n",
      "Epoch [80], Batch [50/391], Loss: 3.4493, LR: 0.000010\n",
      "Epoch [80], Batch [100/391], Loss: 3.6585, LR: 0.000010\n",
      "Epoch [80], Batch [150/391], Loss: 1.2212, LR: 0.000010\n",
      "Epoch [80], Batch [200/391], Loss: 1.2806, LR: 0.000010\n",
      "Epoch [80], Batch [250/391], Loss: 3.7347, LR: 0.000010\n",
      "Epoch [80], Batch [300/391], Loss: 3.5027, LR: 0.000010\n",
      "Epoch [80], Batch [350/391], Loss: 1.4065, LR: 0.000010\n",
      "Train set: Epoch: 80, Average loss:2.2000, LR: 0.000010 Top-1 Accuracy: 50.3100%, Top-5 Accuracy: 77.6160%, Time consumed:205.68s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|███████████████████████▍                                                                | 80/300 [5:00:24<13:36:18, 222.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 80, Average loss:1.4491, Top-1 Accuracy: 60.7900%, Top-5 Accuracy: 87.0200%, Time consumed:17.51s\n",
      "\n",
      "EarlyStopping 카운터: 6 / 30\n",
      "Epoch [81], Batch [50/391], Loss: 1.3332, LR: 0.000010\n",
      "Epoch [81], Batch [100/391], Loss: 1.5323, LR: 0.000010\n",
      "Epoch [81], Batch [150/391], Loss: 1.3563, LR: 0.000010\n",
      "Epoch [81], Batch [200/391], Loss: 1.2723, LR: 0.000010\n",
      "Epoch [81], Batch [250/391], Loss: 3.7628, LR: 0.000010\n",
      "Epoch [81], Batch [300/391], Loss: 1.4123, LR: 0.000010\n",
      "Epoch [81], Batch [350/391], Loss: 3.4926, LR: 0.000010\n",
      "Train set: Epoch: 81, Average loss:2.2121, LR: 0.000010 Top-1 Accuracy: 49.8240%, Top-5 Accuracy: 77.3320%, Time consumed:203.73s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|███████████████████████▊                                                                | 81/300 [5:04:06<13:32:05, 222.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 81, Average loss:1.4423, Top-1 Accuracy: 60.7500%, Top-5 Accuracy: 86.9700%, Time consumed:18.43s\n",
      "\n",
      "EarlyStopping 카운터: 7 / 30\n",
      "Epoch [82], Batch [50/391], Loss: 3.5797, LR: 0.000010\n",
      "Epoch [82], Batch [100/391], Loss: 1.4701, LR: 0.000010\n",
      "Epoch [82], Batch [150/391], Loss: 1.1995, LR: 0.000010\n",
      "Epoch [82], Batch [200/391], Loss: 3.5687, LR: 0.000010\n",
      "Epoch [82], Batch [250/391], Loss: 1.3960, LR: 0.000010\n",
      "Epoch [82], Batch [300/391], Loss: 1.5885, LR: 0.000010\n",
      "Epoch [82], Batch [350/391], Loss: 2.5539, LR: 0.000010\n",
      "Train set: Epoch: 82, Average loss:2.1751, LR: 0.000010 Top-1 Accuracy: 50.5080%, Top-5 Accuracy: 78.0680%, Time consumed:207.21s\n",
      "Test set: Epoch: 82, Average loss:1.4254, Top-1 Accuracy: 61.1600%, Top-5 Accuracy: 87.1900%, Time consumed:18.96s\n",
      "\n",
      "새로운 최고 top-1 정확도: 61.16%, top-5 정확도: 87.19%\n",
      "Accuracy improved (61.12% --> 61.16%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|████████████████████████                                                                | 82/300 [5:07:53<13:32:36, 223.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [83], Batch [50/391], Loss: 3.5349, LR: 0.000010\n",
      "Epoch [83], Batch [100/391], Loss: 1.4927, LR: 0.000010\n",
      "Epoch [83], Batch [150/391], Loss: 1.3201, LR: 0.000010\n",
      "Epoch [83], Batch [200/391], Loss: 3.0207, LR: 0.000010\n",
      "Epoch [83], Batch [250/391], Loss: 2.6609, LR: 0.000010\n",
      "Epoch [83], Batch [300/391], Loss: 1.3019, LR: 0.000010\n",
      "Epoch [83], Batch [350/391], Loss: 1.4015, LR: 0.000010\n",
      "Train set: Epoch: 83, Average loss:2.1312, LR: 0.000010 Top-1 Accuracy: 51.5960%, Top-5 Accuracy: 79.2680%, Time consumed:203.73s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|████████████████████████▎                                                               | 83/300 [5:11:35<13:27:50, 223.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 83, Average loss:1.4704, Top-1 Accuracy: 60.4100%, Top-5 Accuracy: 86.6100%, Time consumed:18.96s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [84], Batch [50/391], Loss: 3.3994, LR: 0.000010\n",
      "Epoch [84], Batch [100/391], Loss: 3.4654, LR: 0.000010\n",
      "Epoch [84], Batch [150/391], Loss: 1.1928, LR: 0.000010\n",
      "Epoch [84], Batch [200/391], Loss: 3.3106, LR: 0.000010\n",
      "Epoch [84], Batch [250/391], Loss: 1.4580, LR: 0.000010\n",
      "Epoch [84], Batch [300/391], Loss: 3.5406, LR: 0.000010\n",
      "Epoch [84], Batch [350/391], Loss: 1.3156, LR: 0.000010\n",
      "Train set: Epoch: 84, Average loss:2.2209, LR: 0.000010 Top-1 Accuracy: 49.3980%, Top-5 Accuracy: 76.6940%, Time consumed:206.24s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|████████████████████████▋                                                               | 84/300 [5:15:20<13:25:15, 223.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 84, Average loss:1.4426, Top-1 Accuracy: 60.6600%, Top-5 Accuracy: 86.8500%, Time consumed:18.17s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [85], Batch [50/391], Loss: 2.3409, LR: 0.000010\n",
      "Epoch [85], Batch [100/391], Loss: 1.7060, LR: 0.000010\n",
      "Epoch [85], Batch [150/391], Loss: 1.5988, LR: 0.000010\n",
      "Epoch [85], Batch [200/391], Loss: 2.3605, LR: 0.000010\n",
      "Epoch [85], Batch [250/391], Loss: 1.3038, LR: 0.000010\n",
      "Epoch [85], Batch [300/391], Loss: 3.1685, LR: 0.000010\n",
      "Epoch [85], Batch [350/391], Loss: 1.3726, LR: 0.000010\n",
      "Train set: Epoch: 85, Average loss:2.2163, LR: 0.000010 Top-1 Accuracy: 50.0860%, Top-5 Accuracy: 77.9200%, Time consumed:205.88s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|████████████████████████▉                                                               | 85/300 [5:19:06<13:23:38, 224.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 85, Average loss:1.4306, Top-1 Accuracy: 61.1900%, Top-5 Accuracy: 87.1400%, Time consumed:19.61s\n",
      "\n",
      "새로운 최고 top-1 정확도: 61.19%, top-5 정확도: 87.14%\n",
      "Accuracy improved (61.16% --> 61.19%). Saving model ...\n",
      "Epoch [86], Batch [50/391], Loss: 2.1643, LR: 0.000005\n",
      "Epoch [86], Batch [100/391], Loss: 2.6116, LR: 0.000005\n",
      "Epoch [86], Batch [150/391], Loss: 1.5398, LR: 0.000005\n",
      "Epoch [86], Batch [200/391], Loss: 1.3659, LR: 0.000005\n",
      "Epoch [86], Batch [250/391], Loss: 1.3862, LR: 0.000005\n",
      "Epoch [86], Batch [300/391], Loss: 1.2458, LR: 0.000005\n",
      "Epoch [86], Batch [350/391], Loss: 1.4819, LR: 0.000005\n",
      "Train set: Epoch: 86, Average loss:2.2193, LR: 0.000005 Top-1 Accuracy: 49.9520%, Top-5 Accuracy: 77.6420%, Time consumed:205.98s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|█████████████████████████▏                                                              | 86/300 [5:22:50<13:19:48, 224.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 86, Average loss:1.4454, Top-1 Accuracy: 60.9300%, Top-5 Accuracy: 86.9300%, Time consumed:18.19s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [87], Batch [50/391], Loss: 3.1499, LR: 0.000005\n",
      "Epoch [87], Batch [100/391], Loss: 1.5690, LR: 0.000005\n",
      "Epoch [87], Batch [150/391], Loss: 1.5760, LR: 0.000005\n",
      "Epoch [87], Batch [200/391], Loss: 2.5353, LR: 0.000005\n",
      "Epoch [87], Batch [250/391], Loss: 3.7304, LR: 0.000005\n",
      "Epoch [87], Batch [300/391], Loss: 3.5516, LR: 0.000005\n",
      "Epoch [87], Batch [350/391], Loss: 1.5980, LR: 0.000005\n",
      "Train set: Epoch: 87, Average loss:2.2455, LR: 0.000005 Top-1 Accuracy: 49.6560%, Top-5 Accuracy: 77.7420%, Time consumed:204.46s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|█████████████████████████▌                                                              | 87/300 [5:26:33<13:14:45, 223.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 87, Average loss:1.4344, Top-1 Accuracy: 61.3100%, Top-5 Accuracy: 87.2700%, Time consumed:18.41s\n",
      "\n",
      "새로운 최고 top-1 정확도: 61.31%, top-5 정확도: 87.27%\n",
      "Accuracy improved (61.19% --> 61.31%). Saving model ...\n",
      "Epoch [88], Batch [50/391], Loss: 2.5823, LR: 0.000005\n",
      "Epoch [88], Batch [100/391], Loss: 1.2411, LR: 0.000005\n",
      "Epoch [88], Batch [150/391], Loss: 1.4671, LR: 0.000005\n",
      "Epoch [88], Batch [200/391], Loss: 1.4365, LR: 0.000005\n",
      "Epoch [88], Batch [250/391], Loss: 1.3899, LR: 0.000005\n",
      "Epoch [88], Batch [300/391], Loss: 1.4816, LR: 0.000005\n",
      "Epoch [88], Batch [350/391], Loss: 2.2265, LR: 0.000005\n",
      "Train set: Epoch: 88, Average loss:2.1466, LR: 0.000005 Top-1 Accuracy: 51.2080%, Top-5 Accuracy: 78.8280%, Time consumed:206.08s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|█████████████████████████▊                                                              | 88/300 [5:30:18<13:12:40, 224.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 88, Average loss:1.4529, Top-1 Accuracy: 60.8400%, Top-5 Accuracy: 86.8400%, Time consumed:19.33s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [89], Batch [50/391], Loss: 2.2644, LR: 0.000005\n",
      "Epoch [89], Batch [100/391], Loss: 1.5586, LR: 0.000005\n",
      "Epoch [89], Batch [150/391], Loss: 1.3384, LR: 0.000005\n",
      "Epoch [89], Batch [200/391], Loss: 1.9074, LR: 0.000005\n",
      "Epoch [89], Batch [250/391], Loss: 1.4527, LR: 0.000005\n",
      "Epoch [89], Batch [300/391], Loss: 1.5208, LR: 0.000005\n",
      "Epoch [89], Batch [350/391], Loss: 2.3071, LR: 0.000005\n",
      "Train set: Epoch: 89, Average loss:2.1687, LR: 0.000005 Top-1 Accuracy: 50.8800%, Top-5 Accuracy: 78.2120%, Time consumed:202.77s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██████████████████████████                                                              | 89/300 [5:34:01<13:06:54, 223.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 89, Average loss:1.4337, Top-1 Accuracy: 61.2800%, Top-5 Accuracy: 87.1000%, Time consumed:19.63s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [90], Batch [50/391], Loss: 3.6845, LR: 0.000005\n",
      "Epoch [90], Batch [100/391], Loss: 1.1950, LR: 0.000005\n",
      "Epoch [90], Batch [150/391], Loss: 1.3635, LR: 0.000005\n",
      "Epoch [90], Batch [200/391], Loss: 1.3490, LR: 0.000005\n",
      "Epoch [90], Batch [250/391], Loss: 1.3259, LR: 0.000005\n",
      "Epoch [90], Batch [300/391], Loss: 1.5638, LR: 0.000005\n",
      "Epoch [90], Batch [350/391], Loss: 3.6971, LR: 0.000005\n",
      "Train set: Epoch: 90, Average loss:2.1891, LR: 0.000005 Top-1 Accuracy: 50.7840%, Top-5 Accuracy: 77.9340%, Time consumed:204.33s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██████████████████████████▍                                                             | 90/300 [5:37:43<13:02:10, 223.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 90, Average loss:1.4317, Top-1 Accuracy: 61.1100%, Top-5 Accuracy: 87.1100%, Time consumed:18.48s\n",
      "\n",
      "EarlyStopping 카운터: 3 / 30\n",
      "Epoch [91], Batch [50/391], Loss: 3.2163, LR: 0.000005\n",
      "Epoch [91], Batch [100/391], Loss: 3.6703, LR: 0.000005\n",
      "Epoch [91], Batch [150/391], Loss: 3.7746, LR: 0.000005\n",
      "Epoch [91], Batch [200/391], Loss: 1.2152, LR: 0.000005\n",
      "Epoch [91], Batch [250/391], Loss: 2.6179, LR: 0.000005\n",
      "Epoch [91], Batch [300/391], Loss: 1.4773, LR: 0.000005\n",
      "Epoch [91], Batch [350/391], Loss: 3.7008, LR: 0.000005\n",
      "Train set: Epoch: 91, Average loss:2.1742, LR: 0.000005 Top-1 Accuracy: 50.2000%, Top-5 Accuracy: 77.6400%, Time consumed:205.58s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██████████████████████████▋                                                             | 91/300 [5:41:27<12:58:53, 223.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 91, Average loss:1.4649, Top-1 Accuracy: 60.7300%, Top-5 Accuracy: 87.0500%, Time consumed:18.31s\n",
      "\n",
      "EarlyStopping 카운터: 4 / 30\n",
      "Epoch [92], Batch [50/391], Loss: 3.3337, LR: 0.000002\n",
      "Epoch [92], Batch [100/391], Loss: 1.5499, LR: 0.000002\n",
      "Epoch [92], Batch [150/391], Loss: 1.2295, LR: 0.000002\n",
      "Epoch [92], Batch [200/391], Loss: 3.8626, LR: 0.000002\n",
      "Epoch [92], Batch [250/391], Loss: 1.4239, LR: 0.000002\n",
      "Epoch [92], Batch [300/391], Loss: 1.7515, LR: 0.000002\n",
      "Epoch [92], Batch [350/391], Loss: 3.6923, LR: 0.000002\n",
      "Train set: Epoch: 92, Average loss:2.1025, LR: 0.000002 Top-1 Accuracy: 51.8280%, Top-5 Accuracy: 79.2140%, Time consumed:207.85s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|██████████████████████████▉                                                             | 92/300 [5:45:13<12:57:27, 224.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 92, Average loss:1.4635, Top-1 Accuracy: 60.5500%, Top-5 Accuracy: 86.8200%, Time consumed:17.95s\n",
      "\n",
      "EarlyStopping 카운터: 5 / 30\n",
      "Epoch [93], Batch [50/391], Loss: 1.3106, LR: 0.000002\n",
      "Epoch [93], Batch [100/391], Loss: 2.3821, LR: 0.000002\n",
      "Epoch [93], Batch [150/391], Loss: 3.4411, LR: 0.000002\n",
      "Epoch [93], Batch [200/391], Loss: 3.8289, LR: 0.000002\n",
      "Epoch [93], Batch [250/391], Loss: 1.7348, LR: 0.000002\n",
      "Epoch [93], Batch [300/391], Loss: 1.1815, LR: 0.000002\n",
      "Epoch [93], Batch [350/391], Loss: 3.6868, LR: 0.000002\n",
      "Train set: Epoch: 93, Average loss:2.2202, LR: 0.000002 Top-1 Accuracy: 50.3520%, Top-5 Accuracy: 77.6580%, Time consumed:202.64s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███████████████████████████▎                                                            | 93/300 [5:48:55<12:51:06, 223.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 93, Average loss:1.4501, Top-1 Accuracy: 60.4800%, Top-5 Accuracy: 86.9600%, Time consumed:19.08s\n",
      "\n",
      "EarlyStopping 카운터: 6 / 30\n",
      "Epoch [94], Batch [50/391], Loss: 3.6571, LR: 0.000002\n",
      "Epoch [94], Batch [100/391], Loss: 3.6438, LR: 0.000002\n",
      "Epoch [94], Batch [150/391], Loss: 1.4510, LR: 0.000002\n",
      "Epoch [94], Batch [200/391], Loss: 1.5651, LR: 0.000002\n",
      "Epoch [94], Batch [250/391], Loss: 1.3636, LR: 0.000002\n",
      "Epoch [94], Batch [300/391], Loss: 3.6768, LR: 0.000002\n",
      "Epoch [94], Batch [350/391], Loss: 3.6103, LR: 0.000002\n",
      "Train set: Epoch: 94, Average loss:2.1843, LR: 0.000002 Top-1 Accuracy: 50.6340%, Top-5 Accuracy: 78.2120%, Time consumed:206.72s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███████████████████████████▌                                                            | 94/300 [5:52:40<12:48:38, 223.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 94, Average loss:1.4560, Top-1 Accuracy: 61.0400%, Top-5 Accuracy: 87.0600%, Time consumed:18.02s\n",
      "\n",
      "EarlyStopping 카운터: 7 / 30\n",
      "Epoch [95], Batch [50/391], Loss: 1.2956, LR: 0.000002\n",
      "Epoch [95], Batch [100/391], Loss: 1.6254, LR: 0.000002\n",
      "Epoch [95], Batch [150/391], Loss: 1.4514, LR: 0.000002\n",
      "Epoch [95], Batch [200/391], Loss: 3.3430, LR: 0.000002\n",
      "Epoch [95], Batch [250/391], Loss: 3.0632, LR: 0.000002\n",
      "Epoch [95], Batch [300/391], Loss: 3.8730, LR: 0.000002\n",
      "Epoch [95], Batch [350/391], Loss: 1.3712, LR: 0.000002\n",
      "Train set: Epoch: 95, Average loss:2.1769, LR: 0.000002 Top-1 Accuracy: 50.9420%, Top-5 Accuracy: 78.6160%, Time consumed:220.59s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███████████████████████████▊                                                            | 95/300 [5:56:38<13:00:14, 228.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 95, Average loss:1.4453, Top-1 Accuracy: 60.8600%, Top-5 Accuracy: 87.0800%, Time consumed:18.23s\n",
      "\n",
      "EarlyStopping 카운터: 8 / 30\n",
      "Epoch [96], Batch [50/391], Loss: 2.9435, LR: 0.000002\n",
      "Epoch [96], Batch [100/391], Loss: 3.2893, LR: 0.000002\n",
      "Epoch [96], Batch [150/391], Loss: 3.3119, LR: 0.000002\n",
      "Epoch [96], Batch [200/391], Loss: 3.7538, LR: 0.000002\n",
      "Epoch [96], Batch [250/391], Loss: 1.3538, LR: 0.000002\n",
      "Epoch [96], Batch [300/391], Loss: 3.6218, LR: 0.000002\n",
      "Epoch [96], Batch [350/391], Loss: 1.3963, LR: 0.000002\n",
      "Train set: Epoch: 96, Average loss:2.2344, LR: 0.000002 Top-1 Accuracy: 49.5000%, Top-5 Accuracy: 76.9680%, Time consumed:210.33s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|████████████████████████████▏                                                           | 96/300 [6:00:27<12:56:34, 228.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 96, Average loss:1.4639, Top-1 Accuracy: 60.4300%, Top-5 Accuracy: 86.6600%, Time consumed:18.16s\n",
      "\n",
      "EarlyStopping 카운터: 9 / 30\n",
      "Epoch [97], Batch [50/391], Loss: 3.6872, LR: 0.000002\n",
      "Epoch [97], Batch [100/391], Loss: 1.1308, LR: 0.000002\n",
      "Epoch [97], Batch [150/391], Loss: 1.2954, LR: 0.000002\n",
      "Epoch [97], Batch [200/391], Loss: 3.6789, LR: 0.000002\n",
      "Epoch [97], Batch [250/391], Loss: 1.3709, LR: 0.000002\n",
      "Epoch [97], Batch [300/391], Loss: 2.5892, LR: 0.000002\n",
      "Epoch [97], Batch [350/391], Loss: 1.3660, LR: 0.000002\n",
      "Train set: Epoch: 97, Average loss:2.2383, LR: 0.000002 Top-1 Accuracy: 49.4860%, Top-5 Accuracy: 76.6620%, Time consumed:203.19s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|████████████████████████████▍                                                           | 97/300 [6:04:09<12:46:06, 226.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 97, Average loss:1.4418, Top-1 Accuracy: 60.9300%, Top-5 Accuracy: 86.9400%, Time consumed:18.63s\n",
      "\n",
      "EarlyStopping 카운터: 10 / 30\n",
      "Epoch [98], Batch [50/391], Loss: 1.4071, LR: 0.000001\n",
      "Epoch [98], Batch [100/391], Loss: 1.3430, LR: 0.000001\n",
      "Epoch [98], Batch [150/391], Loss: 3.0056, LR: 0.000001\n",
      "Epoch [98], Batch [200/391], Loss: 1.3498, LR: 0.000001\n",
      "Epoch [98], Batch [250/391], Loss: 3.1146, LR: 0.000001\n",
      "Epoch [98], Batch [300/391], Loss: 1.2340, LR: 0.000001\n",
      "Epoch [98], Batch [350/391], Loss: 3.6178, LR: 0.000001\n",
      "Train set: Epoch: 98, Average loss:2.1976, LR: 0.000001 Top-1 Accuracy: 50.2780%, Top-5 Accuracy: 77.8580%, Time consumed:208.82s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|████████████████████████████▋                                                           | 98/300 [6:07:58<12:45:09, 227.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 98, Average loss:1.4690, Top-1 Accuracy: 60.6300%, Top-5 Accuracy: 86.5700%, Time consumed:20.41s\n",
      "\n",
      "EarlyStopping 카운터: 11 / 30\n",
      "Epoch [99], Batch [50/391], Loss: 1.4253, LR: 0.000001\n",
      "Epoch [99], Batch [100/391], Loss: 1.4512, LR: 0.000001\n",
      "Epoch [99], Batch [150/391], Loss: 1.2775, LR: 0.000001\n",
      "Epoch [99], Batch [200/391], Loss: 1.5434, LR: 0.000001\n",
      "Epoch [99], Batch [250/391], Loss: 1.3791, LR: 0.000001\n",
      "Epoch [99], Batch [300/391], Loss: 1.2597, LR: 0.000001\n",
      "Epoch [99], Batch [350/391], Loss: 2.9694, LR: 0.000001\n",
      "Train set: Epoch: 99, Average loss:2.2255, LR: 0.000001 Top-1 Accuracy: 50.1600%, Top-5 Accuracy: 77.5840%, Time consumed:221.96s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|█████████████████████████████                                                           | 99/300 [6:11:58<12:54:06, 231.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 99, Average loss:1.4514, Top-1 Accuracy: 60.7900%, Top-5 Accuracy: 86.9200%, Time consumed:17.98s\n",
      "\n",
      "EarlyStopping 카운터: 12 / 30\n",
      "Epoch [100], Batch [50/391], Loss: 3.2324, LR: 0.000001\n",
      "Epoch [100], Batch [100/391], Loss: 3.2801, LR: 0.000001\n",
      "Epoch [100], Batch [150/391], Loss: 1.3345, LR: 0.000001\n",
      "Epoch [100], Batch [200/391], Loss: 3.2420, LR: 0.000001\n",
      "Epoch [100], Batch [250/391], Loss: 1.3424, LR: 0.000001\n",
      "Epoch [100], Batch [300/391], Loss: 1.4668, LR: 0.000001\n",
      "Epoch [100], Batch [350/391], Loss: 3.3770, LR: 0.000001\n",
      "Train set: Epoch: 100, Average loss:2.1823, LR: 0.000001 Top-1 Accuracy: 51.0240%, Top-5 Accuracy: 78.6100%, Time consumed:205.77s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|█████████████████████████████                                                          | 100/300 [6:15:42<12:43:20, 229.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 100, Average loss:1.4336, Top-1 Accuracy: 60.7400%, Top-5 Accuracy: 86.9600%, Time consumed:18.37s\n",
      "\n",
      "EarlyStopping 카운터: 13 / 30\n",
      "Epoch [101], Batch [50/391], Loss: 2.2643, LR: 0.000001\n",
      "Epoch [101], Batch [100/391], Loss: 3.2649, LR: 0.000001\n",
      "Epoch [101], Batch [150/391], Loss: 1.3000, LR: 0.000001\n",
      "Epoch [101], Batch [200/391], Loss: 1.9496, LR: 0.000001\n",
      "Epoch [101], Batch [250/391], Loss: 1.3310, LR: 0.000001\n",
      "Epoch [101], Batch [300/391], Loss: 2.7265, LR: 0.000001\n",
      "Epoch [101], Batch [350/391], Loss: 3.2912, LR: 0.000001\n",
      "Train set: Epoch: 101, Average loss:2.2516, LR: 0.000001 Top-1 Accuracy: 49.4060%, Top-5 Accuracy: 77.0440%, Time consumed:202.72s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|█████████████████████████████▎                                                         | 101/300 [6:19:23<12:31:22, 226.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 101, Average loss:1.4564, Top-1 Accuracy: 60.9200%, Top-5 Accuracy: 86.6400%, Time consumed:18.09s\n",
      "\n",
      "EarlyStopping 카운터: 14 / 30\n",
      "Epoch [102], Batch [50/391], Loss: 3.2768, LR: 0.000001\n",
      "Epoch [102], Batch [100/391], Loss: 1.2514, LR: 0.000001\n",
      "Epoch [102], Batch [150/391], Loss: 1.1838, LR: 0.000001\n",
      "Epoch [102], Batch [200/391], Loss: 3.4358, LR: 0.000001\n",
      "Epoch [102], Batch [250/391], Loss: 3.2117, LR: 0.000001\n",
      "Epoch [102], Batch [300/391], Loss: 1.4710, LR: 0.000001\n",
      "Epoch [102], Batch [350/391], Loss: 1.7571, LR: 0.000001\n",
      "Train set: Epoch: 102, Average loss:2.1874, LR: 0.000001 Top-1 Accuracy: 50.8360%, Top-5 Accuracy: 78.1380%, Time consumed:221.38s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|█████████████████████████████▌                                                         | 102/300 [6:23:22<12:40:19, 230.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 102, Average loss:1.4331, Top-1 Accuracy: 61.0100%, Top-5 Accuracy: 86.9600%, Time consumed:18.02s\n",
      "\n",
      "EarlyStopping 카운터: 15 / 30\n",
      "Epoch [103], Batch [50/391], Loss: 1.3896, LR: 0.000001\n",
      "Epoch [103], Batch [100/391], Loss: 3.1302, LR: 0.000001\n",
      "Epoch [103], Batch [150/391], Loss: 1.4724, LR: 0.000001\n",
      "Epoch [103], Batch [200/391], Loss: 1.3819, LR: 0.000001\n",
      "Epoch [103], Batch [250/391], Loss: 1.3273, LR: 0.000001\n",
      "Epoch [103], Batch [300/391], Loss: 2.9168, LR: 0.000001\n",
      "Epoch [103], Batch [350/391], Loss: 1.5680, LR: 0.000001\n",
      "Train set: Epoch: 103, Average loss:2.1493, LR: 0.000001 Top-1 Accuracy: 51.7800%, Top-5 Accuracy: 79.4360%, Time consumed:209.68s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|█████████████████████████████▊                                                         | 103/300 [6:27:11<12:35:12, 230.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 103, Average loss:1.4493, Top-1 Accuracy: 60.6400%, Top-5 Accuracy: 86.9400%, Time consumed:19.42s\n",
      "\n",
      "EarlyStopping 카운터: 16 / 30\n",
      "Epoch [104], Batch [50/391], Loss: 3.0434, LR: 0.000001\n",
      "Epoch [104], Batch [100/391], Loss: 3.7245, LR: 0.000001\n",
      "Epoch [104], Batch [150/391], Loss: 1.3721, LR: 0.000001\n",
      "Epoch [104], Batch [200/391], Loss: 2.2990, LR: 0.000001\n",
      "Epoch [104], Batch [250/391], Loss: 3.0465, LR: 0.000001\n",
      "Epoch [104], Batch [300/391], Loss: 1.9871, LR: 0.000001\n",
      "Epoch [104], Batch [350/391], Loss: 1.2917, LR: 0.000001\n",
      "Train set: Epoch: 104, Average loss:2.1355, LR: 0.000001 Top-1 Accuracy: 51.2440%, Top-5 Accuracy: 79.1020%, Time consumed:215.16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|██████████████████████████████▏                                                        | 104/300 [6:31:06<12:35:53, 231.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 104, Average loss:1.4144, Top-1 Accuracy: 61.3900%, Top-5 Accuracy: 87.3900%, Time consumed:19.31s\n",
      "\n",
      "새로운 최고 top-1 정확도: 61.39%, top-5 정확도: 87.39%\n",
      "새로운 최고 top-5 정확도: 87.39%\n",
      "Accuracy improved (61.31% --> 61.39%). Saving model ...\n",
      "Epoch [105], Batch [50/391], Loss: 1.6082, LR: 0.000001\n",
      "Epoch [105], Batch [100/391], Loss: 1.4142, LR: 0.000001\n",
      "Epoch [105], Batch [150/391], Loss: 3.5766, LR: 0.000001\n",
      "Epoch [105], Batch [200/391], Loss: 3.3216, LR: 0.000001\n",
      "Epoch [105], Batch [250/391], Loss: 1.3906, LR: 0.000001\n",
      "Epoch [105], Batch [300/391], Loss: 3.6231, LR: 0.000001\n",
      "Epoch [105], Batch [350/391], Loss: 1.3163, LR: 0.000001\n",
      "Train set: Epoch: 105, Average loss:2.2320, LR: 0.000001 Top-1 Accuracy: 49.7340%, Top-5 Accuracy: 77.1240%, Time consumed:219.06s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|██████████████████████████████▍                                                        | 105/300 [6:35:04<12:38:18, 233.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 105, Average loss:1.4275, Top-1 Accuracy: 61.1700%, Top-5 Accuracy: 87.1800%, Time consumed:18.76s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [106], Batch [50/391], Loss: 3.1630, LR: 0.000001\n",
      "Epoch [106], Batch [100/391], Loss: 1.1384, LR: 0.000001\n",
      "Epoch [106], Batch [150/391], Loss: 3.1910, LR: 0.000001\n",
      "Epoch [106], Batch [200/391], Loss: 1.4144, LR: 0.000001\n",
      "Epoch [106], Batch [250/391], Loss: 1.3618, LR: 0.000001\n",
      "Epoch [106], Batch [300/391], Loss: 1.3167, LR: 0.000001\n",
      "Epoch [106], Batch [350/391], Loss: 1.2883, LR: 0.000001\n",
      "Train set: Epoch: 106, Average loss:2.1657, LR: 0.000001 Top-1 Accuracy: 51.2160%, Top-5 Accuracy: 78.8320%, Time consumed:203.18s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|██████████████████████████████▋                                                        | 106/300 [6:38:46<12:23:18, 229.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 106, Average loss:1.4265, Top-1 Accuracy: 61.1500%, Top-5 Accuracy: 87.2500%, Time consumed:18.69s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [107], Batch [50/391], Loss: 3.8197, LR: 0.000001\n",
      "Epoch [107], Batch [100/391], Loss: 1.4319, LR: 0.000001\n",
      "Epoch [107], Batch [150/391], Loss: 1.2913, LR: 0.000001\n",
      "Epoch [107], Batch [200/391], Loss: 3.6350, LR: 0.000001\n",
      "Epoch [107], Batch [250/391], Loss: 3.2339, LR: 0.000001\n",
      "Epoch [107], Batch [300/391], Loss: 1.3752, LR: 0.000001\n",
      "Epoch [107], Batch [350/391], Loss: 1.4740, LR: 0.000001\n",
      "Train set: Epoch: 107, Average loss:2.1359, LR: 0.000001 Top-1 Accuracy: 50.7160%, Top-5 Accuracy: 78.3780%, Time consumed:204.34s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███████████████████████████████                                                        | 107/300 [6:42:28<12:12:01, 227.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 107, Average loss:1.4547, Top-1 Accuracy: 60.7100%, Top-5 Accuracy: 87.0200%, Time consumed:17.81s\n",
      "\n",
      "EarlyStopping 카운터: 3 / 30\n",
      "Epoch [108], Batch [50/391], Loss: 1.4362, LR: 0.000001\n",
      "Epoch [108], Batch [100/391], Loss: 1.4598, LR: 0.000001\n",
      "Epoch [108], Batch [150/391], Loss: 1.6866, LR: 0.000001\n",
      "Epoch [108], Batch [200/391], Loss: 2.3652, LR: 0.000001\n",
      "Epoch [108], Batch [250/391], Loss: 3.4891, LR: 0.000001\n",
      "Epoch [108], Batch [300/391], Loss: 1.3352, LR: 0.000001\n",
      "Epoch [108], Batch [350/391], Loss: 3.1245, LR: 0.000001\n",
      "Train set: Epoch: 108, Average loss:2.1802, LR: 0.000001 Top-1 Accuracy: 50.4040%, Top-5 Accuracy: 78.1460%, Time consumed:207.62s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███████████████████████████████▎                                                       | 108/300 [6:46:14<12:06:42, 227.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 108, Average loss:1.4442, Top-1 Accuracy: 60.6100%, Top-5 Accuracy: 86.9900%, Time consumed:18.36s\n",
      "\n",
      "EarlyStopping 카운터: 4 / 30\n",
      "Epoch [109], Batch [50/391], Loss: 2.6316, LR: 0.000001\n",
      "Epoch [109], Batch [100/391], Loss: 3.5212, LR: 0.000001\n",
      "Epoch [109], Batch [150/391], Loss: 3.2316, LR: 0.000001\n",
      "Epoch [109], Batch [200/391], Loss: 3.3396, LR: 0.000001\n",
      "Epoch [109], Batch [250/391], Loss: 1.2077, LR: 0.000001\n",
      "Epoch [109], Batch [300/391], Loss: 3.4540, LR: 0.000001\n",
      "Epoch [109], Batch [350/391], Loss: 3.4698, LR: 0.000001\n",
      "Train set: Epoch: 109, Average loss:2.3077, LR: 0.000001 Top-1 Accuracy: 48.3560%, Top-5 Accuracy: 76.1460%, Time consumed:206.20s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███████████████████████████████▌                                                       | 109/300 [6:49:59<12:00:35, 226.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 109, Average loss:1.4605, Top-1 Accuracy: 60.8100%, Top-5 Accuracy: 86.9200%, Time consumed:18.44s\n",
      "\n",
      "EarlyStopping 카운터: 5 / 30\n",
      "Epoch [110], Batch [50/391], Loss: 2.7486, LR: 0.000001\n",
      "Epoch [110], Batch [100/391], Loss: 3.3533, LR: 0.000001\n",
      "Epoch [110], Batch [150/391], Loss: 3.6315, LR: 0.000001\n",
      "Epoch [110], Batch [200/391], Loss: 2.9055, LR: 0.000001\n",
      "Epoch [110], Batch [250/391], Loss: 1.3929, LR: 0.000001\n",
      "Epoch [110], Batch [300/391], Loss: 3.0741, LR: 0.000001\n",
      "Epoch [110], Batch [350/391], Loss: 3.4708, LR: 0.000001\n",
      "Train set: Epoch: 110, Average loss:2.2093, LR: 0.000001 Top-1 Accuracy: 50.7540%, Top-5 Accuracy: 78.1280%, Time consumed:204.51s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███████████████████████████████▉                                                       | 110/300 [6:53:41<11:53:15, 225.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 110, Average loss:1.4416, Top-1 Accuracy: 61.0500%, Top-5 Accuracy: 87.0600%, Time consumed:18.10s\n",
      "\n",
      "EarlyStopping 카운터: 6 / 30\n",
      "Epoch [111], Batch [50/391], Loss: 1.3596, LR: 0.000001\n",
      "Epoch [111], Batch [100/391], Loss: 1.5474, LR: 0.000001\n",
      "Epoch [111], Batch [150/391], Loss: 3.5549, LR: 0.000001\n",
      "Epoch [111], Batch [200/391], Loss: 1.5675, LR: 0.000001\n",
      "Epoch [111], Batch [250/391], Loss: 2.2693, LR: 0.000001\n",
      "Epoch [111], Batch [300/391], Loss: 1.9848, LR: 0.000001\n",
      "Epoch [111], Batch [350/391], Loss: 3.5840, LR: 0.000001\n",
      "Train set: Epoch: 111, Average loss:2.1536, LR: 0.000001 Top-1 Accuracy: 50.4900%, Top-5 Accuracy: 78.3080%, Time consumed:208.92s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|████████████████████████████████▏                                                      | 111/300 [6:57:31<11:53:25, 226.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 111, Average loss:1.4403, Top-1 Accuracy: 60.8600%, Top-5 Accuracy: 86.8700%, Time consumed:20.44s\n",
      "\n",
      "EarlyStopping 카운터: 7 / 30\n",
      "Epoch [112], Batch [50/391], Loss: 3.3911, LR: 0.000001\n",
      "Epoch [112], Batch [100/391], Loss: 1.2195, LR: 0.000001\n",
      "Epoch [112], Batch [150/391], Loss: 3.6375, LR: 0.000001\n",
      "Epoch [112], Batch [200/391], Loss: 2.8819, LR: 0.000001\n",
      "Epoch [112], Batch [250/391], Loss: 3.5975, LR: 0.000001\n",
      "Epoch [112], Batch [300/391], Loss: 1.3111, LR: 0.000001\n",
      "Epoch [112], Batch [350/391], Loss: 3.3494, LR: 0.000001\n",
      "Train set: Epoch: 112, Average loss:2.2359, LR: 0.000001 Top-1 Accuracy: 49.7380%, Top-5 Accuracy: 77.4820%, Time consumed:205.73s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|████████████████████████████████▍                                                      | 112/300 [7:01:15<11:47:34, 225.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 112, Average loss:1.4587, Top-1 Accuracy: 60.7400%, Top-5 Accuracy: 86.9600%, Time consumed:18.53s\n",
      "\n",
      "EarlyStopping 카운터: 8 / 30\n",
      "Epoch [113], Batch [50/391], Loss: 1.4940, LR: 0.000001\n",
      "Epoch [113], Batch [100/391], Loss: 1.4014, LR: 0.000001\n",
      "Epoch [113], Batch [150/391], Loss: 1.2642, LR: 0.000001\n",
      "Epoch [113], Batch [200/391], Loss: 1.4401, LR: 0.000001\n",
      "Epoch [113], Batch [250/391], Loss: 1.4536, LR: 0.000001\n",
      "Epoch [113], Batch [300/391], Loss: 3.3983, LR: 0.000001\n",
      "Epoch [113], Batch [350/391], Loss: 1.5726, LR: 0.000001\n",
      "Train set: Epoch: 113, Average loss:2.1585, LR: 0.000001 Top-1 Accuracy: 50.6680%, Top-5 Accuracy: 78.3820%, Time consumed:203.72s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|████████████████████████████████▊                                                      | 113/300 [7:04:57<11:39:58, 224.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 113, Average loss:1.4727, Top-1 Accuracy: 60.1800%, Top-5 Accuracy: 86.6600%, Time consumed:17.99s\n",
      "\n",
      "EarlyStopping 카운터: 9 / 30\n",
      "Epoch [114], Batch [50/391], Loss: 1.4803, LR: 0.000001\n",
      "Epoch [114], Batch [100/391], Loss: 1.4819, LR: 0.000001\n",
      "Epoch [114], Batch [150/391], Loss: 1.6068, LR: 0.000001\n",
      "Epoch [114], Batch [200/391], Loss: 1.3932, LR: 0.000001\n",
      "Epoch [114], Batch [250/391], Loss: 3.5797, LR: 0.000001\n",
      "Epoch [114], Batch [300/391], Loss: 2.8744, LR: 0.000001\n",
      "Epoch [114], Batch [350/391], Loss: 1.5432, LR: 0.000001\n",
      "Train set: Epoch: 114, Average loss:2.1869, LR: 0.000001 Top-1 Accuracy: 50.1880%, Top-5 Accuracy: 78.1140%, Time consumed:203.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|█████████████████████████████████                                                      | 114/300 [7:08:38<11:33:04, 223.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 114, Average loss:1.4300, Top-1 Accuracy: 61.2900%, Top-5 Accuracy: 87.2900%, Time consumed:18.19s\n",
      "\n",
      "EarlyStopping 카운터: 10 / 30\n",
      "Epoch [115], Batch [50/391], Loss: 1.4495, LR: 0.000001\n",
      "Epoch [115], Batch [100/391], Loss: 1.3492, LR: 0.000001\n",
      "Epoch [115], Batch [150/391], Loss: 3.9057, LR: 0.000001\n",
      "Epoch [115], Batch [200/391], Loss: 1.2848, LR: 0.000001\n",
      "Epoch [115], Batch [250/391], Loss: 1.3959, LR: 0.000001\n",
      "Epoch [115], Batch [300/391], Loss: 3.6412, LR: 0.000001\n",
      "Epoch [115], Batch [350/391], Loss: 2.6217, LR: 0.000001\n",
      "Train set: Epoch: 115, Average loss:2.1804, LR: 0.000001 Top-1 Accuracy: 50.1580%, Top-5 Accuracy: 77.6800%, Time consumed:202.37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|█████████████████████████████████▎                                                     | 115/300 [7:12:18<11:26:21, 222.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 115, Average loss:1.4377, Top-1 Accuracy: 61.3300%, Top-5 Accuracy: 87.1900%, Time consumed:17.97s\n",
      "\n",
      "EarlyStopping 카운터: 11 / 30\n",
      "Epoch [116], Batch [50/391], Loss: 1.4057, LR: 0.000001\n",
      "Epoch [116], Batch [100/391], Loss: 3.5647, LR: 0.000001\n",
      "Epoch [116], Batch [150/391], Loss: 3.6406, LR: 0.000001\n",
      "Epoch [116], Batch [200/391], Loss: 2.7103, LR: 0.000001\n",
      "Epoch [116], Batch [250/391], Loss: 1.4038, LR: 0.000001\n",
      "Epoch [116], Batch [300/391], Loss: 1.3979, LR: 0.000001\n",
      "Epoch [116], Batch [350/391], Loss: 3.3331, LR: 0.000001\n",
      "Train set: Epoch: 116, Average loss:2.2312, LR: 0.000001 Top-1 Accuracy: 49.4560%, Top-5 Accuracy: 76.9720%, Time consumed:222.57s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|█████████████████████████████████▋                                                     | 116/300 [7:16:19<11:39:46, 228.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 116, Average loss:1.4571, Top-1 Accuracy: 60.6900%, Top-5 Accuracy: 86.7300%, Time consumed:18.64s\n",
      "\n",
      "EarlyStopping 카운터: 12 / 30\n",
      "Epoch [117], Batch [50/391], Loss: 3.0979, LR: 0.000001\n",
      "Epoch [117], Batch [100/391], Loss: 3.6027, LR: 0.000001\n",
      "Epoch [117], Batch [150/391], Loss: 1.6154, LR: 0.000001\n",
      "Epoch [117], Batch [200/391], Loss: 1.4284, LR: 0.000001\n",
      "Epoch [117], Batch [250/391], Loss: 2.8730, LR: 0.000001\n",
      "Epoch [117], Batch [300/391], Loss: 1.4517, LR: 0.000001\n",
      "Epoch [117], Batch [350/391], Loss: 3.3549, LR: 0.000001\n",
      "Train set: Epoch: 117, Average loss:2.1761, LR: 0.000001 Top-1 Accuracy: 50.9420%, Top-5 Accuracy: 78.6560%, Time consumed:203.51s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|█████████████████████████████████▉                                                     | 117/300 [7:20:01<11:30:06, 226.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 117, Average loss:1.4279, Top-1 Accuracy: 61.1200%, Top-5 Accuracy: 87.3400%, Time consumed:18.25s\n",
      "\n",
      "EarlyStopping 카운터: 13 / 30\n",
      "Epoch [118], Batch [50/391], Loss: 3.2413, LR: 0.000001\n",
      "Epoch [118], Batch [100/391], Loss: 2.1164, LR: 0.000001\n",
      "Epoch [118], Batch [150/391], Loss: 1.3559, LR: 0.000001\n",
      "Epoch [118], Batch [200/391], Loss: 1.9101, LR: 0.000001\n",
      "Epoch [118], Batch [250/391], Loss: 1.3650, LR: 0.000001\n",
      "Epoch [118], Batch [300/391], Loss: 2.2474, LR: 0.000001\n",
      "Epoch [118], Batch [350/391], Loss: 3.5575, LR: 0.000001\n",
      "Train set: Epoch: 118, Average loss:2.2082, LR: 0.000001 Top-1 Accuracy: 50.3740%, Top-5 Accuracy: 78.1900%, Time consumed:205.03s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|██████████████████████████████████▏                                                    | 118/300 [7:23:44<11:23:29, 225.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 118, Average loss:1.4593, Top-1 Accuracy: 60.6200%, Top-5 Accuracy: 86.7900%, Time consumed:18.10s\n",
      "\n",
      "EarlyStopping 카운터: 14 / 30\n",
      "Epoch [119], Batch [50/391], Loss: 1.8319, LR: 0.000001\n",
      "Epoch [119], Batch [100/391], Loss: 1.3111, LR: 0.000001\n",
      "Epoch [119], Batch [150/391], Loss: 3.2579, LR: 0.000001\n",
      "Epoch [119], Batch [200/391], Loss: 1.2973, LR: 0.000001\n",
      "Epoch [119], Batch [250/391], Loss: 1.4176, LR: 0.000001\n",
      "Epoch [119], Batch [300/391], Loss: 3.2754, LR: 0.000001\n",
      "Epoch [119], Batch [350/391], Loss: 1.6611, LR: 0.000001\n",
      "Train set: Epoch: 119, Average loss:2.1143, LR: 0.000001 Top-1 Accuracy: 52.1440%, Top-5 Accuracy: 79.7940%, Time consumed:210.59s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████████▌                                                    | 119/300 [7:27:34<11:23:17, 226.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 119, Average loss:1.4504, Top-1 Accuracy: 60.9700%, Top-5 Accuracy: 86.9300%, Time consumed:18.66s\n",
      "\n",
      "EarlyStopping 카운터: 15 / 30\n",
      "Epoch [120], Batch [50/391], Loss: 1.2684, LR: 0.000001\n",
      "Epoch [120], Batch [100/391], Loss: 1.3599, LR: 0.000001\n",
      "Epoch [120], Batch [150/391], Loss: 1.2924, LR: 0.000001\n",
      "Epoch [120], Batch [200/391], Loss: 3.6372, LR: 0.000001\n",
      "Epoch [120], Batch [250/391], Loss: 1.3724, LR: 0.000001\n",
      "Epoch [120], Batch [300/391], Loss: 3.7486, LR: 0.000001\n",
      "Epoch [120], Batch [350/391], Loss: 1.3830, LR: 0.000001\n",
      "Train set: Epoch: 120, Average loss:2.1209, LR: 0.000001 Top-1 Accuracy: 51.8900%, Top-5 Accuracy: 79.0320%, Time consumed:203.44s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████████▊                                                    | 120/300 [7:31:16<11:15:50, 225.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 120, Average loss:1.4321, Top-1 Accuracy: 61.1100%, Top-5 Accuracy: 87.2100%, Time consumed:18.98s\n",
      "\n",
      "EarlyStopping 카운터: 16 / 30\n",
      "Epoch [121], Batch [50/391], Loss: 1.5477, LR: 0.000001\n",
      "Epoch [121], Batch [100/391], Loss: 3.3636, LR: 0.000001\n",
      "Epoch [121], Batch [150/391], Loss: 3.5763, LR: 0.000001\n",
      "Epoch [121], Batch [200/391], Loss: 1.5363, LR: 0.000001\n",
      "Epoch [121], Batch [250/391], Loss: 1.6421, LR: 0.000001\n",
      "Epoch [121], Batch [300/391], Loss: 1.4809, LR: 0.000001\n",
      "Epoch [121], Batch [350/391], Loss: 2.7469, LR: 0.000001\n",
      "Train set: Epoch: 121, Average loss:2.1861, LR: 0.000001 Top-1 Accuracy: 50.2620%, Top-5 Accuracy: 77.7500%, Time consumed:204.03s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███████████████████████████████████                                                    | 121/300 [7:34:58<11:09:09, 224.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 121, Average loss:1.4459, Top-1 Accuracy: 60.9200%, Top-5 Accuracy: 86.8900%, Time consumed:17.96s\n",
      "\n",
      "EarlyStopping 카운터: 17 / 30\n",
      "Epoch [122], Batch [50/391], Loss: 3.5450, LR: 0.000001\n",
      "Epoch [122], Batch [100/391], Loss: 1.9420, LR: 0.000001\n",
      "Epoch [122], Batch [150/391], Loss: 2.7776, LR: 0.000001\n",
      "Epoch [122], Batch [200/391], Loss: 1.4844, LR: 0.000001\n",
      "Epoch [122], Batch [250/391], Loss: 3.4918, LR: 0.000001\n",
      "Epoch [122], Batch [300/391], Loss: 3.5777, LR: 0.000001\n",
      "Epoch [122], Batch [350/391], Loss: 3.6478, LR: 0.000001\n",
      "Train set: Epoch: 122, Average loss:2.2714, LR: 0.000001 Top-1 Accuracy: 49.1920%, Top-5 Accuracy: 76.9460%, Time consumed:211.14s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|███████████████████████████████████▍                                                   | 122/300 [7:38:47<11:09:43, 225.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 122, Average loss:1.4518, Top-1 Accuracy: 60.9700%, Top-5 Accuracy: 87.0800%, Time consumed:17.99s\n",
      "\n",
      "EarlyStopping 카운터: 18 / 30\n",
      "Epoch [123], Batch [50/391], Loss: 3.3427, LR: 0.000001\n",
      "Epoch [123], Batch [100/391], Loss: 3.7583, LR: 0.000001\n",
      "Epoch [123], Batch [150/391], Loss: 3.3226, LR: 0.000001\n",
      "Epoch [123], Batch [200/391], Loss: 3.4420, LR: 0.000001\n",
      "Epoch [123], Batch [250/391], Loss: 2.6058, LR: 0.000001\n",
      "Epoch [123], Batch [300/391], Loss: 3.9079, LR: 0.000001\n",
      "Epoch [123], Batch [350/391], Loss: 3.7136, LR: 0.000001\n",
      "Train set: Epoch: 123, Average loss:2.1919, LR: 0.000001 Top-1 Accuracy: 50.0780%, Top-5 Accuracy: 77.4320%, Time consumed:204.14s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|███████████████████████████████████▋                                                   | 123/300 [7:42:31<11:04:01, 225.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 123, Average loss:1.4441, Top-1 Accuracy: 60.9100%, Top-5 Accuracy: 86.9900%, Time consumed:19.40s\n",
      "\n",
      "EarlyStopping 카운터: 19 / 30\n",
      "Epoch [124], Batch [50/391], Loss: 2.9897, LR: 0.000001\n",
      "Epoch [124], Batch [100/391], Loss: 3.0410, LR: 0.000001\n",
      "Epoch [124], Batch [150/391], Loss: 3.3228, LR: 0.000001\n",
      "Epoch [124], Batch [200/391], Loss: 1.4108, LR: 0.000001\n",
      "Epoch [124], Batch [250/391], Loss: 1.4501, LR: 0.000001\n",
      "Epoch [124], Batch [300/391], Loss: 1.3903, LR: 0.000001\n",
      "Epoch [124], Batch [350/391], Loss: 3.6682, LR: 0.000001\n",
      "Train set: Epoch: 124, Average loss:2.1401, LR: 0.000001 Top-1 Accuracy: 51.5160%, Top-5 Accuracy: 79.1500%, Time consumed:204.79s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|███████████████████████████████████▉                                                   | 124/300 [7:46:14<10:58:24, 224.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 124, Average loss:1.4207, Top-1 Accuracy: 61.5400%, Top-5 Accuracy: 87.2700%, Time consumed:18.04s\n",
      "\n",
      "새로운 최고 top-1 정확도: 61.54%, top-5 정확도: 87.27%\n",
      "Accuracy improved (61.39% --> 61.54%). Saving model ...\n",
      "Epoch [125], Batch [50/391], Loss: 2.5686, LR: 0.000001\n",
      "Epoch [125], Batch [100/391], Loss: 1.4018, LR: 0.000001\n",
      "Epoch [125], Batch [150/391], Loss: 1.3914, LR: 0.000001\n",
      "Epoch [125], Batch [200/391], Loss: 3.0060, LR: 0.000001\n",
      "Epoch [125], Batch [250/391], Loss: 1.3910, LR: 0.000001\n",
      "Epoch [125], Batch [300/391], Loss: 1.2406, LR: 0.000001\n",
      "Epoch [125], Batch [350/391], Loss: 3.1723, LR: 0.000001\n",
      "Train set: Epoch: 125, Average loss:2.2276, LR: 0.000001 Top-1 Accuracy: 49.8820%, Top-5 Accuracy: 77.4320%, Time consumed:205.96s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████████████████████████████████████▎                                                  | 125/300 [7:49:59<10:55:30, 224.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 125, Average loss:1.4604, Top-1 Accuracy: 60.2300%, Top-5 Accuracy: 86.8800%, Time consumed:19.44s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [126], Batch [50/391], Loss: 1.3364, LR: 0.000001\n",
      "Epoch [126], Batch [100/391], Loss: 1.2915, LR: 0.000001\n",
      "Epoch [126], Batch [150/391], Loss: 1.3748, LR: 0.000001\n",
      "Epoch [126], Batch [200/391], Loss: 1.2132, LR: 0.000001\n",
      "Epoch [126], Batch [250/391], Loss: 3.6091, LR: 0.000001\n",
      "Epoch [126], Batch [300/391], Loss: 3.6701, LR: 0.000001\n",
      "Epoch [126], Batch [350/391], Loss: 1.5346, LR: 0.000001\n",
      "Train set: Epoch: 126, Average loss:2.2758, LR: 0.000001 Top-1 Accuracy: 48.9720%, Top-5 Accuracy: 76.7600%, Time consumed:210.82s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████████████████████████████████████▌                                                  | 126/300 [7:53:48<10:55:31, 226.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 126, Average loss:1.4342, Top-1 Accuracy: 61.2300%, Top-5 Accuracy: 87.3500%, Time consumed:18.23s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [127], Batch [50/391], Loss: 3.5906, LR: 0.000001\n",
      "Epoch [127], Batch [100/391], Loss: 1.5301, LR: 0.000001\n",
      "Epoch [127], Batch [150/391], Loss: 3.6049, LR: 0.000001\n",
      "Epoch [127], Batch [200/391], Loss: 1.5025, LR: 0.000001\n",
      "Epoch [127], Batch [250/391], Loss: 1.6209, LR: 0.000001\n",
      "Epoch [127], Batch [300/391], Loss: 3.4316, LR: 0.000001\n",
      "Epoch [127], Batch [350/391], Loss: 3.8033, LR: 0.000001\n",
      "Train set: Epoch: 127, Average loss:2.2708, LR: 0.000001 Top-1 Accuracy: 48.6700%, Top-5 Accuracy: 76.5880%, Time consumed:205.23s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████████████████████████████████████▊                                                  | 127/300 [7:57:31<10:49:07, 225.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 127, Average loss:1.4444, Top-1 Accuracy: 60.8400%, Top-5 Accuracy: 87.0200%, Time consumed:17.78s\n",
      "\n",
      "EarlyStopping 카운터: 3 / 30\n",
      "Epoch [128], Batch [50/391], Loss: 1.4088, LR: 0.000001\n",
      "Epoch [128], Batch [100/391], Loss: 3.0512, LR: 0.000001\n",
      "Epoch [128], Batch [150/391], Loss: 1.5047, LR: 0.000001\n",
      "Epoch [128], Batch [200/391], Loss: 1.3940, LR: 0.000001\n",
      "Epoch [128], Batch [250/391], Loss: 1.3063, LR: 0.000001\n",
      "Epoch [128], Batch [300/391], Loss: 3.3368, LR: 0.000001\n",
      "Epoch [128], Batch [350/391], Loss: 2.8448, LR: 0.000001\n",
      "Train set: Epoch: 128, Average loss:2.2919, LR: 0.000001 Top-1 Accuracy: 48.8720%, Top-5 Accuracy: 76.6720%, Time consumed:203.56s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|█████████████████████████████████████                                                  | 128/300 [8:01:15<10:44:02, 224.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 128, Average loss:1.4377, Top-1 Accuracy: 60.7900%, Top-5 Accuracy: 87.2900%, Time consumed:20.01s\n",
      "\n",
      "EarlyStopping 카운터: 4 / 30\n",
      "Epoch [129], Batch [50/391], Loss: 3.4621, LR: 0.000001\n",
      "Epoch [129], Batch [100/391], Loss: 1.4644, LR: 0.000001\n",
      "Epoch [129], Batch [150/391], Loss: 0.9298, LR: 0.000001\n",
      "Epoch [129], Batch [200/391], Loss: 3.8483, LR: 0.000001\n",
      "Epoch [129], Batch [250/391], Loss: 1.3737, LR: 0.000001\n",
      "Epoch [129], Batch [300/391], Loss: 1.1254, LR: 0.000001\n",
      "Epoch [129], Batch [350/391], Loss: 1.5215, LR: 0.000001\n",
      "Train set: Epoch: 129, Average loss:2.2220, LR: 0.000001 Top-1 Accuracy: 49.6900%, Top-5 Accuracy: 77.4000%, Time consumed:205.43s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|█████████████████████████████████████▍                                                 | 129/300 [8:04:58<10:39:21, 224.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 129, Average loss:1.4487, Top-1 Accuracy: 60.8900%, Top-5 Accuracy: 86.9500%, Time consumed:18.13s\n",
      "\n",
      "EarlyStopping 카운터: 5 / 30\n",
      "Epoch [130], Batch [50/391], Loss: 3.7777, LR: 0.000001\n",
      "Epoch [130], Batch [100/391], Loss: 1.2354, LR: 0.000001\n",
      "Epoch [130], Batch [150/391], Loss: 1.4272, LR: 0.000001\n",
      "Epoch [130], Batch [200/391], Loss: 1.4567, LR: 0.000001\n",
      "Epoch [130], Batch [250/391], Loss: 3.0752, LR: 0.000001\n",
      "Epoch [130], Batch [300/391], Loss: 2.6083, LR: 0.000001\n",
      "Epoch [130], Batch [350/391], Loss: 3.0513, LR: 0.000001\n",
      "Train set: Epoch: 130, Average loss:2.1447, LR: 0.000001 Top-1 Accuracy: 51.5280%, Top-5 Accuracy: 79.4200%, Time consumed:204.76s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|█████████████████████████████████████▋                                                 | 130/300 [8:08:41<10:34:42, 224.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 130, Average loss:1.4635, Top-1 Accuracy: 60.4600%, Top-5 Accuracy: 86.7700%, Time consumed:18.49s\n",
      "\n",
      "EarlyStopping 카운터: 6 / 30\n",
      "Epoch [131], Batch [50/391], Loss: 1.3673, LR: 0.000001\n",
      "Epoch [131], Batch [100/391], Loss: 1.3793, LR: 0.000001\n",
      "Epoch [131], Batch [150/391], Loss: 2.5264, LR: 0.000001\n",
      "Epoch [131], Batch [200/391], Loss: 2.9879, LR: 0.000001\n",
      "Epoch [131], Batch [250/391], Loss: 1.3538, LR: 0.000001\n",
      "Epoch [131], Batch [300/391], Loss: 1.4455, LR: 0.000001\n",
      "Epoch [131], Batch [350/391], Loss: 1.2613, LR: 0.000001\n",
      "Train set: Epoch: 131, Average loss:2.2366, LR: 0.000001 Top-1 Accuracy: 49.4640%, Top-5 Accuracy: 77.1660%, Time consumed:206.91s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|█████████████████████████████████████▉                                                 | 131/300 [8:12:29<10:34:06, 225.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 131, Average loss:1.4349, Top-1 Accuracy: 61.2100%, Top-5 Accuracy: 87.1100%, Time consumed:20.81s\n",
      "\n",
      "EarlyStopping 카운터: 7 / 30\n",
      "Epoch [132], Batch [50/391], Loss: 1.4284, LR: 0.000001\n",
      "Epoch [132], Batch [100/391], Loss: 3.5476, LR: 0.000001\n",
      "Epoch [132], Batch [150/391], Loss: 1.4939, LR: 0.000001\n",
      "Epoch [132], Batch [200/391], Loss: 2.9350, LR: 0.000001\n",
      "Epoch [132], Batch [250/391], Loss: 3.5935, LR: 0.000001\n",
      "Epoch [132], Batch [300/391], Loss: 3.4236, LR: 0.000001\n",
      "Epoch [132], Batch [350/391], Loss: 1.3700, LR: 0.000001\n",
      "Train set: Epoch: 132, Average loss:2.1498, LR: 0.000001 Top-1 Accuracy: 50.7960%, Top-5 Accuracy: 78.1960%, Time consumed:217.57s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|██████████████████████████████████████▎                                                | 132/300 [8:16:26<10:40:25, 228.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 132, Average loss:1.4280, Top-1 Accuracy: 61.3800%, Top-5 Accuracy: 87.3400%, Time consumed:19.53s\n",
      "\n",
      "EarlyStopping 카운터: 8 / 30\n",
      "Epoch [133], Batch [50/391], Loss: 2.5115, LR: 0.000001\n",
      "Epoch [133], Batch [100/391], Loss: 1.3448, LR: 0.000001\n",
      "Epoch [133], Batch [150/391], Loss: 1.4170, LR: 0.000001\n",
      "Epoch [133], Batch [200/391], Loss: 1.4483, LR: 0.000001\n",
      "Epoch [133], Batch [250/391], Loss: 3.7035, LR: 0.000001\n",
      "Epoch [133], Batch [300/391], Loss: 3.6164, LR: 0.000001\n",
      "Epoch [133], Batch [350/391], Loss: 1.4505, LR: 0.000001\n",
      "Train set: Epoch: 133, Average loss:2.2418, LR: 0.000001 Top-1 Accuracy: 49.2840%, Top-5 Accuracy: 77.0000%, Time consumed:207.59s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|██████████████████████████████████████▌                                                | 133/300 [8:20:12<10:34:12, 227.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 133, Average loss:1.4403, Top-1 Accuracy: 60.6000%, Top-5 Accuracy: 87.0100%, Time consumed:18.23s\n",
      "\n",
      "EarlyStopping 카운터: 9 / 30\n",
      "Epoch [134], Batch [50/391], Loss: 3.8157, LR: 0.000001\n",
      "Epoch [134], Batch [100/391], Loss: 1.2801, LR: 0.000001\n",
      "Epoch [134], Batch [150/391], Loss: 1.4525, LR: 0.000001\n",
      "Epoch [134], Batch [200/391], Loss: 2.9301, LR: 0.000001\n",
      "Epoch [134], Batch [250/391], Loss: 1.3119, LR: 0.000001\n",
      "Epoch [134], Batch [300/391], Loss: 2.5808, LR: 0.000001\n",
      "Epoch [134], Batch [350/391], Loss: 2.6294, LR: 0.000001\n",
      "Train set: Epoch: 134, Average loss:2.2023, LR: 0.000001 Top-1 Accuracy: 50.4600%, Top-5 Accuracy: 78.1620%, Time consumed:203.07s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|██████████████████████████████████████▊                                                | 134/300 [8:23:54<10:25:31, 226.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 134, Average loss:1.4471, Top-1 Accuracy: 60.8500%, Top-5 Accuracy: 87.0500%, Time consumed:18.89s\n",
      "\n",
      "EarlyStopping 카운터: 10 / 30\n",
      "Epoch [135], Batch [50/391], Loss: 1.2147, LR: 0.000001\n",
      "Epoch [135], Batch [100/391], Loss: 1.4663, LR: 0.000001\n",
      "Epoch [135], Batch [150/391], Loss: 1.4152, LR: 0.000001\n",
      "Epoch [135], Batch [200/391], Loss: 1.6360, LR: 0.000001\n",
      "Epoch [135], Batch [250/391], Loss: 1.2903, LR: 0.000001\n",
      "Epoch [135], Batch [300/391], Loss: 2.7766, LR: 0.000001\n",
      "Epoch [135], Batch [350/391], Loss: 2.6751, LR: 0.000001\n",
      "Train set: Epoch: 135, Average loss:2.2031, LR: 0.000001 Top-1 Accuracy: 50.2020%, Top-5 Accuracy: 78.0800%, Time consumed:207.35s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|███████████████████████████████████████▏                                               | 135/300 [8:27:40<10:21:09, 225.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 135, Average loss:1.4536, Top-1 Accuracy: 60.9200%, Top-5 Accuracy: 86.9000%, Time consumed:18.02s\n",
      "\n",
      "EarlyStopping 카운터: 11 / 30\n",
      "Epoch [136], Batch [50/391], Loss: 1.4766, LR: 0.000001\n",
      "Epoch [136], Batch [100/391], Loss: 1.2031, LR: 0.000001\n",
      "Epoch [136], Batch [150/391], Loss: 1.4493, LR: 0.000001\n",
      "Epoch [136], Batch [200/391], Loss: 3.4956, LR: 0.000001\n",
      "Epoch [136], Batch [250/391], Loss: 1.3366, LR: 0.000001\n",
      "Epoch [136], Batch [300/391], Loss: 3.7130, LR: 0.000001\n",
      "Epoch [136], Batch [350/391], Loss: 3.0351, LR: 0.000001\n",
      "Train set: Epoch: 136, Average loss:2.2491, LR: 0.000001 Top-1 Accuracy: 49.9940%, Top-5 Accuracy: 77.4880%, Time consumed:203.53s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|███████████████████████████████████████▍                                               | 136/300 [8:31:21<10:13:59, 224.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 136, Average loss:1.4467, Top-1 Accuracy: 60.8500%, Top-5 Accuracy: 87.2100%, Time consumed:18.20s\n",
      "\n",
      "EarlyStopping 카운터: 12 / 30\n",
      "Epoch [137], Batch [50/391], Loss: 1.4731, LR: 0.000001\n",
      "Epoch [137], Batch [100/391], Loss: 1.5057, LR: 0.000001\n",
      "Epoch [137], Batch [150/391], Loss: 1.4387, LR: 0.000001\n",
      "Epoch [137], Batch [200/391], Loss: 1.3759, LR: 0.000001\n",
      "Epoch [137], Batch [250/391], Loss: 2.2411, LR: 0.000001\n",
      "Epoch [137], Batch [300/391], Loss: 2.6185, LR: 0.000001\n",
      "Epoch [137], Batch [350/391], Loss: 1.3570, LR: 0.000001\n",
      "Train set: Epoch: 137, Average loss:2.1737, LR: 0.000001 Top-1 Accuracy: 50.7880%, Top-5 Accuracy: 78.4080%, Time consumed:205.41s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|███████████████████████████████████████▋                                               | 137/300 [8:35:05<10:09:15, 224.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 137, Average loss:1.4498, Top-1 Accuracy: 60.8000%, Top-5 Accuracy: 87.0700%, Time consumed:18.00s\n",
      "\n",
      "EarlyStopping 카운터: 13 / 30\n",
      "Epoch [138], Batch [50/391], Loss: 3.4530, LR: 0.000001\n",
      "Epoch [138], Batch [100/391], Loss: 1.3024, LR: 0.000001\n",
      "Epoch [138], Batch [150/391], Loss: 1.4557, LR: 0.000001\n",
      "Epoch [138], Batch [200/391], Loss: 1.9575, LR: 0.000001\n",
      "Epoch [138], Batch [250/391], Loss: 1.5670, LR: 0.000001\n",
      "Epoch [138], Batch [300/391], Loss: 1.3795, LR: 0.000001\n",
      "Epoch [138], Batch [350/391], Loss: 1.3630, LR: 0.000001\n",
      "Train set: Epoch: 138, Average loss:2.1770, LR: 0.000001 Top-1 Accuracy: 50.6380%, Top-5 Accuracy: 78.0960%, Time consumed:204.58s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████████████████████████████████████████                                               | 138/300 [8:38:47<10:04:08, 223.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 138, Average loss:1.4512, Top-1 Accuracy: 60.4100%, Top-5 Accuracy: 86.8900%, Time consumed:17.98s\n",
      "\n",
      "EarlyStopping 카운터: 14 / 30\n",
      "Epoch [139], Batch [50/391], Loss: 1.4810, LR: 0.000001\n",
      "Epoch [139], Batch [100/391], Loss: 1.2684, LR: 0.000001\n",
      "Epoch [139], Batch [150/391], Loss: 3.4654, LR: 0.000001\n",
      "Epoch [139], Batch [200/391], Loss: 3.5553, LR: 0.000001\n",
      "Epoch [139], Batch [250/391], Loss: 3.6381, LR: 0.000001\n",
      "Epoch [139], Batch [300/391], Loss: 1.3236, LR: 0.000001\n",
      "Epoch [139], Batch [350/391], Loss: 1.3760, LR: 0.000001\n",
      "Train set: Epoch: 139, Average loss:2.1940, LR: 0.000001 Top-1 Accuracy: 50.2840%, Top-5 Accuracy: 77.6580%, Time consumed:204.14s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████████████████████████████████████████▊                                               | 139/300 [8:42:29<9:59:08, 223.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 139, Average loss:1.4427, Top-1 Accuracy: 60.4200%, Top-5 Accuracy: 86.9800%, Time consumed:18.03s\n",
      "\n",
      "EarlyStopping 카운터: 15 / 30\n",
      "Epoch [140], Batch [50/391], Loss: 3.5920, LR: 0.000001\n",
      "Epoch [140], Batch [100/391], Loss: 1.4498, LR: 0.000001\n",
      "Epoch [140], Batch [150/391], Loss: 1.3393, LR: 0.000001\n",
      "Epoch [140], Batch [200/391], Loss: 1.3194, LR: 0.000001\n",
      "Epoch [140], Batch [250/391], Loss: 1.9105, LR: 0.000001\n",
      "Epoch [140], Batch [300/391], Loss: 2.6471, LR: 0.000001\n",
      "Epoch [140], Batch [350/391], Loss: 1.4615, LR: 0.000001\n",
      "Train set: Epoch: 140, Average loss:2.2073, LR: 0.000001 Top-1 Accuracy: 49.4200%, Top-5 Accuracy: 77.2120%, Time consumed:204.77s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|█████████████████████████████████████████                                               | 140/300 [8:46:13<9:55:39, 223.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 140, Average loss:1.4594, Top-1 Accuracy: 60.5800%, Top-5 Accuracy: 86.7100%, Time consumed:18.79s\n",
      "\n",
      "EarlyStopping 카운터: 16 / 30\n",
      "Epoch [141], Batch [50/391], Loss: 3.3269, LR: 0.000001\n",
      "Epoch [141], Batch [100/391], Loss: 1.3872, LR: 0.000001\n",
      "Epoch [141], Batch [150/391], Loss: 3.2340, LR: 0.000001\n",
      "Epoch [141], Batch [200/391], Loss: 1.2134, LR: 0.000001\n",
      "Epoch [141], Batch [250/391], Loss: 1.3548, LR: 0.000001\n",
      "Epoch [141], Batch [300/391], Loss: 1.3167, LR: 0.000001\n",
      "Epoch [141], Batch [350/391], Loss: 3.7822, LR: 0.000001\n",
      "Train set: Epoch: 141, Average loss:2.1379, LR: 0.000001 Top-1 Accuracy: 51.5240%, Top-5 Accuracy: 79.3120%, Time consumed:202.40s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|█████████████████████████████████████████▎                                              | 141/300 [8:49:54<9:49:48, 222.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 141, Average loss:1.4758, Top-1 Accuracy: 60.4600%, Top-5 Accuracy: 86.5000%, Time consumed:18.30s\n",
      "\n",
      "EarlyStopping 카운터: 17 / 30\n",
      "Epoch [142], Batch [50/391], Loss: 1.7125, LR: 0.000001\n",
      "Epoch [142], Batch [100/391], Loss: 2.8621, LR: 0.000001\n",
      "Epoch [142], Batch [150/391], Loss: 3.5682, LR: 0.000001\n",
      "Epoch [142], Batch [200/391], Loss: 3.5961, LR: 0.000001\n",
      "Epoch [142], Batch [250/391], Loss: 3.1630, LR: 0.000001\n",
      "Epoch [142], Batch [300/391], Loss: 1.4231, LR: 0.000001\n",
      "Epoch [142], Batch [350/391], Loss: 2.2207, LR: 0.000001\n",
      "Train set: Epoch: 142, Average loss:2.1516, LR: 0.000001 Top-1 Accuracy: 50.7360%, Top-5 Accuracy: 78.0740%, Time consumed:205.46s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|█████████████████████████████████████████▋                                              | 142/300 [8:53:37<9:46:56, 222.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 142, Average loss:1.4312, Top-1 Accuracy: 61.2600%, Top-5 Accuracy: 87.0000%, Time consumed:18.15s\n",
      "\n",
      "EarlyStopping 카운터: 18 / 30\n",
      "Epoch [143], Batch [50/391], Loss: 1.4333, LR: 0.000001\n",
      "Epoch [143], Batch [100/391], Loss: 1.3090, LR: 0.000001\n",
      "Epoch [143], Batch [150/391], Loss: 3.4343, LR: 0.000001\n",
      "Epoch [143], Batch [200/391], Loss: 1.4085, LR: 0.000001\n",
      "Epoch [143], Batch [250/391], Loss: 2.9463, LR: 0.000001\n",
      "Epoch [143], Batch [300/391], Loss: 3.3623, LR: 0.000001\n",
      "Epoch [143], Batch [350/391], Loss: 1.4151, LR: 0.000001\n",
      "Train set: Epoch: 143, Average loss:2.1624, LR: 0.000001 Top-1 Accuracy: 50.8100%, Top-5 Accuracy: 78.1780%, Time consumed:202.60s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|█████████████████████████████████████████▉                                              | 143/300 [8:57:19<9:42:19, 222.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 143, Average loss:1.4362, Top-1 Accuracy: 61.0300%, Top-5 Accuracy: 86.9800%, Time consumed:19.13s\n",
      "\n",
      "EarlyStopping 카운터: 19 / 30\n",
      "Epoch [144], Batch [50/391], Loss: 1.4518, LR: 0.000001\n",
      "Epoch [144], Batch [100/391], Loss: 1.5169, LR: 0.000001\n",
      "Epoch [144], Batch [150/391], Loss: 1.5064, LR: 0.000001\n",
      "Epoch [144], Batch [200/391], Loss: 3.4737, LR: 0.000001\n",
      "Epoch [144], Batch [250/391], Loss: 2.6634, LR: 0.000001\n",
      "Epoch [144], Batch [300/391], Loss: 1.3154, LR: 0.000001\n",
      "Epoch [144], Batch [350/391], Loss: 1.4262, LR: 0.000001\n",
      "Train set: Epoch: 144, Average loss:2.1368, LR: 0.000001 Top-1 Accuracy: 50.6440%, Top-5 Accuracy: 78.2200%, Time consumed:204.26s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|██████████████████████████████████████████▏                                             | 144/300 [9:01:03<9:39:21, 222.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 144, Average loss:1.4553, Top-1 Accuracy: 60.6500%, Top-5 Accuracy: 86.7700%, Time consumed:19.23s\n",
      "\n",
      "EarlyStopping 카운터: 20 / 30\n",
      "Epoch [145], Batch [50/391], Loss: 3.3671, LR: 0.000001\n",
      "Epoch [145], Batch [100/391], Loss: 1.4295, LR: 0.000001\n",
      "Epoch [145], Batch [150/391], Loss: 3.4900, LR: 0.000001\n",
      "Epoch [145], Batch [200/391], Loss: 3.4976, LR: 0.000001\n",
      "Epoch [145], Batch [250/391], Loss: 1.3273, LR: 0.000001\n",
      "Epoch [145], Batch [300/391], Loss: 1.2793, LR: 0.000001\n",
      "Epoch [145], Batch [350/391], Loss: 3.1873, LR: 0.000001\n",
      "Train set: Epoch: 145, Average loss:2.2124, LR: 0.000001 Top-1 Accuracy: 49.9600%, Top-5 Accuracy: 77.7080%, Time consumed:206.69s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|██████████████████████████████████████████▌                                             | 145/300 [9:04:49<9:38:21, 223.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 145, Average loss:1.4373, Top-1 Accuracy: 61.0500%, Top-5 Accuracy: 86.9000%, Time consumed:19.62s\n",
      "\n",
      "EarlyStopping 카운터: 21 / 30\n",
      "Epoch [146], Batch [50/391], Loss: 3.4644, LR: 0.000001\n",
      "Epoch [146], Batch [100/391], Loss: 1.2333, LR: 0.000001\n",
      "Epoch [146], Batch [150/391], Loss: 1.2698, LR: 0.000001\n",
      "Epoch [146], Batch [200/391], Loss: 3.7733, LR: 0.000001\n",
      "Epoch [146], Batch [250/391], Loss: 1.4898, LR: 0.000001\n",
      "Epoch [146], Batch [300/391], Loss: 3.6105, LR: 0.000001\n",
      "Epoch [146], Batch [350/391], Loss: 1.4525, LR: 0.000001\n",
      "Train set: Epoch: 146, Average loss:2.2636, LR: 0.000001 Top-1 Accuracy: 49.4880%, Top-5 Accuracy: 76.8340%, Time consumed:203.04s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|██████████████████████████████████████████▊                                             | 146/300 [9:08:30<9:32:18, 222.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 146, Average loss:1.4607, Top-1 Accuracy: 60.5500%, Top-5 Accuracy: 87.0300%, Time consumed:17.83s\n",
      "\n",
      "EarlyStopping 카운터: 22 / 30\n",
      "Epoch [147], Batch [50/391], Loss: 1.5380, LR: 0.000001\n",
      "Epoch [147], Batch [100/391], Loss: 1.3964, LR: 0.000001\n",
      "Epoch [147], Batch [150/391], Loss: 1.3634, LR: 0.000001\n",
      "Epoch [147], Batch [200/391], Loss: 1.4426, LR: 0.000001\n",
      "Epoch [147], Batch [250/391], Loss: 1.3862, LR: 0.000001\n",
      "Epoch [147], Batch [300/391], Loss: 3.7358, LR: 0.000001\n",
      "Epoch [147], Batch [350/391], Loss: 3.4020, LR: 0.000001\n",
      "Train set: Epoch: 147, Average loss:2.1457, LR: 0.000001 Top-1 Accuracy: 50.7080%, Top-5 Accuracy: 77.9060%, Time consumed:204.84s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|███████████████████████████████████████████                                             | 147/300 [9:12:13<9:29:05, 223.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 147, Average loss:1.4584, Top-1 Accuracy: 60.3500%, Top-5 Accuracy: 86.9800%, Time consumed:18.76s\n",
      "\n",
      "EarlyStopping 카운터: 23 / 30\n",
      "Epoch [148], Batch [50/391], Loss: 3.4465, LR: 0.000001\n",
      "Epoch [148], Batch [100/391], Loss: 1.6982, LR: 0.000001\n",
      "Epoch [148], Batch [150/391], Loss: 1.3274, LR: 0.000001\n",
      "Epoch [148], Batch [200/391], Loss: 1.2518, LR: 0.000001\n",
      "Epoch [148], Batch [250/391], Loss: 3.6138, LR: 0.000001\n",
      "Epoch [148], Batch [300/391], Loss: 2.8775, LR: 0.000001\n",
      "Epoch [148], Batch [350/391], Loss: 1.3242, LR: 0.000001\n",
      "Train set: Epoch: 148, Average loss:2.2356, LR: 0.000001 Top-1 Accuracy: 50.2660%, Top-5 Accuracy: 77.6460%, Time consumed:222.14s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|███████████████████████████████████████████▍                                            | 148/300 [9:16:15<9:39:23, 228.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 148, Average loss:1.4370, Top-1 Accuracy: 61.0000%, Top-5 Accuracy: 87.0900%, Time consumed:19.47s\n",
      "\n",
      "EarlyStopping 카운터: 24 / 30\n",
      "Epoch [149], Batch [50/391], Loss: 3.6269, LR: 0.000001\n",
      "Epoch [149], Batch [100/391], Loss: 3.4411, LR: 0.000001\n",
      "Epoch [149], Batch [150/391], Loss: 2.7112, LR: 0.000001\n",
      "Epoch [149], Batch [200/391], Loss: 2.4929, LR: 0.000001\n",
      "Epoch [149], Batch [250/391], Loss: 3.3850, LR: 0.000001\n",
      "Epoch [149], Batch [300/391], Loss: 1.3957, LR: 0.000001\n",
      "Epoch [149], Batch [350/391], Loss: 2.4751, LR: 0.000001\n",
      "Train set: Epoch: 149, Average loss:2.2200, LR: 0.000001 Top-1 Accuracy: 49.8760%, Top-5 Accuracy: 77.4140%, Time consumed:217.61s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████████████████████████████▋                                            | 149/300 [9:20:11<9:41:19, 230.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 149, Average loss:1.4365, Top-1 Accuracy: 60.9600%, Top-5 Accuracy: 87.0600%, Time consumed:18.71s\n",
      "\n",
      "EarlyStopping 카운터: 25 / 30\n",
      "Epoch [150], Batch [50/391], Loss: 1.4501, LR: 0.000001\n",
      "Epoch [150], Batch [100/391], Loss: 3.6540, LR: 0.000001\n",
      "Epoch [150], Batch [150/391], Loss: 3.4845, LR: 0.000001\n",
      "Epoch [150], Batch [200/391], Loss: 1.4374, LR: 0.000001\n",
      "Epoch [150], Batch [250/391], Loss: 1.4484, LR: 0.000001\n",
      "Epoch [150], Batch [300/391], Loss: 1.2317, LR: 0.000001\n",
      "Epoch [150], Batch [350/391], Loss: 1.3284, LR: 0.000001\n",
      "Train set: Epoch: 150, Average loss:2.2665, LR: 0.000001 Top-1 Accuracy: 49.1720%, Top-5 Accuracy: 76.7340%, Time consumed:202.81s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████████████████████████████████                                            | 150/300 [9:23:53<9:30:38, 228.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 150, Average loss:1.4595, Top-1 Accuracy: 60.2900%, Top-5 Accuracy: 86.4300%, Time consumed:19.05s\n",
      "\n",
      "EarlyStopping 카운터: 26 / 30\n",
      "Epoch [151], Batch [50/391], Loss: 3.6297, LR: 0.000001\n",
      "Epoch [151], Batch [100/391], Loss: 1.4543, LR: 0.000001\n",
      "Epoch [151], Batch [150/391], Loss: 3.6221, LR: 0.000001\n",
      "Epoch [151], Batch [200/391], Loss: 1.2981, LR: 0.000001\n",
      "Epoch [151], Batch [250/391], Loss: 1.4513, LR: 0.000001\n",
      "Epoch [151], Batch [300/391], Loss: 3.7315, LR: 0.000001\n",
      "Epoch [151], Batch [350/391], Loss: 1.5041, LR: 0.000001\n",
      "Train set: Epoch: 151, Average loss:2.2532, LR: 0.000001 Top-1 Accuracy: 49.7020%, Top-5 Accuracy: 77.1760%, Time consumed:203.82s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████████████████████████████████▎                                           | 151/300 [9:27:36<9:22:32, 226.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 151, Average loss:1.4571, Top-1 Accuracy: 60.5600%, Top-5 Accuracy: 86.5800%, Time consumed:18.67s\n",
      "\n",
      "EarlyStopping 카운터: 27 / 30\n",
      "Epoch [152], Batch [50/391], Loss: 3.7307, LR: 0.000001\n",
      "Epoch [152], Batch [100/391], Loss: 1.5736, LR: 0.000001\n",
      "Epoch [152], Batch [150/391], Loss: 2.7922, LR: 0.000001\n",
      "Epoch [152], Batch [200/391], Loss: 1.4685, LR: 0.000001\n",
      "Epoch [152], Batch [250/391], Loss: 3.4975, LR: 0.000001\n",
      "Epoch [152], Batch [300/391], Loss: 1.2412, LR: 0.000001\n",
      "Epoch [152], Batch [350/391], Loss: 1.5136, LR: 0.000001\n",
      "Train set: Epoch: 152, Average loss:2.2858, LR: 0.000001 Top-1 Accuracy: 48.6900%, Top-5 Accuracy: 76.5680%, Time consumed:205.18s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|████████████████████████████████████████████▌                                           | 152/300 [9:31:19<9:16:13, 225.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 152, Average loss:1.4427, Top-1 Accuracy: 61.0100%, Top-5 Accuracy: 86.8900%, Time consumed:17.91s\n",
      "\n",
      "EarlyStopping 카운터: 28 / 30\n",
      "Epoch [153], Batch [50/391], Loss: 1.2668, LR: 0.000001\n",
      "Epoch [153], Batch [100/391], Loss: 1.3914, LR: 0.000001\n",
      "Epoch [153], Batch [150/391], Loss: 3.1277, LR: 0.000001\n",
      "Epoch [153], Batch [200/391], Loss: 1.5270, LR: 0.000001\n",
      "Epoch [153], Batch [250/391], Loss: 2.9593, LR: 0.000001\n",
      "Epoch [153], Batch [300/391], Loss: 3.6940, LR: 0.000001\n",
      "Epoch [153], Batch [350/391], Loss: 3.5992, LR: 0.000001\n",
      "Train set: Epoch: 153, Average loss:2.1927, LR: 0.000001 Top-1 Accuracy: 50.4180%, Top-5 Accuracy: 78.1740%, Time consumed:202.13s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|████████████████████████████████████████████▉                                           | 153/300 [9:34:59<9:08:21, 223.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 153, Average loss:1.4352, Top-1 Accuracy: 61.3000%, Top-5 Accuracy: 87.2300%, Time consumed:17.77s\n",
      "\n",
      "EarlyStopping 카운터: 29 / 30\n",
      "Epoch [154], Batch [50/391], Loss: 1.3883, LR: 0.000001\n",
      "Epoch [154], Batch [100/391], Loss: 1.3316, LR: 0.000001\n",
      "Epoch [154], Batch [150/391], Loss: 1.3399, LR: 0.000001\n",
      "Epoch [154], Batch [200/391], Loss: 2.4018, LR: 0.000001\n",
      "Epoch [154], Batch [250/391], Loss: 1.3398, LR: 0.000001\n",
      "Epoch [154], Batch [300/391], Loss: 3.5165, LR: 0.000001\n",
      "Epoch [154], Batch [350/391], Loss: 1.3786, LR: 0.000001\n",
      "Train set: Epoch: 154, Average loss:2.2575, LR: 0.000001 Top-1 Accuracy: 49.2320%, Top-5 Accuracy: 76.7540%, Time consumed:204.37s\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.v2 as transforms_v2  # CutMix를 위한 v2 transforms 추가\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "from tools.tool import AccuracyEarlyStopping, WarmUpLR, SAM  # 수정된 AccuracyEarlyStopping 클래스 임포트\n",
    "from models.efficientnet import efficientnet  # EfficientNet 임포트\n",
    "\n",
    "wandb.login(key=\"ef091b9abcea3186341ddf8995d62bde62d7469e\")\n",
    "wandb.init(project=\"PBL-2\", name=\"efficientnet-b0,lr=0.005,factor=0.5,SAM_SGD,crossentropy\")\n",
    "\n",
    "# WandB 설정\n",
    "config = {\n",
    "    # 모델 설정\n",
    "    \"model\": \"efficientnet-b0\",  # 모델을 efficientnet-b0로 변경\n",
    "    \"batch_size\": 128,    # 동일하게 설정\n",
    "    \"num_epochs\": 300,\n",
    "    \n",
    "    # 모델 파라미터 (EfficientNet-B0 기준)\n",
    "    \"width_multiplier\": 1.0,\n",
    "    \"depth_multiplier\": 1.0,\n",
    "    \"dropout_ratio\": 0.2,\n",
    "    \n",
    "    \"learning_rate\": 0.005,  # 동일하게 설정\n",
    "    \"optimizer\": \"SAM_SGD\",\n",
    "    \"momentum\": 0.9,\n",
    "    \"weight_decay\": 5e-4,\n",
    "    \"nesterov\": True,\n",
    "    \n",
    "    # SAM 옵티마이저 설정\n",
    "    \"rho\": 0.05,\n",
    "    \"adaptive\": False,\n",
    "    \n",
    "    # 학습 과정 설정\n",
    "    \"seed\": 2025,\n",
    "    \"deterministic\": False,\n",
    "    \"patience\": 30,  # early stopping patience\n",
    "    \"max_epochs_wait\": float('inf'),\n",
    "    \n",
    "    # 데이터 증강 설정\n",
    "    \"cutmix_alpha\": 1.0,  # CutMix 알파 파라미터\n",
    "    \"cutmix_prob\": 0.5,   # CutMix 적용 확률\n",
    "    \"crop_padding\": 4,    # RandomCrop 패딩 크기\n",
    "    \"crop_size\": 32,      # RandomCrop 크기 (CIFAR-100 이미지 크기는 32x32)\n",
    "    \n",
    "    # 스케줄러 설정 - 동일하게 적용\n",
    "    \"warmup_epochs\": 10,\n",
    "    \"lr_scheduler\": \"ReduceLROnPlateau\",\n",
    "    \"lr_factor\": 0.5,\n",
    "    \"lr_patience\": 5,\n",
    "    \"lr_threshold\": 0.1,\n",
    "    \"min_lr\": 1e-6,\n",
    "    \n",
    "    # 시스템 설정\n",
    "    \"num_workers\": 32,\n",
    "    \"pin_memory\": True,\n",
    "}\n",
    "\n",
    "wandb.config.update(config)\n",
    "\n",
    "# CIFAR-100 데이터셋 로드 - 기본 train/test 분할 사용\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(config[\"crop_size\"], padding=config[\"crop_padding\"]),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR100(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR100(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "# DataLoader 생성 - config 사용\n",
    "trainloader = DataLoader(\n",
    "    trainset, \n",
    "    batch_size=config[\"batch_size\"], \n",
    "    shuffle=True, \n",
    "    pin_memory=config[\"pin_memory\"], \n",
    "    num_workers=config[\"num_workers\"]\n",
    ")\n",
    "\n",
    "testloader = DataLoader(\n",
    "    testset, \n",
    "    batch_size=config[\"batch_size\"], \n",
    "    shuffle=False, \n",
    "    pin_memory=config[\"pin_memory\"], \n",
    "    num_workers=config[\"num_workers\"]\n",
    ")\n",
    "\n",
    "print(f\"Train set size: {len(trainset)}\")\n",
    "print(f\"Test set size: {len(testset)}\")\n",
    "\n",
    "# CutMix 변환 정의\n",
    "cutmix = transforms_v2.CutMix(alpha=config[\"cutmix_alpha\"], num_classes=100)  # CIFAR-100은 100개 클래스\n",
    "\n",
    "def train(model, trainloader, criterion, optimizer, device, epoch, warmup_scheduler=None, warmup_epochs=None):\n",
    "    \"\"\"\n",
    "    학습 함수 (CutMix 적용)\n",
    "    \"\"\"\n",
    "    # config에서 warmup_epochs 가져오기 (None이면)\n",
    "    if warmup_epochs is None:\n",
    "        warmup_epochs = config[\"warmup_epochs\"]\n",
    "        \n",
    "    model.train()   # 모델을 학습 모드로 설정\n",
    "    start_time = time.time()  # 시간 측정 시작\n",
    "    running_loss = 0.0\n",
    "    correct_top1 = 0\n",
    "    correct_top5 = 0\n",
    "    total = 0\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(trainloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # CutMix 확률적 적용\n",
    "        if random.random() < config[\"cutmix_prob\"]:\n",
    "            inputs, labels = cutmix(inputs, labels)\n",
    "            # 이 경우 labels은 원-핫 인코딩 형태로 변환됨\n",
    "            use_cutmix = True\n",
    "        else:\n",
    "            use_cutmix = False\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # SAM 첫 번째 스텝을 위한 손실 계산\n",
    "        if use_cutmix:\n",
    "            # CutMix가 적용된 경우 (이미 원-핫 인코딩된 레이블)\n",
    "            loss = criterion(outputs, labels)\n",
    "        else:\n",
    "            # 일반적인 경우 (정수 인덱스 레이블)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "        loss.backward()\n",
    "        optimizer.first_step(zero_grad=True)\n",
    "        \n",
    "        # SAM 두 번째 스텝을 위한 손실 계산\n",
    "        outputs = model(inputs)\n",
    "        if use_cutmix:\n",
    "            loss = criterion(outputs, labels)\n",
    "        else:\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.second_step(zero_grad=True)\n",
    "        \n",
    "        # 학습률 스케줄러 업데이트 - warmup 스케줄러만 여기서 업데이트\n",
    "        if epoch < warmup_epochs and warmup_scheduler is not None:\n",
    "            warmup_scheduler.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # 정확도 계산 - CutMix 적용 여부에 따라 다르게 처리\n",
    "        if use_cutmix:\n",
    "            # 원-핫 인코딩된 레이블에서 argmax를 사용해 가장 큰 값의 인덱스 추출\n",
    "            _, label_idx = labels.max(1)\n",
    "        else:\n",
    "            # 정수 인덱스 레이블 그대로 사용\n",
    "            label_idx = labels\n",
    "            \n",
    "        # top-1 정확도 계산\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += inputs.size(0)\n",
    "        correct_top1 += predicted.eq(label_idx).sum().item()\n",
    "        \n",
    "        # top-5 정확도 계산\n",
    "        _, top5_idx = outputs.topk(5, 1, largest=True, sorted=True)\n",
    "        correct_top5 += sum([1 for i in range(len(label_idx)) if label_idx[i] in top5_idx[i]])\n",
    "        \n",
    "        if (i + 1) % 50 == 0:  # 50 배치마다 출력\n",
    "            print(f'Epoch [{epoch+1}], Batch [{i+1}/{len(trainloader)}], Loss: {loss.item():.4f}, LR: {optimizer.param_groups[0][\"lr\"]:.6f}')\n",
    "    \n",
    "    epoch_loss = running_loss / len(trainloader)\n",
    "    accuracy_top1 = 100.0 * correct_top1 / total\n",
    "    accuracy_top5 = 100.0 * correct_top5 / total\n",
    "    \n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    # 학습 세트에 대한 성능 출력\n",
    "    print(f'Train set: Epoch: {epoch+1}, Average loss:{epoch_loss:.4f}, LR: {optimizer.param_groups[0][\"lr\"]:.6f} '\n",
    "          f'Top-1 Accuracy: {accuracy_top1:.4f}%, Top-5 Accuracy: {accuracy_top5:.4f}%, Time consumed:{train_time:.2f}s')\n",
    "    \n",
    "    return epoch_loss, accuracy_top1, accuracy_top5\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device, epoch, phase=\"test\"):\n",
    "    \"\"\"\n",
    "    평가 함수 (표준 CrossEntropyLoss 적용)\n",
    "    \"\"\"\n",
    "    model.eval()  # 모델을 평가 모드로 설정\n",
    "    start_time = time.time()  # 시간 측정 시작\n",
    "    \n",
    "    eval_loss = 0.0\n",
    "    correct_top1 = 0\n",
    "    correct_top5 = 0\n",
    "    total = 0\n",
    "    \n",
    "    # 그래디언트 계산 비활성화\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # 순전파\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # 표준 손실 계산\n",
    "            loss = criterion(outputs, labels)\n",
    "            eval_loss += loss.item()\n",
    "            \n",
    "            # top-1 정확도 계산\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct_top1 += (predicted == labels).sum().item()\n",
    "            \n",
    "            # top-5 정확도 계산\n",
    "            _, top5_idx = outputs.topk(5, 1, largest=True, sorted=True)\n",
    "            correct_top5 += top5_idx.eq(labels.view(-1, 1).expand_as(top5_idx)).sum().item()\n",
    "    \n",
    "    # 평균 손실 및 정확도 계산\n",
    "    eval_loss = eval_loss / len(dataloader)\n",
    "    accuracy_top1 = 100.0 * correct_top1 / total\n",
    "    accuracy_top5 = 100.0 * correct_top5 / total\n",
    "    \n",
    "    # 평가 시간 계산\n",
    "    eval_time = time.time() - start_time\n",
    "    \n",
    "    # 테스트 세트에 대한 성능 출력\n",
    "    print(f'{phase.capitalize()} set: Epoch: {epoch+1}, Average loss:{eval_loss:.4f}, '\n",
    "          f'Top-1 Accuracy: {accuracy_top1:.4f}%, Top-5 Accuracy: {accuracy_top5:.4f}%, Time consumed:{eval_time:.2f}s')\n",
    "    print()\n",
    "    \n",
    "    return eval_loss, accuracy_top1, accuracy_top5\n",
    "\n",
    "# 메인 학습 루프\n",
    "def main_training_loop(model, trainloader, testloader, criterion, optimizer, device, num_epochs=None, patience=None, max_epochs_wait=None, warmup_scheduler=None, main_scheduler=None, warmup_epochs=None):\n",
    "    \"\"\"\n",
    "    메인 학습 루프 (accuracy 기준 early stopping) - config에서 기본값 가져오기\n",
    "    \"\"\"\n",
    "    # config에서 값 가져오기 (None이면)\n",
    "    if num_epochs is None:\n",
    "        num_epochs = config[\"num_epochs\"]\n",
    "    if patience is None:\n",
    "        patience = config[\"patience\"]\n",
    "    if max_epochs_wait is None:\n",
    "        max_epochs_wait = config[\"max_epochs_wait\"]\n",
    "    if warmup_epochs is None:\n",
    "        warmup_epochs = config[\"warmup_epochs\"]\n",
    "        \n",
    "    # 정확도 기반 얼리 스토핑 사용\n",
    "    early_stopping = AccuracyEarlyStopping(patience=patience, verbose=True, path='checkpoint.pt', max_epochs=max_epochs_wait)\n",
    "    \n",
    "    best_test_acc_top1 = 0.0\n",
    "    best_test_acc_top5 = 0.0\n",
    "    \n",
    "    # 테스트 정확도 기록을 위한 리스트\n",
    "    test_acc_top1_history = []\n",
    "    \n",
    "    # tqdm을 사용한 진행 상황 표시\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        # 학습\n",
    "        train_loss, train_acc_top1, train_acc_top5 = train(\n",
    "            model, \n",
    "            trainloader, \n",
    "            criterion, \n",
    "            optimizer, \n",
    "            device, \n",
    "            epoch, \n",
    "            warmup_scheduler, \n",
    "            warmup_epochs\n",
    "        )\n",
    "        \n",
    "        # 테스트 데이터로 평가\n",
    "        test_loss, test_acc_top1, test_acc_top5 = evaluate(model, testloader, criterion, device, epoch, phase=\"test\")\n",
    "\n",
    "        # 웜업 이후 스케줄러 업데이트 \n",
    "        if epoch >= warmup_epochs and main_scheduler is not None:\n",
    "            if isinstance(main_scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "                main_scheduler.step(test_acc_top1)  # 테스트 정확도에 따라 학습률 업데이트\n",
    "            else:\n",
    "                main_scheduler.step()  # 다른 스케줄러 (예: CosineAnnealingLR)\n",
    "            \n",
    "        # 테스트 정확도 기록\n",
    "        test_acc_top1_history.append(test_acc_top1)\n",
    "        \n",
    "        # WandB에 로깅\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_accuracy_top1\": train_acc_top1,\n",
    "            \"train_accuracy_top5\": train_acc_top5,\n",
    "            \"test_loss\": test_loss,\n",
    "            \"test_accuracy_top1\": test_acc_top1,\n",
    "            \"test_accuracy_top5\": test_acc_top5\n",
    "        })\n",
    "            \n",
    "        # 최고 정확도 모델 저장 (top-1 기준)\n",
    "        if test_acc_top1 > best_test_acc_top1:\n",
    "            best_test_acc_top1 = test_acc_top1\n",
    "            best_test_acc_top5_at_best_top1 = test_acc_top5\n",
    "            print(f'새로운 최고 top-1 정확도: {best_test_acc_top1:.2f}%, top-5 정확도: {best_test_acc_top5_at_best_top1:.2f}%')\n",
    "            # 모델 저장\n",
    "            model_path = f'best_model_{wandb.run.name}.pth'\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            \n",
    "            # WandB에 모델 아티팩트 저장\n",
    "            wandb.save(model_path)\n",
    "        \n",
    "        # top-5 accuracy 기록 업데이트\n",
    "        if test_acc_top5 > best_test_acc_top5:\n",
    "            best_test_acc_top5 = test_acc_top5\n",
    "            print(f'새로운 최고 top-5 정확도: {best_test_acc_top5:.2f}%')\n",
    "\n",
    "        # Early stopping 체크 (test_acc_top1 기준)\n",
    "        early_stopping(test_acc_top1, model, epoch)\n",
    "        if early_stopping.early_stop:\n",
    "            print(f\"에폭 {epoch+1}에서 학습 조기 종료. 최고 성능 에폭: {early_stopping.best_epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    # 훈련 완료 후 최고 모델 로드\n",
    "    print(\"테스트 정확도 기준 최고 모델 로드 중...\")\n",
    "    model_path = f'best_model_{wandb.run.name}.pth'\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    # 최종 테스트 세트 평가\n",
    "    final_test_loss, final_test_acc_top1, final_test_acc_top5 = evaluate(model, testloader, criterion, device, num_epochs-1, phase=\"test\")\n",
    "    \n",
    "    print(f'완료! 최고 테스트 top-1 정확도: {best_test_acc_top1:.2f}%, 최고 테스트 top-5 정확도: {best_test_acc_top5:.2f}%')\n",
    "    print(f'최종 테스트 top-1 정확도: {final_test_acc_top1:.2f}%, 최종 테스트 top-5 정확도: {final_test_acc_top5:.2f}%')\n",
    "    \n",
    "    # WandB에 최종 결과 기록\n",
    "    wandb.run.summary[\"best_test_accuracy_top1\"] = best_test_acc_top1\n",
    "    wandb.run.summary[\"best_test_accuracy_top5\"] = best_test_acc_top5\n",
    "    wandb.run.summary[\"final_test_accuracy_top1\"] = final_test_acc_top1\n",
    "    wandb.run.summary[\"final_test_accuracy_top5\"] = final_test_acc_top5\n",
    "\n",
    "    # Early stopping 정보 저장\n",
    "    if early_stopping.early_stop:\n",
    "        wandb.run.summary[\"early_stopped\"] = True\n",
    "        wandb.run.summary[\"early_stopped_epoch\"] = epoch+1\n",
    "        wandb.run.summary[\"best_epoch\"] = early_stopping.best_epoch+1\n",
    "    else:\n",
    "        wandb.run.summary[\"early_stopped\"] = False\n",
    "\n",
    "\n",
    "# 디바이스 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 모델 초기화 - config 기반\n",
    "if config[\"model\"] == \"efficientnet-b0\":\n",
    "    # EfficientNet-B0 모델 초기화\n",
    "    model = efficientnet(\n",
    "        width_multipler=config[\"width_multiplier\"],\n",
    "        depth_multipler=config[\"depth_multiplier\"],\n",
    "        num_class=100,  # CIFAR-100에는 100개 클래스\n",
    "        do_ratio=config[\"dropout_ratio\"]\n",
    "    ).to(device)\n",
    "else:\n",
    "    raise ValueError(f\"지원되지 않는 모델: {config['model']}\")\n",
    "\n",
    "# CrossEntropyLoss 손실 함수 설정\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 옵티마이저 설정\n",
    "if config[\"optimizer\"] == \"SAM_SGD\":\n",
    "    base_optimizer = optim.SGD\n",
    "    optimizer = SAM(\n",
    "        model.parameters(), \n",
    "        base_optimizer, \n",
    "        lr=config[\"learning_rate\"],\n",
    "        momentum=config[\"momentum\"],\n",
    "        weight_decay=config[\"weight_decay\"],\n",
    "        nesterov=config[\"nesterov\"],\n",
    "        rho=config[\"rho\"],\n",
    "        adaptive=config[\"adaptive\"]\n",
    "    )\n",
    "else:\n",
    "    raise ValueError(f\"지원되지 않는 옵티마이저: {config['optimizer']}\")\n",
    "\n",
    "# WarmUpLR 스케줄러 초기화\n",
    "warmup_steps = config[\"warmup_epochs\"] * len(trainloader)\n",
    "warmup_scheduler = WarmUpLR(optimizer, total_iters=warmup_steps)\n",
    "\n",
    "if config[\"lr_scheduler\"] == \"ReduceLROnPlateau\":\n",
    "    main_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, \n",
    "        mode='max',\n",
    "        factor=config[\"lr_factor\"],\n",
    "        patience=config[\"lr_patience\"],\n",
    "        verbose=True,\n",
    "        threshold=config[\"lr_threshold\"],\n",
    "        min_lr=config[\"min_lr\"]\n",
    "    )\n",
    "else:\n",
    "    raise ValueError(f\"지원되지 않는 스케줄러: {config['lr_scheduler']}\")\n",
    "\n",
    "# WandB에 모델 구조 기록\n",
    "wandb.watch(model, log=\"all\")\n",
    "\n",
    "# GPU 가속 - 여러 GPU 사용\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"{torch.cuda.device_count()}개의 GPU를 사용합니다.\")\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "# 훈련 시작 시간 기록\n",
    "start_time = time.time()\n",
    "\n",
    "# 메인 학습 루프 호출\n",
    "main_training_loop(\n",
    "    model=model,\n",
    "    trainloader=trainloader,\n",
    "    testloader=testloader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    warmup_scheduler=warmup_scheduler,\n",
    "    main_scheduler=main_scheduler\n",
    ")\n",
    "\n",
    "# 훈련 종료 시간 기록 및 출력\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "wandb.log({\"total_training_time\": total_time})\n",
    "\n",
    "print(f\"전체 학습 시간: {total_time:.2f} 초\")\n",
    "\n",
    "# WandB 실행 종료\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57b9218-aa24-4297-bb92-473c215e6767",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
