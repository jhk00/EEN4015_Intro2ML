{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "516f9d5f-6361-4b03-98ee-e1ba4de86b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/guswls/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msokjh1310\u001b[0m (\u001b[33msokjh1310-hanyang-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/guswls/EEN4015_Intro2ML/pbl-2/wandb/run-20250430_054810-vwv8smvj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/vwv8smvj' target=\"_blank\">resnet18_cfc,lr=0.01,factor=0.5,SAM_SGD,PSKD</a></strong> to <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/vwv8smvj' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/vwv8smvj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Train set size: 50000\n",
      "Test set size: 10000\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2개의 GPU를 사용합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                       | 0/300 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Batch [50/391], Loss: 4.8711, LR: 0.000128\n",
      "Epoch [1], Batch [100/391], Loss: 4.8324, LR: 0.000256\n",
      "Epoch [1], Batch [150/391], Loss: 4.7646, LR: 0.000384\n",
      "Epoch [1], Batch [200/391], Loss: 4.6984, LR: 0.000512\n",
      "Epoch [1], Batch [250/391], Loss: 4.7285, LR: 0.000639\n",
      "Epoch [1], Batch [300/391], Loss: 4.6238, LR: 0.000767\n",
      "Epoch [1], Batch [350/391], Loss: 4.5379, LR: 0.000895\n",
      "Train set: Epoch: 1, Average loss:4.7127, LR: 0.001000 Top-1 Accuracy: 0.9540%, Top-5 Accuracy: 5.0920%, Time consumed:91.68s\n",
      "Test set: Epoch: 1, Average loss:4.1102, Top-1 Accuracy: 7.4500%, Top-5 Accuracy: 24.8600%, Time consumed:8.88s\n",
      "\n",
      "새로운 최고 top-1 정확도: 7.45%, top-5 정확도: 24.86%\n",
      "새로운 최고 top-5 정확도: 24.86%\n",
      "Accuracy improved (-inf% --> 7.45%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                                           | 1/300 [01:40<8:22:09, 100.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], Batch [50/391], Loss: 4.4933, LR: 0.001128\n",
      "Epoch [2], Batch [100/391], Loss: 4.2763, LR: 0.001256\n",
      "Epoch [2], Batch [150/391], Loss: 4.5365, LR: 0.001384\n",
      "Epoch [2], Batch [200/391], Loss: 4.3563, LR: 0.001512\n",
      "Epoch [2], Batch [250/391], Loss: 4.2621, LR: 0.001639\n",
      "Epoch [2], Batch [300/391], Loss: 4.2720, LR: 0.001767\n",
      "Epoch [2], Batch [350/391], Loss: 4.3729, LR: 0.001895\n",
      "Train set: Epoch: 2, Average loss:4.2149, LR: 0.002000 Top-1 Accuracy: 5.8460%, Top-5 Accuracy: 21.5580%, Time consumed:94.21s\n",
      "Test set: Epoch: 2, Average loss:3.6289, Top-1 Accuracy: 14.6500%, Top-5 Accuracy: 39.5600%, Time consumed:9.38s\n",
      "\n",
      "새로운 최고 top-1 정확도: 14.65%, top-5 정확도: 39.56%\n",
      "새로운 최고 top-5 정확도: 39.56%\n",
      "Accuracy improved (7.45% --> 14.65%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▌                                                                                           | 2/300 [03:24<8:29:22, 102.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3], Batch [50/391], Loss: 4.0710, LR: 0.002128\n",
      "Epoch [3], Batch [100/391], Loss: 3.7396, LR: 0.002256\n",
      "Epoch [3], Batch [150/391], Loss: 3.9064, LR: 0.002384\n",
      "Epoch [3], Batch [200/391], Loss: 3.6869, LR: 0.002512\n",
      "Epoch [3], Batch [250/391], Loss: 3.9242, LR: 0.002639\n",
      "Epoch [3], Batch [300/391], Loss: 3.7124, LR: 0.002767\n",
      "Epoch [3], Batch [350/391], Loss: 3.6763, LR: 0.002895\n",
      "Train set: Epoch: 3, Average loss:3.9369, LR: 0.003000 Top-1 Accuracy: 10.5320%, Top-5 Accuracy: 31.8360%, Time consumed:98.58s\n",
      "Test set: Epoch: 3, Average loss:3.3449, Top-1 Accuracy: 19.1300%, Top-5 Accuracy: 47.4500%, Time consumed:9.67s\n",
      "\n",
      "새로운 최고 top-1 정확도: 19.13%, top-5 정확도: 47.45%\n",
      "새로운 최고 top-5 정확도: 47.45%\n",
      "Accuracy improved (14.65% --> 19.13%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▉                                                                                           | 3/300 [05:13<8:41:06, 105.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4], Batch [50/391], Loss: 3.5717, LR: 0.003128\n",
      "Epoch [4], Batch [100/391], Loss: 3.3360, LR: 0.003256\n",
      "Epoch [4], Batch [150/391], Loss: 3.4064, LR: 0.003384\n",
      "Epoch [4], Batch [200/391], Loss: 3.9116, LR: 0.003512\n",
      "Epoch [4], Batch [250/391], Loss: 3.5422, LR: 0.003639\n",
      "Epoch [4], Batch [300/391], Loss: 3.2772, LR: 0.003767\n",
      "Epoch [4], Batch [350/391], Loss: 4.3791, LR: 0.003895\n",
      "Train set: Epoch: 4, Average loss:3.7018, LR: 0.004000 Top-1 Accuracy: 15.2480%, Top-5 Accuracy: 40.0400%, Time consumed:90.99s\n",
      "Test set: Epoch: 4, Average loss:2.9407, Top-1 Accuracy: 26.8100%, Top-5 Accuracy: 57.1700%, Time consumed:9.95s\n",
      "\n",
      "새로운 최고 top-1 정확도: 26.81%, top-5 정확도: 57.17%\n",
      "새로운 최고 top-5 정확도: 57.17%\n",
      "Accuracy improved (19.13% --> 26.81%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▏                                                                                          | 4/300 [06:54<8:31:26, 103.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5], Batch [50/391], Loss: 3.1122, LR: 0.004128\n",
      "Epoch [5], Batch [100/391], Loss: 3.2133, LR: 0.004256\n",
      "Epoch [5], Batch [150/391], Loss: 3.2978, LR: 0.004384\n",
      "Epoch [5], Batch [200/391], Loss: 3.9158, LR: 0.004512\n",
      "Epoch [5], Batch [250/391], Loss: 4.3128, LR: 0.004639\n",
      "Epoch [5], Batch [300/391], Loss: 2.8309, LR: 0.004767\n",
      "Epoch [5], Batch [350/391], Loss: 2.9648, LR: 0.004895\n",
      "Train set: Epoch: 5, Average loss:3.4514, LR: 0.005000 Top-1 Accuracy: 19.7440%, Top-5 Accuracy: 47.2800%, Time consumed:92.26s\n",
      "Test set: Epoch: 5, Average loss:2.6550, Top-1 Accuracy: 32.0700%, Top-5 Accuracy: 63.8600%, Time consumed:9.56s\n",
      "\n",
      "새로운 최고 top-1 정확도: 32.07%, top-5 정확도: 63.86%\n",
      "새로운 최고 top-5 정확도: 63.86%\n",
      "Accuracy improved (26.81% --> 32.07%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▌                                                                                          | 5/300 [08:36<8:26:53, 103.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6], Batch [50/391], Loss: 2.9190, LR: 0.005128\n",
      "Epoch [6], Batch [100/391], Loss: 2.7391, LR: 0.005256\n",
      "Epoch [6], Batch [150/391], Loss: 2.9586, LR: 0.005384\n",
      "Epoch [6], Batch [200/391], Loss: 2.9551, LR: 0.005512\n",
      "Epoch [6], Batch [250/391], Loss: 3.5977, LR: 0.005639\n",
      "Epoch [6], Batch [300/391], Loss: 2.7482, LR: 0.005767\n",
      "Epoch [6], Batch [350/391], Loss: 3.0441, LR: 0.005895\n",
      "Train set: Epoch: 6, Average loss:3.2483, LR: 0.006000 Top-1 Accuracy: 24.0560%, Top-5 Accuracy: 53.3580%, Time consumed:89.35s\n",
      "Test set: Epoch: 6, Average loss:2.4404, Top-1 Accuracy: 36.4700%, Top-5 Accuracy: 68.5400%, Time consumed:9.51s\n",
      "\n",
      "새로운 최고 top-1 정확도: 36.47%, top-5 정확도: 68.54%\n",
      "새로운 최고 top-5 정확도: 68.54%\n",
      "Accuracy improved (32.07% --> 36.47%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▊                                                                                          | 6/300 [10:15<8:18:34, 101.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7], Batch [50/391], Loss: 2.6375, LR: 0.006128\n",
      "Epoch [7], Batch [100/391], Loss: 3.3782, LR: 0.006256\n",
      "Epoch [7], Batch [150/391], Loss: 2.4947, LR: 0.006384\n",
      "Epoch [7], Batch [200/391], Loss: 2.6586, LR: 0.006512\n",
      "Epoch [7], Batch [250/391], Loss: 2.4493, LR: 0.006639\n",
      "Epoch [7], Batch [300/391], Loss: 3.9029, LR: 0.006767\n",
      "Epoch [7], Batch [350/391], Loss: 4.0977, LR: 0.006895\n",
      "Train set: Epoch: 7, Average loss:3.0794, LR: 0.007000 Top-1 Accuracy: 27.8980%, Top-5 Accuracy: 57.6000%, Time consumed:89.09s\n",
      "Test set: Epoch: 7, Average loss:2.3211, Top-1 Accuracy: 38.6100%, Top-5 Accuracy: 71.5400%, Time consumed:10.34s\n",
      "\n",
      "새로운 최고 top-1 정확도: 38.61%, top-5 정확도: 71.54%\n",
      "새로운 최고 top-5 정확도: 71.54%\n",
      "Accuracy improved (36.47% --> 38.61%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██▏                                                                                         | 7/300 [11:55<8:13:32, 101.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8], Batch [50/391], Loss: 2.5681, LR: 0.007128\n",
      "Epoch [8], Batch [100/391], Loss: 3.3431, LR: 0.007256\n",
      "Epoch [8], Batch [150/391], Loss: 3.3180, LR: 0.007384\n",
      "Epoch [8], Batch [200/391], Loss: 2.2029, LR: 0.007512\n",
      "Epoch [8], Batch [250/391], Loss: 2.6646, LR: 0.007639\n",
      "Epoch [8], Batch [300/391], Loss: 2.3223, LR: 0.007767\n",
      "Epoch [8], Batch [350/391], Loss: 3.9223, LR: 0.007895\n",
      "Train set: Epoch: 8, Average loss:2.8880, LR: 0.008000 Top-1 Accuracy: 31.6400%, Top-5 Accuracy: 62.3700%, Time consumed:89.01s\n",
      "Test set: Epoch: 8, Average loss:2.0036, Top-1 Accuracy: 46.4300%, Top-5 Accuracy: 77.1600%, Time consumed:9.43s\n",
      "\n",
      "새로운 최고 top-1 정확도: 46.43%, top-5 정확도: 77.16%\n",
      "새로운 최고 top-5 정확도: 77.16%\n",
      "Accuracy improved (38.61% --> 46.43%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▍                                                                                         | 8/300 [13:33<8:08:10, 100.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9], Batch [50/391], Loss: 2.2645, LR: 0.008128\n",
      "Epoch [9], Batch [100/391], Loss: 2.1776, LR: 0.008256\n",
      "Epoch [9], Batch [150/391], Loss: 3.6509, LR: 0.008384\n",
      "Epoch [9], Batch [200/391], Loss: 3.8754, LR: 0.008512\n",
      "Epoch [9], Batch [250/391], Loss: 3.7747, LR: 0.008639\n",
      "Epoch [9], Batch [300/391], Loss: 2.1238, LR: 0.008767\n",
      "Epoch [9], Batch [350/391], Loss: 3.4588, LR: 0.008895\n",
      "Train set: Epoch: 9, Average loss:2.8230, LR: 0.009000 Top-1 Accuracy: 34.0540%, Top-5 Accuracy: 64.3340%, Time consumed:89.27s\n",
      "Test set: Epoch: 9, Average loss:1.9883, Top-1 Accuracy: 47.0900%, Top-5 Accuracy: 77.5600%, Time consumed:9.84s\n",
      "\n",
      "새로운 최고 top-1 정확도: 47.09%, top-5 정확도: 77.56%\n",
      "새로운 최고 top-5 정확도: 77.56%\n",
      "Accuracy improved (46.43% --> 47.09%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▊                                                                                         | 9/300 [15:13<8:05:02, 100.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10], Batch [50/391], Loss: 3.6058, LR: 0.009128\n",
      "Epoch [10], Batch [100/391], Loss: 2.3598, LR: 0.009256\n",
      "Epoch [10], Batch [150/391], Loss: 2.6396, LR: 0.009384\n",
      "Epoch [10], Batch [200/391], Loss: 1.9265, LR: 0.009512\n",
      "Epoch [10], Batch [250/391], Loss: 3.7525, LR: 0.009639\n",
      "Epoch [10], Batch [300/391], Loss: 1.9879, LR: 0.009767\n",
      "Epoch [10], Batch [350/391], Loss: 3.6061, LR: 0.009895\n",
      "Train set: Epoch: 10, Average loss:2.6965, LR: 0.010000 Top-1 Accuracy: 37.2260%, Top-5 Accuracy: 67.8220%, Time consumed:89.48s\n",
      "Test set: Epoch: 10, Average loss:1.8268, Top-1 Accuracy: 51.2300%, Top-5 Accuracy: 80.3600%, Time consumed:9.43s\n",
      "\n",
      "새로운 최고 top-1 정확도: 51.23%, top-5 정확도: 80.36%\n",
      "새로운 최고 top-5 정확도: 80.36%\n",
      "Accuracy improved (47.09% --> 51.23%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|███                                                                                         | 10/300 [16:52<8:02:06, 99.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11], Batch [50/391], Loss: 1.8386, LR: 0.010000\n",
      "Epoch [11], Batch [100/391], Loss: 1.8184, LR: 0.010000\n",
      "Epoch [11], Batch [150/391], Loss: 1.9593, LR: 0.010000\n",
      "Epoch [11], Batch [200/391], Loss: 3.6770, LR: 0.010000\n",
      "Epoch [11], Batch [250/391], Loss: 3.7431, LR: 0.010000\n",
      "Epoch [11], Batch [300/391], Loss: 3.3862, LR: 0.010000\n",
      "Epoch [11], Batch [350/391], Loss: 2.6467, LR: 0.010000\n",
      "Train set: Epoch: 11, Average loss:2.6177, LR: 0.010000 Top-1 Accuracy: 39.4180%, Top-5 Accuracy: 69.7800%, Time consumed:90.33s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▎                                                                                        | 11/300 [18:32<8:00:29, 99.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 11, Average loss:1.9179, Top-1 Accuracy: 48.5800%, Top-5 Accuracy: 79.0200%, Time consumed:9.45s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [12], Batch [50/391], Loss: 1.6956, LR: 0.010000\n",
      "Epoch [12], Batch [100/391], Loss: 2.3260, LR: 0.010000\n",
      "Epoch [12], Batch [150/391], Loss: 1.7603, LR: 0.010000\n",
      "Epoch [12], Batch [200/391], Loss: 1.7583, LR: 0.010000\n",
      "Epoch [12], Batch [250/391], Loss: 3.5296, LR: 0.010000\n",
      "Epoch [12], Batch [300/391], Loss: 1.7929, LR: 0.010000\n",
      "Epoch [12], Batch [350/391], Loss: 2.9046, LR: 0.010000\n",
      "Train set: Epoch: 12, Average loss:2.4639, LR: 0.010000 Top-1 Accuracy: 42.8100%, Top-5 Accuracy: 72.4300%, Time consumed:88.93s\n",
      "Test set: Epoch: 12, Average loss:1.6833, Top-1 Accuracy: 54.0000%, Top-5 Accuracy: 82.5300%, Time consumed:9.48s\n",
      "\n",
      "새로운 최고 top-1 정확도: 54.00%, top-5 정확도: 82.53%\n",
      "새로운 최고 top-5 정확도: 82.53%\n",
      "Accuracy improved (51.23% --> 54.00%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▋                                                                                        | 12/300 [20:10<7:57:16, 99.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13], Batch [50/391], Loss: 1.6726, LR: 0.010000\n",
      "Epoch [13], Batch [100/391], Loss: 1.5952, LR: 0.010000\n",
      "Epoch [13], Batch [150/391], Loss: 2.2987, LR: 0.010000\n",
      "Epoch [13], Batch [200/391], Loss: 2.9115, LR: 0.010000\n",
      "Epoch [13], Batch [250/391], Loss: 1.5425, LR: 0.010000\n",
      "Epoch [13], Batch [300/391], Loss: 1.5790, LR: 0.010000\n",
      "Epoch [13], Batch [350/391], Loss: 1.6435, LR: 0.010000\n",
      "Train set: Epoch: 13, Average loss:2.4266, LR: 0.010000 Top-1 Accuracy: 44.4640%, Top-5 Accuracy: 73.9800%, Time consumed:89.29s\n",
      "Test set: Epoch: 13, Average loss:1.6245, Top-1 Accuracy: 55.9000%, Top-5 Accuracy: 84.3100%, Time consumed:9.08s\n",
      "\n",
      "새로운 최고 top-1 정확도: 55.90%, top-5 정확도: 84.31%\n",
      "새로운 최고 top-5 정확도: 84.31%\n",
      "Accuracy improved (54.00% --> 55.90%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▉                                                                                        | 13/300 [21:49<7:54:28, 99.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14], Batch [50/391], Loss: 1.7818, LR: 0.010000\n",
      "Epoch [14], Batch [100/391], Loss: 1.5817, LR: 0.010000\n",
      "Epoch [14], Batch [150/391], Loss: 1.8251, LR: 0.010000\n",
      "Epoch [14], Batch [200/391], Loss: 1.8583, LR: 0.010000\n",
      "Epoch [14], Batch [250/391], Loss: 3.3186, LR: 0.010000\n",
      "Epoch [14], Batch [300/391], Loss: 2.2282, LR: 0.010000\n",
      "Epoch [14], Batch [350/391], Loss: 1.6284, LR: 0.010000\n",
      "Train set: Epoch: 14, Average loss:2.2562, LR: 0.010000 Top-1 Accuracy: 48.2960%, Top-5 Accuracy: 77.9820%, Time consumed:88.97s\n",
      "Test set: Epoch: 14, Average loss:1.4788, Top-1 Accuracy: 59.0700%, Top-5 Accuracy: 86.2400%, Time consumed:10.51s\n",
      "\n",
      "새로운 최고 top-1 정확도: 59.07%, top-5 정확도: 86.24%\n",
      "새로운 최고 top-5 정확도: 86.24%\n",
      "Accuracy improved (55.90% --> 59.07%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▎                                                                                       | 14/300 [23:29<7:53:35, 99.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15], Batch [50/391], Loss: 3.5606, LR: 0.010000\n",
      "Epoch [15], Batch [100/391], Loss: 1.4924, LR: 0.010000\n",
      "Epoch [15], Batch [150/391], Loss: 1.4852, LR: 0.010000\n",
      "Epoch [15], Batch [200/391], Loss: 1.5378, LR: 0.010000\n",
      "Epoch [15], Batch [250/391], Loss: 1.6214, LR: 0.010000\n",
      "Epoch [15], Batch [300/391], Loss: 3.7366, LR: 0.010000\n",
      "Epoch [15], Batch [350/391], Loss: 1.4840, LR: 0.010000\n",
      "Train set: Epoch: 15, Average loss:2.3049, LR: 0.010000 Top-1 Accuracy: 48.4660%, Top-5 Accuracy: 77.2700%, Time consumed:89.18s\n",
      "Test set: Epoch: 15, Average loss:1.4672, Top-1 Accuracy: 59.3300%, Top-5 Accuracy: 86.5500%, Time consumed:9.82s\n",
      "\n",
      "새로운 최고 top-1 정확도: 59.33%, top-5 정확도: 86.55%\n",
      "새로운 최고 top-5 정확도: 86.55%\n",
      "Accuracy improved (59.07% --> 59.33%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▌                                                                                       | 15/300 [25:08<7:51:49, 99.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16], Batch [50/391], Loss: 1.5103, LR: 0.010000\n",
      "Epoch [16], Batch [100/391], Loss: 1.7214, LR: 0.010000\n",
      "Epoch [16], Batch [150/391], Loss: 1.4331, LR: 0.010000\n",
      "Epoch [16], Batch [200/391], Loss: 3.4815, LR: 0.010000\n",
      "Epoch [16], Batch [250/391], Loss: 3.5558, LR: 0.010000\n",
      "Epoch [16], Batch [300/391], Loss: 1.7113, LR: 0.010000\n",
      "Epoch [16], Batch [350/391], Loss: 1.7244, LR: 0.010000\n",
      "Train set: Epoch: 16, Average loss:2.2395, LR: 0.010000 Top-1 Accuracy: 49.5880%, Top-5 Accuracy: 77.7480%, Time consumed:89.28s\n",
      "Test set: Epoch: 16, Average loss:1.3282, Top-1 Accuracy: 62.5300%, Top-5 Accuracy: 88.3400%, Time consumed:9.48s\n",
      "\n",
      "새로운 최고 top-1 정확도: 62.53%, top-5 정확도: 88.34%\n",
      "새로운 최고 top-5 정확도: 88.34%\n",
      "Accuracy improved (59.33% --> 62.53%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▉                                                                                       | 16/300 [26:47<7:49:43, 99.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17], Batch [50/391], Loss: 3.1276, LR: 0.010000\n",
      "Epoch [17], Batch [100/391], Loss: 2.9143, LR: 0.010000\n",
      "Epoch [17], Batch [150/391], Loss: 1.3643, LR: 0.010000\n",
      "Epoch [17], Batch [200/391], Loss: 1.1370, LR: 0.010000\n",
      "Epoch [17], Batch [250/391], Loss: 3.3084, LR: 0.010000\n",
      "Epoch [17], Batch [300/391], Loss: 1.5170, LR: 0.010000\n",
      "Epoch [17], Batch [350/391], Loss: 1.3600, LR: 0.010000\n",
      "Train set: Epoch: 17, Average loss:2.1549, LR: 0.010000 Top-1 Accuracy: 51.4700%, Top-5 Accuracy: 79.4920%, Time consumed:88.62s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████▏                                                                                      | 17/300 [28:25<7:46:38, 98.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 17, Average loss:1.3810, Top-1 Accuracy: 61.8300%, Top-5 Accuracy: 87.5600%, Time consumed:9.59s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [18], Batch [50/391], Loss: 3.4614, LR: 0.010000\n",
      "Epoch [18], Batch [100/391], Loss: 1.6380, LR: 0.010000\n",
      "Epoch [18], Batch [150/391], Loss: 3.3694, LR: 0.010000\n",
      "Epoch [18], Batch [200/391], Loss: 3.4322, LR: 0.010000\n",
      "Epoch [18], Batch [250/391], Loss: 1.4557, LR: 0.010000\n",
      "Epoch [18], Batch [300/391], Loss: 1.3681, LR: 0.010000\n",
      "Epoch [18], Batch [350/391], Loss: 1.5256, LR: 0.010000\n",
      "Train set: Epoch: 18, Average loss:2.1062, LR: 0.010000 Top-1 Accuracy: 51.9080%, Top-5 Accuracy: 79.4960%, Time consumed:89.14s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████▌                                                                                      | 18/300 [30:05<7:45:29, 99.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 18, Average loss:1.3837, Top-1 Accuracy: 61.8700%, Top-5 Accuracy: 87.6500%, Time consumed:10.15s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [19], Batch [50/391], Loss: 1.3642, LR: 0.010000\n",
      "Epoch [19], Batch [100/391], Loss: 1.4727, LR: 0.010000\n",
      "Epoch [19], Batch [150/391], Loss: 1.3188, LR: 0.010000\n",
      "Epoch [19], Batch [200/391], Loss: 1.3327, LR: 0.010000\n",
      "Epoch [19], Batch [250/391], Loss: 1.1882, LR: 0.010000\n",
      "Epoch [19], Batch [300/391], Loss: 3.1159, LR: 0.010000\n",
      "Epoch [19], Batch [350/391], Loss: 3.5070, LR: 0.010000\n",
      "Train set: Epoch: 19, Average loss:2.0152, LR: 0.010000 Top-1 Accuracy: 54.7300%, Top-5 Accuracy: 82.0200%, Time consumed:88.69s\n",
      "Test set: Epoch: 19, Average loss:1.3387, Top-1 Accuracy: 62.6800%, Top-5 Accuracy: 88.1900%, Time consumed:9.50s\n",
      "\n",
      "새로운 최고 top-1 정확도: 62.68%, top-5 정확도: 88.19%\n",
      "Accuracy improved (62.53% --> 62.68%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████▊                                                                                      | 19/300 [31:43<7:42:59, 98.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20], Batch [50/391], Loss: 1.1169, LR: 0.010000\n",
      "Epoch [20], Batch [100/391], Loss: 1.6331, LR: 0.010000\n",
      "Epoch [20], Batch [150/391], Loss: 3.2700, LR: 0.010000\n",
      "Epoch [20], Batch [200/391], Loss: 1.2845, LR: 0.010000\n",
      "Epoch [20], Batch [250/391], Loss: 1.4036, LR: 0.010000\n",
      "Epoch [20], Batch [300/391], Loss: 3.5750, LR: 0.010000\n",
      "Epoch [20], Batch [350/391], Loss: 3.3299, LR: 0.010000\n",
      "Train set: Epoch: 20, Average loss:1.9628, LR: 0.010000 Top-1 Accuracy: 55.1720%, Top-5 Accuracy: 81.4680%, Time consumed:89.13s\n",
      "Test set: Epoch: 20, Average loss:1.2709, Top-1 Accuracy: 64.1100%, Top-5 Accuracy: 89.2100%, Time consumed:9.63s\n",
      "\n",
      "새로운 최고 top-1 정확도: 64.11%, top-5 정확도: 89.21%\n",
      "새로운 최고 top-5 정확도: 89.21%\n",
      "Accuracy improved (62.68% --> 64.11%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████▏                                                                                     | 20/300 [33:22<7:41:34, 98.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21], Batch [50/391], Loss: 1.2190, LR: 0.010000\n",
      "Epoch [21], Batch [100/391], Loss: 1.1887, LR: 0.010000\n",
      "Epoch [21], Batch [150/391], Loss: 1.1272, LR: 0.010000\n",
      "Epoch [21], Batch [200/391], Loss: 1.1187, LR: 0.010000\n",
      "Epoch [21], Batch [250/391], Loss: 1.3137, LR: 0.010000\n",
      "Epoch [21], Batch [300/391], Loss: 1.0466, LR: 0.010000\n",
      "Epoch [21], Batch [350/391], Loss: 3.0926, LR: 0.010000\n",
      "Train set: Epoch: 21, Average loss:1.9581, LR: 0.010000 Top-1 Accuracy: 55.8280%, Top-5 Accuracy: 82.0200%, Time consumed:89.53s\n",
      "Test set: Epoch: 21, Average loss:1.2816, Top-1 Accuracy: 64.3400%, Top-5 Accuracy: 89.3300%, Time consumed:9.58s\n",
      "\n",
      "새로운 최고 top-1 정확도: 64.34%, top-5 정확도: 89.33%\n",
      "새로운 최고 top-5 정확도: 89.33%\n",
      "Accuracy improved (64.11% --> 64.34%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████▍                                                                                     | 21/300 [35:01<7:40:31, 99.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22], Batch [50/391], Loss: 1.0405, LR: 0.010000\n",
      "Epoch [22], Batch [100/391], Loss: 1.1954, LR: 0.010000\n",
      "Epoch [22], Batch [150/391], Loss: 1.0563, LR: 0.010000\n",
      "Epoch [22], Batch [200/391], Loss: 2.4603, LR: 0.010000\n",
      "Epoch [22], Batch [250/391], Loss: 3.1528, LR: 0.010000\n",
      "Epoch [22], Batch [300/391], Loss: 2.5533, LR: 0.010000\n",
      "Epoch [22], Batch [350/391], Loss: 3.1712, LR: 0.010000\n",
      "Train set: Epoch: 22, Average loss:1.9924, LR: 0.010000 Top-1 Accuracy: 56.6920%, Top-5 Accuracy: 82.8280%, Time consumed:88.57s\n",
      "Test set: Epoch: 22, Average loss:1.1898, Top-1 Accuracy: 66.4200%, Top-5 Accuracy: 90.3000%, Time consumed:10.57s\n",
      "\n",
      "새로운 최고 top-1 정확도: 66.42%, top-5 정확도: 90.30%\n",
      "새로운 최고 top-5 정확도: 90.30%\n",
      "Accuracy improved (64.34% --> 66.42%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████▋                                                                                     | 22/300 [36:41<7:39:20, 99.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23], Batch [50/391], Loss: 1.1596, LR: 0.005000\n",
      "Epoch [23], Batch [100/391], Loss: 1.1565, LR: 0.005000\n",
      "Epoch [23], Batch [150/391], Loss: 3.2504, LR: 0.005000\n",
      "Epoch [23], Batch [200/391], Loss: 1.0699, LR: 0.005000\n",
      "Epoch [23], Batch [250/391], Loss: 3.1331, LR: 0.005000\n",
      "Epoch [23], Batch [300/391], Loss: 1.0467, LR: 0.005000\n",
      "Epoch [23], Batch [350/391], Loss: 2.2418, LR: 0.005000\n",
      "Train set: Epoch: 23, Average loss:1.8129, LR: 0.005000 Top-1 Accuracy: 61.0220%, Top-5 Accuracy: 85.2860%, Time consumed:89.29s\n",
      "Test set: Epoch: 23, Average loss:1.0931, Top-1 Accuracy: 68.9600%, Top-5 Accuracy: 91.5900%, Time consumed:9.67s\n",
      "\n",
      "새로운 최고 top-1 정확도: 68.96%, top-5 정확도: 91.59%\n",
      "새로운 최고 top-5 정확도: 91.59%\n",
      "Accuracy improved (66.42% --> 68.96%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███████                                                                                     | 23/300 [38:20<7:37:48, 99.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24], Batch [50/391], Loss: 2.7496, LR: 0.005000\n",
      "Epoch [24], Batch [100/391], Loss: 2.7288, LR: 0.005000\n",
      "Epoch [24], Batch [150/391], Loss: 0.9824, LR: 0.005000\n",
      "Epoch [24], Batch [200/391], Loss: 0.9649, LR: 0.005000\n",
      "Epoch [24], Batch [250/391], Loss: 2.4613, LR: 0.005000\n",
      "Epoch [24], Batch [300/391], Loss: 1.1731, LR: 0.005000\n",
      "Epoch [24], Batch [350/391], Loss: 0.7382, LR: 0.005000\n",
      "Train set: Epoch: 24, Average loss:1.7499, LR: 0.005000 Top-1 Accuracy: 62.9600%, Top-5 Accuracy: 86.9500%, Time consumed:89.03s\n",
      "Test set: Epoch: 24, Average loss:1.0828, Top-1 Accuracy: 69.6400%, Top-5 Accuracy: 91.8600%, Time consumed:9.88s\n",
      "\n",
      "새로운 최고 top-1 정확도: 69.64%, top-5 정확도: 91.86%\n",
      "새로운 최고 top-5 정확도: 91.86%\n",
      "Accuracy improved (68.96% --> 69.64%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███████▎                                                                                    | 24/300 [39:59<7:36:07, 99.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25], Batch [50/391], Loss: 0.9518, LR: 0.005000\n",
      "Epoch [25], Batch [100/391], Loss: 3.3730, LR: 0.005000\n",
      "Epoch [25], Batch [150/391], Loss: 0.9556, LR: 0.005000\n",
      "Epoch [25], Batch [200/391], Loss: 1.8795, LR: 0.005000\n",
      "Epoch [25], Batch [250/391], Loss: 1.6311, LR: 0.005000\n",
      "Epoch [25], Batch [300/391], Loss: 1.6547, LR: 0.005000\n",
      "Epoch [25], Batch [350/391], Loss: 1.0313, LR: 0.005000\n",
      "Train set: Epoch: 25, Average loss:1.8305, LR: 0.005000 Top-1 Accuracy: 61.3240%, Top-5 Accuracy: 85.5500%, Time consumed:89.15s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███████▋                                                                                    | 25/300 [41:38<7:34:48, 99.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 25, Average loss:1.1160, Top-1 Accuracy: 69.1700%, Top-5 Accuracy: 91.6800%, Time consumed:10.25s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [26], Batch [50/391], Loss: 1.0156, LR: 0.005000\n",
      "Epoch [26], Batch [100/391], Loss: 3.0940, LR: 0.005000\n",
      "Epoch [26], Batch [150/391], Loss: 0.8774, LR: 0.005000\n",
      "Epoch [26], Batch [200/391], Loss: 1.8749, LR: 0.005000\n",
      "Epoch [26], Batch [250/391], Loss: 2.6207, LR: 0.005000\n",
      "Epoch [26], Batch [300/391], Loss: 0.9628, LR: 0.005000\n",
      "Epoch [26], Batch [350/391], Loss: 1.0435, LR: 0.005000\n",
      "Train set: Epoch: 26, Average loss:1.8103, LR: 0.005000 Top-1 Accuracy: 60.5460%, Top-5 Accuracy: 84.6280%, Time consumed:88.88s\n",
      "Test set: Epoch: 26, Average loss:1.0748, Top-1 Accuracy: 69.8900%, Top-5 Accuracy: 91.9500%, Time consumed:9.74s\n",
      "\n",
      "새로운 최고 top-1 정확도: 69.89%, top-5 정확도: 91.95%\n",
      "새로운 최고 top-5 정확도: 91.95%\n",
      "Accuracy improved (69.64% --> 69.89%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███████▉                                                                                    | 26/300 [43:17<7:32:44, 99.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27], Batch [50/391], Loss: 0.9138, LR: 0.005000\n",
      "Epoch [27], Batch [100/391], Loss: 3.0183, LR: 0.005000\n",
      "Epoch [27], Batch [150/391], Loss: 0.8538, LR: 0.005000\n",
      "Epoch [27], Batch [200/391], Loss: 0.8723, LR: 0.005000\n",
      "Epoch [27], Batch [250/391], Loss: 0.9201, LR: 0.005000\n",
      "Epoch [27], Batch [300/391], Loss: 1.1365, LR: 0.005000\n",
      "Epoch [27], Batch [350/391], Loss: 0.9912, LR: 0.005000\n",
      "Train set: Epoch: 27, Average loss:1.7431, LR: 0.005000 Top-1 Accuracy: 62.5080%, Top-5 Accuracy: 86.3120%, Time consumed:89.36s\n",
      "Test set: Epoch: 27, Average loss:1.0462, Top-1 Accuracy: 70.2700%, Top-5 Accuracy: 92.3700%, Time consumed:9.62s\n",
      "\n",
      "새로운 최고 top-1 정확도: 70.27%, top-5 정확도: 92.37%\n",
      "새로운 최고 top-5 정확도: 92.37%\n",
      "Accuracy improved (69.89% --> 70.27%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|████████▎                                                                                   | 27/300 [44:57<7:31:14, 99.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28], Batch [50/391], Loss: 2.5995, LR: 0.005000\n",
      "Epoch [28], Batch [100/391], Loss: 0.8501, LR: 0.005000\n",
      "Epoch [28], Batch [150/391], Loss: 0.8716, LR: 0.005000\n",
      "Epoch [28], Batch [200/391], Loss: 0.7720, LR: 0.005000\n",
      "Epoch [28], Batch [250/391], Loss: 1.0850, LR: 0.005000\n",
      "Epoch [28], Batch [300/391], Loss: 0.9603, LR: 0.005000\n",
      "Epoch [28], Batch [350/391], Loss: 1.4203, LR: 0.005000\n",
      "Train set: Epoch: 28, Average loss:1.6770, LR: 0.005000 Top-1 Accuracy: 63.9540%, Top-5 Accuracy: 87.4400%, Time consumed:89.20s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|████████▌                                                                                   | 28/300 [46:35<7:29:08, 99.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 28, Average loss:1.0728, Top-1 Accuracy: 70.0700%, Top-5 Accuracy: 91.9500%, Time consumed:9.64s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [29], Batch [50/391], Loss: 0.8680, LR: 0.005000\n",
      "Epoch [29], Batch [100/391], Loss: 0.9183, LR: 0.005000\n",
      "Epoch [29], Batch [150/391], Loss: 3.0412, LR: 0.005000\n",
      "Epoch [29], Batch [200/391], Loss: 0.8964, LR: 0.005000\n",
      "Epoch [29], Batch [250/391], Loss: 0.8968, LR: 0.005000\n",
      "Epoch [29], Batch [300/391], Loss: 2.5309, LR: 0.005000\n",
      "Epoch [29], Batch [350/391], Loss: 2.3633, LR: 0.005000\n",
      "Train set: Epoch: 29, Average loss:1.6226, LR: 0.005000 Top-1 Accuracy: 65.0220%, Top-5 Accuracy: 87.8440%, Time consumed:89.36s\n",
      "Test set: Epoch: 29, Average loss:1.0337, Top-1 Accuracy: 71.0000%, Top-5 Accuracy: 92.4100%, Time consumed:10.04s\n",
      "\n",
      "새로운 최고 top-1 정확도: 71.00%, top-5 정확도: 92.41%\n",
      "새로운 최고 top-5 정확도: 92.41%\n",
      "Accuracy improved (70.27% --> 71.00%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▉                                                                                   | 29/300 [48:15<7:28:15, 99.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30], Batch [50/391], Loss: 0.7470, LR: 0.002500\n",
      "Epoch [30], Batch [100/391], Loss: 0.7210, LR: 0.002500\n",
      "Epoch [30], Batch [150/391], Loss: 2.4875, LR: 0.002500\n",
      "Epoch [30], Batch [200/391], Loss: 1.6414, LR: 0.002500\n",
      "Epoch [30], Batch [250/391], Loss: 0.8530, LR: 0.002500\n",
      "Epoch [30], Batch [300/391], Loss: 0.6511, LR: 0.002500\n",
      "Epoch [30], Batch [350/391], Loss: 0.8940, LR: 0.002500\n",
      "Train set: Epoch: 30, Average loss:1.6894, LR: 0.002500 Top-1 Accuracy: 64.8980%, Top-5 Accuracy: 87.1500%, Time consumed:89.37s\n",
      "Test set: Epoch: 30, Average loss:0.9897, Top-1 Accuracy: 72.2300%, Top-5 Accuracy: 93.2300%, Time consumed:9.87s\n",
      "\n",
      "새로운 최고 top-1 정확도: 72.23%, top-5 정확도: 93.23%\n",
      "새로운 최고 top-5 정확도: 93.23%\n",
      "Accuracy improved (71.00% --> 72.23%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█████████▏                                                                                  | 30/300 [49:55<7:26:54, 99.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31], Batch [50/391], Loss: 0.7862, LR: 0.002500\n",
      "Epoch [31], Batch [100/391], Loss: 2.7127, LR: 0.002500\n",
      "Epoch [31], Batch [150/391], Loss: 2.9780, LR: 0.002500\n",
      "Epoch [31], Batch [200/391], Loss: 0.7245, LR: 0.002500\n",
      "Epoch [31], Batch [250/391], Loss: 0.7391, LR: 0.002500\n",
      "Epoch [31], Batch [300/391], Loss: 0.8684, LR: 0.002500\n",
      "Epoch [31], Batch [350/391], Loss: 1.0797, LR: 0.002500\n",
      "Train set: Epoch: 31, Average loss:1.6494, LR: 0.002500 Top-1 Accuracy: 65.8380%, Top-5 Accuracy: 87.8100%, Time consumed:90.43s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█████████▌                                                                                  | 31/300 [51:35<7:26:10, 99.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 31, Average loss:1.0065, Top-1 Accuracy: 72.1100%, Top-5 Accuracy: 92.7300%, Time consumed:9.56s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [32], Batch [50/391], Loss: 2.3909, LR: 0.002500\n",
      "Epoch [32], Batch [100/391], Loss: 2.1600, LR: 0.002500\n",
      "Epoch [32], Batch [150/391], Loss: 0.8872, LR: 0.002500\n",
      "Epoch [32], Batch [200/391], Loss: 3.0788, LR: 0.002500\n",
      "Epoch [32], Batch [250/391], Loss: 3.0695, LR: 0.002500\n",
      "Epoch [32], Batch [300/391], Loss: 2.5102, LR: 0.002500\n",
      "Epoch [32], Batch [350/391], Loss: 3.1282, LR: 0.002500\n",
      "Train set: Epoch: 32, Average loss:1.5575, LR: 0.002500 Top-1 Accuracy: 67.5780%, Top-5 Accuracy: 88.9220%, Time consumed:89.44s\n",
      "Test set: Epoch: 32, Average loss:0.9878, Top-1 Accuracy: 72.2700%, Top-5 Accuracy: 93.2400%, Time consumed:10.22s\n",
      "\n",
      "새로운 최고 top-1 정확도: 72.27%, top-5 정확도: 93.24%\n",
      "새로운 최고 top-5 정확도: 93.24%\n",
      "Accuracy improved (72.23% --> 72.27%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█████████▊                                                                                  | 32/300 [53:15<7:25:04, 99.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33], Batch [50/391], Loss: 0.9666, LR: 0.002500\n",
      "Epoch [33], Batch [100/391], Loss: 1.8154, LR: 0.002500\n",
      "Epoch [33], Batch [150/391], Loss: 3.0866, LR: 0.002500\n",
      "Epoch [33], Batch [200/391], Loss: 0.8750, LR: 0.002500\n",
      "Epoch [33], Batch [250/391], Loss: 1.1197, LR: 0.002500\n",
      "Epoch [33], Batch [300/391], Loss: 0.6692, LR: 0.002500\n",
      "Epoch [33], Batch [350/391], Loss: 1.5982, LR: 0.002500\n",
      "Train set: Epoch: 33, Average loss:1.6299, LR: 0.002500 Top-1 Accuracy: 66.6880%, Top-5 Accuracy: 88.4260%, Time consumed:88.88s\n",
      "Test set: Epoch: 33, Average loss:1.0145, Top-1 Accuracy: 72.4900%, Top-5 Accuracy: 92.9300%, Time consumed:9.60s\n",
      "\n",
      "새로운 최고 top-1 정확도: 72.49%, top-5 정확도: 92.93%\n",
      "Accuracy improved (72.27% --> 72.49%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|██████████                                                                                  | 33/300 [54:53<7:22:15, 99.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34], Batch [50/391], Loss: 0.6856, LR: 0.002500\n",
      "Epoch [34], Batch [100/391], Loss: 0.8079, LR: 0.002500\n",
      "Epoch [34], Batch [150/391], Loss: 1.8994, LR: 0.002500\n",
      "Epoch [34], Batch [200/391], Loss: 2.8612, LR: 0.002500\n",
      "Epoch [34], Batch [250/391], Loss: 1.4667, LR: 0.002500\n",
      "Epoch [34], Batch [300/391], Loss: 0.6991, LR: 0.002500\n",
      "Epoch [34], Batch [350/391], Loss: 0.7628, LR: 0.002500\n",
      "Train set: Epoch: 34, Average loss:1.6299, LR: 0.002500 Top-1 Accuracy: 66.7060%, Top-5 Accuracy: 88.4400%, Time consumed:89.89s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|██████████▍                                                                                 | 34/300 [56:33<7:20:43, 99.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 34, Average loss:1.0099, Top-1 Accuracy: 71.8400%, Top-5 Accuracy: 92.8300%, Time consumed:9.58s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [35], Batch [50/391], Loss: 2.9034, LR: 0.002500\n",
      "Epoch [35], Batch [100/391], Loss: 2.6522, LR: 0.002500\n",
      "Epoch [35], Batch [150/391], Loss: 3.2211, LR: 0.002500\n",
      "Epoch [35], Batch [200/391], Loss: 0.7409, LR: 0.002500\n",
      "Epoch [35], Batch [250/391], Loss: 1.5849, LR: 0.002500\n",
      "Epoch [35], Batch [300/391], Loss: 1.5911, LR: 0.002500\n",
      "Epoch [35], Batch [350/391], Loss: 2.7511, LR: 0.002500\n",
      "Train set: Epoch: 35, Average loss:1.5407, LR: 0.002500 Top-1 Accuracy: 67.7720%, Top-5 Accuracy: 88.6940%, Time consumed:89.32s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████▋                                                                                 | 35/300 [58:12<7:18:24, 99.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 35, Average loss:0.9879, Top-1 Accuracy: 71.6300%, Top-5 Accuracy: 92.7900%, Time consumed:9.58s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [36], Batch [50/391], Loss: 0.7443, LR: 0.001250\n",
      "Epoch [36], Batch [100/391], Loss: 0.6236, LR: 0.001250\n",
      "Epoch [36], Batch [150/391], Loss: 2.7105, LR: 0.001250\n",
      "Epoch [36], Batch [200/391], Loss: 1.5379, LR: 0.001250\n",
      "Epoch [36], Batch [250/391], Loss: 0.6939, LR: 0.001250\n",
      "Epoch [36], Batch [300/391], Loss: 0.8405, LR: 0.001250\n",
      "Epoch [36], Batch [350/391], Loss: 0.6862, LR: 0.001250\n",
      "Train set: Epoch: 36, Average loss:1.5912, LR: 0.001250 Top-1 Accuracy: 68.0200%, Top-5 Accuracy: 88.9560%, Time consumed:89.25s\n",
      "Test set: Epoch: 36, Average loss:0.9636, Top-1 Accuracy: 73.4200%, Top-5 Accuracy: 93.4700%, Time consumed:9.84s\n",
      "\n",
      "새로운 최고 top-1 정확도: 73.42%, top-5 정확도: 93.47%\n",
      "새로운 최고 top-5 정확도: 93.47%\n",
      "Accuracy improved (72.49% --> 73.42%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|███████████                                                                                 | 36/300 [59:51<7:16:53, 99.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37], Batch [50/391], Loss: 1.6140, LR: 0.001250\n",
      "Epoch [37], Batch [100/391], Loss: 0.5951, LR: 0.001250\n",
      "Epoch [37], Batch [150/391], Loss: 3.0514, LR: 0.001250\n",
      "Epoch [37], Batch [200/391], Loss: 3.1900, LR: 0.001250\n",
      "Epoch [37], Batch [250/391], Loss: 2.9385, LR: 0.001250\n",
      "Epoch [37], Batch [300/391], Loss: 0.8318, LR: 0.001250\n",
      "Epoch [37], Batch [350/391], Loss: 0.7004, LR: 0.001250\n",
      "Train set: Epoch: 37, Average loss:1.4739, LR: 0.001250 Top-1 Accuracy: 70.2700%, Top-5 Accuracy: 90.2320%, Time consumed:88.85s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|███████████                                                                               | 37/300 [1:01:30<7:14:08, 99.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 37, Average loss:0.9516, Top-1 Accuracy: 73.3200%, Top-5 Accuracy: 93.5000%, Time consumed:9.61s\n",
      "\n",
      "새로운 최고 top-5 정확도: 93.50%\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [38], Batch [50/391], Loss: 2.8321, LR: 0.001250\n",
      "Epoch [38], Batch [100/391], Loss: 1.0662, LR: 0.001250\n",
      "Epoch [38], Batch [150/391], Loss: 0.7597, LR: 0.001250\n",
      "Epoch [38], Batch [200/391], Loss: 0.5560, LR: 0.001250\n",
      "Epoch [38], Batch [250/391], Loss: 0.6902, LR: 0.001250\n",
      "Epoch [38], Batch [300/391], Loss: 0.6786, LR: 0.001250\n",
      "Epoch [38], Batch [350/391], Loss: 0.7664, LR: 0.001250\n",
      "Train set: Epoch: 38, Average loss:1.5383, LR: 0.001250 Top-1 Accuracy: 69.3080%, Top-5 Accuracy: 89.6680%, Time consumed:89.32s\n",
      "Test set: Epoch: 38, Average loss:0.9429, Top-1 Accuracy: 73.4900%, Top-5 Accuracy: 93.5600%, Time consumed:10.52s\n",
      "\n",
      "새로운 최고 top-1 정확도: 73.49%, top-5 정확도: 93.56%\n",
      "새로운 최고 top-5 정확도: 93.56%\n",
      "Accuracy improved (73.42% --> 73.49%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|███████████▍                                                                              | 38/300 [1:03:10<7:13:50, 99.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39], Batch [50/391], Loss: 0.5846, LR: 0.001250\n",
      "Epoch [39], Batch [100/391], Loss: 3.0691, LR: 0.001250\n",
      "Epoch [39], Batch [150/391], Loss: 0.5693, LR: 0.001250\n",
      "Epoch [39], Batch [200/391], Loss: 3.1695, LR: 0.001250\n",
      "Epoch [39], Batch [250/391], Loss: 0.6060, LR: 0.001250\n",
      "Epoch [39], Batch [300/391], Loss: 0.6277, LR: 0.001250\n",
      "Epoch [39], Batch [350/391], Loss: 1.5225, LR: 0.001250\n",
      "Train set: Epoch: 39, Average loss:1.6065, LR: 0.001250 Top-1 Accuracy: 67.0760%, Top-5 Accuracy: 87.8900%, Time consumed:89.34s\n",
      "Test set: Epoch: 39, Average loss:0.9375, Top-1 Accuracy: 73.8300%, Top-5 Accuracy: 93.6300%, Time consumed:10.10s\n",
      "\n",
      "새로운 최고 top-1 정확도: 73.83%, top-5 정확도: 93.63%\n",
      "새로운 최고 top-5 정확도: 93.63%\n",
      "Accuracy improved (73.49% --> 73.83%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|███████████▋                                                                              | 39/300 [1:04:49<7:12:37, 99.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40], Batch [50/391], Loss: 2.0018, LR: 0.001250\n",
      "Epoch [40], Batch [100/391], Loss: 2.5509, LR: 0.001250\n",
      "Epoch [40], Batch [150/391], Loss: 2.6382, LR: 0.001250\n",
      "Epoch [40], Batch [200/391], Loss: 1.9474, LR: 0.001250\n",
      "Epoch [40], Batch [250/391], Loss: 0.7614, LR: 0.001250\n",
      "Epoch [40], Batch [300/391], Loss: 2.9800, LR: 0.001250\n",
      "Epoch [40], Batch [350/391], Loss: 0.6454, LR: 0.001250\n",
      "Train set: Epoch: 40, Average loss:1.4330, LR: 0.001250 Top-1 Accuracy: 71.3320%, Top-5 Accuracy: 90.6940%, Time consumed:88.89s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|████████████                                                                              | 40/300 [1:06:28<7:10:22, 99.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 40, Average loss:0.9472, Top-1 Accuracy: 73.7700%, Top-5 Accuracy: 93.6300%, Time consumed:10.09s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [41], Batch [50/391], Loss: 0.7752, LR: 0.001250\n",
      "Epoch [41], Batch [100/391], Loss: 1.4936, LR: 0.001250\n",
      "Epoch [41], Batch [150/391], Loss: 0.5472, LR: 0.001250\n",
      "Epoch [41], Batch [200/391], Loss: 0.7234, LR: 0.001250\n",
      "Epoch [41], Batch [250/391], Loss: 0.7332, LR: 0.001250\n",
      "Epoch [41], Batch [300/391], Loss: 2.3513, LR: 0.001250\n",
      "Epoch [41], Batch [350/391], Loss: 2.7914, LR: 0.001250\n",
      "Train set: Epoch: 41, Average loss:1.5216, LR: 0.001250 Top-1 Accuracy: 70.3720%, Top-5 Accuracy: 90.0580%, Time consumed:89.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████▎                                                                             | 41/300 [1:08:07<7:08:09, 99.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 41, Average loss:0.9255, Top-1 Accuracy: 73.7000%, Top-5 Accuracy: 93.7100%, Time consumed:9.89s\n",
      "\n",
      "새로운 최고 top-5 정확도: 93.71%\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [42], Batch [50/391], Loss: 1.3931, LR: 0.000625\n",
      "Epoch [42], Batch [100/391], Loss: 2.2700, LR: 0.000625\n",
      "Epoch [42], Batch [150/391], Loss: 0.6118, LR: 0.000625\n",
      "Epoch [42], Batch [200/391], Loss: 0.6140, LR: 0.000625\n",
      "Epoch [42], Batch [250/391], Loss: 0.8593, LR: 0.000625\n",
      "Epoch [42], Batch [300/391], Loss: 1.2931, LR: 0.000625\n",
      "Epoch [42], Batch [350/391], Loss: 0.6422, LR: 0.000625\n",
      "Train set: Epoch: 42, Average loss:1.4337, LR: 0.000625 Top-1 Accuracy: 71.4880%, Top-5 Accuracy: 90.9120%, Time consumed:88.93s\n",
      "Test set: Epoch: 42, Average loss:0.9316, Top-1 Accuracy: 74.0200%, Top-5 Accuracy: 93.6700%, Time consumed:9.62s\n",
      "\n",
      "새로운 최고 top-1 정확도: 74.02%, top-5 정확도: 93.67%\n",
      "Accuracy improved (73.83% --> 74.02%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████▌                                                                             | 42/300 [1:09:46<7:05:59, 99.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43], Batch [50/391], Loss: 2.1845, LR: 0.000625\n",
      "Epoch [43], Batch [100/391], Loss: 0.7071, LR: 0.000625\n",
      "Epoch [43], Batch [150/391], Loss: 0.6265, LR: 0.000625\n",
      "Epoch [43], Batch [200/391], Loss: 2.2402, LR: 0.000625\n",
      "Epoch [43], Batch [250/391], Loss: 2.8381, LR: 0.000625\n",
      "Epoch [43], Batch [300/391], Loss: 0.5395, LR: 0.000625\n",
      "Epoch [43], Batch [350/391], Loss: 2.6357, LR: 0.000625\n",
      "Train set: Epoch: 43, Average loss:1.4838, LR: 0.000625 Top-1 Accuracy: 69.9920%, Top-5 Accuracy: 89.4420%, Time consumed:89.21s\n",
      "Test set: Epoch: 43, Average loss:0.9074, Top-1 Accuracy: 74.2100%, Top-5 Accuracy: 93.8100%, Time consumed:10.49s\n",
      "\n",
      "새로운 최고 top-1 정확도: 74.21%, top-5 정확도: 93.81%\n",
      "새로운 최고 top-5 정확도: 93.81%\n",
      "Accuracy improved (74.02% --> 74.21%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████▉                                                                             | 43/300 [1:11:26<7:05:33, 99.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44], Batch [50/391], Loss: 2.5519, LR: 0.000625\n",
      "Epoch [44], Batch [100/391], Loss: 2.9278, LR: 0.000625\n",
      "Epoch [44], Batch [150/391], Loss: 0.5530, LR: 0.000625\n",
      "Epoch [44], Batch [200/391], Loss: 0.8955, LR: 0.000625\n",
      "Epoch [44], Batch [250/391], Loss: 2.2934, LR: 0.000625\n",
      "Epoch [44], Batch [300/391], Loss: 2.7377, LR: 0.000625\n",
      "Epoch [44], Batch [350/391], Loss: 3.4198, LR: 0.000625\n",
      "Train set: Epoch: 44, Average loss:1.5481, LR: 0.000625 Top-1 Accuracy: 69.8940%, Top-5 Accuracy: 89.6740%, Time consumed:89.28s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████████████▏                                                                            | 44/300 [1:13:05<7:03:25, 99.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 44, Average loss:0.9178, Top-1 Accuracy: 74.1200%, Top-5 Accuracy: 93.8800%, Time consumed:9.69s\n",
      "\n",
      "새로운 최고 top-5 정확도: 93.88%\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [45], Batch [50/391], Loss: 0.6000, LR: 0.000625\n",
      "Epoch [45], Batch [100/391], Loss: 3.0326, LR: 0.000625\n",
      "Epoch [45], Batch [150/391], Loss: 2.5611, LR: 0.000625\n",
      "Epoch [45], Batch [200/391], Loss: 1.0058, LR: 0.000625\n",
      "Epoch [45], Batch [250/391], Loss: 2.2389, LR: 0.000625\n",
      "Epoch [45], Batch [300/391], Loss: 0.5325, LR: 0.000625\n",
      "Epoch [45], Batch [350/391], Loss: 2.3381, LR: 0.000625\n",
      "Train set: Epoch: 45, Average loss:1.5387, LR: 0.000625 Top-1 Accuracy: 69.4960%, Top-5 Accuracy: 89.2940%, Time consumed:89.15s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████████████▌                                                                            | 45/300 [1:14:44<7:01:18, 99.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 45, Average loss:0.9277, Top-1 Accuracy: 73.9100%, Top-5 Accuracy: 93.6800%, Time consumed:9.72s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [46], Batch [50/391], Loss: 0.5850, LR: 0.000625\n",
      "Epoch [46], Batch [100/391], Loss: 2.1677, LR: 0.000625\n",
      "Epoch [46], Batch [150/391], Loss: 2.9152, LR: 0.000625\n",
      "Epoch [46], Batch [200/391], Loss: 1.8112, LR: 0.000625\n",
      "Epoch [46], Batch [250/391], Loss: 3.1066, LR: 0.000625\n",
      "Epoch [46], Batch [300/391], Loss: 1.0256, LR: 0.000625\n",
      "Epoch [46], Batch [350/391], Loss: 3.1101, LR: 0.000625\n",
      "Train set: Epoch: 46, Average loss:1.4966, LR: 0.000625 Top-1 Accuracy: 70.2520%, Top-5 Accuracy: 89.9420%, Time consumed:90.22s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████████████▊                                                                            | 46/300 [1:16:24<7:00:50, 99.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 46, Average loss:0.9362, Top-1 Accuracy: 73.9900%, Top-5 Accuracy: 93.6300%, Time consumed:9.84s\n",
      "\n",
      "EarlyStopping 카운터: 3 / 30\n",
      "Epoch [47], Batch [50/391], Loss: 1.3453, LR: 0.000625\n",
      "Epoch [47], Batch [100/391], Loss: 2.4342, LR: 0.000625\n",
      "Epoch [47], Batch [150/391], Loss: 1.5791, LR: 0.000625\n",
      "Epoch [47], Batch [200/391], Loss: 1.7377, LR: 0.000625\n",
      "Epoch [47], Batch [250/391], Loss: 0.5883, LR: 0.000625\n",
      "Epoch [47], Batch [300/391], Loss: 0.7663, LR: 0.000625\n",
      "Epoch [47], Batch [350/391], Loss: 0.6409, LR: 0.000625\n",
      "Train set: Epoch: 47, Average loss:1.3738, LR: 0.000625 Top-1 Accuracy: 72.9080%, Top-5 Accuracy: 91.4360%, Time consumed:91.20s\n",
      "Test set: Epoch: 47, Average loss:0.9160, Top-1 Accuracy: 74.2200%, Top-5 Accuracy: 93.8100%, Time consumed:9.57s\n",
      "\n",
      "새로운 최고 top-1 정확도: 74.22%, top-5 정확도: 93.81%\n",
      "Accuracy improved (74.21% --> 74.22%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████████████                                                                            | 47/300 [1:18:05<7:01:12, 99.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48], Batch [50/391], Loss: 0.6081, LR: 0.000312\n",
      "Epoch [48], Batch [100/391], Loss: 1.7712, LR: 0.000312\n",
      "Epoch [48], Batch [150/391], Loss: 2.1425, LR: 0.000312\n",
      "Epoch [48], Batch [200/391], Loss: 2.6011, LR: 0.000312\n",
      "Epoch [48], Batch [250/391], Loss: 0.5793, LR: 0.000312\n",
      "Epoch [48], Batch [300/391], Loss: 0.6234, LR: 0.000312\n",
      "Epoch [48], Batch [350/391], Loss: 0.5826, LR: 0.000312\n",
      "Train set: Epoch: 48, Average loss:1.4465, LR: 0.000312 Top-1 Accuracy: 71.8080%, Top-5 Accuracy: 90.7280%, Time consumed:88.80s\n",
      "Test set: Epoch: 48, Average loss:0.9111, Top-1 Accuracy: 74.4300%, Top-5 Accuracy: 93.8600%, Time consumed:9.85s\n",
      "\n",
      "새로운 최고 top-1 정확도: 74.43%, top-5 정확도: 93.86%\n",
      "Accuracy improved (74.22% --> 74.43%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████████████▍                                                                           | 48/300 [1:19:44<6:58:17, 99.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49], Batch [50/391], Loss: 0.5834, LR: 0.000312\n",
      "Epoch [49], Batch [100/391], Loss: 0.6411, LR: 0.000312\n",
      "Epoch [49], Batch [150/391], Loss: 2.7111, LR: 0.000312\n",
      "Epoch [49], Batch [200/391], Loss: 0.5681, LR: 0.000312\n",
      "Epoch [49], Batch [250/391], Loss: 2.5336, LR: 0.000312\n",
      "Epoch [49], Batch [300/391], Loss: 0.6378, LR: 0.000312\n",
      "Epoch [49], Batch [350/391], Loss: 2.0598, LR: 0.000312\n",
      "Train set: Epoch: 49, Average loss:1.4740, LR: 0.000312 Top-1 Accuracy: 71.0120%, Top-5 Accuracy: 90.2200%, Time consumed:89.27s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████████████▋                                                                           | 49/300 [1:21:23<6:55:59, 99.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 49, Average loss:0.9259, Top-1 Accuracy: 74.3600%, Top-5 Accuracy: 93.8900%, Time consumed:9.80s\n",
      "\n",
      "새로운 최고 top-5 정확도: 93.89%\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [50], Batch [50/391], Loss: 1.7051, LR: 0.000312\n",
      "Epoch [50], Batch [100/391], Loss: 0.4686, LR: 0.000312\n",
      "Epoch [50], Batch [150/391], Loss: 0.5149, LR: 0.000312\n",
      "Epoch [50], Batch [200/391], Loss: 0.7121, LR: 0.000312\n",
      "Epoch [50], Batch [250/391], Loss: 0.5314, LR: 0.000312\n",
      "Epoch [50], Batch [300/391], Loss: 0.7539, LR: 0.000312\n",
      "Epoch [50], Batch [350/391], Loss: 0.6208, LR: 0.000312\n",
      "Train set: Epoch: 50, Average loss:1.4596, LR: 0.000312 Top-1 Accuracy: 71.7680%, Top-5 Accuracy: 90.4920%, Time consumed:89.14s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████████████                                                                           | 50/300 [1:23:02<6:53:54, 99.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 50, Average loss:0.9151, Top-1 Accuracy: 74.4000%, Top-5 Accuracy: 93.8800%, Time consumed:9.96s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [51], Batch [50/391], Loss: 2.1602, LR: 0.000312\n",
      "Epoch [51], Batch [100/391], Loss: 0.5149, LR: 0.000312\n",
      "Epoch [51], Batch [150/391], Loss: 0.5311, LR: 0.000312\n",
      "Epoch [51], Batch [200/391], Loss: 0.6018, LR: 0.000312\n",
      "Epoch [51], Batch [250/391], Loss: 3.0680, LR: 0.000312\n",
      "Epoch [51], Batch [300/391], Loss: 0.6569, LR: 0.000312\n",
      "Epoch [51], Batch [350/391], Loss: 0.4966, LR: 0.000312\n",
      "Train set: Epoch: 51, Average loss:1.4579, LR: 0.000312 Top-1 Accuracy: 71.3100%, Top-5 Accuracy: 90.2100%, Time consumed:90.37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████████████▎                                                                          | 51/300 [1:24:43<6:54:05, 99.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 51, Average loss:0.9190, Top-1 Accuracy: 74.3800%, Top-5 Accuracy: 93.8600%, Time consumed:10.43s\n",
      "\n",
      "EarlyStopping 카운터: 3 / 30\n",
      "Epoch [52], Batch [50/391], Loss: 0.5988, LR: 0.000312\n",
      "Epoch [52], Batch [100/391], Loss: 2.7086, LR: 0.000312\n",
      "Epoch [52], Batch [150/391], Loss: 0.7111, LR: 0.000312\n",
      "Epoch [52], Batch [200/391], Loss: 0.6486, LR: 0.000312\n",
      "Epoch [52], Batch [250/391], Loss: 0.5775, LR: 0.000312\n",
      "Epoch [52], Batch [300/391], Loss: 0.5909, LR: 0.000312\n",
      "Epoch [52], Batch [350/391], Loss: 0.5183, LR: 0.000312\n",
      "Train set: Epoch: 52, Average loss:1.3735, LR: 0.000312 Top-1 Accuracy: 73.0500%, Top-5 Accuracy: 91.1500%, Time consumed:89.54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████████████▌                                                                          | 52/300 [1:26:22<6:51:41, 99.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 52, Average loss:0.9169, Top-1 Accuracy: 74.3300%, Top-5 Accuracy: 93.7100%, Time consumed:9.64s\n",
      "\n",
      "EarlyStopping 카운터: 4 / 30\n",
      "Epoch [53], Batch [50/391], Loss: 3.1413, LR: 0.000312\n",
      "Epoch [53], Batch [100/391], Loss: 0.5805, LR: 0.000312\n",
      "Epoch [53], Batch [150/391], Loss: 0.5156, LR: 0.000312\n",
      "Epoch [53], Batch [200/391], Loss: 3.0196, LR: 0.000312\n",
      "Epoch [53], Batch [250/391], Loss: 0.5526, LR: 0.000312\n",
      "Epoch [53], Batch [300/391], Loss: 0.6974, LR: 0.000312\n",
      "Epoch [53], Batch [350/391], Loss: 2.1417, LR: 0.000312\n",
      "Train set: Epoch: 53, Average loss:1.4339, LR: 0.000312 Top-1 Accuracy: 71.3280%, Top-5 Accuracy: 90.1340%, Time consumed:90.62s\n",
      "Test set: Epoch: 53, Average loss:0.8995, Top-1 Accuracy: 74.4800%, Top-5 Accuracy: 93.7900%, Time consumed:9.68s\n",
      "\n",
      "새로운 최고 top-1 정확도: 74.48%, top-5 정확도: 93.79%\n",
      "Accuracy improved (74.43% --> 74.48%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████████████▉                                                                          | 53/300 [1:28:03<6:51:11, 99.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54], Batch [50/391], Loss: 2.6255, LR: 0.000156\n",
      "Epoch [54], Batch [100/391], Loss: 2.8816, LR: 0.000156\n",
      "Epoch [54], Batch [150/391], Loss: 0.6342, LR: 0.000156\n",
      "Epoch [54], Batch [200/391], Loss: 0.5489, LR: 0.000156\n",
      "Epoch [54], Batch [250/391], Loss: 3.0398, LR: 0.000156\n",
      "Epoch [54], Batch [300/391], Loss: 3.2016, LR: 0.000156\n",
      "Epoch [54], Batch [350/391], Loss: 0.5230, LR: 0.000156\n",
      "Train set: Epoch: 54, Average loss:1.4362, LR: 0.000156 Top-1 Accuracy: 72.2280%, Top-5 Accuracy: 90.7140%, Time consumed:89.89s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|████████████████▏                                                                         | 54/300 [1:29:42<6:49:08, 99.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 54, Average loss:0.9134, Top-1 Accuracy: 74.3800%, Top-5 Accuracy: 93.7000%, Time consumed:9.69s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [55], Batch [50/391], Loss: 0.5516, LR: 0.000156\n",
      "Epoch [55], Batch [100/391], Loss: 2.4167, LR: 0.000156\n",
      "Epoch [55], Batch [150/391], Loss: 1.7316, LR: 0.000156\n",
      "Epoch [55], Batch [200/391], Loss: 2.6374, LR: 0.000156\n",
      "Epoch [55], Batch [250/391], Loss: 0.6251, LR: 0.000156\n",
      "Epoch [55], Batch [300/391], Loss: 0.6179, LR: 0.000156\n",
      "Epoch [55], Batch [350/391], Loss: 0.6104, LR: 0.000156\n",
      "Train set: Epoch: 55, Average loss:1.4972, LR: 0.000156 Top-1 Accuracy: 71.3320%, Top-5 Accuracy: 90.4060%, Time consumed:89.54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|████████████████▌                                                                         | 55/300 [1:31:21<6:46:45, 99.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 55, Average loss:0.9058, Top-1 Accuracy: 74.3900%, Top-5 Accuracy: 93.9400%, Time consumed:9.65s\n",
      "\n",
      "새로운 최고 top-5 정확도: 93.94%\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [56], Batch [50/391], Loss: 2.7328, LR: 0.000156\n",
      "Epoch [56], Batch [100/391], Loss: 0.7148, LR: 0.000156\n",
      "Epoch [56], Batch [150/391], Loss: 0.5080, LR: 0.000156\n",
      "Epoch [56], Batch [200/391], Loss: 0.5077, LR: 0.000156\n",
      "Epoch [56], Batch [250/391], Loss: 0.4660, LR: 0.000156\n",
      "Epoch [56], Batch [300/391], Loss: 0.6634, LR: 0.000156\n",
      "Epoch [56], Batch [350/391], Loss: 2.7002, LR: 0.000156\n",
      "Train set: Epoch: 56, Average loss:1.4660, LR: 0.000156 Top-1 Accuracy: 71.5340%, Top-5 Accuracy: 90.5680%, Time consumed:89.60s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|████████████████▊                                                                         | 56/300 [1:33:01<6:44:41, 99.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 56, Average loss:0.9365, Top-1 Accuracy: 74.1700%, Top-5 Accuracy: 93.7500%, Time consumed:9.67s\n",
      "\n",
      "EarlyStopping 카운터: 3 / 30\n",
      "Epoch [57], Batch [50/391], Loss: 0.5960, LR: 0.000156\n",
      "Epoch [57], Batch [100/391], Loss: 0.6540, LR: 0.000156\n",
      "Epoch [57], Batch [150/391], Loss: 3.1175, LR: 0.000156\n",
      "Epoch [57], Batch [200/391], Loss: 1.8743, LR: 0.000156\n",
      "Epoch [57], Batch [250/391], Loss: 3.0517, LR: 0.000156\n",
      "Epoch [57], Batch [300/391], Loss: 3.0954, LR: 0.000156\n",
      "Epoch [57], Batch [350/391], Loss: 0.6476, LR: 0.000156\n",
      "Train set: Epoch: 57, Average loss:1.4592, LR: 0.000156 Top-1 Accuracy: 71.6000%, Top-5 Accuracy: 90.6620%, Time consumed:89.53s\n",
      "Test set: Epoch: 57, Average loss:0.8995, Top-1 Accuracy: 74.7200%, Top-5 Accuracy: 93.9100%, Time consumed:10.56s\n",
      "\n",
      "새로운 최고 top-1 정확도: 74.72%, top-5 정확도: 93.91%\n",
      "Accuracy improved (74.48% --> 74.72%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█████████████████                                                                         | 57/300 [1:34:41<6:44:01, 99.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58], Batch [50/391], Loss: 2.8161, LR: 0.000156\n",
      "Epoch [58], Batch [100/391], Loss: 1.1318, LR: 0.000156\n",
      "Epoch [58], Batch [150/391], Loss: 0.6729, LR: 0.000156\n",
      "Epoch [58], Batch [200/391], Loss: 3.0043, LR: 0.000156\n",
      "Epoch [58], Batch [250/391], Loss: 0.5227, LR: 0.000156\n",
      "Epoch [58], Batch [300/391], Loss: 2.5990, LR: 0.000156\n",
      "Epoch [58], Batch [350/391], Loss: 0.4748, LR: 0.000156\n",
      "Train set: Epoch: 58, Average loss:1.4287, LR: 0.000156 Top-1 Accuracy: 70.8660%, Top-5 Accuracy: 89.6140%, Time consumed:89.49s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█████████████████▍                                                                        | 58/300 [1:36:20<6:41:49, 99.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 58, Average loss:0.9014, Top-1 Accuracy: 74.6500%, Top-5 Accuracy: 93.8900%, Time consumed:9.81s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [59], Batch [50/391], Loss: 0.5416, LR: 0.000156\n",
      "Epoch [59], Batch [100/391], Loss: 2.8388, LR: 0.000156\n",
      "Epoch [59], Batch [150/391], Loss: 2.0363, LR: 0.000156\n",
      "Epoch [59], Batch [200/391], Loss: 2.5510, LR: 0.000156\n",
      "Epoch [59], Batch [250/391], Loss: 1.2792, LR: 0.000156\n",
      "Epoch [59], Batch [300/391], Loss: 0.5580, LR: 0.000156\n",
      "Epoch [59], Batch [350/391], Loss: 2.7532, LR: 0.000156\n",
      "Train set: Epoch: 59, Average loss:1.4450, LR: 0.000156 Top-1 Accuracy: 71.8140%, Top-5 Accuracy: 90.3520%, Time consumed:89.18s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█████████████████▋                                                                        | 59/300 [1:38:00<6:39:43, 99.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 59, Average loss:0.8966, Top-1 Accuracy: 74.6400%, Top-5 Accuracy: 93.8900%, Time consumed:10.08s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [60], Batch [50/391], Loss: 0.5417, LR: 0.000078\n",
      "Epoch [60], Batch [100/391], Loss: 3.1243, LR: 0.000078\n",
      "Epoch [60], Batch [150/391], Loss: 0.6034, LR: 0.000078\n",
      "Epoch [60], Batch [200/391], Loss: 0.6296, LR: 0.000078\n",
      "Epoch [60], Batch [250/391], Loss: 1.6622, LR: 0.000078\n",
      "Epoch [60], Batch [300/391], Loss: 0.6230, LR: 0.000078\n",
      "Epoch [60], Batch [350/391], Loss: 2.5695, LR: 0.000078\n",
      "Train set: Epoch: 60, Average loss:1.4619, LR: 0.000078 Top-1 Accuracy: 71.3960%, Top-5 Accuracy: 90.3260%, Time consumed:89.38s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████████████                                                                        | 60/300 [1:39:39<6:37:35, 99.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 60, Average loss:0.8972, Top-1 Accuracy: 74.5500%, Top-5 Accuracy: 93.9900%, Time consumed:9.74s\n",
      "\n",
      "새로운 최고 top-5 정확도: 93.99%\n",
      "EarlyStopping 카운터: 3 / 30\n",
      "Epoch [61], Batch [50/391], Loss: 2.4933, LR: 0.000078\n",
      "Epoch [61], Batch [100/391], Loss: 0.6135, LR: 0.000078\n",
      "Epoch [61], Batch [150/391], Loss: 3.0115, LR: 0.000078\n",
      "Epoch [61], Batch [200/391], Loss: 2.9722, LR: 0.000078\n",
      "Epoch [61], Batch [250/391], Loss: 1.0814, LR: 0.000078\n",
      "Epoch [61], Batch [300/391], Loss: 0.5574, LR: 0.000078\n",
      "Epoch [61], Batch [350/391], Loss: 0.8562, LR: 0.000078\n",
      "Train set: Epoch: 61, Average loss:1.4168, LR: 0.000078 Top-1 Accuracy: 73.5140%, Top-5 Accuracy: 91.8140%, Time consumed:89.40s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████████████▎                                                                       | 61/300 [1:41:19<6:36:37, 99.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 61, Average loss:0.9124, Top-1 Accuracy: 74.1100%, Top-5 Accuracy: 93.8000%, Time consumed:10.56s\n",
      "\n",
      "EarlyStopping 카운터: 4 / 30\n",
      "Epoch [62], Batch [50/391], Loss: 2.7026, LR: 0.000078\n",
      "Epoch [62], Batch [100/391], Loss: 2.7723, LR: 0.000078\n",
      "Epoch [62], Batch [150/391], Loss: 3.0426, LR: 0.000078\n",
      "Epoch [62], Batch [200/391], Loss: 0.5182, LR: 0.000078\n",
      "Epoch [62], Batch [250/391], Loss: 0.6794, LR: 0.000078\n",
      "Epoch [62], Batch [300/391], Loss: 3.0390, LR: 0.000078\n",
      "Epoch [62], Batch [350/391], Loss: 1.1070, LR: 0.000078\n",
      "Train set: Epoch: 62, Average loss:1.4698, LR: 0.000078 Top-1 Accuracy: 71.0600%, Top-5 Accuracy: 90.0180%, Time consumed:89.84s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██████████████████▌                                                                       | 62/300 [1:42:58<6:34:51, 99.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 62, Average loss:0.9074, Top-1 Accuracy: 74.4400%, Top-5 Accuracy: 93.8700%, Time consumed:9.64s\n",
      "\n",
      "EarlyStopping 카운터: 5 / 30\n",
      "Epoch [63], Batch [50/391], Loss: 2.5214, LR: 0.000078\n",
      "Epoch [63], Batch [100/391], Loss: 0.4862, LR: 0.000078\n",
      "Epoch [63], Batch [150/391], Loss: 2.3193, LR: 0.000078\n",
      "Epoch [63], Batch [200/391], Loss: 0.5374, LR: 0.000078\n",
      "Epoch [63], Batch [250/391], Loss: 0.6210, LR: 0.000078\n",
      "Epoch [63], Batch [300/391], Loss: 0.6758, LR: 0.000078\n",
      "Epoch [63], Batch [350/391], Loss: 0.6888, LR: 0.000078\n",
      "Train set: Epoch: 63, Average loss:1.4292, LR: 0.000078 Top-1 Accuracy: 73.0980%, Top-5 Accuracy: 91.6320%, Time consumed:89.18s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██████████████████▉                                                                       | 63/300 [1:44:37<6:32:28, 99.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 63, Average loss:0.9263, Top-1 Accuracy: 74.2200%, Top-5 Accuracy: 93.7400%, Time consumed:9.75s\n",
      "\n",
      "EarlyStopping 카운터: 6 / 30\n",
      "Epoch [64], Batch [50/391], Loss: 0.6017, LR: 0.000078\n",
      "Epoch [64], Batch [100/391], Loss: 0.5940, LR: 0.000078\n",
      "Epoch [64], Batch [150/391], Loss: 0.5850, LR: 0.000078\n",
      "Epoch [64], Batch [200/391], Loss: 0.5527, LR: 0.000078\n",
      "Epoch [64], Batch [250/391], Loss: 2.6349, LR: 0.000078\n",
      "Epoch [64], Batch [300/391], Loss: 2.7597, LR: 0.000078\n",
      "Epoch [64], Batch [350/391], Loss: 3.0361, LR: 0.000078\n",
      "Train set: Epoch: 64, Average loss:1.3627, LR: 0.000078 Top-1 Accuracy: 73.3760%, Top-5 Accuracy: 91.6280%, Time consumed:89.29s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|███████████████████▏                                                                      | 64/300 [1:46:16<6:30:17, 99.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 64, Average loss:0.9025, Top-1 Accuracy: 74.5300%, Top-5 Accuracy: 93.9500%, Time consumed:9.62s\n",
      "\n",
      "EarlyStopping 카운터: 7 / 30\n",
      "Epoch [65], Batch [50/391], Loss: 0.4861, LR: 0.000078\n",
      "Epoch [65], Batch [100/391], Loss: 2.2118, LR: 0.000078\n",
      "Epoch [65], Batch [150/391], Loss: 0.4624, LR: 0.000078\n",
      "Epoch [65], Batch [200/391], Loss: 2.7964, LR: 0.000078\n",
      "Epoch [65], Batch [250/391], Loss: 0.5043, LR: 0.000078\n",
      "Epoch [65], Batch [300/391], Loss: 0.5379, LR: 0.000078\n",
      "Epoch [65], Batch [350/391], Loss: 2.2189, LR: 0.000078\n",
      "Train set: Epoch: 65, Average loss:1.4961, LR: 0.000078 Top-1 Accuracy: 71.1360%, Top-5 Accuracy: 89.8780%, Time consumed:90.28s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|███████████████████▌                                                                      | 65/300 [1:47:56<6:29:41, 99.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 65, Average loss:0.9193, Top-1 Accuracy: 74.5100%, Top-5 Accuracy: 93.8900%, Time consumed:9.84s\n",
      "\n",
      "EarlyStopping 카운터: 8 / 30\n",
      "Epoch [66], Batch [50/391], Loss: 0.6330, LR: 0.000039\n",
      "Epoch [66], Batch [100/391], Loss: 0.5353, LR: 0.000039\n",
      "Epoch [66], Batch [150/391], Loss: 3.1101, LR: 0.000039\n",
      "Epoch [66], Batch [200/391], Loss: 0.4789, LR: 0.000039\n",
      "Epoch [66], Batch [250/391], Loss: 3.2364, LR: 0.000039\n",
      "Epoch [66], Batch [300/391], Loss: 0.5031, LR: 0.000039\n",
      "Epoch [66], Batch [350/391], Loss: 0.6720, LR: 0.000039\n",
      "Train set: Epoch: 66, Average loss:1.3797, LR: 0.000039 Top-1 Accuracy: 72.7000%, Top-5 Accuracy: 90.8420%, Time consumed:88.79s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|███████████████████▊                                                                      | 66/300 [1:49:35<6:27:50, 99.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 66, Average loss:0.9079, Top-1 Accuracy: 74.6500%, Top-5 Accuracy: 93.9900%, Time consumed:10.54s\n",
      "\n",
      "EarlyStopping 카운터: 9 / 30\n",
      "Epoch [67], Batch [50/391], Loss: 0.5080, LR: 0.000039\n",
      "Epoch [67], Batch [100/391], Loss: 1.2278, LR: 0.000039\n",
      "Epoch [67], Batch [150/391], Loss: 0.5566, LR: 0.000039\n",
      "Epoch [67], Batch [200/391], Loss: 3.0058, LR: 0.000039\n",
      "Epoch [67], Batch [250/391], Loss: 0.4682, LR: 0.000039\n",
      "Epoch [67], Batch [300/391], Loss: 0.5201, LR: 0.000039\n",
      "Epoch [67], Batch [350/391], Loss: 3.0411, LR: 0.000039\n",
      "Train set: Epoch: 67, Average loss:1.4078, LR: 0.000039 Top-1 Accuracy: 73.4240%, Top-5 Accuracy: 91.5220%, Time consumed:89.14s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|████████████████████                                                                      | 67/300 [1:51:14<6:25:40, 99.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 67, Average loss:0.9078, Top-1 Accuracy: 74.3700%, Top-5 Accuracy: 93.9700%, Time consumed:9.87s\n",
      "\n",
      "EarlyStopping 카운터: 10 / 30\n",
      "Epoch [68], Batch [50/391], Loss: 0.5758, LR: 0.000039\n",
      "Epoch [68], Batch [100/391], Loss: 0.5691, LR: 0.000039\n",
      "Epoch [68], Batch [150/391], Loss: 1.3307, LR: 0.000039\n",
      "Epoch [68], Batch [200/391], Loss: 0.5736, LR: 0.000039\n",
      "Epoch [68], Batch [250/391], Loss: 0.9326, LR: 0.000039\n",
      "Epoch [68], Batch [300/391], Loss: 0.5314, LR: 0.000039\n",
      "Epoch [68], Batch [350/391], Loss: 2.2324, LR: 0.000039\n",
      "Train set: Epoch: 68, Average loss:1.4385, LR: 0.000039 Top-1 Accuracy: 72.4180%, Top-5 Accuracy: 90.9160%, Time consumed:91.68s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|████████████████████▏                                                                    | 68/300 [1:52:57<6:27:28, 100.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 68, Average loss:0.9140, Top-1 Accuracy: 74.5700%, Top-5 Accuracy: 93.9700%, Time consumed:10.61s\n",
      "\n",
      "EarlyStopping 카운터: 11 / 30\n",
      "Epoch [69], Batch [50/391], Loss: 0.5538, LR: 0.000039\n",
      "Epoch [69], Batch [100/391], Loss: 2.8266, LR: 0.000039\n",
      "Epoch [69], Batch [150/391], Loss: 0.6167, LR: 0.000039\n",
      "Epoch [69], Batch [200/391], Loss: 0.5923, LR: 0.000039\n",
      "Epoch [69], Batch [250/391], Loss: 2.8929, LR: 0.000039\n",
      "Epoch [69], Batch [300/391], Loss: 0.5761, LR: 0.000039\n",
      "Epoch [69], Batch [350/391], Loss: 0.5077, LR: 0.000039\n",
      "Train set: Epoch: 69, Average loss:1.4511, LR: 0.000039 Top-1 Accuracy: 71.8940%, Top-5 Accuracy: 90.6320%, Time consumed:88.90s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|████████████████████▋                                                                     | 69/300 [1:54:36<6:24:17, 99.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 69, Average loss:0.9233, Top-1 Accuracy: 74.4600%, Top-5 Accuracy: 93.7800%, Time consumed:9.99s\n",
      "\n",
      "EarlyStopping 카운터: 12 / 30\n",
      "Epoch [70], Batch [50/391], Loss: 2.4437, LR: 0.000039\n",
      "Epoch [70], Batch [100/391], Loss: 0.5714, LR: 0.000039\n",
      "Epoch [70], Batch [150/391], Loss: 0.6181, LR: 0.000039\n",
      "Epoch [70], Batch [200/391], Loss: 2.6923, LR: 0.000039\n",
      "Epoch [70], Batch [250/391], Loss: 0.6192, LR: 0.000039\n",
      "Epoch [70], Batch [300/391], Loss: 0.5429, LR: 0.000039\n",
      "Epoch [70], Batch [350/391], Loss: 0.4666, LR: 0.000039\n",
      "Train set: Epoch: 70, Average loss:1.3970, LR: 0.000039 Top-1 Accuracy: 72.5880%, Top-5 Accuracy: 90.7320%, Time consumed:89.12s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|█████████████████████                                                                     | 70/300 [1:56:15<6:22:04, 99.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 70, Average loss:0.9219, Top-1 Accuracy: 74.6000%, Top-5 Accuracy: 93.8500%, Time consumed:10.21s\n",
      "\n",
      "EarlyStopping 카운터: 13 / 30\n",
      "Epoch [71], Batch [50/391], Loss: 1.1441, LR: 0.000039\n",
      "Epoch [71], Batch [100/391], Loss: 0.5753, LR: 0.000039\n",
      "Epoch [71], Batch [150/391], Loss: 0.6216, LR: 0.000039\n",
      "Epoch [71], Batch [200/391], Loss: 2.8856, LR: 0.000039\n",
      "Epoch [71], Batch [250/391], Loss: 2.7701, LR: 0.000039\n",
      "Epoch [71], Batch [300/391], Loss: 0.6395, LR: 0.000039\n",
      "Epoch [71], Batch [350/391], Loss: 0.4358, LR: 0.000039\n",
      "Train set: Epoch: 71, Average loss:1.4033, LR: 0.000039 Top-1 Accuracy: 73.0540%, Top-5 Accuracy: 91.2800%, Time consumed:89.10s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|█████████████████████▎                                                                    | 71/300 [1:57:54<6:19:32, 99.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 71, Average loss:0.9232, Top-1 Accuracy: 74.5200%, Top-5 Accuracy: 93.8500%, Time consumed:9.80s\n",
      "\n",
      "EarlyStopping 카운터: 14 / 30\n",
      "Epoch [72], Batch [50/391], Loss: 2.0791, LR: 0.000020\n",
      "Epoch [72], Batch [100/391], Loss: 0.6491, LR: 0.000020\n",
      "Epoch [72], Batch [150/391], Loss: 2.6273, LR: 0.000020\n",
      "Epoch [72], Batch [200/391], Loss: 0.6259, LR: 0.000020\n",
      "Epoch [72], Batch [250/391], Loss: 1.5201, LR: 0.000020\n",
      "Epoch [72], Batch [300/391], Loss: 0.5593, LR: 0.000020\n",
      "Epoch [72], Batch [350/391], Loss: 0.4858, LR: 0.000020\n",
      "Train set: Epoch: 72, Average loss:1.3963, LR: 0.000020 Top-1 Accuracy: 72.6920%, Top-5 Accuracy: 90.9720%, Time consumed:89.30s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|█████████████████████▌                                                                    | 72/300 [1:59:33<6:17:40, 99.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 72, Average loss:0.9154, Top-1 Accuracy: 74.4600%, Top-5 Accuracy: 93.7900%, Time consumed:9.95s\n",
      "\n",
      "EarlyStopping 카운터: 15 / 30\n",
      "Epoch [73], Batch [50/391], Loss: 2.7176, LR: 0.000020\n",
      "Epoch [73], Batch [100/391], Loss: 3.0938, LR: 0.000020\n",
      "Epoch [73], Batch [150/391], Loss: 0.5453, LR: 0.000020\n",
      "Epoch [73], Batch [200/391], Loss: 0.5964, LR: 0.000020\n",
      "Epoch [73], Batch [250/391], Loss: 0.4786, LR: 0.000020\n",
      "Epoch [73], Batch [300/391], Loss: 0.6279, LR: 0.000020\n",
      "Epoch [73], Batch [350/391], Loss: 0.5095, LR: 0.000020\n",
      "Train set: Epoch: 73, Average loss:1.4753, LR: 0.000020 Top-1 Accuracy: 71.1600%, Top-5 Accuracy: 90.0380%, Time consumed:88.82s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|█████████████████████▉                                                                    | 73/300 [2:01:12<6:15:03, 99.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 73, Average loss:0.9224, Top-1 Accuracy: 74.3400%, Top-5 Accuracy: 93.7700%, Time consumed:9.71s\n",
      "\n",
      "EarlyStopping 카운터: 16 / 30\n",
      "Epoch [74], Batch [50/391], Loss: 1.9472, LR: 0.000020\n",
      "Epoch [74], Batch [100/391], Loss: 2.0905, LR: 0.000020\n",
      "Epoch [74], Batch [150/391], Loss: 0.5836, LR: 0.000020\n",
      "Epoch [74], Batch [200/391], Loss: 0.7086, LR: 0.000020\n",
      "Epoch [74], Batch [250/391], Loss: 0.5160, LR: 0.000020\n",
      "Epoch [74], Batch [300/391], Loss: 2.8260, LR: 0.000020\n",
      "Epoch [74], Batch [350/391], Loss: 2.3287, LR: 0.000020\n",
      "Train set: Epoch: 74, Average loss:1.5063, LR: 0.000020 Top-1 Accuracy: 70.6820%, Top-5 Accuracy: 89.9480%, Time consumed:89.18s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██████████████████████▏                                                                   | 74/300 [2:02:51<6:13:20, 99.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 74, Average loss:0.9037, Top-1 Accuracy: 74.6400%, Top-5 Accuracy: 94.1000%, Time consumed:9.89s\n",
      "\n",
      "새로운 최고 top-5 정확도: 94.10%\n",
      "EarlyStopping 카운터: 17 / 30\n",
      "Epoch [75], Batch [50/391], Loss: 2.5981, LR: 0.000020\n",
      "Epoch [75], Batch [100/391], Loss: 2.8740, LR: 0.000020\n",
      "Epoch [75], Batch [150/391], Loss: 0.9743, LR: 0.000020\n",
      "Epoch [75], Batch [200/391], Loss: 0.6221, LR: 0.000020\n",
      "Epoch [75], Batch [250/391], Loss: 2.8335, LR: 0.000020\n",
      "Epoch [75], Batch [300/391], Loss: 0.5345, LR: 0.000020\n",
      "Epoch [75], Batch [350/391], Loss: 2.3488, LR: 0.000020\n",
      "Train set: Epoch: 75, Average loss:1.4634, LR: 0.000020 Top-1 Accuracy: 71.9060%, Top-5 Accuracy: 90.6520%, Time consumed:89.45s\n",
      "Test set: Epoch: 75, Average loss:0.8951, Top-1 Accuracy: 74.7500%, Top-5 Accuracy: 93.9200%, Time consumed:9.67s\n",
      "\n",
      "새로운 최고 top-1 정확도: 74.75%, top-5 정확도: 93.92%\n",
      "Accuracy improved (74.72% --> 74.75%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██████████████████████▌                                                                   | 75/300 [2:04:30<6:12:02, 99.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [76], Batch [50/391], Loss: 0.5663, LR: 0.000020\n",
      "Epoch [76], Batch [100/391], Loss: 1.8849, LR: 0.000020\n",
      "Epoch [76], Batch [150/391], Loss: 0.5194, LR: 0.000020\n",
      "Epoch [76], Batch [200/391], Loss: 0.5301, LR: 0.000020\n",
      "Epoch [76], Batch [250/391], Loss: 0.5935, LR: 0.000020\n",
      "Epoch [76], Batch [300/391], Loss: 2.5981, LR: 0.000020\n",
      "Epoch [76], Batch [350/391], Loss: 1.2898, LR: 0.000020\n",
      "Train set: Epoch: 76, Average loss:1.4108, LR: 0.000020 Top-1 Accuracy: 72.1600%, Top-5 Accuracy: 90.5900%, Time consumed:91.91s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██████████████████████▌                                                                  | 76/300 [2:06:12<6:13:25, 100.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 76, Average loss:0.9074, Top-1 Accuracy: 74.7200%, Top-5 Accuracy: 93.9300%, Time consumed:10.00s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [77], Batch [50/391], Loss: 0.5794, LR: 0.000020\n",
      "Epoch [77], Batch [100/391], Loss: 1.7444, LR: 0.000020\n",
      "Epoch [77], Batch [150/391], Loss: 0.4891, LR: 0.000020\n",
      "Epoch [77], Batch [200/391], Loss: 1.3587, LR: 0.000020\n",
      "Epoch [77], Batch [250/391], Loss: 0.4754, LR: 0.000020\n",
      "Epoch [77], Batch [300/391], Loss: 0.5327, LR: 0.000020\n",
      "Epoch [77], Batch [350/391], Loss: 0.6630, LR: 0.000020\n",
      "Train set: Epoch: 77, Average loss:1.4313, LR: 0.000020 Top-1 Accuracy: 72.4480%, Top-5 Accuracy: 90.8800%, Time consumed:89.26s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|███████████████████████                                                                   | 77/300 [2:07:51<6:10:34, 99.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 77, Average loss:0.9089, Top-1 Accuracy: 74.5600%, Top-5 Accuracy: 94.0300%, Time consumed:9.69s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [78], Batch [50/391], Loss: 2.9866, LR: 0.000010\n",
      "Epoch [78], Batch [100/391], Loss: 0.4814, LR: 0.000010\n",
      "Epoch [78], Batch [150/391], Loss: 2.6839, LR: 0.000010\n",
      "Epoch [78], Batch [200/391], Loss: 0.5211, LR: 0.000010\n",
      "Epoch [78], Batch [250/391], Loss: 2.6324, LR: 0.000010\n",
      "Epoch [78], Batch [300/391], Loss: 0.5029, LR: 0.000010\n",
      "Epoch [78], Batch [350/391], Loss: 2.5820, LR: 0.000010\n",
      "Train set: Epoch: 78, Average loss:1.3766, LR: 0.000010 Top-1 Accuracy: 73.2140%, Top-5 Accuracy: 91.2740%, Time consumed:89.16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|███████████████████████▍                                                                  | 78/300 [2:09:30<6:08:30, 99.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 78, Average loss:0.9047, Top-1 Accuracy: 74.5800%, Top-5 Accuracy: 93.8600%, Time consumed:10.19s\n",
      "\n",
      "EarlyStopping 카운터: 3 / 30\n",
      "Epoch [79], Batch [50/391], Loss: 0.6824, LR: 0.000010\n",
      "Epoch [79], Batch [100/391], Loss: 0.6052, LR: 0.000010\n",
      "Epoch [79], Batch [150/391], Loss: 0.6201, LR: 0.000010\n",
      "Epoch [79], Batch [200/391], Loss: 2.8592, LR: 0.000010\n",
      "Epoch [79], Batch [250/391], Loss: 0.5692, LR: 0.000010\n",
      "Epoch [79], Batch [300/391], Loss: 1.5616, LR: 0.000010\n",
      "Epoch [79], Batch [350/391], Loss: 0.6242, LR: 0.000010\n",
      "Train set: Epoch: 79, Average loss:1.4393, LR: 0.000010 Top-1 Accuracy: 72.4560%, Top-5 Accuracy: 90.7320%, Time consumed:93.03s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|███████████████████████▍                                                                 | 79/300 [2:11:14<6:10:59, 100.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 79, Average loss:0.8987, Top-1 Accuracy: 74.4900%, Top-5 Accuracy: 93.8600%, Time consumed:10.31s\n",
      "\n",
      "EarlyStopping 카운터: 4 / 30\n",
      "Epoch [80], Batch [50/391], Loss: 0.4844, LR: 0.000010\n",
      "Epoch [80], Batch [100/391], Loss: 0.5044, LR: 0.000010\n",
      "Epoch [80], Batch [150/391], Loss: 1.5088, LR: 0.000010\n",
      "Epoch [80], Batch [200/391], Loss: 0.5442, LR: 0.000010\n",
      "Epoch [80], Batch [250/391], Loss: 0.4552, LR: 0.000010\n",
      "Epoch [80], Batch [300/391], Loss: 2.5963, LR: 0.000010\n",
      "Epoch [80], Batch [350/391], Loss: 0.9920, LR: 0.000010\n",
      "Train set: Epoch: 80, Average loss:1.3847, LR: 0.000010 Top-1 Accuracy: 72.6780%, Top-5 Accuracy: 90.9180%, Time consumed:89.14s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|███████████████████████▋                                                                 | 80/300 [2:12:53<6:07:39, 100.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 80, Average loss:0.9065, Top-1 Accuracy: 74.6300%, Top-5 Accuracy: 94.0200%, Time consumed:10.07s\n",
      "\n",
      "EarlyStopping 카운터: 5 / 30\n",
      "Epoch [81], Batch [50/391], Loss: 3.2996, LR: 0.000010\n",
      "Epoch [81], Batch [100/391], Loss: 3.1789, LR: 0.000010\n",
      "Epoch [81], Batch [150/391], Loss: 1.1199, LR: 0.000010\n",
      "Epoch [81], Batch [200/391], Loss: 1.3621, LR: 0.000010\n",
      "Epoch [81], Batch [250/391], Loss: 0.5695, LR: 0.000010\n",
      "Epoch [81], Batch [300/391], Loss: 0.6414, LR: 0.000010\n",
      "Epoch [81], Batch [350/391], Loss: 0.8864, LR: 0.000010\n",
      "Train set: Epoch: 81, Average loss:1.4185, LR: 0.000010 Top-1 Accuracy: 72.8640%, Top-5 Accuracy: 91.0860%, Time consumed:89.46s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|████████████████████████▎                                                                 | 81/300 [2:14:32<6:04:50, 99.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 81, Average loss:0.9001, Top-1 Accuracy: 74.6000%, Top-5 Accuracy: 94.0500%, Time consumed:9.76s\n",
      "\n",
      "EarlyStopping 카운터: 6 / 30\n",
      "Epoch [82], Batch [50/391], Loss: 0.5482, LR: 0.000010\n",
      "Epoch [82], Batch [100/391], Loss: 2.8791, LR: 0.000010\n",
      "Epoch [82], Batch [150/391], Loss: 0.5341, LR: 0.000010\n",
      "Epoch [82], Batch [200/391], Loss: 0.7180, LR: 0.000010\n",
      "Epoch [82], Batch [250/391], Loss: 0.5721, LR: 0.000010\n",
      "Epoch [82], Batch [300/391], Loss: 3.0662, LR: 0.000010\n",
      "Epoch [82], Batch [350/391], Loss: 1.9811, LR: 0.000010\n",
      "Train set: Epoch: 82, Average loss:1.4741, LR: 0.000010 Top-1 Accuracy: 71.3260%, Top-5 Accuracy: 90.0240%, Time consumed:90.26s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|████████████████████████▌                                                                 | 82/300 [2:16:12<6:03:04, 99.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 82, Average loss:0.9010, Top-1 Accuracy: 74.6900%, Top-5 Accuracy: 93.8900%, Time consumed:9.60s\n",
      "\n",
      "EarlyStopping 카운터: 7 / 30\n",
      "Epoch [83], Batch [50/391], Loss: 0.5527, LR: 0.000010\n",
      "Epoch [83], Batch [100/391], Loss: 2.9943, LR: 0.000010\n",
      "Epoch [83], Batch [150/391], Loss: 0.4653, LR: 0.000010\n",
      "Epoch [83], Batch [200/391], Loss: 0.6777, LR: 0.000010\n",
      "Epoch [83], Batch [250/391], Loss: 2.4237, LR: 0.000010\n",
      "Epoch [83], Batch [300/391], Loss: 1.1964, LR: 0.000010\n",
      "Epoch [83], Batch [350/391], Loss: 0.6098, LR: 0.000010\n",
      "Train set: Epoch: 83, Average loss:1.4362, LR: 0.000010 Top-1 Accuracy: 72.5420%, Top-5 Accuracy: 90.9020%, Time consumed:89.75s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|████████████████████████▉                                                                 | 83/300 [2:17:51<6:00:54, 99.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 83, Average loss:0.9003, Top-1 Accuracy: 74.6200%, Top-5 Accuracy: 94.0500%, Time consumed:9.71s\n",
      "\n",
      "EarlyStopping 카운터: 8 / 30\n",
      "Epoch [84], Batch [50/391], Loss: 2.0786, LR: 0.000005\n",
      "Epoch [84], Batch [100/391], Loss: 0.4739, LR: 0.000005\n",
      "Epoch [84], Batch [150/391], Loss: 2.4663, LR: 0.000005\n",
      "Epoch [84], Batch [200/391], Loss: 0.5305, LR: 0.000005\n",
      "Epoch [84], Batch [250/391], Loss: 0.6310, LR: 0.000005\n",
      "Epoch [84], Batch [300/391], Loss: 0.5612, LR: 0.000005\n",
      "Epoch [84], Batch [350/391], Loss: 1.8670, LR: 0.000005\n",
      "Train set: Epoch: 84, Average loss:1.4432, LR: 0.000005 Top-1 Accuracy: 72.4820%, Top-5 Accuracy: 90.7620%, Time consumed:88.98s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|█████████████████████████▏                                                                | 84/300 [2:19:30<5:58:09, 99.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 84, Average loss:0.9123, Top-1 Accuracy: 74.6200%, Top-5 Accuracy: 93.8200%, Time consumed:9.80s\n",
      "\n",
      "EarlyStopping 카운터: 9 / 30\n",
      "Epoch [85], Batch [50/391], Loss: 0.5910, LR: 0.000005\n",
      "Epoch [85], Batch [100/391], Loss: 0.6658, LR: 0.000005\n",
      "Epoch [85], Batch [150/391], Loss: 3.0044, LR: 0.000005\n",
      "Epoch [85], Batch [200/391], Loss: 2.5672, LR: 0.000005\n",
      "Epoch [85], Batch [250/391], Loss: 2.6366, LR: 0.000005\n",
      "Epoch [85], Batch [300/391], Loss: 0.5338, LR: 0.000005\n",
      "Epoch [85], Batch [350/391], Loss: 0.5934, LR: 0.000005\n",
      "Train set: Epoch: 85, Average loss:1.4681, LR: 0.000005 Top-1 Accuracy: 72.3000%, Top-5 Accuracy: 90.9400%, Time consumed:89.68s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|█████████████████████████▌                                                                | 85/300 [2:21:10<5:56:21, 99.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 85, Average loss:0.9031, Top-1 Accuracy: 74.7400%, Top-5 Accuracy: 94.0800%, Time consumed:9.67s\n",
      "\n",
      "EarlyStopping 카운터: 10 / 30\n",
      "Epoch [86], Batch [50/391], Loss: 0.5185, LR: 0.000005\n",
      "Epoch [86], Batch [100/391], Loss: 0.6809, LR: 0.000005\n",
      "Epoch [86], Batch [150/391], Loss: 1.8936, LR: 0.000005\n",
      "Epoch [86], Batch [200/391], Loss: 0.5305, LR: 0.000005\n",
      "Epoch [86], Batch [250/391], Loss: 0.5172, LR: 0.000005\n",
      "Epoch [86], Batch [300/391], Loss: 0.5050, LR: 0.000005\n",
      "Epoch [86], Batch [350/391], Loss: 2.8668, LR: 0.000005\n",
      "Train set: Epoch: 86, Average loss:1.4086, LR: 0.000005 Top-1 Accuracy: 73.0160%, Top-5 Accuracy: 90.9340%, Time consumed:89.32s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|█████████████████████████▊                                                                | 86/300 [2:22:49<5:54:50, 99.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 86, Average loss:0.9005, Top-1 Accuracy: 74.6700%, Top-5 Accuracy: 93.9000%, Time consumed:10.25s\n",
      "\n",
      "EarlyStopping 카운터: 11 / 30\n",
      "Epoch [87], Batch [50/391], Loss: 1.6947, LR: 0.000005\n",
      "Epoch [87], Batch [100/391], Loss: 2.5810, LR: 0.000005\n",
      "Epoch [87], Batch [150/391], Loss: 2.5647, LR: 0.000005\n",
      "Epoch [87], Batch [200/391], Loss: 2.9217, LR: 0.000005\n",
      "Epoch [87], Batch [250/391], Loss: 0.7151, LR: 0.000005\n",
      "Epoch [87], Batch [300/391], Loss: 0.6175, LR: 0.000005\n",
      "Epoch [87], Batch [350/391], Loss: 2.9947, LR: 0.000005\n",
      "Train set: Epoch: 87, Average loss:1.4522, LR: 0.000005 Top-1 Accuracy: 72.5820%, Top-5 Accuracy: 90.9240%, Time consumed:89.27s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██████████████████████████                                                                | 87/300 [2:24:29<5:53:06, 99.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 87, Average loss:0.9290, Top-1 Accuracy: 74.3900%, Top-5 Accuracy: 93.6400%, Time consumed:10.15s\n",
      "\n",
      "EarlyStopping 카운터: 12 / 30\n",
      "Epoch [88], Batch [50/391], Loss: 0.5890, LR: 0.000005\n",
      "Epoch [88], Batch [100/391], Loss: 2.9739, LR: 0.000005\n",
      "Epoch [88], Batch [150/391], Loss: 2.5779, LR: 0.000005\n",
      "Epoch [88], Batch [200/391], Loss: 0.4725, LR: 0.000005\n",
      "Epoch [88], Batch [250/391], Loss: 2.9096, LR: 0.000005\n",
      "Epoch [88], Batch [300/391], Loss: 0.5171, LR: 0.000005\n",
      "Epoch [88], Batch [350/391], Loss: 2.8287, LR: 0.000005\n",
      "Train set: Epoch: 88, Average loss:1.4489, LR: 0.000005 Top-1 Accuracy: 71.1400%, Top-5 Accuracy: 89.9000%, Time consumed:89.35s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██████████████████████████▍                                                               | 88/300 [2:26:08<5:51:17, 99.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 88, Average loss:0.8923, Top-1 Accuracy: 74.6900%, Top-5 Accuracy: 93.9400%, Time consumed:9.96s\n",
      "\n",
      "EarlyStopping 카운터: 13 / 30\n",
      "Epoch [89], Batch [50/391], Loss: 0.6021, LR: 0.000005\n",
      "Epoch [89], Batch [100/391], Loss: 2.6589, LR: 0.000005\n",
      "Epoch [89], Batch [150/391], Loss: 0.5518, LR: 0.000005\n",
      "Epoch [89], Batch [200/391], Loss: 0.5522, LR: 0.000005\n",
      "Epoch [89], Batch [250/391], Loss: 0.4272, LR: 0.000005\n",
      "Epoch [89], Batch [300/391], Loss: 0.8897, LR: 0.000005\n",
      "Epoch [89], Batch [350/391], Loss: 2.1513, LR: 0.000005\n",
      "Train set: Epoch: 89, Average loss:1.4148, LR: 0.000005 Top-1 Accuracy: 72.8720%, Top-5 Accuracy: 91.2420%, Time consumed:89.19s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██████████████████████████▋                                                               | 89/300 [2:27:47<5:49:07, 99.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 89, Average loss:0.9049, Top-1 Accuracy: 74.6800%, Top-5 Accuracy: 93.9200%, Time consumed:9.74s\n",
      "\n",
      "EarlyStopping 카운터: 14 / 30\n",
      "Epoch [90], Batch [50/391], Loss: 0.5479, LR: 0.000002\n",
      "Epoch [90], Batch [100/391], Loss: 0.5426, LR: 0.000002\n",
      "Epoch [90], Batch [150/391], Loss: 2.4308, LR: 0.000002\n",
      "Epoch [90], Batch [200/391], Loss: 0.6451, LR: 0.000002\n",
      "Epoch [90], Batch [250/391], Loss: 0.5532, LR: 0.000002\n",
      "Epoch [90], Batch [300/391], Loss: 0.5274, LR: 0.000002\n",
      "Epoch [90], Batch [350/391], Loss: 0.6784, LR: 0.000002\n",
      "Train set: Epoch: 90, Average loss:1.4261, LR: 0.000002 Top-1 Accuracy: 72.5580%, Top-5 Accuracy: 90.6640%, Time consumed:89.58s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████████████████████                                                               | 90/300 [2:29:26<5:47:29, 99.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 90, Average loss:0.9286, Top-1 Accuracy: 74.4700%, Top-5 Accuracy: 93.7300%, Time consumed:9.70s\n",
      "\n",
      "EarlyStopping 카운터: 15 / 30\n",
      "Epoch [91], Batch [50/391], Loss: 2.3391, LR: 0.000002\n",
      "Epoch [91], Batch [100/391], Loss: 0.6114, LR: 0.000002\n",
      "Epoch [91], Batch [150/391], Loss: 3.0618, LR: 0.000002\n",
      "Epoch [91], Batch [200/391], Loss: 0.5598, LR: 0.000002\n",
      "Epoch [91], Batch [250/391], Loss: 0.6282, LR: 0.000002\n",
      "Epoch [91], Batch [300/391], Loss: 0.4731, LR: 0.000002\n",
      "Epoch [91], Batch [350/391], Loss: 0.5953, LR: 0.000002\n",
      "Train set: Epoch: 91, Average loss:1.3432, LR: 0.000002 Top-1 Accuracy: 74.2700%, Top-5 Accuracy: 91.9020%, Time consumed:89.16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████████████████████▎                                                              | 91/300 [2:31:05<5:45:22, 99.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 91, Average loss:0.9097, Top-1 Accuracy: 74.5000%, Top-5 Accuracy: 93.9400%, Time consumed:9.68s\n",
      "\n",
      "EarlyStopping 카운터: 16 / 30\n",
      "Epoch [92], Batch [50/391], Loss: 2.1612, LR: 0.000002\n",
      "Epoch [92], Batch [100/391], Loss: 2.6821, LR: 0.000002\n",
      "Epoch [92], Batch [150/391], Loss: 3.0675, LR: 0.000002\n",
      "Epoch [92], Batch [200/391], Loss: 0.6458, LR: 0.000002\n",
      "Epoch [92], Batch [250/391], Loss: 0.5570, LR: 0.000002\n",
      "Epoch [92], Batch [300/391], Loss: 1.3870, LR: 0.000002\n",
      "Epoch [92], Batch [350/391], Loss: 0.5613, LR: 0.000002\n",
      "Train set: Epoch: 92, Average loss:1.4753, LR: 0.000002 Top-1 Accuracy: 70.7040%, Top-5 Accuracy: 89.3960%, Time consumed:89.11s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███████████████████████████▌                                                              | 92/300 [2:32:45<5:44:31, 99.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 92, Average loss:0.9193, Top-1 Accuracy: 74.4300%, Top-5 Accuracy: 93.6700%, Time consumed:10.82s\n",
      "\n",
      "EarlyStopping 카운터: 17 / 30\n",
      "Epoch [93], Batch [50/391], Loss: 1.0226, LR: 0.000002\n",
      "Epoch [93], Batch [100/391], Loss: 0.6366, LR: 0.000002\n",
      "Epoch [93], Batch [150/391], Loss: 0.6862, LR: 0.000002\n",
      "Epoch [93], Batch [200/391], Loss: 0.5061, LR: 0.000002\n",
      "Epoch [93], Batch [250/391], Loss: 2.8283, LR: 0.000002\n",
      "Epoch [93], Batch [300/391], Loss: 2.3241, LR: 0.000002\n",
      "Epoch [93], Batch [350/391], Loss: 1.2538, LR: 0.000002\n",
      "Train set: Epoch: 93, Average loss:1.4369, LR: 0.000002 Top-1 Accuracy: 72.0460%, Top-5 Accuracy: 90.3880%, Time consumed:89.49s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███████████████████████████▉                                                              | 93/300 [2:34:25<5:43:24, 99.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 93, Average loss:0.9104, Top-1 Accuracy: 74.6700%, Top-5 Accuracy: 93.7900%, Time consumed:10.41s\n",
      "\n",
      "EarlyStopping 카운터: 18 / 30\n",
      "Epoch [94], Batch [50/391], Loss: 0.9140, LR: 0.000002\n",
      "Epoch [94], Batch [100/391], Loss: 0.5027, LR: 0.000002\n",
      "Epoch [94], Batch [150/391], Loss: 2.7348, LR: 0.000002\n",
      "Epoch [94], Batch [200/391], Loss: 1.3979, LR: 0.000002\n",
      "Epoch [94], Batch [250/391], Loss: 3.0511, LR: 0.000002\n",
      "Epoch [94], Batch [300/391], Loss: 0.4182, LR: 0.000002\n",
      "Epoch [94], Batch [350/391], Loss: 2.0746, LR: 0.000002\n",
      "Train set: Epoch: 94, Average loss:1.4701, LR: 0.000002 Top-1 Accuracy: 70.4240%, Top-5 Accuracy: 89.4040%, Time consumed:90.13s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|████████████████████████████▏                                                             | 94/300 [2:36:05<5:42:14, 99.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 94, Average loss:0.8990, Top-1 Accuracy: 74.4700%, Top-5 Accuracy: 93.9900%, Time consumed:9.89s\n",
      "\n",
      "EarlyStopping 카운터: 19 / 30\n",
      "Epoch [95], Batch [50/391], Loss: 0.5037, LR: 0.000002\n",
      "Epoch [95], Batch [100/391], Loss: 1.0632, LR: 0.000002\n",
      "Epoch [95], Batch [150/391], Loss: 1.0873, LR: 0.000002\n",
      "Epoch [95], Batch [200/391], Loss: 2.9609, LR: 0.000002\n",
      "Epoch [95], Batch [250/391], Loss: 0.5321, LR: 0.000002\n",
      "Epoch [95], Batch [300/391], Loss: 2.7809, LR: 0.000002\n",
      "Epoch [95], Batch [350/391], Loss: 0.5284, LR: 0.000002\n",
      "Train set: Epoch: 95, Average loss:1.4735, LR: 0.000002 Top-1 Accuracy: 72.1060%, Top-5 Accuracy: 90.6920%, Time consumed:89.16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|████████████████████████████▌                                                             | 95/300 [2:37:44<5:39:54, 99.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 95, Average loss:0.9390, Top-1 Accuracy: 74.0200%, Top-5 Accuracy: 93.6200%, Time consumed:9.86s\n",
      "\n",
      "EarlyStopping 카운터: 20 / 30\n",
      "Epoch [96], Batch [50/391], Loss: 0.6102, LR: 0.000001\n",
      "Epoch [96], Batch [100/391], Loss: 0.6082, LR: 0.000001\n",
      "Epoch [96], Batch [150/391], Loss: 0.6008, LR: 0.000001\n",
      "Epoch [96], Batch [200/391], Loss: 2.7323, LR: 0.000001\n",
      "Epoch [96], Batch [250/391], Loss: 1.6054, LR: 0.000001\n",
      "Epoch [96], Batch [300/391], Loss: 2.2033, LR: 0.000001\n",
      "Epoch [96], Batch [350/391], Loss: 1.9880, LR: 0.000001\n",
      "Train set: Epoch: 96, Average loss:1.4039, LR: 0.000001 Top-1 Accuracy: 71.9600%, Top-5 Accuracy: 90.3820%, Time consumed:90.13s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|████████████████████████████▊                                                             | 96/300 [2:39:24<5:38:49, 99.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 96, Average loss:0.9087, Top-1 Accuracy: 74.7300%, Top-5 Accuracy: 93.9900%, Time consumed:9.92s\n",
      "\n",
      "EarlyStopping 카운터: 21 / 30\n",
      "Epoch [97], Batch [50/391], Loss: 0.5858, LR: 0.000001\n",
      "Epoch [97], Batch [100/391], Loss: 0.6673, LR: 0.000001\n",
      "Epoch [97], Batch [150/391], Loss: 2.5266, LR: 0.000001\n",
      "Epoch [97], Batch [200/391], Loss: 0.5766, LR: 0.000001\n",
      "Epoch [97], Batch [250/391], Loss: 2.5905, LR: 0.000001\n",
      "Epoch [97], Batch [300/391], Loss: 0.4883, LR: 0.000001\n",
      "Epoch [97], Batch [350/391], Loss: 1.6004, LR: 0.000001\n",
      "Train set: Epoch: 97, Average loss:1.4935, LR: 0.000001 Top-1 Accuracy: 71.4240%, Top-5 Accuracy: 90.3360%, Time consumed:89.06s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|█████████████████████████████                                                             | 97/300 [2:41:03<5:36:14, 99.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 97, Average loss:0.9066, Top-1 Accuracy: 74.5700%, Top-5 Accuracy: 93.9300%, Time consumed:9.67s\n",
      "\n",
      "EarlyStopping 카운터: 22 / 30\n",
      "Epoch [98], Batch [50/391], Loss: 0.6540, LR: 0.000001\n",
      "Epoch [98], Batch [100/391], Loss: 0.5492, LR: 0.000001\n",
      "Epoch [98], Batch [150/391], Loss: 0.5262, LR: 0.000001\n",
      "Epoch [98], Batch [200/391], Loss: 0.8870, LR: 0.000001\n",
      "Epoch [98], Batch [250/391], Loss: 0.5349, LR: 0.000001\n",
      "Epoch [98], Batch [300/391], Loss: 2.9064, LR: 0.000001\n",
      "Epoch [98], Batch [350/391], Loss: 3.1490, LR: 0.000001\n",
      "Train set: Epoch: 98, Average loss:1.3920, LR: 0.000001 Top-1 Accuracy: 72.7100%, Top-5 Accuracy: 90.9400%, Time consumed:89.91s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|█████████████████████████████▍                                                            | 98/300 [2:42:43<5:35:12, 99.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 98, Average loss:0.9131, Top-1 Accuracy: 74.5400%, Top-5 Accuracy: 93.8800%, Time consumed:10.09s\n",
      "\n",
      "EarlyStopping 카운터: 23 / 30\n",
      "Epoch [99], Batch [50/391], Loss: 2.9921, LR: 0.000001\n",
      "Epoch [99], Batch [100/391], Loss: 0.5522, LR: 0.000001\n",
      "Epoch [99], Batch [150/391], Loss: 2.2625, LR: 0.000001\n",
      "Epoch [99], Batch [200/391], Loss: 1.1576, LR: 0.000001\n",
      "Epoch [99], Batch [250/391], Loss: 2.4473, LR: 0.000001\n",
      "Epoch [99], Batch [300/391], Loss: 0.6699, LR: 0.000001\n",
      "Epoch [99], Batch [350/391], Loss: 3.1925, LR: 0.000001\n",
      "Train set: Epoch: 99, Average loss:1.4117, LR: 0.000001 Top-1 Accuracy: 72.6220%, Top-5 Accuracy: 91.2860%, Time consumed:88.99s\n",
      "Test set: Epoch: 99, Average loss:0.8936, Top-1 Accuracy: 74.8200%, Top-5 Accuracy: 93.9000%, Time consumed:10.16s\n",
      "\n",
      "새로운 최고 top-1 정확도: 74.82%, top-5 정확도: 93.90%\n",
      "Accuracy improved (74.75% --> 74.82%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|█████████████████████████████▋                                                            | 99/300 [2:44:22<5:33:22, 99.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100], Batch [50/391], Loss: 1.0716, LR: 0.000001\n",
      "Epoch [100], Batch [100/391], Loss: 0.5134, LR: 0.000001\n",
      "Epoch [100], Batch [150/391], Loss: 0.5814, LR: 0.000001\n",
      "Epoch [100], Batch [200/391], Loss: 0.5512, LR: 0.000001\n",
      "Epoch [100], Batch [250/391], Loss: 0.5560, LR: 0.000001\n",
      "Epoch [100], Batch [300/391], Loss: 0.5643, LR: 0.000001\n",
      "Epoch [100], Batch [350/391], Loss: 0.5283, LR: 0.000001\n",
      "Train set: Epoch: 100, Average loss:1.4025, LR: 0.000001 Top-1 Accuracy: 72.2400%, Top-5 Accuracy: 90.3540%, Time consumed:89.56s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|█████████████████████████████▋                                                           | 100/300 [2:46:02<5:31:48, 99.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 100, Average loss:0.9010, Top-1 Accuracy: 74.5000%, Top-5 Accuracy: 93.8000%, Time consumed:10.03s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [101], Batch [50/391], Loss: 0.6361, LR: 0.000001\n",
      "Epoch [101], Batch [100/391], Loss: 0.5824, LR: 0.000001\n",
      "Epoch [101], Batch [150/391], Loss: 1.1528, LR: 0.000001\n",
      "Epoch [101], Batch [200/391], Loss: 1.6511, LR: 0.000001\n",
      "Epoch [101], Batch [250/391], Loss: 2.6737, LR: 0.000001\n",
      "Epoch [101], Batch [300/391], Loss: 1.9352, LR: 0.000001\n",
      "Epoch [101], Batch [350/391], Loss: 1.3386, LR: 0.000001\n",
      "Train set: Epoch: 101, Average loss:1.4183, LR: 0.000001 Top-1 Accuracy: 73.0040%, Top-5 Accuracy: 91.2680%, Time consumed:89.95s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|█████████████████████████████▉                                                           | 101/300 [2:47:41<5:30:22, 99.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 101, Average loss:0.9078, Top-1 Accuracy: 74.6300%, Top-5 Accuracy: 93.7600%, Time consumed:9.81s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [102], Batch [50/391], Loss: 0.6232, LR: 0.000001\n",
      "Epoch [102], Batch [100/391], Loss: 0.5756, LR: 0.000001\n",
      "Epoch [102], Batch [150/391], Loss: 2.9950, LR: 0.000001\n",
      "Epoch [102], Batch [200/391], Loss: 0.6105, LR: 0.000001\n",
      "Epoch [102], Batch [250/391], Loss: 0.6677, LR: 0.000001\n",
      "Epoch [102], Batch [300/391], Loss: 3.0991, LR: 0.000001\n",
      "Epoch [102], Batch [350/391], Loss: 0.5783, LR: 0.000001\n",
      "Train set: Epoch: 102, Average loss:1.5475, LR: 0.000001 Top-1 Accuracy: 69.6940%, Top-5 Accuracy: 89.1820%, Time consumed:89.42s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|██████████████████████████████▎                                                          | 102/300 [2:49:22<5:29:14, 99.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 102, Average loss:0.8991, Top-1 Accuracy: 74.6200%, Top-5 Accuracy: 93.9800%, Time consumed:10.71s\n",
      "\n",
      "EarlyStopping 카운터: 3 / 30\n",
      "Epoch [103], Batch [50/391], Loss: 0.6623, LR: 0.000001\n",
      "Epoch [103], Batch [100/391], Loss: 1.1576, LR: 0.000001\n",
      "Epoch [103], Batch [150/391], Loss: 0.4741, LR: 0.000001\n",
      "Epoch [103], Batch [200/391], Loss: 2.2775, LR: 0.000001\n",
      "Epoch [103], Batch [250/391], Loss: 0.5427, LR: 0.000001\n",
      "Epoch [103], Batch [300/391], Loss: 0.6445, LR: 0.000001\n",
      "Epoch [103], Batch [350/391], Loss: 0.5784, LR: 0.000001\n",
      "Train set: Epoch: 103, Average loss:1.3538, LR: 0.000001 Top-1 Accuracy: 73.0700%, Top-5 Accuracy: 91.0060%, Time consumed:89.76s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|██████████████████████████████▌                                                          | 103/300 [2:51:01<5:27:17, 99.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 103, Average loss:0.8899, Top-1 Accuracy: 74.7700%, Top-5 Accuracy: 93.9400%, Time consumed:9.71s\n",
      "\n",
      "EarlyStopping 카운터: 4 / 30\n",
      "Epoch [104], Batch [50/391], Loss: 2.3624, LR: 0.000001\n",
      "Epoch [104], Batch [100/391], Loss: 3.1025, LR: 0.000001\n",
      "Epoch [104], Batch [150/391], Loss: 2.0290, LR: 0.000001\n",
      "Epoch [104], Batch [200/391], Loss: 0.5301, LR: 0.000001\n",
      "Epoch [104], Batch [250/391], Loss: 0.6796, LR: 0.000001\n",
      "Epoch [104], Batch [300/391], Loss: 1.9339, LR: 0.000001\n",
      "Epoch [104], Batch [350/391], Loss: 0.5639, LR: 0.000001\n",
      "Train set: Epoch: 104, Average loss:1.3931, LR: 0.000001 Top-1 Accuracy: 73.3720%, Top-5 Accuracy: 91.5960%, Time consumed:90.33s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|██████████████████████████████▊                                                          | 104/300 [2:52:42<5:26:35, 99.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 104, Average loss:0.9155, Top-1 Accuracy: 74.4300%, Top-5 Accuracy: 93.7800%, Time consumed:10.34s\n",
      "\n",
      "EarlyStopping 카운터: 5 / 30\n",
      "Epoch [105], Batch [50/391], Loss: 2.8928, LR: 0.000001\n",
      "Epoch [105], Batch [100/391], Loss: 2.7731, LR: 0.000001\n",
      "Epoch [105], Batch [150/391], Loss: 1.4484, LR: 0.000001\n",
      "Epoch [105], Batch [200/391], Loss: 1.9225, LR: 0.000001\n",
      "Epoch [105], Batch [250/391], Loss: 0.4102, LR: 0.000001\n",
      "Epoch [105], Batch [300/391], Loss: 2.4261, LR: 0.000001\n",
      "Epoch [105], Batch [350/391], Loss: 1.8709, LR: 0.000001\n",
      "Train set: Epoch: 105, Average loss:1.4894, LR: 0.000001 Top-1 Accuracy: 71.2460%, Top-5 Accuracy: 90.1280%, Time consumed:89.40s\n",
      "Test set: Epoch: 105, Average loss:0.9036, Top-1 Accuracy: 74.8800%, Top-5 Accuracy: 94.0400%, Time consumed:9.76s\n",
      "\n",
      "새로운 최고 top-1 정확도: 74.88%, top-5 정확도: 94.04%\n",
      "Accuracy improved (74.82% --> 74.88%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███████████████████████████████▏                                                         | 105/300 [2:54:21<5:24:23, 99.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [106], Batch [50/391], Loss: 3.0933, LR: 0.000001\n",
      "Epoch [106], Batch [100/391], Loss: 0.7522, LR: 0.000001\n",
      "Epoch [106], Batch [150/391], Loss: 0.6463, LR: 0.000001\n",
      "Epoch [106], Batch [200/391], Loss: 0.5248, LR: 0.000001\n",
      "Epoch [106], Batch [250/391], Loss: 0.7477, LR: 0.000001\n",
      "Epoch [106], Batch [300/391], Loss: 1.3453, LR: 0.000001\n",
      "Epoch [106], Batch [350/391], Loss: 0.5415, LR: 0.000001\n",
      "Train set: Epoch: 106, Average loss:1.4153, LR: 0.000001 Top-1 Accuracy: 72.9980%, Top-5 Accuracy: 91.3320%, Time consumed:88.95s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███████████████████████████████▍                                                         | 106/300 [2:56:00<5:22:03, 99.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 106, Average loss:0.9027, Top-1 Accuracy: 74.5800%, Top-5 Accuracy: 93.8100%, Time consumed:10.17s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [107], Batch [50/391], Loss: 2.3523, LR: 0.000001\n",
      "Epoch [107], Batch [100/391], Loss: 1.0760, LR: 0.000001\n",
      "Epoch [107], Batch [150/391], Loss: 0.9651, LR: 0.000001\n",
      "Epoch [107], Batch [200/391], Loss: 3.0601, LR: 0.000001\n",
      "Epoch [107], Batch [250/391], Loss: 0.6620, LR: 0.000001\n",
      "Epoch [107], Batch [300/391], Loss: 0.4779, LR: 0.000001\n",
      "Epoch [107], Batch [350/391], Loss: 2.2759, LR: 0.000001\n",
      "Train set: Epoch: 107, Average loss:1.3389, LR: 0.000001 Top-1 Accuracy: 74.2220%, Top-5 Accuracy: 91.7780%, Time consumed:90.40s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███████████████████████████████▋                                                         | 107/300 [2:57:41<5:21:10, 99.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 107, Average loss:0.9100, Top-1 Accuracy: 74.7100%, Top-5 Accuracy: 93.9100%, Time consumed:10.00s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [108], Batch [50/391], Loss: 0.4632, LR: 0.000001\n",
      "Epoch [108], Batch [100/391], Loss: 0.5460, LR: 0.000001\n",
      "Epoch [108], Batch [150/391], Loss: 0.5927, LR: 0.000001\n",
      "Epoch [108], Batch [200/391], Loss: 2.9218, LR: 0.000001\n",
      "Epoch [108], Batch [250/391], Loss: 0.5561, LR: 0.000001\n",
      "Epoch [108], Batch [300/391], Loss: 0.5539, LR: 0.000001\n",
      "Epoch [108], Batch [350/391], Loss: 0.5796, LR: 0.000001\n",
      "Train set: Epoch: 108, Average loss:1.4009, LR: 0.000001 Top-1 Accuracy: 73.0600%, Top-5 Accuracy: 91.1540%, Time consumed:89.36s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|████████████████████████████████                                                         | 108/300 [2:59:20<5:18:51, 99.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 108, Average loss:0.9096, Top-1 Accuracy: 74.5400%, Top-5 Accuracy: 93.7800%, Time consumed:9.81s\n",
      "\n",
      "EarlyStopping 카운터: 3 / 30\n",
      "Epoch [109], Batch [50/391], Loss: 1.1990, LR: 0.000001\n",
      "Epoch [109], Batch [100/391], Loss: 3.0000, LR: 0.000001\n",
      "Epoch [109], Batch [150/391], Loss: 0.9948, LR: 0.000001\n",
      "Epoch [109], Batch [200/391], Loss: 0.5585, LR: 0.000001\n",
      "Epoch [109], Batch [250/391], Loss: 0.7021, LR: 0.000001\n",
      "Epoch [109], Batch [300/391], Loss: 3.1355, LR: 0.000001\n",
      "Epoch [109], Batch [350/391], Loss: 0.4542, LR: 0.000001\n",
      "Train set: Epoch: 109, Average loss:1.4026, LR: 0.000001 Top-1 Accuracy: 72.4060%, Top-5 Accuracy: 90.4500%, Time consumed:89.23s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|████████████████████████████████▎                                                        | 109/300 [3:00:59<5:17:11, 99.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 109, Average loss:0.9264, Top-1 Accuracy: 74.2100%, Top-5 Accuracy: 93.8800%, Time consumed:10.40s\n",
      "\n",
      "EarlyStopping 카운터: 4 / 30\n",
      "Epoch [110], Batch [50/391], Loss: 3.0179, LR: 0.000001\n",
      "Epoch [110], Batch [100/391], Loss: 0.5444, LR: 0.000001\n",
      "Epoch [110], Batch [150/391], Loss: 0.5495, LR: 0.000001\n",
      "Epoch [110], Batch [200/391], Loss: 2.8735, LR: 0.000001\n",
      "Epoch [110], Batch [250/391], Loss: 1.5559, LR: 0.000001\n",
      "Epoch [110], Batch [300/391], Loss: 0.4797, LR: 0.000001\n",
      "Epoch [110], Batch [350/391], Loss: 2.9544, LR: 0.000001\n",
      "Train set: Epoch: 110, Average loss:1.4509, LR: 0.000001 Top-1 Accuracy: 72.5860%, Top-5 Accuracy: 90.9780%, Time consumed:90.72s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|████████████████████████████████▋                                                        | 110/300 [3:02:40<5:16:24, 99.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 110, Average loss:0.9082, Top-1 Accuracy: 74.5000%, Top-5 Accuracy: 93.8800%, Time consumed:9.84s\n",
      "\n",
      "EarlyStopping 카운터: 5 / 30\n",
      "Epoch [111], Batch [50/391], Loss: 2.8549, LR: 0.000001\n",
      "Epoch [111], Batch [100/391], Loss: 2.5298, LR: 0.000001\n",
      "Epoch [111], Batch [150/391], Loss: 2.8459, LR: 0.000001\n",
      "Epoch [111], Batch [200/391], Loss: 3.0711, LR: 0.000001\n",
      "Epoch [111], Batch [250/391], Loss: 0.5155, LR: 0.000001\n",
      "Epoch [111], Batch [300/391], Loss: 0.5190, LR: 0.000001\n",
      "Epoch [111], Batch [350/391], Loss: 0.5600, LR: 0.000001\n",
      "Train set: Epoch: 111, Average loss:1.4718, LR: 0.000001 Top-1 Accuracy: 71.7620%, Top-5 Accuracy: 90.4240%, Time consumed:89.42s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|████████████████████████████████▉                                                        | 111/300 [3:04:19<5:14:08, 99.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 111, Average loss:0.9103, Top-1 Accuracy: 74.5500%, Top-5 Accuracy: 93.8200%, Time consumed:9.86s\n",
      "\n",
      "EarlyStopping 카운터: 6 / 30\n",
      "Epoch [112], Batch [50/391], Loss: 0.5831, LR: 0.000001\n",
      "Epoch [112], Batch [100/391], Loss: 0.4711, LR: 0.000001\n",
      "Epoch [112], Batch [150/391], Loss: 0.6186, LR: 0.000001\n",
      "Epoch [112], Batch [200/391], Loss: 0.5439, LR: 0.000001\n",
      "Epoch [112], Batch [250/391], Loss: 2.7620, LR: 0.000001\n",
      "Epoch [112], Batch [300/391], Loss: 1.8032, LR: 0.000001\n",
      "Epoch [112], Batch [350/391], Loss: 2.2190, LR: 0.000001\n",
      "Train set: Epoch: 112, Average loss:1.3771, LR: 0.000001 Top-1 Accuracy: 73.1540%, Top-5 Accuracy: 90.9500%, Time consumed:89.19s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|█████████████████████████████████▏                                                       | 112/300 [3:05:58<5:11:46, 99.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 112, Average loss:0.8958, Top-1 Accuracy: 74.7800%, Top-5 Accuracy: 94.1400%, Time consumed:9.78s\n",
      "\n",
      "새로운 최고 top-5 정확도: 94.14%\n",
      "EarlyStopping 카운터: 7 / 30\n",
      "Epoch [113], Batch [50/391], Loss: 0.8762, LR: 0.000001\n",
      "Epoch [113], Batch [100/391], Loss: 3.0328, LR: 0.000001\n",
      "Epoch [113], Batch [150/391], Loss: 0.7613, LR: 0.000001\n",
      "Epoch [113], Batch [200/391], Loss: 0.5347, LR: 0.000001\n",
      "Epoch [113], Batch [250/391], Loss: 0.4798, LR: 0.000001\n",
      "Epoch [113], Batch [300/391], Loss: 0.5577, LR: 0.000001\n",
      "Epoch [113], Batch [350/391], Loss: 2.0735, LR: 0.000001\n",
      "Train set: Epoch: 113, Average loss:1.4787, LR: 0.000001 Top-1 Accuracy: 70.5940%, Top-5 Accuracy: 89.7800%, Time consumed:88.79s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|█████████████████████████████████▌                                                       | 113/300 [3:07:37<5:09:24, 99.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 113, Average loss:0.8918, Top-1 Accuracy: 74.6500%, Top-5 Accuracy: 94.0300%, Time consumed:9.95s\n",
      "\n",
      "EarlyStopping 카운터: 8 / 30\n",
      "Epoch [114], Batch [50/391], Loss: 2.8189, LR: 0.000001\n",
      "Epoch [114], Batch [100/391], Loss: 2.0541, LR: 0.000001\n",
      "Epoch [114], Batch [150/391], Loss: 2.7367, LR: 0.000001\n",
      "Epoch [114], Batch [200/391], Loss: 2.4526, LR: 0.000001\n",
      "Epoch [114], Batch [250/391], Loss: 0.5255, LR: 0.000001\n",
      "Epoch [114], Batch [300/391], Loss: 0.6499, LR: 0.000001\n",
      "Epoch [114], Batch [350/391], Loss: 2.4973, LR: 0.000001\n",
      "Train set: Epoch: 114, Average loss:1.5042, LR: 0.000001 Top-1 Accuracy: 71.7700%, Top-5 Accuracy: 90.5380%, Time consumed:90.34s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|█████████████████████████████████▊                                                       | 114/300 [3:09:17<5:08:34, 99.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 114, Average loss:0.9099, Top-1 Accuracy: 74.8100%, Top-5 Accuracy: 93.8300%, Time consumed:9.81s\n",
      "\n",
      "EarlyStopping 카운터: 9 / 30\n",
      "Epoch [115], Batch [50/391], Loss: 2.9952, LR: 0.000001\n",
      "Epoch [115], Batch [100/391], Loss: 0.6280, LR: 0.000001\n",
      "Epoch [115], Batch [150/391], Loss: 0.6227, LR: 0.000001\n",
      "Epoch [115], Batch [200/391], Loss: 0.5336, LR: 0.000001\n",
      "Epoch [115], Batch [250/391], Loss: 2.9018, LR: 0.000001\n",
      "Epoch [115], Batch [300/391], Loss: 2.4263, LR: 0.000001\n",
      "Epoch [115], Batch [350/391], Loss: 2.4503, LR: 0.000001\n",
      "Train set: Epoch: 115, Average loss:1.4971, LR: 0.000001 Top-1 Accuracy: 71.4680%, Top-5 Accuracy: 90.2020%, Time consumed:89.30s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|██████████████████████████████████                                                       | 115/300 [3:10:56<5:06:38, 99.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 115, Average loss:0.9180, Top-1 Accuracy: 74.3400%, Top-5 Accuracy: 93.6300%, Time consumed:9.95s\n",
      "\n",
      "EarlyStopping 카운터: 10 / 30\n",
      "Epoch [116], Batch [50/391], Loss: 0.5881, LR: 0.000001\n",
      "Epoch [116], Batch [100/391], Loss: 0.6428, LR: 0.000001\n",
      "Epoch [116], Batch [150/391], Loss: 0.6382, LR: 0.000001\n",
      "Epoch [116], Batch [200/391], Loss: 2.7667, LR: 0.000001\n",
      "Epoch [116], Batch [250/391], Loss: 0.5308, LR: 0.000001\n",
      "Epoch [116], Batch [300/391], Loss: 0.4781, LR: 0.000001\n",
      "Epoch [116], Batch [350/391], Loss: 0.5955, LR: 0.000001\n",
      "Train set: Epoch: 116, Average loss:1.3776, LR: 0.000001 Top-1 Accuracy: 73.4580%, Top-5 Accuracy: 91.3720%, Time consumed:88.93s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|██████████████████████████████████▍                                                      | 116/300 [3:12:36<5:04:55, 99.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 116, Average loss:0.9020, Top-1 Accuracy: 74.6600%, Top-5 Accuracy: 93.9500%, Time consumed:10.44s\n",
      "\n",
      "EarlyStopping 카운터: 11 / 30\n",
      "Epoch [117], Batch [50/391], Loss: 0.5895, LR: 0.000001\n",
      "Epoch [117], Batch [100/391], Loss: 0.5875, LR: 0.000001\n",
      "Epoch [117], Batch [150/391], Loss: 2.7199, LR: 0.000001\n",
      "Epoch [117], Batch [200/391], Loss: 0.5751, LR: 0.000001\n",
      "Epoch [117], Batch [250/391], Loss: 0.5395, LR: 0.000001\n",
      "Epoch [117], Batch [300/391], Loss: 2.7630, LR: 0.000001\n",
      "Epoch [117], Batch [350/391], Loss: 0.5627, LR: 0.000001\n",
      "Train set: Epoch: 117, Average loss:1.4209, LR: 0.000001 Top-1 Accuracy: 72.3140%, Top-5 Accuracy: 90.7580%, Time consumed:88.92s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|██████████████████████████████████▋                                                      | 117/300 [3:14:15<5:02:33, 99.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 117, Average loss:0.9221, Top-1 Accuracy: 74.4100%, Top-5 Accuracy: 93.8100%, Time consumed:9.74s\n",
      "\n",
      "EarlyStopping 카운터: 12 / 30\n",
      "Epoch [118], Batch [50/391], Loss: 1.3846, LR: 0.000001\n",
      "Epoch [118], Batch [100/391], Loss: 0.8900, LR: 0.000001\n",
      "Epoch [118], Batch [150/391], Loss: 0.5188, LR: 0.000001\n",
      "Epoch [118], Batch [200/391], Loss: 0.5773, LR: 0.000001\n",
      "Epoch [118], Batch [250/391], Loss: 0.5977, LR: 0.000001\n",
      "Epoch [118], Batch [300/391], Loss: 0.4428, LR: 0.000001\n",
      "Epoch [118], Batch [350/391], Loss: 1.4880, LR: 0.000001\n",
      "Train set: Epoch: 118, Average loss:1.5114, LR: 0.000001 Top-1 Accuracy: 70.9320%, Top-5 Accuracy: 90.0460%, Time consumed:89.56s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███████████████████████████████████                                                      | 118/300 [3:15:54<5:01:23, 99.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 118, Average loss:0.9179, Top-1 Accuracy: 74.5100%, Top-5 Accuracy: 93.9500%, Time consumed:10.17s\n",
      "\n",
      "EarlyStopping 카운터: 13 / 30\n",
      "Epoch [119], Batch [50/391], Loss: 2.8738, LR: 0.000001\n",
      "Epoch [119], Batch [100/391], Loss: 2.3550, LR: 0.000001\n",
      "Epoch [119], Batch [150/391], Loss: 0.5192, LR: 0.000001\n",
      "Epoch [119], Batch [200/391], Loss: 0.5655, LR: 0.000001\n",
      "Epoch [119], Batch [250/391], Loss: 2.9790, LR: 0.000001\n",
      "Epoch [119], Batch [300/391], Loss: 0.5713, LR: 0.000001\n",
      "Epoch [119], Batch [350/391], Loss: 2.4713, LR: 0.000001\n",
      "Train set: Epoch: 119, Average loss:1.4643, LR: 0.000001 Top-1 Accuracy: 71.9100%, Top-5 Accuracy: 90.5100%, Time consumed:89.66s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███████████████████████████████████▎                                                     | 119/300 [3:17:34<4:59:46, 99.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 119, Average loss:0.9147, Top-1 Accuracy: 74.4600%, Top-5 Accuracy: 93.8400%, Time consumed:9.74s\n",
      "\n",
      "EarlyStopping 카운터: 14 / 30\n",
      "Epoch [120], Batch [50/391], Loss: 2.9314, LR: 0.000001\n",
      "Epoch [120], Batch [100/391], Loss: 0.6199, LR: 0.000001\n",
      "Epoch [120], Batch [150/391], Loss: 0.5126, LR: 0.000001\n",
      "Epoch [120], Batch [200/391], Loss: 0.4885, LR: 0.000001\n",
      "Epoch [120], Batch [250/391], Loss: 0.6021, LR: 0.000001\n",
      "Epoch [120], Batch [300/391], Loss: 0.5853, LR: 0.000001\n",
      "Epoch [120], Batch [350/391], Loss: 0.5966, LR: 0.000001\n",
      "Train set: Epoch: 120, Average loss:1.3276, LR: 0.000001 Top-1 Accuracy: 74.6140%, Top-5 Accuracy: 92.3200%, Time consumed:88.79s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███████████████████████████████████▌                                                     | 120/300 [3:19:12<4:57:36, 99.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 120, Average loss:0.9056, Top-1 Accuracy: 74.4500%, Top-5 Accuracy: 93.8800%, Time consumed:10.00s\n",
      "\n",
      "EarlyStopping 카운터: 15 / 30\n",
      "Epoch [121], Batch [50/391], Loss: 0.5665, LR: 0.000001\n",
      "Epoch [121], Batch [100/391], Loss: 2.5734, LR: 0.000001\n",
      "Epoch [121], Batch [150/391], Loss: 0.7351, LR: 0.000001\n",
      "Epoch [121], Batch [200/391], Loss: 0.5080, LR: 0.000001\n",
      "Epoch [121], Batch [250/391], Loss: 1.5980, LR: 0.000001\n",
      "Epoch [121], Batch [300/391], Loss: 0.6297, LR: 0.000001\n",
      "Epoch [121], Batch [350/391], Loss: 0.5014, LR: 0.000001\n",
      "Train set: Epoch: 121, Average loss:1.4764, LR: 0.000001 Top-1 Accuracy: 71.0900%, Top-5 Accuracy: 90.0580%, Time consumed:90.12s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███████████████████████████████████▉                                                     | 121/300 [3:20:52<4:56:34, 99.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 121, Average loss:0.8961, Top-1 Accuracy: 74.6900%, Top-5 Accuracy: 94.0300%, Time consumed:9.77s\n",
      "\n",
      "EarlyStopping 카운터: 16 / 30\n",
      "Epoch [122], Batch [50/391], Loss: 1.3795, LR: 0.000001\n",
      "Epoch [122], Batch [100/391], Loss: 3.0026, LR: 0.000001\n",
      "Epoch [122], Batch [150/391], Loss: 0.5724, LR: 0.000001\n",
      "Epoch [122], Batch [200/391], Loss: 0.4832, LR: 0.000001\n",
      "Epoch [122], Batch [250/391], Loss: 2.7994, LR: 0.000001\n",
      "Epoch [122], Batch [300/391], Loss: 1.2032, LR: 0.000001\n",
      "Epoch [122], Batch [350/391], Loss: 0.6490, LR: 0.000001\n",
      "Train set: Epoch: 122, Average loss:1.3543, LR: 0.000001 Top-1 Accuracy: 73.6480%, Top-5 Accuracy: 91.5340%, Time consumed:89.39s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████████████████████████████████████▏                                                    | 122/300 [3:22:32<4:54:49, 99.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 122, Average loss:0.9009, Top-1 Accuracy: 74.7600%, Top-5 Accuracy: 93.9400%, Time consumed:9.92s\n",
      "\n",
      "EarlyStopping 카운터: 17 / 30\n",
      "Epoch [123], Batch [50/391], Loss: 2.2354, LR: 0.000001\n",
      "Epoch [123], Batch [100/391], Loss: 3.0206, LR: 0.000001\n",
      "Epoch [123], Batch [150/391], Loss: 0.5974, LR: 0.000001\n",
      "Epoch [123], Batch [200/391], Loss: 2.8279, LR: 0.000001\n",
      "Epoch [123], Batch [250/391], Loss: 2.7269, LR: 0.000001\n",
      "Epoch [123], Batch [300/391], Loss: 2.7496, LR: 0.000001\n",
      "Epoch [123], Batch [350/391], Loss: 0.4385, LR: 0.000001\n",
      "Train set: Epoch: 123, Average loss:1.4264, LR: 0.000001 Top-1 Accuracy: 72.7680%, Top-5 Accuracy: 90.8960%, Time consumed:90.38s\n",
      "Test set: Epoch: 123, Average loss:0.8855, Top-1 Accuracy: 74.9100%, Top-5 Accuracy: 93.9900%, Time consumed:9.98s\n",
      "\n",
      "새로운 최고 top-1 정확도: 74.91%, top-5 정확도: 93.99%\n",
      "Accuracy improved (74.88% --> 74.91%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████████████████████████████████████▍                                                    | 123/300 [3:24:12<4:54:14, 99.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [124], Batch [50/391], Loss: 2.6859, LR: 0.000001\n",
      "Epoch [124], Batch [100/391], Loss: 0.5529, LR: 0.000001\n",
      "Epoch [124], Batch [150/391], Loss: 2.5967, LR: 0.000001\n",
      "Epoch [124], Batch [200/391], Loss: 0.6427, LR: 0.000001\n",
      "Epoch [124], Batch [250/391], Loss: 2.7557, LR: 0.000001\n",
      "Epoch [124], Batch [300/391], Loss: 0.8212, LR: 0.000001\n",
      "Epoch [124], Batch [350/391], Loss: 0.5728, LR: 0.000001\n",
      "Train set: Epoch: 124, Average loss:1.4067, LR: 0.000001 Top-1 Accuracy: 72.6180%, Top-5 Accuracy: 90.8140%, Time consumed:89.21s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████████████████████████████████████▊                                                    | 124/300 [3:25:52<4:52:40, 99.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 124, Average loss:0.9254, Top-1 Accuracy: 74.2500%, Top-5 Accuracy: 93.7800%, Time consumed:10.64s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [125], Batch [50/391], Loss: 0.5384, LR: 0.000001\n",
      "Epoch [125], Batch [100/391], Loss: 2.9315, LR: 0.000001\n",
      "Epoch [125], Batch [150/391], Loss: 0.6162, LR: 0.000001\n",
      "Epoch [125], Batch [200/391], Loss: 0.5350, LR: 0.000001\n",
      "Epoch [125], Batch [250/391], Loss: 0.5095, LR: 0.000001\n",
      "Epoch [125], Batch [300/391], Loss: 2.9214, LR: 0.000001\n",
      "Epoch [125], Batch [350/391], Loss: 0.6150, LR: 0.000001\n",
      "Train set: Epoch: 125, Average loss:1.4292, LR: 0.000001 Top-1 Accuracy: 72.2880%, Top-5 Accuracy: 90.7260%, Time consumed:89.64s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|█████████████████████████████████████                                                    | 125/300 [3:27:32<4:50:57, 99.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 125, Average loss:0.9230, Top-1 Accuracy: 74.5100%, Top-5 Accuracy: 93.7800%, Time consumed:10.06s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [126], Batch [50/391], Loss: 0.5654, LR: 0.000001\n",
      "Epoch [126], Batch [100/391], Loss: 0.5791, LR: 0.000001\n",
      "Epoch [126], Batch [150/391], Loss: 0.6175, LR: 0.000001\n",
      "Epoch [126], Batch [200/391], Loss: 0.4430, LR: 0.000001\n",
      "Epoch [126], Batch [250/391], Loss: 0.4930, LR: 0.000001\n",
      "Epoch [126], Batch [300/391], Loss: 0.3865, LR: 0.000001\n",
      "Epoch [126], Batch [350/391], Loss: 1.8771, LR: 0.000001\n",
      "Train set: Epoch: 126, Average loss:1.4266, LR: 0.000001 Top-1 Accuracy: 72.0360%, Top-5 Accuracy: 90.5760%, Time consumed:90.01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████████████████████████████████████▉                                                   | 126/300 [3:29:13<4:50:07, 100.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 126, Average loss:0.9000, Top-1 Accuracy: 74.6300%, Top-5 Accuracy: 94.0400%, Time consumed:10.71s\n",
      "\n",
      "EarlyStopping 카운터: 3 / 30\n",
      "Epoch [127], Batch [50/391], Loss: 2.4421, LR: 0.000001\n",
      "Epoch [127], Batch [100/391], Loss: 2.7618, LR: 0.000001\n",
      "Epoch [127], Batch [150/391], Loss: 1.8034, LR: 0.000001\n",
      "Epoch [127], Batch [200/391], Loss: 0.5437, LR: 0.000001\n",
      "Epoch [127], Batch [250/391], Loss: 0.7336, LR: 0.000001\n",
      "Epoch [127], Batch [300/391], Loss: 1.8020, LR: 0.000001\n",
      "Epoch [127], Batch [350/391], Loss: 2.7042, LR: 0.000001\n",
      "Train set: Epoch: 127, Average loss:1.3954, LR: 0.000001 Top-1 Accuracy: 72.8800%, Top-5 Accuracy: 91.1140%, Time consumed:89.36s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|█████████████████████████████████████▎                                                  | 127/300 [3:30:53<4:48:48, 100.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 127, Average loss:0.8886, Top-1 Accuracy: 74.8900%, Top-5 Accuracy: 94.0100%, Time consumed:11.08s\n",
      "\n",
      "EarlyStopping 카운터: 4 / 30\n",
      "Epoch [128], Batch [50/391], Loss: 0.6479, LR: 0.000001\n",
      "Epoch [128], Batch [100/391], Loss: 0.6026, LR: 0.000001\n",
      "Epoch [128], Batch [150/391], Loss: 2.4691, LR: 0.000001\n",
      "Epoch [128], Batch [200/391], Loss: 2.9387, LR: 0.000001\n",
      "Epoch [128], Batch [250/391], Loss: 0.7345, LR: 0.000001\n",
      "Epoch [128], Batch [300/391], Loss: 2.7573, LR: 0.000001\n",
      "Epoch [128], Batch [350/391], Loss: 2.8875, LR: 0.000001\n",
      "Train set: Epoch: 128, Average loss:1.3566, LR: 0.000001 Top-1 Accuracy: 73.4180%, Top-5 Accuracy: 91.3120%, Time consumed:89.11s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|█████████████████████████████████████▉                                                   | 128/300 [3:32:32<4:46:19, 99.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 128, Average loss:0.9062, Top-1 Accuracy: 74.5500%, Top-5 Accuracy: 93.9200%, Time consumed:10.10s\n",
      "\n",
      "EarlyStopping 카운터: 5 / 30\n",
      "Epoch [129], Batch [50/391], Loss: 2.8977, LR: 0.000001\n",
      "Epoch [129], Batch [100/391], Loss: 0.6335, LR: 0.000001\n",
      "Epoch [129], Batch [150/391], Loss: 1.6009, LR: 0.000001\n",
      "Epoch [129], Batch [200/391], Loss: 2.6812, LR: 0.000001\n",
      "Epoch [129], Batch [250/391], Loss: 0.5974, LR: 0.000001\n",
      "Epoch [129], Batch [300/391], Loss: 0.4026, LR: 0.000001\n",
      "Epoch [129], Batch [350/391], Loss: 0.9040, LR: 0.000001\n",
      "Train set: Epoch: 129, Average loss:1.4464, LR: 0.000001 Top-1 Accuracy: 72.6360%, Top-5 Accuracy: 90.8440%, Time consumed:89.47s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|█████████████████████████████████████▊                                                  | 129/300 [3:34:13<4:45:13, 100.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 129, Average loss:0.9089, Top-1 Accuracy: 74.5700%, Top-5 Accuracy: 93.8500%, Time consumed:11.07s\n",
      "\n",
      "EarlyStopping 카운터: 6 / 30\n",
      "Epoch [130], Batch [50/391], Loss: 0.7290, LR: 0.000001\n",
      "Epoch [130], Batch [100/391], Loss: 2.7066, LR: 0.000001\n",
      "Epoch [130], Batch [150/391], Loss: 0.6422, LR: 0.000001\n",
      "Epoch [130], Batch [200/391], Loss: 0.5929, LR: 0.000001\n",
      "Epoch [130], Batch [250/391], Loss: 2.8287, LR: 0.000001\n",
      "Epoch [130], Batch [300/391], Loss: 0.4892, LR: 0.000001\n",
      "Epoch [130], Batch [350/391], Loss: 2.1605, LR: 0.000001\n",
      "Train set: Epoch: 130, Average loss:1.5570, LR: 0.000001 Top-1 Accuracy: 69.4140%, Top-5 Accuracy: 88.7400%, Time consumed:89.34s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|██████████████████████████████████████▌                                                  | 130/300 [3:35:52<4:42:41, 99.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 130, Average loss:0.9029, Top-1 Accuracy: 74.6800%, Top-5 Accuracy: 93.9100%, Time consumed:9.72s\n",
      "\n",
      "EarlyStopping 카운터: 7 / 30\n",
      "Epoch [131], Batch [50/391], Loss: 0.6137, LR: 0.000001\n",
      "Epoch [131], Batch [100/391], Loss: 0.5693, LR: 0.000001\n",
      "Epoch [131], Batch [150/391], Loss: 1.5006, LR: 0.000001\n",
      "Epoch [131], Batch [200/391], Loss: 0.6431, LR: 0.000001\n",
      "Epoch [131], Batch [250/391], Loss: 1.5527, LR: 0.000001\n",
      "Epoch [131], Batch [300/391], Loss: 0.5315, LR: 0.000001\n",
      "Epoch [131], Batch [350/391], Loss: 0.4651, LR: 0.000001\n",
      "Train set: Epoch: 131, Average loss:1.4048, LR: 0.000001 Top-1 Accuracy: 72.7680%, Top-5 Accuracy: 90.7000%, Time consumed:89.94s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|██████████████████████████████████████▊                                                  | 131/300 [3:37:32<4:40:58, 99.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 131, Average loss:0.9021, Top-1 Accuracy: 74.6400%, Top-5 Accuracy: 93.9400%, Time consumed:9.77s\n",
      "\n",
      "EarlyStopping 카운터: 8 / 30\n",
      "Epoch [132], Batch [50/391], Loss: 0.8541, LR: 0.000001\n",
      "Epoch [132], Batch [100/391], Loss: 2.1307, LR: 0.000001\n",
      "Epoch [132], Batch [150/391], Loss: 2.9423, LR: 0.000001\n",
      "Epoch [132], Batch [200/391], Loss: 0.5458, LR: 0.000001\n",
      "Epoch [132], Batch [250/391], Loss: 0.4437, LR: 0.000001\n",
      "Epoch [132], Batch [300/391], Loss: 2.8392, LR: 0.000001\n",
      "Epoch [132], Batch [350/391], Loss: 2.6595, LR: 0.000001\n",
      "Train set: Epoch: 132, Average loss:1.4849, LR: 0.000001 Top-1 Accuracy: 71.0680%, Top-5 Accuracy: 89.9000%, Time consumed:91.07s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|██████████████████████████████████████▋                                                 | 132/300 [3:39:12<4:40:19, 100.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 132, Average loss:0.8947, Top-1 Accuracy: 74.7000%, Top-5 Accuracy: 93.9500%, Time consumed:9.88s\n",
      "\n",
      "EarlyStopping 카운터: 9 / 30\n",
      "Epoch [133], Batch [50/391], Loss: 0.6746, LR: 0.000001\n",
      "Epoch [133], Batch [100/391], Loss: 2.1950, LR: 0.000001\n",
      "Epoch [133], Batch [150/391], Loss: 2.2486, LR: 0.000001\n",
      "Epoch [133], Batch [200/391], Loss: 0.5071, LR: 0.000001\n",
      "Epoch [133], Batch [250/391], Loss: 1.9212, LR: 0.000001\n",
      "Epoch [133], Batch [300/391], Loss: 0.5210, LR: 0.000001\n",
      "Epoch [133], Batch [350/391], Loss: 2.5124, LR: 0.000001\n",
      "Train set: Epoch: 133, Average loss:1.4080, LR: 0.000001 Top-1 Accuracy: 73.2380%, Top-5 Accuracy: 91.3100%, Time consumed:90.20s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|███████████████████████████████████████                                                 | 133/300 [3:40:52<4:38:32, 100.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 133, Average loss:0.8980, Top-1 Accuracy: 74.8500%, Top-5 Accuracy: 93.9700%, Time consumed:9.77s\n",
      "\n",
      "EarlyStopping 카운터: 10 / 30\n",
      "Epoch [134], Batch [50/391], Loss: 2.8360, LR: 0.000001\n",
      "Epoch [134], Batch [100/391], Loss: 1.0485, LR: 0.000001\n",
      "Epoch [134], Batch [150/391], Loss: 2.7098, LR: 0.000001\n",
      "Epoch [134], Batch [200/391], Loss: 2.5126, LR: 0.000001\n",
      "Epoch [134], Batch [250/391], Loss: 0.5117, LR: 0.000001\n",
      "Epoch [134], Batch [300/391], Loss: 2.8876, LR: 0.000001\n",
      "Epoch [134], Batch [350/391], Loss: 2.9841, LR: 0.000001\n",
      "Train set: Epoch: 134, Average loss:1.4515, LR: 0.000001 Top-1 Accuracy: 71.4560%, Top-5 Accuracy: 90.2340%, Time consumed:89.97s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|███████████████████████████████████████▎                                                | 134/300 [3:42:32<4:36:44, 100.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 134, Average loss:0.8946, Top-1 Accuracy: 74.8100%, Top-5 Accuracy: 93.9800%, Time consumed:9.95s\n",
      "\n",
      "EarlyStopping 카운터: 11 / 30\n",
      "Epoch [135], Batch [50/391], Loss: 0.5952, LR: 0.000001\n",
      "Epoch [135], Batch [100/391], Loss: 0.5760, LR: 0.000001\n",
      "Epoch [135], Batch [150/391], Loss: 0.5404, LR: 0.000001\n",
      "Epoch [135], Batch [200/391], Loss: 0.4677, LR: 0.000001\n",
      "Epoch [135], Batch [250/391], Loss: 0.5154, LR: 0.000001\n",
      "Epoch [135], Batch [300/391], Loss: 1.8056, LR: 0.000001\n",
      "Epoch [135], Batch [350/391], Loss: 0.4982, LR: 0.000001\n",
      "Train set: Epoch: 135, Average loss:1.4870, LR: 0.000001 Top-1 Accuracy: 71.1920%, Top-5 Accuracy: 89.8080%, Time consumed:89.10s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████████████████████████████████████████                                                 | 135/300 [3:44:12<4:34:27, 99.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 135, Average loss:0.9110, Top-1 Accuracy: 74.3100%, Top-5 Accuracy: 93.9500%, Time consumed:10.16s\n",
      "\n",
      "EarlyStopping 카운터: 12 / 30\n",
      "Epoch [136], Batch [50/391], Loss: 0.5590, LR: 0.000001\n",
      "Epoch [136], Batch [100/391], Loss: 1.8506, LR: 0.000001\n",
      "Epoch [136], Batch [150/391], Loss: 0.9479, LR: 0.000001\n",
      "Epoch [136], Batch [200/391], Loss: 0.5850, LR: 0.000001\n",
      "Epoch [136], Batch [250/391], Loss: 0.6410, LR: 0.000001\n",
      "Epoch [136], Batch [300/391], Loss: 2.6360, LR: 0.000001\n",
      "Epoch [136], Batch [350/391], Loss: 1.9019, LR: 0.000001\n",
      "Train set: Epoch: 136, Average loss:1.3086, LR: 0.000001 Top-1 Accuracy: 74.3260%, Top-5 Accuracy: 91.9600%, Time consumed:89.70s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████████████████████████████████████████▎                                                | 136/300 [3:45:51<4:32:39, 99.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 136, Average loss:0.9363, Top-1 Accuracy: 74.3000%, Top-5 Accuracy: 93.6300%, Time consumed:9.93s\n",
      "\n",
      "EarlyStopping 카운터: 13 / 30\n",
      "Epoch [137], Batch [50/391], Loss: 0.6368, LR: 0.000001\n",
      "Epoch [137], Batch [100/391], Loss: 1.9030, LR: 0.000001\n",
      "Epoch [137], Batch [150/391], Loss: 0.5495, LR: 0.000001\n",
      "Epoch [137], Batch [200/391], Loss: 0.6963, LR: 0.000001\n",
      "Epoch [137], Batch [250/391], Loss: 1.4316, LR: 0.000001\n",
      "Epoch [137], Batch [300/391], Loss: 2.6631, LR: 0.000001\n",
      "Epoch [137], Batch [350/391], Loss: 2.9022, LR: 0.000001\n",
      "Train set: Epoch: 137, Average loss:1.5125, LR: 0.000001 Top-1 Accuracy: 71.6380%, Top-5 Accuracy: 90.2500%, Time consumed:89.51s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████████████████████████████████████████▋                                                | 137/300 [3:47:31<4:30:41, 99.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 137, Average loss:0.9095, Top-1 Accuracy: 74.4200%, Top-5 Accuracy: 93.9400%, Time consumed:9.88s\n",
      "\n",
      "EarlyStopping 카운터: 14 / 30\n",
      "Epoch [138], Batch [50/391], Loss: 3.0253, LR: 0.000001\n",
      "Epoch [138], Batch [100/391], Loss: 0.6673, LR: 0.000001\n",
      "Epoch [138], Batch [150/391], Loss: 2.2776, LR: 0.000001\n",
      "Epoch [138], Batch [200/391], Loss: 0.6368, LR: 0.000001\n",
      "Epoch [138], Batch [250/391], Loss: 2.8431, LR: 0.000001\n",
      "Epoch [138], Batch [300/391], Loss: 0.6642, LR: 0.000001\n",
      "Epoch [138], Batch [350/391], Loss: 0.5721, LR: 0.000001\n",
      "Train set: Epoch: 138, Average loss:1.4167, LR: 0.000001 Top-1 Accuracy: 72.0200%, Top-5 Accuracy: 90.5840%, Time consumed:88.89s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████████████████████████████████████████▉                                                | 138/300 [3:49:10<4:28:28, 99.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 138, Average loss:0.9134, Top-1 Accuracy: 74.4500%, Top-5 Accuracy: 93.7600%, Time consumed:10.05s\n",
      "\n",
      "EarlyStopping 카운터: 15 / 30\n",
      "Epoch [139], Batch [50/391], Loss: 2.7284, LR: 0.000001\n",
      "Epoch [139], Batch [100/391], Loss: 2.8390, LR: 0.000001\n",
      "Epoch [139], Batch [150/391], Loss: 2.6842, LR: 0.000001\n",
      "Epoch [139], Batch [200/391], Loss: 0.4279, LR: 0.000001\n",
      "Epoch [139], Batch [250/391], Loss: 2.4512, LR: 0.000001\n",
      "Epoch [139], Batch [300/391], Loss: 0.7528, LR: 0.000001\n",
      "Epoch [139], Batch [350/391], Loss: 0.4898, LR: 0.000001\n",
      "Train set: Epoch: 139, Average loss:1.4042, LR: 0.000001 Top-1 Accuracy: 72.8820%, Top-5 Accuracy: 91.0980%, Time consumed:89.03s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|█████████████████████████████████████████▏                                               | 139/300 [3:50:49<4:26:25, 99.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 139, Average loss:0.8980, Top-1 Accuracy: 74.6500%, Top-5 Accuracy: 93.9100%, Time consumed:9.90s\n",
      "\n",
      "EarlyStopping 카운터: 16 / 30\n",
      "Epoch [140], Batch [50/391], Loss: 0.5969, LR: 0.000001\n",
      "Epoch [140], Batch [100/391], Loss: 0.4608, LR: 0.000001\n",
      "Epoch [140], Batch [150/391], Loss: 0.5586, LR: 0.000001\n",
      "Epoch [140], Batch [200/391], Loss: 0.5611, LR: 0.000001\n",
      "Epoch [140], Batch [250/391], Loss: 2.7037, LR: 0.000001\n",
      "Epoch [140], Batch [300/391], Loss: 3.1192, LR: 0.000001\n",
      "Epoch [140], Batch [350/391], Loss: 2.7966, LR: 0.000001\n",
      "Train set: Epoch: 140, Average loss:1.3837, LR: 0.000001 Top-1 Accuracy: 73.0540%, Top-5 Accuracy: 91.1480%, Time consumed:89.83s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|█████████████████████████████████████████▌                                               | 140/300 [3:52:28<4:25:02, 99.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 140, Average loss:0.9010, Top-1 Accuracy: 74.6200%, Top-5 Accuracy: 93.9000%, Time consumed:9.81s\n",
      "\n",
      "EarlyStopping 카운터: 17 / 30\n",
      "Epoch [141], Batch [50/391], Loss: 2.8653, LR: 0.000001\n",
      "Epoch [141], Batch [100/391], Loss: 0.5554, LR: 0.000001\n",
      "Epoch [141], Batch [150/391], Loss: 1.4878, LR: 0.000001\n",
      "Epoch [141], Batch [200/391], Loss: 2.1755, LR: 0.000001\n",
      "Epoch [141], Batch [250/391], Loss: 2.4935, LR: 0.000001\n",
      "Epoch [141], Batch [300/391], Loss: 0.5096, LR: 0.000001\n",
      "Epoch [141], Batch [350/391], Loss: 0.5300, LR: 0.000001\n",
      "Train set: Epoch: 141, Average loss:1.4510, LR: 0.000001 Top-1 Accuracy: 72.1960%, Top-5 Accuracy: 90.7980%, Time consumed:93.18s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|█████████████████████████████████████████▎                                              | 141/300 [3:54:11<4:26:14, 100.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 141, Average loss:0.9231, Top-1 Accuracy: 74.3200%, Top-5 Accuracy: 93.7500%, Time consumed:9.78s\n",
      "\n",
      "EarlyStopping 카운터: 18 / 30\n",
      "Epoch [142], Batch [50/391], Loss: 0.5722, LR: 0.000001\n",
      "Epoch [142], Batch [100/391], Loss: 2.4065, LR: 0.000001\n",
      "Epoch [142], Batch [150/391], Loss: 0.6079, LR: 0.000001\n",
      "Epoch [142], Batch [200/391], Loss: 1.9665, LR: 0.000001\n",
      "Epoch [142], Batch [250/391], Loss: 1.9859, LR: 0.000001\n",
      "Epoch [142], Batch [300/391], Loss: 0.4766, LR: 0.000001\n",
      "Epoch [142], Batch [350/391], Loss: 0.4588, LR: 0.000001\n",
      "Train set: Epoch: 142, Average loss:1.4718, LR: 0.000001 Top-1 Accuracy: 71.8580%, Top-5 Accuracy: 90.3540%, Time consumed:89.49s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|█████████████████████████████████████████▋                                              | 142/300 [3:55:51<4:23:55, 100.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 142, Average loss:0.9202, Top-1 Accuracy: 74.5800%, Top-5 Accuracy: 93.8500%, Time consumed:10.18s\n",
      "\n",
      "EarlyStopping 카운터: 19 / 30\n",
      "Epoch [143], Batch [50/391], Loss: 2.9164, LR: 0.000001\n",
      "Epoch [143], Batch [100/391], Loss: 2.9082, LR: 0.000001\n",
      "Epoch [143], Batch [150/391], Loss: 2.9551, LR: 0.000001\n",
      "Epoch [143], Batch [200/391], Loss: 2.9477, LR: 0.000001\n",
      "Epoch [143], Batch [250/391], Loss: 0.5551, LR: 0.000001\n",
      "Epoch [143], Batch [300/391], Loss: 1.5733, LR: 0.000001\n",
      "Epoch [143], Batch [350/391], Loss: 3.0006, LR: 0.000001\n",
      "Train set: Epoch: 143, Average loss:1.3751, LR: 0.000001 Top-1 Accuracy: 72.8300%, Top-5 Accuracy: 90.8940%, Time consumed:89.69s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|█████████████████████████████████████████▉                                              | 143/300 [3:57:30<4:21:42, 100.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 143, Average loss:0.9085, Top-1 Accuracy: 74.5300%, Top-5 Accuracy: 93.9000%, Time consumed:9.83s\n",
      "\n",
      "EarlyStopping 카운터: 20 / 30\n",
      "Epoch [144], Batch [50/391], Loss: 2.7035, LR: 0.000001\n",
      "Epoch [144], Batch [100/391], Loss: 0.7660, LR: 0.000001\n",
      "Epoch [144], Batch [150/391], Loss: 3.2903, LR: 0.000001\n",
      "Epoch [144], Batch [200/391], Loss: 1.4407, LR: 0.000001\n",
      "Epoch [144], Batch [250/391], Loss: 1.3600, LR: 0.000001\n",
      "Epoch [144], Batch [300/391], Loss: 2.1265, LR: 0.000001\n",
      "Epoch [144], Batch [350/391], Loss: 0.4809, LR: 0.000001\n",
      "Train set: Epoch: 144, Average loss:1.3721, LR: 0.000001 Top-1 Accuracy: 73.8500%, Top-5 Accuracy: 91.5400%, Time consumed:89.59s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|██████████████████████████████████████████▋                                              | 144/300 [3:59:10<4:19:36, 99.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 144, Average loss:0.8904, Top-1 Accuracy: 74.6800%, Top-5 Accuracy: 94.0100%, Time consumed:9.85s\n",
      "\n",
      "EarlyStopping 카운터: 21 / 30\n",
      "Epoch [145], Batch [50/391], Loss: 0.5666, LR: 0.000001\n",
      "Epoch [145], Batch [100/391], Loss: 0.5342, LR: 0.000001\n",
      "Epoch [145], Batch [150/391], Loss: 0.5593, LR: 0.000001\n",
      "Epoch [145], Batch [200/391], Loss: 0.5459, LR: 0.000001\n",
      "Epoch [145], Batch [250/391], Loss: 2.3981, LR: 0.000001\n",
      "Epoch [145], Batch [300/391], Loss: 2.7607, LR: 0.000001\n",
      "Epoch [145], Batch [350/391], Loss: 2.7665, LR: 0.000001\n",
      "Train set: Epoch: 145, Average loss:1.4445, LR: 0.000001 Top-1 Accuracy: 72.0760%, Top-5 Accuracy: 90.9140%, Time consumed:89.17s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|███████████████████████████████████████████                                              | 145/300 [4:00:49<4:17:41, 99.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 145, Average loss:0.9134, Top-1 Accuracy: 74.3000%, Top-5 Accuracy: 93.8500%, Time consumed:10.36s\n",
      "\n",
      "EarlyStopping 카운터: 22 / 30\n",
      "Epoch [146], Batch [50/391], Loss: 3.1588, LR: 0.000001\n",
      "Epoch [146], Batch [100/391], Loss: 0.4754, LR: 0.000001\n",
      "Epoch [146], Batch [150/391], Loss: 0.4582, LR: 0.000001\n",
      "Epoch [146], Batch [200/391], Loss: 2.8265, LR: 0.000001\n",
      "Epoch [146], Batch [250/391], Loss: 1.8144, LR: 0.000001\n",
      "Epoch [146], Batch [300/391], Loss: 0.5861, LR: 0.000001\n",
      "Epoch [146], Batch [350/391], Loss: 1.2876, LR: 0.000001\n",
      "Train set: Epoch: 146, Average loss:1.4076, LR: 0.000001 Top-1 Accuracy: 72.6680%, Top-5 Accuracy: 90.7060%, Time consumed:90.18s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|███████████████████████████████████████████▎                                             | 146/300 [4:02:29<4:16:13, 99.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 146, Average loss:0.9150, Top-1 Accuracy: 74.4500%, Top-5 Accuracy: 93.8300%, Time consumed:9.82s\n",
      "\n",
      "EarlyStopping 카운터: 23 / 30\n",
      "Epoch [147], Batch [50/391], Loss: 0.6323, LR: 0.000001\n",
      "Epoch [147], Batch [100/391], Loss: 2.2636, LR: 0.000001\n",
      "Epoch [147], Batch [150/391], Loss: 3.0079, LR: 0.000001\n",
      "Epoch [147], Batch [200/391], Loss: 0.4660, LR: 0.000001\n",
      "Epoch [147], Batch [250/391], Loss: 2.6401, LR: 0.000001\n",
      "Epoch [147], Batch [300/391], Loss: 1.3207, LR: 0.000001\n",
      "Epoch [147], Batch [350/391], Loss: 2.5432, LR: 0.000001\n",
      "Train set: Epoch: 147, Average loss:1.4748, LR: 0.000001 Top-1 Accuracy: 71.2720%, Top-5 Accuracy: 89.9560%, Time consumed:89.41s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|███████████████████████████████████████████▌                                             | 147/300 [4:04:09<4:14:35, 99.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 147, Average loss:0.9154, Top-1 Accuracy: 74.3900%, Top-5 Accuracy: 93.8200%, Time consumed:10.45s\n",
      "\n",
      "EarlyStopping 카운터: 24 / 30\n",
      "Epoch [148], Batch [50/391], Loss: 1.9166, LR: 0.000001\n",
      "Epoch [148], Batch [100/391], Loss: 0.6335, LR: 0.000001\n",
      "Epoch [148], Batch [150/391], Loss: 1.7430, LR: 0.000001\n",
      "Epoch [148], Batch [200/391], Loss: 2.0893, LR: 0.000001\n",
      "Epoch [148], Batch [250/391], Loss: 2.7797, LR: 0.000001\n",
      "Epoch [148], Batch [300/391], Loss: 0.5343, LR: 0.000001\n",
      "Epoch [148], Batch [350/391], Loss: 2.4141, LR: 0.000001\n",
      "Train set: Epoch: 148, Average loss:1.4644, LR: 0.000001 Top-1 Accuracy: 71.3720%, Top-5 Accuracy: 90.1360%, Time consumed:90.07s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|███████████████████████████████████████████▉                                             | 148/300 [4:05:49<4:12:58, 99.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 148, Average loss:0.9043, Top-1 Accuracy: 74.6800%, Top-5 Accuracy: 93.9000%, Time consumed:9.82s\n",
      "\n",
      "EarlyStopping 카운터: 25 / 30\n",
      "Epoch [149], Batch [50/391], Loss: 0.4822, LR: 0.000001\n",
      "Epoch [149], Batch [100/391], Loss: 0.4770, LR: 0.000001\n",
      "Epoch [149], Batch [150/391], Loss: 0.5975, LR: 0.000001\n",
      "Epoch [149], Batch [200/391], Loss: 0.4185, LR: 0.000001\n",
      "Epoch [149], Batch [250/391], Loss: 2.4430, LR: 0.000001\n",
      "Epoch [149], Batch [300/391], Loss: 0.6161, LR: 0.000001\n",
      "Epoch [149], Batch [350/391], Loss: 1.7039, LR: 0.000001\n",
      "Train set: Epoch: 149, Average loss:1.5575, LR: 0.000001 Top-1 Accuracy: 69.9440%, Top-5 Accuracy: 89.1700%, Time consumed:89.16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████████████████████████████████▏                                            | 149/300 [4:07:28<4:10:40, 99.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 149, Average loss:0.8939, Top-1 Accuracy: 74.7300%, Top-5 Accuracy: 94.0300%, Time consumed:9.85s\n",
      "\n",
      "EarlyStopping 카운터: 26 / 30\n",
      "Epoch [150], Batch [50/391], Loss: 2.5351, LR: 0.000001\n",
      "Epoch [150], Batch [100/391], Loss: 2.3001, LR: 0.000001\n",
      "Epoch [150], Batch [150/391], Loss: 2.7501, LR: 0.000001\n",
      "Epoch [150], Batch [200/391], Loss: 1.7439, LR: 0.000001\n",
      "Epoch [150], Batch [250/391], Loss: 0.4370, LR: 0.000001\n",
      "Epoch [150], Batch [300/391], Loss: 0.5649, LR: 0.000001\n",
      "Epoch [150], Batch [350/391], Loss: 0.4728, LR: 0.000001\n",
      "Train set: Epoch: 150, Average loss:1.4673, LR: 0.000001 Top-1 Accuracy: 71.1180%, Top-5 Accuracy: 90.0260%, Time consumed:90.29s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████████████████████████████████▌                                            | 150/300 [4:09:08<4:09:23, 99.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 150, Average loss:0.9177, Top-1 Accuracy: 74.4800%, Top-5 Accuracy: 93.9300%, Time consumed:9.82s\n",
      "\n",
      "EarlyStopping 카운터: 27 / 30\n",
      "Epoch [151], Batch [50/391], Loss: 0.4825, LR: 0.000001\n",
      "Epoch [151], Batch [100/391], Loss: 1.2873, LR: 0.000001\n",
      "Epoch [151], Batch [150/391], Loss: 0.5916, LR: 0.000001\n",
      "Epoch [151], Batch [200/391], Loss: 3.1054, LR: 0.000001\n",
      "Epoch [151], Batch [250/391], Loss: 2.5996, LR: 0.000001\n",
      "Epoch [151], Batch [300/391], Loss: 2.8714, LR: 0.000001\n",
      "Epoch [151], Batch [350/391], Loss: 0.5482, LR: 0.000001\n",
      "Train set: Epoch: 151, Average loss:1.4481, LR: 0.000001 Top-1 Accuracy: 71.5040%, Top-5 Accuracy: 89.9400%, Time consumed:89.84s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████████████████████████████████▊                                            | 151/300 [4:10:49<4:08:10, 99.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 151, Average loss:0.9031, Top-1 Accuracy: 74.5400%, Top-5 Accuracy: 93.9800%, Time consumed:10.52s\n",
      "\n",
      "EarlyStopping 카운터: 28 / 30\n",
      "Epoch [152], Batch [50/391], Loss: 0.5660, LR: 0.000001\n",
      "Epoch [152], Batch [100/391], Loss: 3.1680, LR: 0.000001\n",
      "Epoch [152], Batch [150/391], Loss: 0.5253, LR: 0.000001\n",
      "Epoch [152], Batch [200/391], Loss: 0.6625, LR: 0.000001\n",
      "Epoch [152], Batch [250/391], Loss: 3.0625, LR: 0.000001\n",
      "Epoch [152], Batch [300/391], Loss: 0.5914, LR: 0.000001\n",
      "Epoch [152], Batch [350/391], Loss: 0.6429, LR: 0.000001\n",
      "Train set: Epoch: 152, Average loss:1.4511, LR: 0.000001 Top-1 Accuracy: 72.7500%, Top-5 Accuracy: 91.1120%, Time consumed:89.93s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████████████████████████████████████████████                                            | 152/300 [4:12:28<4:06:26, 99.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 152, Average loss:0.9025, Top-1 Accuracy: 74.5900%, Top-5 Accuracy: 93.9200%, Time consumed:9.90s\n",
      "\n",
      "EarlyStopping 카운터: 29 / 30\n",
      "Epoch [153], Batch [50/391], Loss: 0.4552, LR: 0.000001\n",
      "Epoch [153], Batch [100/391], Loss: 2.9970, LR: 0.000001\n",
      "Epoch [153], Batch [150/391], Loss: 2.9973, LR: 0.000001\n",
      "Epoch [153], Batch [200/391], Loss: 2.6349, LR: 0.000001\n",
      "Epoch [153], Batch [250/391], Loss: 0.5401, LR: 0.000001\n",
      "Epoch [153], Batch [300/391], Loss: 3.0909, LR: 0.000001\n",
      "Epoch [153], Batch [350/391], Loss: 0.5708, LR: 0.000001\n",
      "Train set: Epoch: 153, Average loss:1.5131, LR: 0.000001 Top-1 Accuracy: 69.9540%, Top-5 Accuracy: 89.2400%, Time consumed:89.69s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|████████████████████████████████████████████▌                                           | 152/300 [4:14:08<4:07:27, 100.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 153, Average loss:0.8972, Top-1 Accuracy: 74.7300%, Top-5 Accuracy: 93.9700%, Time consumed:9.97s\n",
      "\n",
      "EarlyStopping 카운터: 30 / 30\n",
      "에폭 153에서 학습 조기 종료. 최고 성능 에폭: 123\n",
      "테스트 정확도 기준 최고 모델 로드 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 300, Average loss:0.8855, Top-1 Accuracy: 74.9100%, Top-5 Accuracy: 93.9900%, Time consumed:9.89s\n",
      "\n",
      "완료! 최고 테스트 top-1 정확도: 74.91%, 최고 테스트 top-5 정확도: 94.14%\n",
      "최종 테스트 top-1 정확도: 74.91%, 최종 테스트 top-5 정확도: 93.99%\n",
      "전체 학습 시간: 15258.64 초\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▃▃▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇█████</td></tr><tr><td>learning_rate</td><td>▂███▄▄▄▃▃▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_accuracy_top1</td><td>▁▃▄▅▅▆▆▇▇▇██████████████████████████████</td></tr><tr><td>test_accuracy_top5</td><td>▁▂▅▇▇███████████████████████████████████</td></tr><tr><td>test_loss</td><td>█▆▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>total_training_time</td><td>▁</td></tr><tr><td>train_accuracy_top1</td><td>▁▃▄▄▅▆▆▇▇▇█▇█████████████▇▇█████████████</td></tr><tr><td>train_accuracy_top5</td><td>▁▅▆▆▇▇▇▇▇███████████████████████████████</td></tr><tr><td>train_loss</td><td>█▄▃▃▃▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>123</td></tr><tr><td>best_test_accuracy_top1</td><td>74.91</td></tr><tr><td>best_test_accuracy_top5</td><td>94.14</td></tr><tr><td>early_stopped</td><td>True</td></tr><tr><td>early_stopped_epoch</td><td>153</td></tr><tr><td>epoch</td><td>153</td></tr><tr><td>final_test_accuracy_top1</td><td>74.91</td></tr><tr><td>final_test_accuracy_top5</td><td>93.99</td></tr><tr><td>learning_rate</td><td>0.0</td></tr><tr><td>test_accuracy_top1</td><td>74.73</td></tr><tr><td>test_accuracy_top5</td><td>93.97</td></tr><tr><td>test_loss</td><td>0.8972</td></tr><tr><td>total_training_time</td><td>15258.63769</td></tr><tr><td>train_accuracy_top1</td><td>69.954</td></tr><tr><td>train_accuracy_top5</td><td>89.24</td></tr><tr><td>train_loss</td><td>1.51313</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">resnet18_cfc,lr=0.01,factor=0.5,SAM_SGD,PSKD</strong> at: <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/vwv8smvj' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/vwv8smvj</a><br> View project at: <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250430_054810-vwv8smvj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.v2 as transforms_v2  # CutMix를 위한 v2 transforms 추가\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "from tools.tool import AccuracyEarlyStopping, WarmUpLR, SAM, PSKD  # 수정된 AccuracyEarlyStopping 클래스 임포트\n",
    "from models.resnet import resnet18\n",
    "\n",
    "wandb.login(key=\"ef091b9abcea3186341ddf8995d62bde62d7469e\")\n",
    "\n",
    "# WandB 설정 - ResNeXt 코드의 파라미터 사용하되 모델만 resnet18로 변경\n",
    "config = {\n",
    "    # 모델 설정\n",
    "    \"model\": \"resnet18\",  # 모델만 resnet18로 유지\n",
    "    \"batch_size\": 128,    \n",
    "    \"num_epochs\": 300,\n",
    "    \n",
    "    \"learning_rate\": 0.01,  \n",
    "    \"optimizer\": \"SAM_SGD\",\n",
    "    \"momentum\": 0.9,\n",
    "    \"weight_decay\": 5e-4,\n",
    "    \"nesterov\": True,\n",
    "    \n",
    "    # SAM 옵티마이저 설정\n",
    "    \"rho\": 0.05,\n",
    "    \"adaptive\": False,\n",
    "    \n",
    "    # 학습 과정 설정\n",
    "    \"seed\": 2025,\n",
    "    \"deterministic\": False,\n",
    "    \"patience\": 30, \n",
    "    \"max_epochs_wait\": float('inf'),\n",
    "    \n",
    "    # 데이터 증강 설정\n",
    "    \"cutmix_alpha\": 1.0,  \n",
    "    \"cutmix_prob\": 0.5,   \n",
    "    \"crop_padding\": 4,    \n",
    "    \"crop_size\": 32,      \n",
    "    \n",
    "    # 스케줄러 설정 - \n",
    "    \"warmup_epochs\": 10,  \n",
    "    \"lr_scheduler\": \"ReduceLROnPlateau\",\n",
    "    \"lr_factor\": 0.5,\n",
    "    \"lr_patience\": 5,\n",
    "    \"lr_threshold\": 0.1,\n",
    "    \"min_lr\": 1e-6,\n",
    "    \n",
    "    # 시스템 설정\n",
    "    \"num_workers\": 32,\n",
    "    \"pin_memory\": True,\n",
    "}\n",
    "\n",
    "wandb.init(\n",
    "    project=\"PBL-2\", \n",
    "    name=\"resnet18_cfc,lr=0.01,factor=0.5,SAM_SGD,PSKD\",\n",
    "    config=config  # 여기서 직접 config 전달\n",
    ")\n",
    "wandb.config.update(config)\n",
    "\n",
    "# CIFAR-100 데이터셋 로드 - 기본 train/test 분할 사용\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(config[\"crop_size\"], padding=config[\"crop_padding\"]),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR100(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR100(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "# DataLoader 생성 - config 사용\n",
    "trainloader = DataLoader(\n",
    "    trainset, \n",
    "    batch_size=config[\"batch_size\"], \n",
    "    shuffle=True, \n",
    "    pin_memory=config[\"pin_memory\"], \n",
    "    num_workers=config[\"num_workers\"]\n",
    ")\n",
    "\n",
    "testloader = DataLoader(\n",
    "    testset, \n",
    "    batch_size=config[\"batch_size\"], \n",
    "    shuffle=False, \n",
    "    pin_memory=config[\"pin_memory\"], \n",
    "    num_workers=config[\"num_workers\"]\n",
    ")\n",
    "\n",
    "print(f\"Train set size: {len(trainset)}\")\n",
    "print(f\"Test set size: {len(testset)}\")\n",
    "\n",
    "# CutMix 변환 정의\n",
    "cutmix = transforms_v2.CutMix(alpha=config[\"cutmix_alpha\"], num_classes=100)  # CIFAR-100은 100개 클래스\n",
    "\n",
    "def train(model, trainloader, criterion, optimizer, device, epoch, warmup_scheduler=None, warmup_epochs=None):\n",
    "    \"\"\"\n",
    "    학습 함수 (CutMix 및 PSKD 적용)\n",
    "    \"\"\"\n",
    "    # config에서 warmup_epochs 가져오기 (None이면)\n",
    "    if warmup_epochs is None:\n",
    "        warmup_epochs = config[\"warmup_epochs\"]\n",
    "        \n",
    "    model.train()   # 모델을 학습 모드로 설정\n",
    "    start_time = time.time()  # 시간 측정 시작\n",
    "    running_loss = 0.0\n",
    "    correct_top1 = 0\n",
    "    correct_top5 = 0\n",
    "    total = 0\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(trainloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # CutMix 확률적 적용\n",
    "        if random.random() < config[\"cutmix_prob\"]:\n",
    "            inputs, labels = cutmix(inputs, labels)\n",
    "            # 이 경우 labels은 원-핫 인코딩 형태로 변환됨\n",
    "            use_cutmix = True\n",
    "        else:\n",
    "            # 일반 레이블을 원-핫 인코딩으로 변환 (PSKD에 필요)\n",
    "            batch_size = labels.size(0)\n",
    "            one_hot_labels = torch.zeros(batch_size, 100).to(device)  # CIFAR-100은 100개 클래스\n",
    "            one_hot_labels.scatter_(1, labels.unsqueeze(1), 1)\n",
    "            use_cutmix = False\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # SAM 첫 번째 스텝을 위한 손실 계산\n",
    "        if use_cutmix:\n",
    "            # CutMix가 적용된 경우 (이미 원-핫 인코딩된 레이블)\n",
    "            loss = criterion(outputs, labels)\n",
    "        else:\n",
    "            # 일반적인 경우 (원-핫 인코딩으로 변환한 레이블)\n",
    "            loss = criterion(outputs, one_hot_labels)\n",
    "            \n",
    "        loss.backward()\n",
    "        optimizer.first_step(zero_grad=True)\n",
    "        \n",
    "        # SAM 두 번째 스텝을 위한 손실 계산\n",
    "        outputs = model(inputs)\n",
    "        if use_cutmix:\n",
    "            loss = criterion(outputs, labels)\n",
    "        else:\n",
    "            loss = criterion(outputs, one_hot_labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.second_step(zero_grad=True)\n",
    "        \n",
    "        # 학습률 스케줄러 업데이트 - warmup 스케줄러만 여기서 업데이트\n",
    "        if epoch < warmup_epochs and warmup_scheduler is not None:\n",
    "            warmup_scheduler.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # 정확도 계산 - CutMix 적용 여부에 따라 다르게 처리\n",
    "        if use_cutmix:\n",
    "            # 원-핫 인코딩된 레이블에서 argmax를 사용해 가장 큰 값의 인덱스 추출\n",
    "            _, label_idx = labels.max(1)\n",
    "        else:\n",
    "            # 정수 인덱스 레이블 그대로 사용\n",
    "            label_idx = labels\n",
    "            \n",
    "        # top-1 정확도 계산\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += inputs.size(0)\n",
    "        correct_top1 += predicted.eq(label_idx).sum().item()\n",
    "        \n",
    "        # top-5 정확도 계산\n",
    "        _, top5_idx = outputs.topk(5, 1, largest=True, sorted=True)\n",
    "        correct_top5 += sum([1 for i in range(len(label_idx)) if label_idx[i] in top5_idx[i]])\n",
    "        \n",
    "        if (i + 1) % 50 == 0:  # 50 배치마다 출력\n",
    "            print(f'Epoch [{epoch+1}], Batch [{i+1}/{len(trainloader)}], Loss: {loss.item():.4f}, LR: {optimizer.param_groups[0][\"lr\"]:.6f}')\n",
    "    \n",
    "    epoch_loss = running_loss / len(trainloader)\n",
    "    accuracy_top1 = 100.0 * correct_top1 / total\n",
    "    accuracy_top5 = 100.0 * correct_top5 / total\n",
    "    \n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    # 학습 세트에 대한 성능 출력\n",
    "    print(f'Train set: Epoch: {epoch+1}, Average loss:{epoch_loss:.4f}, LR: {optimizer.param_groups[0][\"lr\"]:.6f} '\n",
    "          f'Top-1 Accuracy: {accuracy_top1:.4f}%, Top-5 Accuracy: {accuracy_top5:.4f}%, Time consumed:{train_time:.2f}s')\n",
    "    \n",
    "    return epoch_loss, accuracy_top1, accuracy_top5\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device, epoch, phase=\"test\"):\n",
    "    \"\"\"\n",
    "    평가 함수 (PSKD 손실 함수 적용)\n",
    "    \"\"\"\n",
    "    model.eval()  # 모델을 평가 모드로 설정\n",
    "    start_time = time.time()  # 시간 측정 시작\n",
    "    \n",
    "    eval_loss = 0.0\n",
    "    correct_top1 = 0\n",
    "    correct_top5 = 0\n",
    "    total = 0\n",
    "    \n",
    "    # 그래디언트 계산 비활성화\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # 원-핫 인코딩 변환 (PSKD에 필요)\n",
    "            batch_size = labels.size(0)\n",
    "            one_hot_labels = torch.zeros(batch_size, 100).to(device)  # CIFAR-100은 100개 클래스\n",
    "            one_hot_labels.scatter_(1, labels.unsqueeze(1), 1)\n",
    "            \n",
    "            # 순전파\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # PSKD 손실 계산\n",
    "            loss = criterion(outputs, one_hot_labels)\n",
    "            eval_loss += loss.item()\n",
    "            \n",
    "            # top-1 정확도 계산\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct_top1 += (predicted == labels).sum().item()\n",
    "            \n",
    "            # top-5 정확도 계산\n",
    "            _, top5_idx = outputs.topk(5, 1, largest=True, sorted=True)\n",
    "            correct_top5 += top5_idx.eq(labels.view(-1, 1).expand_as(top5_idx)).sum().item()\n",
    "    \n",
    "    # 평균 손실 및 정확도 계산\n",
    "    eval_loss = eval_loss / len(dataloader)\n",
    "    accuracy_top1 = 100.0 * correct_top1 / total\n",
    "    accuracy_top5 = 100.0 * correct_top5 / total\n",
    "    \n",
    "    # 평가 시간 계산\n",
    "    eval_time = time.time() - start_time\n",
    "    \n",
    "    # 테스트 세트에 대한 성능 출력\n",
    "    print(f'{phase.capitalize()} set: Epoch: {epoch+1}, Average loss:{eval_loss:.4f}, '\n",
    "          f'Top-1 Accuracy: {accuracy_top1:.4f}%, Top-5 Accuracy: {accuracy_top5:.4f}%, Time consumed:{eval_time:.2f}s')\n",
    "    print()\n",
    "    \n",
    "    return eval_loss, accuracy_top1, accuracy_top5\n",
    "\n",
    "# 메인 학습 루프\n",
    "def main_training_loop(model, trainloader, testloader, criterion, optimizer, device, num_epochs=None, patience=None, max_epochs_wait=None, warmup_scheduler=None, main_scheduler=None, warmup_epochs=None):\n",
    "    \"\"\"\n",
    "    메인 학습 루프 (accuracy 기준 early stopping) - config에서 기본값 가져오기\n",
    "    \"\"\"\n",
    "    # config에서 값 가져오기 (None이면)\n",
    "    if num_epochs is None:\n",
    "        num_epochs = config[\"num_epochs\"]\n",
    "    if patience is None:\n",
    "        patience = config[\"patience\"]\n",
    "    if max_epochs_wait is None:\n",
    "        max_epochs_wait = config[\"max_epochs_wait\"]\n",
    "    if warmup_epochs is None:\n",
    "        warmup_epochs = config[\"warmup_epochs\"]\n",
    "        \n",
    "    # 정확도 기반 얼리 스토핑 사용\n",
    "    early_stopping = AccuracyEarlyStopping(patience=patience, verbose=True, path='checkpoint.pt', max_epochs=max_epochs_wait)\n",
    "    \n",
    "    best_test_acc_top1 = 0.0\n",
    "    best_test_acc_top5 = 0.0\n",
    "    \n",
    "    # 테스트 정확도 기록을 위한 리스트\n",
    "    test_acc_top1_history = []\n",
    "    \n",
    "    # tqdm을 사용한 진행 상황 표시\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        # 학습\n",
    "        train_loss, train_acc_top1, train_acc_top5 = train(\n",
    "            model, \n",
    "            trainloader, \n",
    "            criterion, \n",
    "            optimizer, \n",
    "            device, \n",
    "            epoch, \n",
    "            warmup_scheduler, \n",
    "            warmup_epochs\n",
    "        )\n",
    "        \n",
    "        # 테스트 데이터로 평가\n",
    "        test_loss, test_acc_top1, test_acc_top5 = evaluate(model, testloader, criterion, device, epoch, phase=\"test\")\n",
    "\n",
    "        # 웜업 이후 스케줄러 업데이트 \n",
    "        if epoch >= warmup_epochs and main_scheduler is not None:\n",
    "            if isinstance(main_scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "                main_scheduler.step(test_acc_top1)  # 테스트 정확도에 따라 학습률 업데이트\n",
    "            else:\n",
    "                main_scheduler.step()  # 다른 스케줄러 (예: CosineAnnealingLR)\n",
    "            \n",
    "        # 테스트 정확도 기록\n",
    "        test_acc_top1_history.append(test_acc_top1)\n",
    "        \n",
    "        # WandB에 로깅\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_accuracy_top1\": train_acc_top1,\n",
    "            \"train_accuracy_top5\": train_acc_top5,\n",
    "            \"test_loss\": test_loss,\n",
    "            \"test_accuracy_top1\": test_acc_top1,\n",
    "            \"test_accuracy_top5\": test_acc_top5\n",
    "        })\n",
    "            \n",
    "        # 최고 정확도 모델 저장 (top-1 기준)\n",
    "        if test_acc_top1 > best_test_acc_top1:\n",
    "            best_test_acc_top1 = test_acc_top1\n",
    "            best_test_acc_top5_at_best_top1 = test_acc_top5\n",
    "            print(f'새로운 최고 top-1 정확도: {best_test_acc_top1:.2f}%, top-5 정확도: {best_test_acc_top5_at_best_top1:.2f}%')\n",
    "            # 모델 저장\n",
    "            model_path = f'best_model_{wandb.run.name}.pth'\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            \n",
    "            # WandB에 모델 아티팩트 저장\n",
    "            wandb.save(model_path)\n",
    "        \n",
    "        # top-5 accuracy 기록 업데이트\n",
    "        if test_acc_top5 > best_test_acc_top5:\n",
    "            best_test_acc_top5 = test_acc_top5\n",
    "            print(f'새로운 최고 top-5 정확도: {best_test_acc_top5:.2f}%')\n",
    "\n",
    "        # Early stopping 체크 (test_acc_top1 기준)\n",
    "        early_stopping(test_acc_top1, model, epoch)\n",
    "        if early_stopping.early_stop:\n",
    "            print(f\"에폭 {epoch+1}에서 학습 조기 종료. 최고 성능 에폭: {early_stopping.best_epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    # 훈련 완료 후 최고 모델 로드\n",
    "    print(\"테스트 정확도 기준 최고 모델 로드 중...\")\n",
    "    model_path = f'best_model_{wandb.run.name}.pth'\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    # 최종 테스트 세트 평가\n",
    "    final_test_loss, final_test_acc_top1, final_test_acc_top5 = evaluate(model, testloader, criterion, device, num_epochs-1, phase=\"test\")\n",
    "    \n",
    "    print(f'완료! 최고 테스트 top-1 정확도: {best_test_acc_top1:.2f}%, 최고 테스트 top-5 정확도: {best_test_acc_top5:.2f}%')\n",
    "    print(f'최종 테스트 top-1 정확도: {final_test_acc_top1:.2f}%, 최종 테스트 top-5 정확도: {final_test_acc_top5:.2f}%')\n",
    "    \n",
    "    # WandB에 최종 결과 기록\n",
    "    wandb.run.summary[\"best_test_accuracy_top1\"] = best_test_acc_top1\n",
    "    wandb.run.summary[\"best_test_accuracy_top5\"] = best_test_acc_top5\n",
    "    wandb.run.summary[\"final_test_accuracy_top1\"] = final_test_acc_top1\n",
    "    wandb.run.summary[\"final_test_accuracy_top5\"] = final_test_acc_top5\n",
    "\n",
    "    # Early stopping 정보 저장\n",
    "    if early_stopping.early_stop:\n",
    "        wandb.run.summary[\"early_stopped\"] = True\n",
    "        wandb.run.summary[\"early_stopped_epoch\"] = epoch+1\n",
    "        wandb.run.summary[\"best_epoch\"] = early_stopping.best_epoch+1\n",
    "    else:\n",
    "        wandb.run.summary[\"early_stopped\"] = False\n",
    "\n",
    "\n",
    "# 디바이스 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 모델 초기화 - config 기반\n",
    "if config[\"model\"] == \"resnet18\":\n",
    "    model = resnet18().to(device)\n",
    "else:\n",
    "    raise ValueError(f\"지원되지 않는 모델: {config['model']}\")\n",
    "\n",
    "# PSKD 손실 함수 설정 (두 번째 코드의 손실 함수 유지)\n",
    "criterion = PSKD()\n",
    "\n",
    "# 옵티마이저 설정 - ResNeXt와 동일한 파라미터 적용\n",
    "if config[\"optimizer\"] == \"SAM_SGD\":\n",
    "    base_optimizer = optim.SGD\n",
    "    optimizer = SAM(\n",
    "        model.parameters(), \n",
    "        base_optimizer, \n",
    "        lr=config[\"learning_rate\"],\n",
    "        momentum=config[\"momentum\"],\n",
    "        weight_decay=config[\"weight_decay\"],\n",
    "        nesterov=config[\"nesterov\"],\n",
    "        rho=config[\"rho\"],\n",
    "        adaptive=config[\"adaptive\"]\n",
    "    )\n",
    "else:\n",
    "    raise ValueError(f\"지원되지 않는 옵티마이저: {config['optimizer']}\")\n",
    "\n",
    "# WarmUpLR 스케줄러 초기화 - ResNeXt와 동일하게 10 에폭으로 설정\n",
    "warmup_steps = config[\"warmup_epochs\"] * len(trainloader)\n",
    "warmup_scheduler = WarmUpLR(optimizer, total_iters=warmup_steps)\n",
    "\n",
    "# 웜업 이후 사용할 스케줄러 설정 - ResNeXt와 동일한 파라미터 적용\n",
    "if config[\"lr_scheduler\"] == \"ReduceLROnPlateau\":\n",
    "    main_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, \n",
    "        mode='max',\n",
    "        factor=config[\"lr_factor\"],\n",
    "        patience=config[\"lr_patience\"],\n",
    "        verbose=True,\n",
    "        threshold=config[\"lr_threshold\"],\n",
    "        min_lr=config[\"min_lr\"]\n",
    "    )\n",
    "else:\n",
    "    raise ValueError(f\"지원되지 않는 스케줄러: {config['lr_scheduler']}\")\n",
    "\n",
    "# WandB에 모델 구조 기록\n",
    "wandb.watch(model, log=\"all\")\n",
    "\n",
    "# GPU 가속 - 여러 GPU 사용\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"{torch.cuda.device_count()}개의 GPU를 사용합니다.\")\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "# 훈련 시작 시간 기록\n",
    "start_time = time.time()\n",
    "\n",
    "# 메인 학습 루프 호출 - 명시적인 파라미터 전달 대신 기본값(config에서 자동으로 가져옴) 사용\n",
    "main_training_loop(\n",
    "    model=model,\n",
    "    trainloader=trainloader,\n",
    "    testloader=testloader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    warmup_scheduler=warmup_scheduler,\n",
    "    main_scheduler=main_scheduler\n",
    ")\n",
    "\n",
    "# 훈련 종료 시간 기록 및 출력\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "wandb.log({\"total_training_time\": total_time})\n",
    "\n",
    "print(f\"전체 학습 시간: {total_time:.2f} 초\")\n",
    "\n",
    "# WandB 실행 종료\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57b9218-aa24-4297-bb92-473c215e6767",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
