{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "516f9d5f-6361-4b03-98ee-e1ba4de86b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/guswls/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msokjh1310\u001b[0m (\u001b[33msokjh1310-hanyang-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/guswls/EEN4015_Intro2ML/pbl-2/wandb/run-20250415_140404-xt0dq6as</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/xt0dq6as' target=\"_blank\">resnet50_cutmix,flip,crop,affine,mixup_standard</a></strong> to <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/xt0dq6as' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/xt0dq6as</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Train set size: 50000\n",
      "Test set size: 10000\n",
      "Using device: cuda\n",
      "2개의 GPU를 사용합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                       | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Batch [50/391], Loss: 4.5773\n",
      "Epoch [1], Batch [100/391], Loss: 4.4942\n",
      "Epoch [1], Batch [150/391], Loss: 4.3066\n",
      "Epoch [1], Batch [200/391], Loss: 4.4279\n",
      "Epoch [1], Batch [250/391], Loss: 4.1970\n",
      "Epoch [1], Batch [300/391], Loss: 4.3546\n",
      "Epoch [1], Batch [350/391], Loss: 4.1441\n",
      "Train set: Epoch: 1, Average loss:4.3237, LR: 0.001000 Top-1 Accuracy: 5.1320%, Top-5 Accuracy: 19.2680%, Time consumed:98.15s\n",
      "Test set: Epoch: 1, Average loss:4.0577, Top-1 Accuracy: 9.5900%, Top-5 Accuracy: 30.7100%, Time consumed:16.04s\n",
      "\n",
      "새로운 최고 top-1 정확도: 9.59%, top-5 정확도: 30.71%\n",
      "새로운 최고 top-5 정확도: 30.71%\n",
      "Accuracy improved (-inf% --> 9.59%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▉                                                                                           | 1/100 [01:54<3:09:12, 114.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], Batch [50/391], Loss: 3.8386\n",
      "Epoch [2], Batch [100/391], Loss: 4.0877\n",
      "Epoch [2], Batch [150/391], Loss: 3.9556\n",
      "Epoch [2], Batch [200/391], Loss: 4.3296\n",
      "Epoch [2], Batch [250/391], Loss: 3.5466\n",
      "Epoch [2], Batch [300/391], Loss: 3.6766\n",
      "Epoch [2], Batch [350/391], Loss: 3.9855\n",
      "Train set: Epoch: 2, Average loss:3.9133, LR: 0.001000 Top-1 Accuracy: 10.6720%, Top-5 Accuracy: 32.3920%, Time consumed:99.31s\n",
      "Test set: Epoch: 2, Average loss:3.6324, Top-1 Accuracy: 15.4100%, Top-5 Accuracy: 41.5900%, Time consumed:16.14s\n",
      "\n",
      "새로운 최고 top-1 정확도: 15.41%, top-5 정확도: 41.59%\n",
      "새로운 최고 top-5 정확도: 41.59%\n",
      "Accuracy improved (9.59% --> 15.41%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▊                                                                                          | 2/100 [03:50<3:08:31, 115.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3], Batch [50/391], Loss: 3.4372\n",
      "Epoch [3], Batch [100/391], Loss: 3.4272\n",
      "Epoch [3], Batch [150/391], Loss: 3.3129\n",
      "Epoch [3], Batch [200/391], Loss: 3.2362\n",
      "Epoch [3], Batch [250/391], Loss: 3.4057\n",
      "Epoch [3], Batch [300/391], Loss: 3.7394\n",
      "Epoch [3], Batch [350/391], Loss: 3.3781\n",
      "Train set: Epoch: 3, Average loss:3.6219, LR: 0.001000 Top-1 Accuracy: 16.0200%, Top-5 Accuracy: 42.1260%, Time consumed:99.33s\n",
      "Test set: Epoch: 3, Average loss:3.1553, Top-1 Accuracy: 23.0900%, Top-5 Accuracy: 52.2500%, Time consumed:15.47s\n",
      "\n",
      "새로운 최고 top-1 정확도: 23.09%, top-5 정확도: 52.25%\n",
      "새로운 최고 top-5 정확도: 52.25%\n",
      "Accuracy improved (15.41% --> 23.09%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▊                                                                                         | 3/100 [05:45<3:06:29, 115.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4], Batch [50/391], Loss: 4.2378\n",
      "Epoch [4], Batch [100/391], Loss: 3.6764\n",
      "Epoch [4], Batch [150/391], Loss: 3.2419\n",
      "Epoch [4], Batch [200/391], Loss: 3.0613\n",
      "Epoch [4], Batch [250/391], Loss: 2.8958\n",
      "Epoch [4], Batch [300/391], Loss: 3.6417\n",
      "Epoch [4], Batch [350/391], Loss: 2.9520\n",
      "Train set: Epoch: 4, Average loss:3.3751, LR: 0.001000 Top-1 Accuracy: 21.2180%, Top-5 Accuracy: 49.8000%, Time consumed:99.69s\n",
      "Test set: Epoch: 4, Average loss:3.0651, Top-1 Accuracy: 28.4800%, Top-5 Accuracy: 60.0900%, Time consumed:16.41s\n",
      "\n",
      "새로운 최고 top-1 정확도: 28.48%, top-5 정확도: 60.09%\n",
      "새로운 최고 top-5 정확도: 60.09%\n",
      "Accuracy improved (23.09% --> 28.48%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▋                                                                                        | 4/100 [07:42<3:05:22, 115.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5], Batch [50/391], Loss: 3.8234\n",
      "Epoch [5], Batch [100/391], Loss: 4.0013\n",
      "Epoch [5], Batch [150/391], Loss: 2.6418\n",
      "Epoch [5], Batch [200/391], Loss: 3.5913\n",
      "Epoch [5], Batch [250/391], Loss: 2.9036\n",
      "Epoch [5], Batch [300/391], Loss: 3.1432\n",
      "Epoch [5], Batch [350/391], Loss: 3.8657\n",
      "Train set: Epoch: 5, Average loss:3.1441, LR: 0.001000 Top-1 Accuracy: 26.0180%, Top-5 Accuracy: 55.8520%, Time consumed:96.81s\n",
      "Test set: Epoch: 5, Average loss:2.5959, Top-1 Accuracy: 33.4500%, Top-5 Accuracy: 66.8300%, Time consumed:16.37s\n",
      "\n",
      "새로운 최고 top-1 정확도: 33.45%, top-5 정확도: 66.83%\n",
      "새로운 최고 top-5 정확도: 66.83%\n",
      "Accuracy improved (28.48% --> 33.45%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▌                                                                                       | 5/100 [09:36<3:02:13, 115.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6], Batch [50/391], Loss: 2.4742\n",
      "Epoch [6], Batch [100/391], Loss: 2.3298\n",
      "Epoch [6], Batch [150/391], Loss: 2.5843\n",
      "Epoch [6], Batch [200/391], Loss: 3.0020\n",
      "Epoch [6], Batch [250/391], Loss: 2.2026\n",
      "Epoch [6], Batch [300/391], Loss: 3.1598\n",
      "Epoch [6], Batch [350/391], Loss: 3.9865\n",
      "Train set: Epoch: 6, Average loss:2.9415, LR: 0.001000 Top-1 Accuracy: 31.2540%, Top-5 Accuracy: 62.0760%, Time consumed:101.41s\n",
      "Test set: Epoch: 6, Average loss:2.3266, Top-1 Accuracy: 39.1800%, Top-5 Accuracy: 72.0600%, Time consumed:15.95s\n",
      "\n",
      "새로운 최고 top-1 정확도: 39.18%, top-5 정확도: 72.06%\n",
      "새로운 최고 top-5 정확도: 72.06%\n",
      "Accuracy improved (33.45% --> 39.18%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████▌                                                                                      | 6/100 [11:34<3:01:47, 116.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7], Batch [50/391], Loss: 2.2139\n",
      "Epoch [7], Batch [100/391], Loss: 3.1856\n",
      "Epoch [7], Batch [150/391], Loss: 2.2028\n",
      "Epoch [7], Batch [200/391], Loss: 2.5188\n",
      "Epoch [7], Batch [250/391], Loss: 2.9699\n",
      "Epoch [7], Batch [300/391], Loss: 2.3925\n",
      "Epoch [7], Batch [350/391], Loss: 2.8398\n",
      "Train set: Epoch: 7, Average loss:2.8326, LR: 0.001000 Top-1 Accuracy: 33.6200%, Top-5 Accuracy: 64.5640%, Time consumed:101.05s\n",
      "Test set: Epoch: 7, Average loss:2.1367, Top-1 Accuracy: 43.1300%, Top-5 Accuracy: 75.9300%, Time consumed:16.02s\n",
      "\n",
      "새로운 최고 top-1 정확도: 43.13%, top-5 정확도: 75.93%\n",
      "새로운 최고 top-5 정확도: 75.93%\n",
      "Accuracy improved (39.18% --> 43.13%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████▍                                                                                     | 7/100 [13:31<3:00:39, 116.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8], Batch [50/391], Loss: 3.9997\n",
      "Epoch [8], Batch [100/391], Loss: 2.6333\n",
      "Epoch [8], Batch [150/391], Loss: 1.7075\n",
      "Epoch [8], Batch [200/391], Loss: 3.6930\n",
      "Epoch [8], Batch [250/391], Loss: 2.0448\n",
      "Epoch [8], Batch [300/391], Loss: 3.5823\n",
      "Epoch [8], Batch [350/391], Loss: 3.1327\n",
      "Train set: Epoch: 8, Average loss:2.5933, LR: 0.001000 Top-1 Accuracy: 38.5700%, Top-5 Accuracy: 69.6520%, Time consumed:101.82s\n",
      "Test set: Epoch: 8, Average loss:2.1470, Top-1 Accuracy: 45.9900%, Top-5 Accuracy: 77.3800%, Time consumed:16.86s\n",
      "\n",
      "새로운 최고 top-1 정확도: 45.99%, top-5 정확도: 77.38%\n",
      "새로운 최고 top-5 정확도: 77.38%\n",
      "Accuracy improved (43.13% --> 45.99%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███████▎                                                                                    | 8/100 [15:30<3:00:01, 117.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9], Batch [50/391], Loss: 2.0626\n",
      "Epoch [9], Batch [100/391], Loss: 2.5410\n",
      "Epoch [9], Batch [150/391], Loss: 2.1525\n",
      "Epoch [9], Batch [200/391], Loss: 1.9108\n",
      "Epoch [9], Batch [250/391], Loss: 1.9269\n",
      "Epoch [9], Batch [300/391], Loss: 3.7370\n",
      "Epoch [9], Batch [350/391], Loss: 2.1139\n",
      "Train set: Epoch: 9, Average loss:2.5805, LR: 0.001000 Top-1 Accuracy: 39.3480%, Top-5 Accuracy: 70.0880%, Time consumed:100.67s\n",
      "Test set: Epoch: 9, Average loss:1.9981, Top-1 Accuracy: 46.2500%, Top-5 Accuracy: 78.0800%, Time consumed:16.00s\n",
      "\n",
      "새로운 최고 top-1 정확도: 46.25%, top-5 정확도: 78.08%\n",
      "새로운 최고 top-5 정확도: 78.08%\n",
      "Accuracy improved (45.99% --> 46.25%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|████████▎                                                                                   | 9/100 [17:28<2:57:57, 117.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10], Batch [50/391], Loss: 3.2817\n",
      "Epoch [10], Batch [100/391], Loss: 3.3129\n",
      "Epoch [10], Batch [150/391], Loss: 1.7732\n",
      "Epoch [10], Batch [200/391], Loss: 2.0028\n",
      "Epoch [10], Batch [250/391], Loss: 1.9801\n",
      "Epoch [10], Batch [300/391], Loss: 1.7618\n",
      "Epoch [10], Batch [350/391], Loss: 3.8032\n",
      "Train set: Epoch: 10, Average loss:2.4683, LR: 0.001000 Top-1 Accuracy: 42.0320%, Top-5 Accuracy: 72.3940%, Time consumed:99.42s\n",
      "Test set: Epoch: 10, Average loss:1.9259, Top-1 Accuracy: 47.5200%, Top-5 Accuracy: 79.3000%, Time consumed:15.67s\n",
      "\n",
      "새로운 최고 top-1 정확도: 47.52%, top-5 정확도: 79.30%\n",
      "새로운 최고 top-5 정확도: 79.30%\n",
      "Accuracy improved (46.25% --> 47.52%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█████████                                                                                  | 10/100 [19:23<2:55:13, 116.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11], Batch [50/391], Loss: 3.4888\n",
      "Epoch [11], Batch [100/391], Loss: 1.9418\n",
      "Epoch [11], Batch [150/391], Loss: 1.8505\n",
      "Epoch [11], Batch [200/391], Loss: 2.2596\n",
      "Epoch [11], Batch [250/391], Loss: 1.8750\n",
      "Epoch [11], Batch [300/391], Loss: 1.7813\n",
      "Epoch [11], Batch [350/391], Loss: 3.5138\n",
      "Train set: Epoch: 11, Average loss:2.4984, LR: 0.001000 Top-1 Accuracy: 42.2220%, Top-5 Accuracy: 72.8740%, Time consumed:98.70s\n",
      "Test set: Epoch: 11, Average loss:1.8815, Top-1 Accuracy: 51.7800%, Top-5 Accuracy: 81.5300%, Time consumed:15.76s\n",
      "\n",
      "새로운 최고 top-1 정확도: 51.78%, top-5 정확도: 81.53%\n",
      "새로운 최고 top-5 정확도: 81.53%\n",
      "Accuracy improved (47.52% --> 51.78%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|██████████                                                                                 | 11/100 [21:18<2:52:26, 116.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12], Batch [50/391], Loss: 1.7302\n",
      "Epoch [12], Batch [100/391], Loss: 1.8408\n",
      "Epoch [12], Batch [150/391], Loss: 2.9552\n",
      "Epoch [12], Batch [200/391], Loss: 1.9308\n",
      "Epoch [12], Batch [250/391], Loss: 1.8195\n",
      "Epoch [12], Batch [300/391], Loss: 1.6531\n",
      "Epoch [12], Batch [350/391], Loss: 3.0155\n",
      "Train set: Epoch: 12, Average loss:2.3507, LR: 0.001000 Top-1 Accuracy: 46.0620%, Top-5 Accuracy: 75.8560%, Time consumed:98.44s\n",
      "Test set: Epoch: 12, Average loss:1.6561, Top-1 Accuracy: 53.8700%, Top-5 Accuracy: 83.9500%, Time consumed:16.54s\n",
      "\n",
      "새로운 최고 top-1 정확도: 53.87%, top-5 정확도: 83.95%\n",
      "새로운 최고 top-5 정확도: 83.95%\n",
      "Accuracy improved (51.78% --> 53.87%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████▉                                                                                | 12/100 [23:14<2:50:11, 116.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13], Batch [50/391], Loss: 3.3120\n",
      "Epoch [13], Batch [100/391], Loss: 1.5622\n",
      "Epoch [13], Batch [150/391], Loss: 2.1838\n",
      "Epoch [13], Batch [200/391], Loss: 1.4078\n",
      "Epoch [13], Batch [250/391], Loss: 1.5737\n",
      "Epoch [13], Batch [300/391], Loss: 1.6283\n",
      "Epoch [13], Batch [350/391], Loss: 1.5614\n",
      "Train set: Epoch: 13, Average loss:2.2340, LR: 0.001000 Top-1 Accuracy: 47.7820%, Top-5 Accuracy: 76.9600%, Time consumed:97.60s\n",
      "Test set: Epoch: 13, Average loss:1.6942, Top-1 Accuracy: 55.3300%, Top-5 Accuracy: 83.8700%, Time consumed:15.36s\n",
      "\n",
      "새로운 최고 top-1 정확도: 55.33%, top-5 정확도: 83.87%\n",
      "Accuracy improved (53.87% --> 55.33%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|███████████▊                                                                               | 13/100 [25:07<2:47:08, 115.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14], Batch [50/391], Loss: 1.4514\n",
      "Epoch [14], Batch [100/391], Loss: 1.3150\n",
      "Epoch [14], Batch [150/391], Loss: 3.0904\n",
      "Epoch [14], Batch [200/391], Loss: 1.4592\n",
      "Epoch [14], Batch [250/391], Loss: 1.7837\n",
      "Epoch [14], Batch [300/391], Loss: 2.7579\n",
      "Epoch [14], Batch [350/391], Loss: 2.9572\n",
      "Train set: Epoch: 14, Average loss:2.2847, LR: 0.001000 Top-1 Accuracy: 48.1220%, Top-5 Accuracy: 76.6840%, Time consumed:102.76s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████▋                                                                              | 14/100 [27:06<2:46:31, 116.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 14, Average loss:1.7447, Top-1 Accuracy: 54.5300%, Top-5 Accuracy: 83.6400%, Time consumed:15.53s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 15\n",
      "Epoch [15], Batch [50/391], Loss: 1.5188\n",
      "Epoch [15], Batch [100/391], Loss: 3.2183\n",
      "Epoch [15], Batch [150/391], Loss: 1.9871\n",
      "Epoch [15], Batch [200/391], Loss: 3.3329\n",
      "Epoch [15], Batch [250/391], Loss: 3.4153\n",
      "Epoch [15], Batch [300/391], Loss: 3.1838\n",
      "Epoch [15], Batch [350/391], Loss: 3.3149\n",
      "Train set: Epoch: 15, Average loss:2.1183, LR: 0.001000 Top-1 Accuracy: 50.3560%, Top-5 Accuracy: 79.3440%, Time consumed:96.25s\n",
      "Test set: Epoch: 15, Average loss:1.6739, Top-1 Accuracy: 56.9800%, Top-5 Accuracy: 85.1200%, Time consumed:15.87s\n",
      "\n",
      "새로운 최고 top-1 정확도: 56.98%, top-5 정확도: 85.12%\n",
      "새로운 최고 top-5 정확도: 85.12%\n",
      "Accuracy improved (55.33% --> 56.98%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████████████▋                                                                             | 15/100 [28:58<2:43:10, 115.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16], Batch [50/391], Loss: 1.7223\n",
      "Epoch [16], Batch [100/391], Loss: 3.2850\n",
      "Epoch [16], Batch [150/391], Loss: 2.0725\n",
      "Epoch [16], Batch [200/391], Loss: 3.5901\n",
      "Epoch [16], Batch [250/391], Loss: 2.9362\n",
      "Epoch [16], Batch [300/391], Loss: 1.5260\n",
      "Epoch [16], Batch [350/391], Loss: 1.4855\n",
      "Train set: Epoch: 16, Average loss:2.1188, LR: 0.001000 Top-1 Accuracy: 51.4720%, Top-5 Accuracy: 79.8740%, Time consumed:97.12s\n",
      "Test set: Epoch: 16, Average loss:1.4557, Top-1 Accuracy: 60.1600%, Top-5 Accuracy: 87.2200%, Time consumed:15.84s\n",
      "\n",
      "새로운 최고 top-1 정확도: 60.16%, top-5 정확도: 87.22%\n",
      "새로운 최고 top-5 정확도: 87.22%\n",
      "Accuracy improved (56.98% --> 60.16%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████████████▌                                                                            | 16/100 [30:52<2:40:32, 114.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17], Batch [50/391], Loss: 1.6306\n",
      "Epoch [17], Batch [100/391], Loss: 1.3749\n",
      "Epoch [17], Batch [150/391], Loss: 1.2073\n",
      "Epoch [17], Batch [200/391], Loss: 1.4440\n",
      "Epoch [17], Batch [250/391], Loss: 3.1725\n",
      "Epoch [17], Batch [300/391], Loss: 3.3327\n",
      "Epoch [17], Batch [350/391], Loss: 1.3743\n",
      "Train set: Epoch: 17, Average loss:2.0683, LR: 0.001000 Top-1 Accuracy: 52.4140%, Top-5 Accuracy: 80.6260%, Time consumed:97.44s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████████████▍                                                                           | 17/100 [32:46<2:38:14, 114.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 17, Average loss:2.9214, Top-1 Accuracy: 53.2000%, Top-5 Accuracy: 80.3700%, Time consumed:16.30s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 15\n",
      "Epoch [18], Batch [50/391], Loss: 2.0546\n",
      "Epoch [18], Batch [100/391], Loss: 1.3617\n",
      "Epoch [18], Batch [150/391], Loss: 3.2638\n",
      "Epoch [18], Batch [200/391], Loss: 1.2711\n",
      "Epoch [18], Batch [250/391], Loss: 3.0036\n",
      "Epoch [18], Batch [300/391], Loss: 1.2829\n",
      "Epoch [18], Batch [350/391], Loss: 1.1514\n",
      "Train set: Epoch: 18, Average loss:2.0758, LR: 0.001000 Top-1 Accuracy: 53.0260%, Top-5 Accuracy: 80.5980%, Time consumed:96.64s\n",
      "Test set: Epoch: 18, Average loss:1.3861, Top-1 Accuracy: 61.7700%, Top-5 Accuracy: 87.7600%, Time consumed:15.66s\n",
      "\n",
      "새로운 최고 top-1 정확도: 61.77%, top-5 정확도: 87.76%\n",
      "새로운 최고 top-5 정확도: 87.76%\n",
      "Accuracy improved (60.16% --> 61.77%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|████████████████▍                                                                          | 18/100 [34:39<2:35:41, 113.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19], Batch [50/391], Loss: 1.2549\n",
      "Epoch [19], Batch [100/391], Loss: 2.3959\n",
      "Epoch [19], Batch [150/391], Loss: 2.4879\n",
      "Epoch [19], Batch [200/391], Loss: 3.0102\n",
      "Epoch [19], Batch [250/391], Loss: 3.1088\n",
      "Epoch [19], Batch [300/391], Loss: 3.2916\n",
      "Epoch [19], Batch [350/391], Loss: 1.0839\n",
      "Train set: Epoch: 19, Average loss:1.9885, LR: 0.001000 Top-1 Accuracy: 55.0860%, Top-5 Accuracy: 82.4580%, Time consumed:99.45s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█████████████████▎                                                                         | 19/100 [36:34<2:34:19, 114.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 19, Average loss:1.4967, Top-1 Accuracy: 61.0300%, Top-5 Accuracy: 87.2600%, Time consumed:15.76s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 15\n",
      "Epoch [20], Batch [50/391], Loss: 1.1209\n",
      "Epoch [20], Batch [100/391], Loss: 1.1395\n",
      "Epoch [20], Batch [150/391], Loss: 2.8121\n",
      "Epoch [20], Batch [200/391], Loss: 2.9472\n",
      "Epoch [20], Batch [250/391], Loss: 3.2344\n",
      "Epoch [20], Batch [300/391], Loss: 3.1888\n",
      "Epoch [20], Batch [350/391], Loss: 3.0794\n",
      "Train set: Epoch: 20, Average loss:1.9476, LR: 0.001000 Top-1 Accuracy: 55.8500%, Top-5 Accuracy: 82.8440%, Time consumed:97.13s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████████████▏                                                                        | 20/100 [38:26<2:31:37, 113.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 20, Average loss:1.3979, Top-1 Accuracy: 60.9400%, Top-5 Accuracy: 87.6600%, Time consumed:15.19s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 15\n",
      "Epoch [21], Batch [50/391], Loss: 1.2918\n",
      "Epoch [21], Batch [100/391], Loss: 1.2413\n",
      "Epoch [21], Batch [150/391], Loss: 1.1946\n",
      "Epoch [21], Batch [200/391], Loss: 2.5461\n",
      "Epoch [21], Batch [250/391], Loss: 1.1854\n",
      "Epoch [21], Batch [300/391], Loss: 3.2509\n",
      "Epoch [21], Batch [350/391], Loss: 3.1422\n",
      "Train set: Epoch: 21, Average loss:1.8366, LR: 0.001000 Top-1 Accuracy: 57.2480%, Top-5 Accuracy: 84.0220%, Time consumed:97.03s\n",
      "Test set: Epoch: 21, Average loss:1.3583, Top-1 Accuracy: 62.3900%, Top-5 Accuracy: 88.1100%, Time consumed:16.16s\n",
      "\n",
      "새로운 최고 top-1 정확도: 62.39%, top-5 정확도: 88.11%\n",
      "새로운 최고 top-5 정확도: 88.11%\n",
      "Accuracy improved (61.77% --> 62.39%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|███████████████████                                                                        | 21/100 [40:20<2:29:43, 113.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22], Batch [50/391], Loss: 2.2791\n",
      "Epoch [22], Batch [100/391], Loss: 1.0178\n",
      "Epoch [22], Batch [150/391], Loss: 3.2943\n",
      "Epoch [22], Batch [200/391], Loss: 1.4081\n",
      "Epoch [22], Batch [250/391], Loss: 1.2815\n",
      "Epoch [22], Batch [300/391], Loss: 2.2279\n",
      "Epoch [22], Batch [350/391], Loss: 1.1126\n",
      "Train set: Epoch: 22, Average loss:1.8914, LR: 0.001000 Top-1 Accuracy: 57.1380%, Top-5 Accuracy: 83.4500%, Time consumed:96.56s\n",
      "Test set: Epoch: 22, Average loss:1.2970, Top-1 Accuracy: 63.4000%, Top-5 Accuracy: 88.8200%, Time consumed:16.34s\n",
      "\n",
      "새로운 최고 top-1 정확도: 63.40%, top-5 정확도: 88.82%\n",
      "새로운 최고 top-5 정확도: 88.82%\n",
      "Accuracy improved (62.39% --> 63.40%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|████████████████████                                                                       | 22/100 [42:13<2:27:44, 113.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23], Batch [50/391], Loss: 1.0785\n",
      "Epoch [23], Batch [100/391], Loss: 1.1034\n",
      "Epoch [23], Batch [150/391], Loss: 3.2675\n",
      "Epoch [23], Batch [200/391], Loss: 0.9847\n",
      "Epoch [23], Batch [250/391], Loss: 2.9578\n",
      "Epoch [23], Batch [300/391], Loss: 1.0826\n",
      "Epoch [23], Batch [350/391], Loss: 1.1505\n",
      "Train set: Epoch: 23, Average loss:1.8377, LR: 0.001000 Top-1 Accuracy: 58.1540%, Top-5 Accuracy: 83.9860%, Time consumed:97.72s\n",
      "Test set: Epoch: 23, Average loss:1.2293, Top-1 Accuracy: 65.2600%, Top-5 Accuracy: 89.8500%, Time consumed:16.42s\n",
      "\n",
      "새로운 최고 top-1 정확도: 65.26%, top-5 정확도: 89.85%\n",
      "새로운 최고 top-5 정확도: 89.85%\n",
      "Accuracy improved (63.40% --> 65.26%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|████████████████████▉                                                                      | 23/100 [44:08<2:26:15, 113.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24], Batch [50/391], Loss: 1.0386\n",
      "Epoch [24], Batch [100/391], Loss: 2.3449\n",
      "Epoch [24], Batch [150/391], Loss: 1.1692\n",
      "Epoch [24], Batch [200/391], Loss: 1.0074\n",
      "Epoch [24], Batch [250/391], Loss: 0.8904\n",
      "Epoch [24], Batch [300/391], Loss: 1.9465\n",
      "Epoch [24], Batch [350/391], Loss: 0.9087\n",
      "Train set: Epoch: 24, Average loss:1.8003, LR: 0.001000 Top-1 Accuracy: 59.8260%, Top-5 Accuracy: 85.3300%, Time consumed:97.77s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|█████████████████████▊                                                                     | 24/100 [46:01<2:24:06, 113.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 24, Average loss:1.4740, Top-1 Accuracy: 61.4700%, Top-5 Accuracy: 86.6900%, Time consumed:15.52s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 15\n",
      "Epoch [25], Batch [50/391], Loss: 2.8672\n",
      "Epoch [25], Batch [100/391], Loss: 0.9447\n",
      "Epoch [25], Batch [150/391], Loss: 3.1902\n",
      "Epoch [25], Batch [200/391], Loss: 2.7183\n",
      "Epoch [25], Batch [250/391], Loss: 0.9845\n",
      "Epoch [25], Batch [300/391], Loss: 1.0160\n",
      "Epoch [25], Batch [350/391], Loss: 0.7917\n",
      "Train set: Epoch: 25, Average loss:1.6562, LR: 0.001000 Top-1 Accuracy: 62.1400%, Top-5 Accuracy: 86.8980%, Time consumed:99.50s\n",
      "Test set: Epoch: 25, Average loss:1.2258, Top-1 Accuracy: 65.7000%, Top-5 Accuracy: 90.5000%, Time consumed:15.30s\n",
      "\n",
      "새로운 최고 top-1 정확도: 65.70%, top-5 정확도: 90.50%\n",
      "새로운 최고 top-5 정확도: 90.50%\n",
      "Accuracy improved (65.26% --> 65.70%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██████████████████████▊                                                                    | 25/100 [47:57<2:22:49, 114.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26], Batch [50/391], Loss: 0.8315\n",
      "Epoch [26], Batch [100/391], Loss: 2.6505\n",
      "Epoch [26], Batch [150/391], Loss: 2.7686\n",
      "Epoch [26], Batch [200/391], Loss: 0.9463\n",
      "Epoch [26], Batch [250/391], Loss: 3.1893\n",
      "Epoch [26], Batch [300/391], Loss: 0.8473\n",
      "Epoch [26], Batch [350/391], Loss: 2.8431\n",
      "Train set: Epoch: 26, Average loss:1.7801, LR: 0.001000 Top-1 Accuracy: 60.6240%, Top-5 Accuracy: 85.3600%, Time consumed:97.99s\n",
      "Test set: Epoch: 26, Average loss:1.2487, Top-1 Accuracy: 65.7400%, Top-5 Accuracy: 89.0000%, Time consumed:15.33s\n",
      "\n",
      "새로운 최고 top-1 정확도: 65.74%, top-5 정확도: 89.00%\n",
      "Accuracy improved (65.70% --> 65.74%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|███████████████████████▋                                                                   | 26/100 [49:51<2:20:46, 114.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27], Batch [50/391], Loss: 1.6507\n",
      "Epoch [27], Batch [100/391], Loss: 2.8790\n",
      "Epoch [27], Batch [150/391], Loss: 0.9462\n",
      "Epoch [27], Batch [200/391], Loss: 0.7536\n",
      "Epoch [27], Batch [250/391], Loss: 2.3315\n",
      "Epoch [27], Batch [300/391], Loss: 0.8996\n",
      "Epoch [27], Batch [350/391], Loss: 0.8071\n",
      "Train set: Epoch: 27, Average loss:1.7150, LR: 0.001000 Top-1 Accuracy: 62.8860%, Top-5 Accuracy: 86.8500%, Time consumed:98.46s\n",
      "Test set: Epoch: 27, Average loss:1.2061, Top-1 Accuracy: 66.3700%, Top-5 Accuracy: 90.2100%, Time consumed:15.67s\n",
      "\n",
      "새로운 최고 top-1 정확도: 66.37%, top-5 정확도: 90.21%\n",
      "Accuracy improved (65.74% --> 66.37%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|████████████████████████▌                                                                  | 27/100 [51:45<2:19:04, 114.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28], Batch [50/391], Loss: 0.9284\n",
      "Epoch [28], Batch [100/391], Loss: 2.8544\n",
      "Epoch [28], Batch [150/391], Loss: 2.2019\n",
      "Epoch [28], Batch [200/391], Loss: 3.1043\n",
      "Epoch [28], Batch [250/391], Loss: 0.8645\n",
      "Epoch [28], Batch [300/391], Loss: 1.4756\n",
      "Epoch [28], Batch [350/391], Loss: 2.6877\n",
      "Train set: Epoch: 28, Average loss:1.6621, LR: 0.001000 Top-1 Accuracy: 62.4000%, Top-5 Accuracy: 86.5920%, Time consumed:97.19s\n",
      "Test set: Epoch: 28, Average loss:1.2006, Top-1 Accuracy: 66.9500%, Top-5 Accuracy: 90.4600%, Time consumed:15.30s\n",
      "\n",
      "새로운 최고 top-1 정확도: 66.95%, top-5 정확도: 90.46%\n",
      "Accuracy improved (66.37% --> 66.95%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|█████████████████████████▍                                                                 | 28/100 [53:38<2:16:42, 113.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29], Batch [50/391], Loss: 0.8008\n",
      "Epoch [29], Batch [100/391], Loss: 0.9334\n",
      "Epoch [29], Batch [150/391], Loss: 1.1527\n",
      "Epoch [29], Batch [200/391], Loss: 3.0538\n",
      "Epoch [29], Batch [250/391], Loss: 0.8646\n",
      "Epoch [29], Batch [300/391], Loss: 0.8231\n",
      "Epoch [29], Batch [350/391], Loss: 2.6523\n",
      "Train set: Epoch: 29, Average loss:1.6281, LR: 0.001000 Top-1 Accuracy: 63.7960%, Top-5 Accuracy: 87.3020%, Time consumed:97.29s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██████████████████████████▍                                                                | 29/100 [55:31<2:14:28, 113.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 29, Average loss:1.4741, Top-1 Accuracy: 60.1600%, Top-5 Accuracy: 86.5000%, Time consumed:15.68s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 15\n",
      "Epoch [30], Batch [50/391], Loss: 2.5517\n",
      "Epoch [30], Batch [100/391], Loss: 0.7154\n",
      "Epoch [30], Batch [150/391], Loss: 2.8423\n",
      "Epoch [30], Batch [200/391], Loss: 0.8233\n",
      "Epoch [30], Batch [250/391], Loss: 2.9714\n",
      "Epoch [30], Batch [300/391], Loss: 0.8300\n",
      "Epoch [30], Batch [350/391], Loss: 0.7183\n",
      "Train set: Epoch: 30, Average loss:1.6902, LR: 0.001000 Top-1 Accuracy: 63.5120%, Top-5 Accuracy: 87.1060%, Time consumed:96.21s\n",
      "Test set: Epoch: 30, Average loss:1.1590, Top-1 Accuracy: 67.7400%, Top-5 Accuracy: 90.4200%, Time consumed:15.79s\n",
      "\n",
      "새로운 최고 top-1 정확도: 67.74%, top-5 정확도: 90.42%\n",
      "Accuracy improved (66.95% --> 67.74%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████████████████████▎                                                               | 30/100 [57:24<2:12:11, 113.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31], Batch [50/391], Loss: 0.8807\n",
      "Epoch [31], Batch [100/391], Loss: 2.6336\n",
      "Epoch [31], Batch [150/391], Loss: 2.5132\n",
      "Epoch [31], Batch [200/391], Loss: 0.8064\n",
      "Epoch [31], Batch [250/391], Loss: 0.6855\n",
      "Epoch [31], Batch [300/391], Loss: 2.0634\n",
      "Epoch [31], Batch [350/391], Loss: 0.6553\n",
      "Train set: Epoch: 31, Average loss:1.5077, LR: 0.001000 Top-1 Accuracy: 67.5020%, Top-5 Accuracy: 89.8960%, Time consumed:96.39s\n",
      "Test set: Epoch: 31, Average loss:1.1506, Top-1 Accuracy: 67.9700%, Top-5 Accuracy: 90.6200%, Time consumed:15.37s\n",
      "\n",
      "새로운 최고 top-1 정확도: 67.97%, top-5 정확도: 90.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████████████████████▎                                                               | 30/100 [59:16<2:18:18, 118.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "새로운 최고 top-5 정확도: 90.62%\n",
      "최대 에폭 (30)에 도달했습니다. 훈련을 중단합니다.\n",
      "에폭 31에서 학습 조기 종료. 최고 성능 에폭: 30\n",
      "테스트 정확도 기준 최고 모델 로드 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 100, Average loss:1.1506, Top-1 Accuracy: 67.9700%, Top-5 Accuracy: 90.6200%, Time consumed:15.80s\n",
      "\n",
      "완료! 최고 테스트 top-1 정확도: 67.97%, 최고 테스트 top-5 정확도: 90.62%\n",
      "최종 테스트 top-1 정확도: 67.97%, 최종 테스트 top-5 정확도: 90.62%\n",
      "전체 학습 시간: 3572.29 초\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_accuracy_top1</td><td>▁▂▃▃▄▅▅▅▅▆▆▆▆▆▇▇▆▇▇▇▇▇█▇████▇██</td></tr><tr><td>test_accuracy_top5</td><td>▁▂▄▄▅▆▆▆▇▇▇▇▇▇▇█▇██████████████</td></tr><tr><td>test_loss</td><td>█▇▆▆▄▄▃▃▃▃▃▂▂▂▂▂▅▂▂▂▂▁▁▂▁▁▁▁▂▁▁</td></tr><tr><td>total_training_time</td><td>▁</td></tr><tr><td>train_accuracy_top1</td><td>▁▂▂▃▃▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇███</td></tr><tr><td>train_accuracy_top5</td><td>▁▂▃▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇████████</td></tr><tr><td>train_loss</td><td>█▇▆▆▅▅▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>30</td></tr><tr><td>best_test_accuracy_top1</td><td>67.97</td></tr><tr><td>best_test_accuracy_top5</td><td>90.62</td></tr><tr><td>early_stopped</td><td>True</td></tr><tr><td>early_stopped_epoch</td><td>31</td></tr><tr><td>epoch</td><td>31</td></tr><tr><td>final_test_accuracy_top1</td><td>67.97</td></tr><tr><td>final_test_accuracy_top5</td><td>90.62</td></tr><tr><td>learning_rate</td><td>0.001</td></tr><tr><td>test_accuracy_top1</td><td>67.97</td></tr><tr><td>test_accuracy_top5</td><td>90.62</td></tr><tr><td>test_loss</td><td>1.15056</td></tr><tr><td>total_training_time</td><td>3572.2945</td></tr><tr><td>train_accuracy_top1</td><td>67.502</td></tr><tr><td>train_accuracy_top5</td><td>89.896</td></tr><tr><td>train_loss</td><td>1.50766</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">resnet50_cutmix,flip,crop,affine,mixup_standard</strong> at: <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/xt0dq6as' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/xt0dq6as</a><br> View project at: <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250415_140404-xt0dq6as/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.v2 as transforms_v2  # CutMix를 위한 v2 transforms 추가\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "from tools.tool import AccuracyEarlyStopping  # 수정된 AccuracyEarlyStopping 클래스 임포트\n",
    "from models.resnet import resnet18, resnet34, resnet50\n",
    "\n",
    "wandb.login(key=\"ef091b9abcea3186341ddf8995d62bde62d7469e\")\n",
    "wandb.init(project=\"PBL-2\", name=\"resnet50_cutmix,flip,crop,affine,mixup_standard\")  # RandomAffine 추가 명시\n",
    "\n",
    "# WandB 설정\n",
    "config = {\n",
    "    \"model\": \"resnet50\",\n",
    "    \"batch_size\": 128,\n",
    "    \"num_epochs\": 100,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"seed\": 2025,\n",
    "    \"deterministic\": False,\n",
    "    \"patience\": 15,  # early stopping patience\n",
    "    \"max_epochs_wait\": 30,  # 최대 30 에폭까지만 기다림\n",
    "    \"cutmix_alpha\": 1.0,  # CutMix 알파 파라미터 추가\n",
    "    \"cutmix_prob\": 0.5,   # CutMix 적용 확률 추가\n",
    "    \"crop_padding\": 4,    # RandomCrop 패딩 크기\n",
    "    \"crop_size\": 32,      # RandomCrop 크기 (CIFAR-100 이미지 크기는 32x32)\n",
    "    \"affine_degrees\": 10, # RandomAffine 회전 각도 범위\n",
    "    \"affine_translate\": (0.1, 0.1),  # RandomAffine 이동 범위 (가로, 세로)\n",
    "    \"affine_scale\": (0.9, 1.1),      # RandomAffine 확대/축소 범위\n",
    "    \"affine_shear\": 10                # RandomAffine 전단 범위\n",
    "}\n",
    "wandb.config.update(config)\n",
    "\n",
    "# CIFAR-100 데이터셋 로드 - 기본 train/test 분할 사용\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(config[\"crop_size\"], padding=config[\"crop_padding\"]),  # 패딩 후 랜덤 크롭\n",
    "    transforms.RandomHorizontalFlip(),  # 수평 뒤집기\n",
    "    transforms.RandomAffine(\n",
    "        degrees=config[\"affine_degrees\"],           # 회전 각도 범위\n",
    "        translate=config[\"affine_translate\"],       # 이동 범위 (가로, 세로)\n",
    "        scale=config[\"affine_scale\"],               # 확대/축소 범위\n",
    "        shear=config[\"affine_shear\"]                # 전단 범위\n",
    "    ),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR100(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR100(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "# DataLoader 생성\n",
    "trainloader = DataLoader(trainset, batch_size=config[\"batch_size\"], shuffle=True, num_workers=16)\n",
    "testloader = DataLoader(testset, batch_size=config[\"batch_size\"], shuffle=False, num_workers=16)\n",
    "\n",
    "print(f\"Train set size: {len(trainset)}\")\n",
    "print(f\"Test set size: {len(testset)}\")\n",
    "\n",
    "# CutMix 변환 정의\n",
    "cutmix = transforms_v2.CutMix(alpha=config[\"cutmix_alpha\"], num_classes=100)  # CIFAR-100은 100개 클래스\n",
    "\n",
    "def train(model, trainloader, criterion, optimizer, device, epoch):\n",
    "    \"\"\"\n",
    "    학습 함수 (CutMix 적용)\n",
    "    \"\"\"\n",
    "    model.train()   # 모델을 학습 모드로 설정\n",
    "    start_time = time.time()  # 시간 측정 시작\n",
    "    running_loss = 0.0\n",
    "    correct_top1 = 0\n",
    "    correct_top5 = 0\n",
    "    total = 0\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(trainloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # CutMix 확률적 적용\n",
    "        if random.random() < config[\"cutmix_prob\"]:\n",
    "            inputs, labels = cutmix(inputs, labels)\n",
    "            # 이 경우 labels은 원-핫 인코딩 형태로 변환됨\n",
    "            use_cutmix = True\n",
    "        else:\n",
    "            use_cutmix = False\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # CutMix 적용 여부에 따라 손실 함수 선택\n",
    "        if use_cutmix:\n",
    "            # CutMix가 적용된 경우 (원-핫 인코딩된 레이블)\n",
    "            loss = torch.nn.functional.cross_entropy(outputs, labels)\n",
    "        else:\n",
    "            # 일반적인 경우 (정수 인덱스 레이블)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # 정확도 계산 - CutMix 적용 여부에 따라 다르게 처리\n",
    "        if use_cutmix:\n",
    "            # 원-핫 인코딩된 레이블에서 argmax를 사용해 가장 큰 값의 인덱스 추출\n",
    "            _, label_idx = labels.max(1)\n",
    "        else:\n",
    "            # 정수 인덱스 레이블 그대로 사용\n",
    "            label_idx = labels\n",
    "            \n",
    "        # top-1 정확도 계산\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += inputs.size(0)\n",
    "        correct_top1 += predicted.eq(label_idx).sum().item()\n",
    "        \n",
    "        # top-5 정확도 계산\n",
    "        _, top5_idx = outputs.topk(5, 1, largest=True, sorted=True)\n",
    "        correct_top5 += sum([1 for i in range(len(label_idx)) if label_idx[i] in top5_idx[i]])\n",
    "        \n",
    "        if (i + 1) % 50 == 0:  # 50 배치마다 출력\n",
    "            print(f'Epoch [{epoch+1}], Batch [{i+1}/{len(trainloader)}], Loss: {loss.item():.4f}')\n",
    "    \n",
    "    epoch_loss = running_loss / len(trainloader)\n",
    "    accuracy_top1 = 100.0 * correct_top1 / total\n",
    "    accuracy_top5 = 100.0 * correct_top5 / total\n",
    "    \n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    # 학습 세트에 대한 성능 출력\n",
    "    print(f'Train set: Epoch: {epoch+1}, Average loss:{epoch_loss:.4f}, LR: {optimizer.param_groups[0][\"lr\"]:.6f} '\n",
    "          f'Top-1 Accuracy: {accuracy_top1:.4f}%, Top-5 Accuracy: {accuracy_top5:.4f}%, Time consumed:{train_time:.2f}s')\n",
    "    \n",
    "    return epoch_loss, accuracy_top1, accuracy_top5\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device, epoch, phase=\"test\"):\n",
    "    \"\"\"\n",
    "    평가 함수\n",
    "    \"\"\"\n",
    "    model.eval()  # 모델을 평가 모드로 설정\n",
    "    start_time = time.time()  # 시간 측정 시작\n",
    "    \n",
    "    eval_loss = 0.0\n",
    "    correct_top1 = 0\n",
    "    correct_top5 = 0\n",
    "    total = 0\n",
    "    \n",
    "    # 그래디언트 계산 비활성화\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # 순전파\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # 손실 계산\n",
    "            loss = criterion(outputs, labels)\n",
    "            eval_loss += loss.item()\n",
    "            \n",
    "            # top-1 정확도 계산\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct_top1 += (predicted == labels).sum().item()\n",
    "            \n",
    "            # top-5 정확도 계산\n",
    "            _, top5_idx = outputs.topk(5, 1, largest=True, sorted=True)\n",
    "            correct_top5 += top5_idx.eq(labels.view(-1, 1).expand_as(top5_idx)).sum().item()\n",
    "    \n",
    "    # 평균 손실 및 정확도 계산\n",
    "    eval_loss = eval_loss / len(dataloader)\n",
    "    accuracy_top1 = 100.0 * correct_top1 / total\n",
    "    accuracy_top5 = 100.0 * correct_top5 / total\n",
    "    \n",
    "    # 평가 시간 계산\n",
    "    eval_time = time.time() - start_time\n",
    "    \n",
    "    # 테스트 세트에 대한 성능 출력\n",
    "    print(f'{phase.capitalize()} set: Epoch: {epoch+1}, Average loss:{eval_loss:.4f}, '\n",
    "          f'Top-1 Accuracy: {accuracy_top1:.4f}%, Top-5 Accuracy: {accuracy_top5:.4f}%, Time consumed:{eval_time:.2f}s')\n",
    "    print()\n",
    "    \n",
    "    return eval_loss, accuracy_top1, accuracy_top5\n",
    "\n",
    "# 메인 학습 루프\n",
    "def main_training_loop(model, trainloader, testloader, criterion, optimizer, device, num_epochs, patience, max_epochs_wait):\n",
    "    \"\"\"\n",
    "    메인 학습 루프 (accuracy 기준 early stopping)\n",
    "    \"\"\"\n",
    "    # 정확도 기반 얼리 스토핑 사용\n",
    "    early_stopping = AccuracyEarlyStopping(patience=patience, verbose=True, path='checkpoint.pt', max_epochs=max_epochs_wait)\n",
    "    \n",
    "    best_test_acc_top1 = 0.0\n",
    "    best_test_acc_top5 = 0.0\n",
    "    \n",
    "    # 테스트 정확도 기록을 위한 리스트\n",
    "    test_acc_top1_history = []\n",
    "    \n",
    "    # tqdm을 사용한 진행 상황 표시\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        # 학습\n",
    "        train_loss, train_acc_top1, train_acc_top5 = train(model, trainloader, criterion, optimizer, device, epoch)\n",
    "        \n",
    "        # 테스트 데이터로 평가\n",
    "        test_loss, test_acc_top1, test_acc_top5 = evaluate(model, testloader, criterion, device, epoch, phase=\"test\")\n",
    "        \n",
    "        # 테스트 정확도 기록\n",
    "        test_acc_top1_history.append(test_acc_top1)\n",
    "        \n",
    "        # WandB에 로깅\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_accuracy_top1\": train_acc_top1,\n",
    "            \"train_accuracy_top5\": train_acc_top5,\n",
    "            \"test_loss\": test_loss,\n",
    "            \"test_accuracy_top1\": test_acc_top1,\n",
    "            \"test_accuracy_top5\": test_acc_top5\n",
    "        })\n",
    "            \n",
    "        # 최고 정확도 모델 저장 (top-1 기준)\n",
    "        if test_acc_top1 > best_test_acc_top1:\n",
    "            best_test_acc_top1 = test_acc_top1\n",
    "            best_test_acc_top5_at_best_top1 = test_acc_top5\n",
    "            print(f'새로운 최고 top-1 정확도: {best_test_acc_top1:.2f}%, top-5 정확도: {best_test_acc_top5_at_best_top1:.2f}%')\n",
    "            # 모델 저장\n",
    "            model_path = f'best_model_{wandb.run.name}.pth'\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            \n",
    "            # WandB에 모델 아티팩트 저장\n",
    "            wandb.save(model_path)\n",
    "        \n",
    "        # top-5 accuracy 기록 업데이트\n",
    "        if test_acc_top5 > best_test_acc_top5:\n",
    "            best_test_acc_top5 = test_acc_top5\n",
    "            print(f'새로운 최고 top-5 정확도: {best_test_acc_top5:.2f}%')\n",
    "\n",
    "        # Early stopping 체크 (test_acc_top1 기준)\n",
    "        early_stopping(test_acc_top1, model, epoch)\n",
    "        if early_stopping.early_stop:\n",
    "            print(f\"에폭 {epoch+1}에서 학습 조기 종료. 최고 성능 에폭: {early_stopping.best_epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    # 훈련 완료 후 최고 모델 로드\n",
    "    print(\"테스트 정확도 기준 최고 모델 로드 중...\")\n",
    "    model_path = f'best_model_{wandb.run.name}.pth'\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    # 최종 테스트 세트 평가\n",
    "    final_test_loss, final_test_acc_top1, final_test_acc_top5 = evaluate(model, testloader, criterion, device, num_epochs-1, phase=\"test\")\n",
    "    \n",
    "    print(f'완료! 최고 테스트 top-1 정확도: {best_test_acc_top1:.2f}%, 최고 테스트 top-5 정확도: {best_test_acc_top5:.2f}%')\n",
    "    print(f'최종 테스트 top-1 정확도: {final_test_acc_top1:.2f}%, 최종 테스트 top-5 정확도: {final_test_acc_top5:.2f}%')\n",
    "    \n",
    "    # WandB에 최종 결과 기록\n",
    "    wandb.run.summary[\"best_test_accuracy_top1\"] = best_test_acc_top1\n",
    "    wandb.run.summary[\"best_test_accuracy_top5\"] = best_test_acc_top5\n",
    "    wandb.run.summary[\"final_test_accuracy_top1\"] = final_test_acc_top1\n",
    "    wandb.run.summary[\"final_test_accuracy_top5\"] = final_test_acc_top5\n",
    "\n",
    "    # Early stopping 정보 저장\n",
    "    if early_stopping.early_stop:\n",
    "        wandb.run.summary[\"early_stopped\"] = True\n",
    "        wandb.run.summary[\"early_stopped_epoch\"] = epoch+1\n",
    "        wandb.run.summary[\"best_epoch\"] = early_stopping.best_epoch+1\n",
    "    else:\n",
    "        wandb.run.summary[\"early_stopped\"] = False\n",
    "\n",
    "\n",
    "# 디바이스 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 모델 초기화\n",
    "model = resnet50().to(device)  \n",
    "criterion = nn.CrossEntropyLoss()  # 기본 CrossEntropyLoss 사용 (라벨 스무딩 없음)\n",
    "optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"])  # 옵티마이저 정의\n",
    "\n",
    "# WandB에 모델 구조 기록\n",
    "wandb.watch(model, log=\"all\")\n",
    "\n",
    "# GPU 가속\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"{torch.cuda.device_count()}개의 GPU를 사용합니다.\")\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "# 훈련 시작 시간 기록\n",
    "start_time = time.time()\n",
    "\n",
    "# 메인 학습 루프 호출\n",
    "main_training_loop(\n",
    "    model=model,\n",
    "    trainloader=trainloader,\n",
    "    testloader=testloader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    num_epochs=config[\"num_epochs\"],\n",
    "    patience=config[\"patience\"],\n",
    "    max_epochs_wait=config[\"max_epochs_wait\"]\n",
    ")\n",
    "\n",
    "# 훈련 종료 시간 기록 및 출력\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "wandb.log({\"total_training_time\": total_time})\n",
    "\n",
    "print(f\"전체 학습 시간: {total_time:.2f} 초\")\n",
    "\n",
    "# WandB 실행 종료\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57b9218-aa24-4297-bb92-473c215e6767",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
