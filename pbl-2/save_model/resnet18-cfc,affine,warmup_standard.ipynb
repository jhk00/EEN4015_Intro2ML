{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "516f9d5f-6361-4b03-98ee-e1ba4de86b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">resnet18_cutmix,flip,crop,affine_standard</strong> at: <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/7rc7dr7l' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/7rc7dr7l</a><br> View project at: <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250415_131206-7rc7dr7l/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/guswls/EEN4015_Intro2ML/pbl-2/wandb/run-20250415_131718-0h0domsu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/0h0domsu' target=\"_blank\">resnet18_cutmix,flip,crop,affine_standard</a></strong> to <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/0h0domsu' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/0h0domsu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Train set size: 50000\n",
      "Test set size: 10000\n",
      "Using device: cuda\n",
      "2개의 GPU를 사용합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                       | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Batch [50/391], Loss: 4.3799\n",
      "Epoch [1], Batch [100/391], Loss: 4.4763\n",
      "Epoch [1], Batch [150/391], Loss: 3.9807\n",
      "Epoch [1], Batch [200/391], Loss: 4.4828\n",
      "Epoch [1], Batch [250/391], Loss: 4.0081\n",
      "Epoch [1], Batch [300/391], Loss: 3.7576\n",
      "Epoch [1], Batch [350/391], Loss: 4.1527\n",
      "Train set: Epoch: 1, Average loss:4.0953, LR: 0.001000 Top-1 Accuracy: 8.1440%, Top-5 Accuracy: 26.4240%, Time consumed:47.10s\n",
      "Test set: Epoch: 1, Average loss:3.5624, Top-1 Accuracy: 14.7000%, Top-5 Accuracy: 40.4800%, Time consumed:8.75s\n",
      "\n",
      "새로운 최고 top-1 정확도: 14.70%, top-5 정확도: 40.48%\n",
      "새로운 최고 top-5 정확도: 40.48%\n",
      "Accuracy improved (-inf% --> 14.70%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▉                                                                                            | 1/100 [00:56<1:32:31, 56.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], Batch [50/391], Loss: 3.5538\n",
      "Epoch [2], Batch [100/391], Loss: 3.5242\n",
      "Epoch [2], Batch [150/391], Loss: 3.5774\n",
      "Epoch [2], Batch [200/391], Loss: 3.2820\n",
      "Epoch [2], Batch [250/391], Loss: 3.1905\n",
      "Epoch [2], Batch [300/391], Loss: 3.9049\n",
      "Epoch [2], Batch [350/391], Loss: 3.8438\n",
      "Train set: Epoch: 2, Average loss:3.7082, LR: 0.001000 Top-1 Accuracy: 15.0600%, Top-5 Accuracy: 39.7080%, Time consumed:50.72s\n",
      "Test set: Epoch: 2, Average loss:3.1077, Top-1 Accuracy: 23.2800%, Top-5 Accuracy: 53.2000%, Time consumed:9.40s\n",
      "\n",
      "새로운 최고 top-1 정확도: 23.28%, top-5 정확도: 53.20%\n",
      "새로운 최고 top-5 정확도: 53.20%\n",
      "Accuracy improved (14.70% --> 23.28%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▊                                                                                           | 2/100 [01:56<1:35:43, 58.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3], Batch [50/391], Loss: 4.0318\n",
      "Epoch [3], Batch [100/391], Loss: 3.0628\n",
      "Epoch [3], Batch [150/391], Loss: 3.0060\n",
      "Epoch [3], Batch [200/391], Loss: 2.9552\n",
      "Epoch [3], Batch [250/391], Loss: 3.0603\n",
      "Epoch [3], Batch [300/391], Loss: 2.8548\n",
      "Epoch [3], Batch [350/391], Loss: 4.0227\n",
      "Train set: Epoch: 3, Average loss:3.3706, LR: 0.001000 Top-1 Accuracy: 21.6920%, Top-5 Accuracy: 50.1820%, Time consumed:48.59s\n",
      "Test set: Epoch: 3, Average loss:2.7463, Top-1 Accuracy: 29.4400%, Top-5 Accuracy: 61.7400%, Time consumed:8.41s\n",
      "\n",
      "새로운 최고 top-1 정확도: 29.44%, top-5 정확도: 61.74%\n",
      "새로운 최고 top-5 정확도: 61.74%\n",
      "Accuracy improved (23.28% --> 29.44%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▊                                                                                          | 3/100 [02:53<1:33:44, 57.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4], Batch [50/391], Loss: 2.8385\n",
      "Epoch [4], Batch [100/391], Loss: 3.6893\n",
      "Epoch [4], Batch [150/391], Loss: 4.0507\n",
      "Epoch [4], Batch [200/391], Loss: 2.4896\n",
      "Epoch [4], Batch [250/391], Loss: 3.7979\n",
      "Epoch [4], Batch [300/391], Loss: 2.5845\n",
      "Epoch [4], Batch [350/391], Loss: 3.1188\n",
      "Train set: Epoch: 4, Average loss:3.1729, LR: 0.001000 Top-1 Accuracy: 26.4360%, Top-5 Accuracy: 56.5580%, Time consumed:48.56s\n",
      "Test set: Epoch: 4, Average loss:2.4356, Top-1 Accuracy: 36.4600%, Top-5 Accuracy: 69.3700%, Time consumed:8.80s\n",
      "\n",
      "새로운 최고 top-1 정확도: 36.46%, top-5 정확도: 69.37%\n",
      "새로운 최고 top-5 정확도: 69.37%\n",
      "Accuracy improved (29.44% --> 36.46%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▋                                                                                         | 4/100 [03:51<1:32:33, 57.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5], Batch [50/391], Loss: 4.0232\n",
      "Epoch [5], Batch [100/391], Loss: 2.6382\n",
      "Epoch [5], Batch [150/391], Loss: 3.2673\n",
      "Epoch [5], Batch [200/391], Loss: 2.6529\n",
      "Epoch [5], Batch [250/391], Loss: 2.9028\n",
      "Epoch [5], Batch [300/391], Loss: 3.8721\n",
      "Epoch [5], Batch [350/391], Loss: 3.8454\n",
      "Train set: Epoch: 5, Average loss:2.9639, LR: 0.001000 Top-1 Accuracy: 31.0860%, Top-5 Accuracy: 61.6600%, Time consumed:46.91s\n",
      "Test set: Epoch: 5, Average loss:2.3074, Top-1 Accuracy: 39.2400%, Top-5 Accuracy: 71.6600%, Time consumed:8.13s\n",
      "\n",
      "새로운 최고 top-1 정확도: 39.24%, top-5 정확도: 71.66%\n",
      "새로운 최고 top-5 정확도: 71.66%\n",
      "Accuracy improved (36.46% --> 39.24%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▋                                                                                        | 5/100 [04:46<1:30:08, 56.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6], Batch [50/391], Loss: 2.1702\n",
      "Epoch [6], Batch [100/391], Loss: 3.8643\n",
      "Epoch [6], Batch [150/391], Loss: 3.3670\n",
      "Epoch [6], Batch [200/391], Loss: 3.9443\n",
      "Epoch [6], Batch [250/391], Loss: 3.1482\n",
      "Epoch [6], Batch [300/391], Loss: 2.3187\n",
      "Epoch [6], Batch [350/391], Loss: 2.1878\n",
      "Train set: Epoch: 6, Average loss:2.7531, LR: 0.001000 Top-1 Accuracy: 35.6920%, Top-5 Accuracy: 66.4280%, Time consumed:47.17s\n",
      "Test set: Epoch: 6, Average loss:2.1613, Top-1 Accuracy: 42.7200%, Top-5 Accuracy: 74.6400%, Time consumed:8.57s\n",
      "\n",
      "새로운 최고 top-1 정확도: 42.72%, top-5 정확도: 74.64%\n",
      "새로운 최고 top-5 정확도: 74.64%\n",
      "Accuracy improved (39.24% --> 42.72%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████▌                                                                                       | 6/100 [05:42<1:28:42, 56.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7], Batch [50/391], Loss: 3.2313\n",
      "Epoch [7], Batch [100/391], Loss: 1.9435\n",
      "Epoch [7], Batch [150/391], Loss: 2.2717\n",
      "Epoch [7], Batch [200/391], Loss: 2.9779\n",
      "Epoch [7], Batch [250/391], Loss: 3.1345\n",
      "Epoch [7], Batch [300/391], Loss: 1.9898\n",
      "Epoch [7], Batch [350/391], Loss: 2.4247\n",
      "Train set: Epoch: 7, Average loss:2.6691, LR: 0.001000 Top-1 Accuracy: 38.1360%, Top-5 Accuracy: 68.6940%, Time consumed:47.05s\n",
      "Test set: Epoch: 7, Average loss:1.9706, Top-1 Accuracy: 46.8600%, Top-5 Accuracy: 78.0800%, Time consumed:8.60s\n",
      "\n",
      "새로운 최고 top-1 정확도: 46.86%, top-5 정확도: 78.08%\n",
      "새로운 최고 top-5 정확도: 78.08%\n",
      "Accuracy improved (42.72% --> 46.86%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████▌                                                                                      | 7/100 [06:38<1:27:23, 56.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8], Batch [50/391], Loss: 3.5470\n",
      "Epoch [8], Batch [100/391], Loss: 2.4081\n",
      "Epoch [8], Batch [150/391], Loss: 1.8795\n",
      "Epoch [8], Batch [200/391], Loss: 3.5948\n",
      "Epoch [8], Batch [250/391], Loss: 1.7089\n",
      "Epoch [8], Batch [300/391], Loss: 1.9839\n",
      "Epoch [8], Batch [350/391], Loss: 3.2934\n",
      "Train set: Epoch: 8, Average loss:2.5784, LR: 0.001000 Top-1 Accuracy: 40.4180%, Top-5 Accuracy: 70.2880%, Time consumed:49.04s\n",
      "Test set: Epoch: 8, Average loss:1.8831, Top-1 Accuracy: 49.7400%, Top-5 Accuracy: 79.0200%, Time consumed:8.45s\n",
      "\n",
      "새로운 최고 top-1 정확도: 49.74%, top-5 정확도: 79.02%\n",
      "새로운 최고 top-5 정확도: 79.02%\n",
      "Accuracy improved (46.86% --> 49.74%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███████▍                                                                                     | 8/100 [07:36<1:27:07, 56.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9], Batch [50/391], Loss: 2.3275\n",
      "Epoch [9], Batch [100/391], Loss: 1.7426\n",
      "Epoch [9], Batch [150/391], Loss: 2.9666\n",
      "Epoch [9], Batch [200/391], Loss: 2.2134\n",
      "Epoch [9], Batch [250/391], Loss: 3.6103\n",
      "Epoch [9], Batch [300/391], Loss: 1.4393\n",
      "Epoch [9], Batch [350/391], Loss: 1.7291\n",
      "Train set: Epoch: 9, Average loss:2.4127, LR: 0.001000 Top-1 Accuracy: 44.5360%, Top-5 Accuracy: 74.4980%, Time consumed:48.41s\n",
      "Test set: Epoch: 9, Average loss:1.7947, Top-1 Accuracy: 50.9100%, Top-5 Accuracy: 80.7500%, Time consumed:8.82s\n",
      "\n",
      "새로운 최고 top-1 정확도: 50.91%, top-5 정확도: 80.75%\n",
      "새로운 최고 top-5 정확도: 80.75%\n",
      "Accuracy improved (49.74% --> 50.91%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|████████▎                                                                                    | 9/100 [08:33<1:26:29, 57.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10], Batch [50/391], Loss: 3.6991\n",
      "Epoch [10], Batch [100/391], Loss: 2.4053\n",
      "Epoch [10], Batch [150/391], Loss: 3.4520\n",
      "Epoch [10], Batch [200/391], Loss: 3.2107\n",
      "Epoch [10], Batch [250/391], Loss: 1.4389\n",
      "Epoch [10], Batch [300/391], Loss: 3.2555\n",
      "Epoch [10], Batch [350/391], Loss: 3.5637\n",
      "Train set: Epoch: 10, Average loss:2.3764, LR: 0.001000 Top-1 Accuracy: 45.5560%, Top-5 Accuracy: 75.0920%, Time consumed:47.99s\n",
      "Test set: Epoch: 10, Average loss:1.7365, Top-1 Accuracy: 52.8000%, Top-5 Accuracy: 81.4900%, Time consumed:8.23s\n",
      "\n",
      "새로운 최고 top-1 정확도: 52.80%, top-5 정확도: 81.49%\n",
      "새로운 최고 top-5 정확도: 81.49%\n",
      "Accuracy improved (50.91% --> 52.80%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█████████▏                                                                                  | 10/100 [09:30<1:25:17, 56.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11], Batch [50/391], Loss: 1.6090\n",
      "Epoch [11], Batch [100/391], Loss: 3.1071\n",
      "Epoch [11], Batch [150/391], Loss: 1.2897\n",
      "Epoch [11], Batch [200/391], Loss: 2.1612\n",
      "Epoch [11], Batch [250/391], Loss: 1.3988\n",
      "Epoch [11], Batch [300/391], Loss: 1.3946\n",
      "Epoch [11], Batch [350/391], Loss: 2.3743\n",
      "Train set: Epoch: 11, Average loss:2.2911, LR: 0.001000 Top-1 Accuracy: 48.0300%, Top-5 Accuracy: 76.7440%, Time consumed:47.10s\n",
      "Test set: Epoch: 11, Average loss:1.5909, Top-1 Accuracy: 56.8200%, Top-5 Accuracy: 84.6400%, Time consumed:8.24s\n",
      "\n",
      "새로운 최고 top-1 정확도: 56.82%, top-5 정확도: 84.64%\n",
      "새로운 최고 top-5 정확도: 84.64%\n",
      "Accuracy improved (52.80% --> 56.82%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|██████████                                                                                  | 11/100 [10:25<1:23:45, 56.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12], Batch [50/391], Loss: 3.1221\n",
      "Epoch [12], Batch [100/391], Loss: 1.6605\n",
      "Epoch [12], Batch [150/391], Loss: 2.5077\n",
      "Epoch [12], Batch [200/391], Loss: 1.5339\n",
      "Epoch [12], Batch [250/391], Loss: 2.6852\n",
      "Epoch [12], Batch [300/391], Loss: 2.6387\n",
      "Epoch [12], Batch [350/391], Loss: 1.3015\n",
      "Train set: Epoch: 12, Average loss:2.2841, LR: 0.001000 Top-1 Accuracy: 48.5440%, Top-5 Accuracy: 77.1380%, Time consumed:48.31s\n",
      "Test set: Epoch: 12, Average loss:1.5049, Top-1 Accuracy: 58.4700%, Top-5 Accuracy: 85.4200%, Time consumed:8.20s\n",
      "\n",
      "새로운 최고 top-1 정확도: 58.47%, top-5 정확도: 85.42%\n",
      "새로운 최고 top-5 정확도: 85.42%\n",
      "Accuracy improved (56.82% --> 58.47%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|███████████                                                                                 | 12/100 [11:22<1:22:57, 56.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13], Batch [50/391], Loss: 2.4266\n",
      "Epoch [13], Batch [100/391], Loss: 1.4887\n",
      "Epoch [13], Batch [150/391], Loss: 3.0694\n",
      "Epoch [13], Batch [200/391], Loss: 3.4348\n",
      "Epoch [13], Batch [250/391], Loss: 1.9178\n",
      "Epoch [13], Batch [300/391], Loss: 1.2431\n",
      "Epoch [13], Batch [350/391], Loss: 3.3308\n",
      "Train set: Epoch: 13, Average loss:2.1364, LR: 0.001000 Top-1 Accuracy: 51.7900%, Top-5 Accuracy: 79.6020%, Time consumed:47.65s\n",
      "Test set: Epoch: 13, Average loss:1.4841, Top-1 Accuracy: 59.0000%, Top-5 Accuracy: 85.8300%, Time consumed:8.14s\n",
      "\n",
      "새로운 최고 top-1 정확도: 59.00%, top-5 정확도: 85.83%\n",
      "새로운 최고 top-5 정확도: 85.83%\n",
      "Accuracy improved (58.47% --> 59.00%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|███████████▉                                                                                | 13/100 [12:18<1:21:46, 56.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14], Batch [50/391], Loss: 1.3208\n",
      "Epoch [14], Batch [100/391], Loss: 1.1965\n",
      "Epoch [14], Batch [150/391], Loss: 1.4391\n",
      "Epoch [14], Batch [200/391], Loss: 1.4111\n",
      "Epoch [14], Batch [250/391], Loss: 3.5645\n",
      "Epoch [14], Batch [300/391], Loss: 1.3379\n",
      "Epoch [14], Batch [350/391], Loss: 1.4455\n",
      "Train set: Epoch: 14, Average loss:2.1409, LR: 0.001000 Top-1 Accuracy: 51.6220%, Top-5 Accuracy: 79.0920%, Time consumed:47.07s\n",
      "Test set: Epoch: 14, Average loss:1.4148, Top-1 Accuracy: 60.6400%, Top-5 Accuracy: 87.2100%, Time consumed:8.14s\n",
      "\n",
      "새로운 최고 top-1 정확도: 60.64%, top-5 정확도: 87.21%\n",
      "새로운 최고 top-5 정확도: 87.21%\n",
      "Accuracy improved (59.00% --> 60.64%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████▉                                                                               | 14/100 [13:14<1:20:25, 56.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15], Batch [50/391], Loss: 1.3068\n",
      "Epoch [15], Batch [100/391], Loss: 2.3765\n",
      "Epoch [15], Batch [150/391], Loss: 2.4859\n",
      "Epoch [15], Batch [200/391], Loss: 1.2452\n",
      "Epoch [15], Batch [250/391], Loss: 1.1765\n",
      "Epoch [15], Batch [300/391], Loss: 1.2072\n",
      "Epoch [15], Batch [350/391], Loss: 1.2906\n",
      "Train set: Epoch: 15, Average loss:2.0751, LR: 0.001000 Top-1 Accuracy: 53.9180%, Top-5 Accuracy: 80.9080%, Time consumed:46.92s\n",
      "Test set: Epoch: 15, Average loss:1.4227, Top-1 Accuracy: 61.4800%, Top-5 Accuracy: 86.8400%, Time consumed:8.97s\n",
      "\n",
      "새로운 최고 top-1 정확도: 61.48%, top-5 정확도: 86.84%\n",
      "Accuracy improved (60.64% --> 61.48%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████████████▊                                                                              | 15/100 [14:10<1:19:30, 56.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16], Batch [50/391], Loss: 3.1080\n",
      "Epoch [16], Batch [100/391], Loss: 2.5300\n",
      "Epoch [16], Batch [150/391], Loss: 3.1661\n",
      "Epoch [16], Batch [200/391], Loss: 1.1402\n",
      "Epoch [16], Batch [250/391], Loss: 3.2030\n",
      "Epoch [16], Batch [300/391], Loss: 0.9868\n",
      "Epoch [16], Batch [350/391], Loss: 3.1717\n",
      "Train set: Epoch: 16, Average loss:2.0553, LR: 0.001000 Top-1 Accuracy: 54.5100%, Top-5 Accuracy: 81.3400%, Time consumed:46.84s\n",
      "Test set: Epoch: 16, Average loss:1.3759, Top-1 Accuracy: 61.6800%, Top-5 Accuracy: 87.6700%, Time consumed:8.75s\n",
      "\n",
      "새로운 최고 top-1 정확도: 61.68%, top-5 정확도: 87.67%\n",
      "새로운 최고 top-5 정확도: 87.67%\n",
      "Accuracy improved (61.48% --> 61.68%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████████████▋                                                                             | 16/100 [15:06<1:18:27, 56.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17], Batch [50/391], Loss: 1.1841\n",
      "Epoch [17], Batch [100/391], Loss: 1.5252\n",
      "Epoch [17], Batch [150/391], Loss: 3.4424\n",
      "Epoch [17], Batch [200/391], Loss: 1.0972\n",
      "Epoch [17], Batch [250/391], Loss: 1.2809\n",
      "Epoch [17], Batch [300/391], Loss: 3.2169\n",
      "Epoch [17], Batch [350/391], Loss: 3.2705\n",
      "Train set: Epoch: 17, Average loss:2.0512, LR: 0.001000 Top-1 Accuracy: 55.9520%, Top-5 Accuracy: 82.1580%, Time consumed:46.66s\n",
      "Test set: Epoch: 17, Average loss:1.3966, Top-1 Accuracy: 62.0000%, Top-5 Accuracy: 87.1600%, Time consumed:8.22s\n",
      "\n",
      "새로운 최고 top-1 정확도: 62.00%, top-5 정확도: 87.16%\n",
      "Accuracy improved (61.68% --> 62.00%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████████████▋                                                                            | 17/100 [16:01<1:17:09, 55.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18], Batch [50/391], Loss: 1.0515\n",
      "Epoch [18], Batch [100/391], Loss: 1.1575\n",
      "Epoch [18], Batch [150/391], Loss: 3.3065\n",
      "Epoch [18], Batch [200/391], Loss: 1.0967\n",
      "Epoch [18], Batch [250/391], Loss: 1.0738\n",
      "Epoch [18], Batch [300/391], Loss: 1.1034\n",
      "Epoch [18], Batch [350/391], Loss: 1.0569\n",
      "Train set: Epoch: 18, Average loss:1.8971, LR: 0.001000 Top-1 Accuracy: 57.8280%, Top-5 Accuracy: 83.3380%, Time consumed:49.70s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|████████████████▌                                                                           | 18/100 [16:59<1:17:11, 56.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 18, Average loss:1.4018, Top-1 Accuracy: 61.9300%, Top-5 Accuracy: 87.4200%, Time consumed:8.40s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 10\n",
      "Epoch [19], Batch [50/391], Loss: 3.2559\n",
      "Epoch [19], Batch [100/391], Loss: 1.0642\n",
      "Epoch [19], Batch [150/391], Loss: 0.9931\n",
      "Epoch [19], Batch [200/391], Loss: 0.9216\n",
      "Epoch [19], Batch [250/391], Loss: 1.2016\n",
      "Epoch [19], Batch [300/391], Loss: 2.4785\n",
      "Epoch [19], Batch [350/391], Loss: 1.2845\n",
      "Train set: Epoch: 19, Average loss:1.9159, LR: 0.001000 Top-1 Accuracy: 58.0940%, Top-5 Accuracy: 83.4300%, Time consumed:48.23s\n",
      "Test set: Epoch: 19, Average loss:1.3085, Top-1 Accuracy: 63.4200%, Top-5 Accuracy: 88.7700%, Time consumed:8.73s\n",
      "\n",
      "새로운 최고 top-1 정확도: 63.42%, top-5 정확도: 88.77%\n",
      "새로운 최고 top-5 정확도: 88.77%\n",
      "Accuracy improved (62.00% --> 63.42%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█████████████████▍                                                                          | 19/100 [17:56<1:16:31, 56.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20], Batch [50/391], Loss: 0.8653\n",
      "Epoch [20], Batch [100/391], Loss: 1.0326\n",
      "Epoch [20], Batch [150/391], Loss: 1.1314\n",
      "Epoch [20], Batch [200/391], Loss: 2.8707\n",
      "Epoch [20], Batch [250/391], Loss: 1.0017\n",
      "Epoch [20], Batch [300/391], Loss: 3.3087\n",
      "Epoch [20], Batch [350/391], Loss: 3.5739\n",
      "Train set: Epoch: 20, Average loss:1.8926, LR: 0.001000 Top-1 Accuracy: 59.1260%, Top-5 Accuracy: 83.9960%, Time consumed:50.99s\n",
      "Test set: Epoch: 20, Average loss:1.2291, Top-1 Accuracy: 66.1000%, Top-5 Accuracy: 89.5900%, Time consumed:8.14s\n",
      "\n",
      "새로운 최고 top-1 정확도: 66.10%, top-5 정확도: 89.59%\n",
      "새로운 최고 top-5 정확도: 89.59%\n",
      "Accuracy improved (63.42% --> 66.10%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████████████▍                                                                         | 20/100 [18:55<1:16:39, 57.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21], Batch [50/391], Loss: 2.3308\n",
      "Epoch [21], Batch [100/391], Loss: 2.6640\n",
      "Epoch [21], Batch [150/391], Loss: 3.3774\n",
      "Epoch [21], Batch [200/391], Loss: 0.8307\n",
      "Epoch [21], Batch [250/391], Loss: 3.1074\n",
      "Epoch [21], Batch [300/391], Loss: 3.5971\n",
      "Epoch [21], Batch [350/391], Loss: 3.1068\n",
      "Train set: Epoch: 21, Average loss:1.7906, LR: 0.001000 Top-1 Accuracy: 61.1420%, Top-5 Accuracy: 85.0980%, Time consumed:47.54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|███████████████████▎                                                                        | 21/100 [19:52<1:15:11, 57.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 21, Average loss:1.3312, Top-1 Accuracy: 63.7900%, Top-5 Accuracy: 88.2500%, Time consumed:8.67s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 10\n",
      "Epoch [22], Batch [50/391], Loss: 2.0340\n",
      "Epoch [22], Batch [100/391], Loss: 2.5182\n",
      "Epoch [22], Batch [150/391], Loss: 0.9509\n",
      "Epoch [22], Batch [200/391], Loss: 3.3933\n",
      "Epoch [22], Batch [250/391], Loss: 1.0828\n",
      "Epoch [22], Batch [300/391], Loss: 0.8454\n",
      "Epoch [22], Batch [350/391], Loss: 3.0415\n",
      "Train set: Epoch: 22, Average loss:1.7685, LR: 0.001000 Top-1 Accuracy: 61.9860%, Top-5 Accuracy: 86.3100%, Time consumed:47.91s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|████████████████████▏                                                                       | 22/100 [20:48<1:13:58, 56.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 22, Average loss:1.2600, Top-1 Accuracy: 65.4100%, Top-5 Accuracy: 89.0800%, Time consumed:8.52s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 10\n",
      "Epoch [23], Batch [50/391], Loss: 2.6305\n",
      "Epoch [23], Batch [100/391], Loss: 0.9961\n",
      "Epoch [23], Batch [150/391], Loss: 0.7689\n",
      "Epoch [23], Batch [200/391], Loss: 2.9622\n",
      "Epoch [23], Batch [250/391], Loss: 2.7001\n",
      "Epoch [23], Batch [300/391], Loss: 3.3245\n",
      "Epoch [23], Batch [350/391], Loss: 0.8939\n",
      "Train set: Epoch: 23, Average loss:1.7311, LR: 0.001000 Top-1 Accuracy: 62.7740%, Top-5 Accuracy: 86.2860%, Time consumed:49.76s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|█████████████████████▏                                                                      | 23/100 [21:46<1:13:30, 57.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 23, Average loss:1.2581, Top-1 Accuracy: 65.6200%, Top-5 Accuracy: 89.4400%, Time consumed:8.38s\n",
      "\n",
      "EarlyStopping 카운터: 3 / 10\n",
      "Epoch [24], Batch [50/391], Loss: 0.9487\n",
      "Epoch [24], Batch [100/391], Loss: 0.8476\n",
      "Epoch [24], Batch [150/391], Loss: 1.0065\n",
      "Epoch [24], Batch [200/391], Loss: 2.8931\n",
      "Epoch [24], Batch [250/391], Loss: 3.4510\n",
      "Epoch [24], Batch [300/391], Loss: 0.9390\n",
      "Epoch [24], Batch [350/391], Loss: 2.4520\n",
      "Train set: Epoch: 24, Average loss:1.7625, LR: 0.001000 Top-1 Accuracy: 62.5860%, Top-5 Accuracy: 86.0680%, Time consumed:47.36s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██████████████████████                                                                      | 24/100 [22:42<1:12:06, 56.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 24, Average loss:1.2415, Top-1 Accuracy: 65.7200%, Top-5 Accuracy: 89.5100%, Time consumed:8.73s\n",
      "\n",
      "EarlyStopping 카운터: 4 / 10\n",
      "Epoch [25], Batch [50/391], Loss: 0.7916\n",
      "Epoch [25], Batch [100/391], Loss: 0.7981\n",
      "Epoch [25], Batch [150/391], Loss: 0.7166\n",
      "Epoch [25], Batch [200/391], Loss: 2.7348\n",
      "Epoch [25], Batch [250/391], Loss: 3.1178\n",
      "Epoch [25], Batch [300/391], Loss: 0.9767\n",
      "Epoch [25], Batch [350/391], Loss: 0.8347\n",
      "Train set: Epoch: 25, Average loss:1.6558, LR: 0.001000 Top-1 Accuracy: 64.5380%, Top-5 Accuracy: 87.3260%, Time consumed:46.40s\n",
      "Test set: Epoch: 25, Average loss:1.2291, Top-1 Accuracy: 66.7200%, Top-5 Accuracy: 89.7500%, Time consumed:8.10s\n",
      "\n",
      "새로운 최고 top-1 정확도: 66.72%, top-5 정확도: 89.75%\n",
      "새로운 최고 top-5 정확도: 89.75%\n",
      "Accuracy improved (66.10% --> 66.72%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████████                                                                     | 25/100 [23:37<1:10:20, 56.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26], Batch [50/391], Loss: 2.1802\n",
      "Epoch [26], Batch [100/391], Loss: 2.6947\n",
      "Epoch [26], Batch [150/391], Loss: 3.0320\n",
      "Epoch [26], Batch [200/391], Loss: 1.0365\n",
      "Epoch [26], Batch [250/391], Loss: 0.9425\n",
      "Epoch [26], Batch [300/391], Loss: 2.7850\n",
      "Epoch [26], Batch [350/391], Loss: 3.1902\n",
      "Train set: Epoch: 26, Average loss:1.6638, LR: 0.001000 Top-1 Accuracy: 64.3040%, Top-5 Accuracy: 86.8240%, Time consumed:46.70s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|███████████████████████▉                                                                    | 26/100 [24:33<1:09:10, 56.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 26, Average loss:1.2535, Top-1 Accuracy: 66.3600%, Top-5 Accuracy: 89.3100%, Time consumed:8.94s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 10\n",
      "Epoch [27], Batch [50/391], Loss: 2.5213\n",
      "Epoch [27], Batch [100/391], Loss: 0.6417\n",
      "Epoch [27], Batch [150/391], Loss: 0.5673\n",
      "Epoch [27], Batch [200/391], Loss: 3.0791\n",
      "Epoch [27], Batch [250/391], Loss: 0.8801\n",
      "Epoch [27], Batch [300/391], Loss: 1.5077\n",
      "Epoch [27], Batch [350/391], Loss: 3.0023\n",
      "Train set: Epoch: 27, Average loss:1.5690, LR: 0.001000 Top-1 Accuracy: 66.0460%, Top-5 Accuracy: 87.7480%, Time consumed:50.01s\n",
      "Test set: Epoch: 27, Average loss:1.2162, Top-1 Accuracy: 67.0100%, Top-5 Accuracy: 89.8200%, Time consumed:8.35s\n",
      "\n",
      "새로운 최고 top-1 정확도: 67.01%, top-5 정확도: 89.82%\n",
      "새로운 최고 top-5 정확도: 89.82%\n",
      "Accuracy improved (66.72% --> 67.01%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|████████████████████████▊                                                                   | 27/100 [25:31<1:09:09, 56.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28], Batch [50/391], Loss: 0.5690\n",
      "Epoch [28], Batch [100/391], Loss: 0.5570\n",
      "Epoch [28], Batch [150/391], Loss: 0.5484\n",
      "Epoch [28], Batch [200/391], Loss: 0.7296\n",
      "Epoch [28], Batch [250/391], Loss: 2.1435\n",
      "Epoch [28], Batch [300/391], Loss: 1.5985\n",
      "Epoch [28], Batch [350/391], Loss: 1.7675\n",
      "Train set: Epoch: 28, Average loss:1.5664, LR: 0.001000 Top-1 Accuracy: 67.8840%, Top-5 Accuracy: 89.2060%, Time consumed:46.40s\n",
      "Test set: Epoch: 28, Average loss:1.1710, Top-1 Accuracy: 68.3500%, Top-5 Accuracy: 90.6500%, Time consumed:8.09s\n",
      "\n",
      "새로운 최고 top-1 정확도: 68.35%, top-5 정확도: 90.65%\n",
      "새로운 최고 top-5 정확도: 90.65%\n",
      "Accuracy improved (67.01% --> 68.35%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|█████████████████████████▊                                                                  | 28/100 [26:26<1:07:26, 56.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29], Batch [50/391], Loss: 0.5386\n",
      "Epoch [29], Batch [100/391], Loss: 0.7075\n",
      "Epoch [29], Batch [150/391], Loss: 0.5045\n",
      "Epoch [29], Batch [200/391], Loss: 3.2161\n",
      "Epoch [29], Batch [250/391], Loss: 3.1004\n",
      "Epoch [29], Batch [300/391], Loss: 0.9667\n",
      "Epoch [29], Batch [350/391], Loss: 0.7133\n",
      "Train set: Epoch: 29, Average loss:1.5454, LR: 0.001000 Top-1 Accuracy: 68.0260%, Top-5 Accuracy: 89.2420%, Time consumed:46.85s\n",
      "Test set: Epoch: 29, Average loss:1.1470, Top-1 Accuracy: 68.7000%, Top-5 Accuracy: 90.5200%, Time consumed:8.84s\n",
      "\n",
      "새로운 최고 top-1 정확도: 68.70%, top-5 정확도: 90.52%\n",
      "Accuracy improved (68.35% --> 68.70%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██████████████████████████▋                                                                 | 29/100 [27:22<1:06:25, 56.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30], Batch [50/391], Loss: 0.6853\n",
      "Epoch [30], Batch [100/391], Loss: 0.6305\n",
      "Epoch [30], Batch [150/391], Loss: 0.7102\n",
      "Epoch [30], Batch [200/391], Loss: 0.6723\n",
      "Epoch [30], Batch [250/391], Loss: 0.5345\n",
      "Epoch [30], Batch [300/391], Loss: 0.6850\n",
      "Epoch [30], Batch [350/391], Loss: 0.5941\n",
      "Train set: Epoch: 30, Average loss:1.6012, LR: 0.001000 Top-1 Accuracy: 66.6540%, Top-5 Accuracy: 88.0280%, Time consumed:50.88s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████████████████████▌                                                                | 30/100 [28:21<1:06:31, 57.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 30, Average loss:1.1917, Top-1 Accuracy: 68.2900%, Top-5 Accuracy: 90.3200%, Time consumed:8.21s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 10\n",
      "Epoch [31], Batch [50/391], Loss: 0.4548\n",
      "Epoch [31], Batch [100/391], Loss: 2.1635\n",
      "Epoch [31], Batch [150/391], Loss: 1.9076\n",
      "Epoch [31], Batch [200/391], Loss: 1.5495\n",
      "Epoch [31], Batch [250/391], Loss: 0.4859\n",
      "Epoch [31], Batch [300/391], Loss: 0.5899\n",
      "Epoch [31], Batch [350/391], Loss: 0.8252\n",
      "Train set: Epoch: 31, Average loss:1.5037, LR: 0.001000 Top-1 Accuracy: 68.4680%, Top-5 Accuracy: 88.9360%, Time consumed:46.48s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████████████████████▌                                                                | 30/100 [29:16<1:08:17, 58.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 31, Average loss:1.1885, Top-1 Accuracy: 67.4200%, Top-5 Accuracy: 90.0900%, Time consumed:8.15s\n",
      "\n",
      "최대 에폭 (30)에 도달했습니다. 훈련을 중단합니다.\n",
      "에폭 31에서 학습 조기 종료. 최고 성능 에폭: 29\n",
      "테스트 정확도 기준 최고 모델 로드 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 100, Average loss:1.1470, Top-1 Accuracy: 68.7000%, Top-5 Accuracy: 90.5200%, Time consumed:8.23s\n",
      "\n",
      "완료! 최고 테스트 top-1 정확도: 68.70%, 최고 테스트 top-5 정확도: 90.65%\n",
      "최종 테스트 top-1 정확도: 68.70%, 최종 테스트 top-5 정확도: 90.52%\n",
      "전체 학습 시간: 1764.57 초\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_accuracy_top1</td><td>▁▂▃▄▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇█▇██████████</td></tr><tr><td>test_accuracy_top5</td><td>▁▃▄▅▅▆▆▆▇▇▇▇▇█▇████████████████</td></tr><tr><td>test_loss</td><td>█▇▆▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>total_training_time</td><td>▁</td></tr><tr><td>train_accuracy_top1</td><td>▁▂▃▃▄▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇███████</td></tr><tr><td>train_accuracy_top5</td><td>▁▂▄▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇███████████</td></tr><tr><td>train_loss</td><td>█▇▆▆▅▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>29</td></tr><tr><td>best_test_accuracy_top1</td><td>68.7</td></tr><tr><td>best_test_accuracy_top5</td><td>90.65</td></tr><tr><td>early_stopped</td><td>True</td></tr><tr><td>early_stopped_epoch</td><td>31</td></tr><tr><td>epoch</td><td>31</td></tr><tr><td>final_test_accuracy_top1</td><td>68.7</td></tr><tr><td>final_test_accuracy_top5</td><td>90.52</td></tr><tr><td>learning_rate</td><td>0.001</td></tr><tr><td>test_accuracy_top1</td><td>67.42</td></tr><tr><td>test_accuracy_top5</td><td>90.09</td></tr><tr><td>test_loss</td><td>1.18853</td></tr><tr><td>total_training_time</td><td>1764.57257</td></tr><tr><td>train_accuracy_top1</td><td>68.468</td></tr><tr><td>train_accuracy_top5</td><td>88.936</td></tr><tr><td>train_loss</td><td>1.50374</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">resnet18_cutmix,flip,crop,affine_standard</strong> at: <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/0h0domsu' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/0h0domsu</a><br> View project at: <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250415_131718-0h0domsu/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.v2 as transforms_v2  # CutMix를 위한 v2 transforms 추가\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "from tools.tool import AccuracyEarlyStopping  # 수정된 AccuracyEarlyStopping 클래스 임포트\n",
    "from models.resnet import resnet18, resnet34, resnet50\n",
    "\n",
    "wandb.login(key=\"ef091b9abcea3186341ddf8995d62bde62d7469e\")\n",
    "wandb.init(project=\"PBL-2\", name=\"resnet18_cutmix,flip,crop,affine,mixup_standard\")  # RandomAffine 추가 명시\n",
    "\n",
    "# WandB 설정\n",
    "config = {\n",
    "    \"model\": \"resnet18\",\n",
    "    \"batch_size\": 228,\n",
    "    \"num_epochs\": 100,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"seed\": 2025,\n",
    "    \"deterministic\": False,\n",
    "    \"patience\": 10,  # early stopping patience\n",
    "    \"max_epochs_wait\": 30,  # 최대 30 에폭까지만 기다림\n",
    "    \"cutmix_alpha\": 1.0,  # CutMix 알파 파라미터 추가\n",
    "    \"cutmix_prob\": 0.5,   # CutMix 적용 확률 추가\n",
    "    \"crop_padding\": 4,    # RandomCrop 패딩 크기\n",
    "    \"crop_size\": 32,      # RandomCrop 크기 (CIFAR-100 이미지 크기는 32x32)\n",
    "    \"affine_degrees\": 10, # RandomAffine 회전 각도 범위\n",
    "    \"affine_translate\": (0.1, 0.1),  # RandomAffine 이동 범위 (가로, 세로)\n",
    "    \"affine_scale\": (0.9, 1.1),      # RandomAffine 확대/축소 범위\n",
    "    \"affine_shear\": 10                # RandomAffine 전단 범위\n",
    "}\n",
    "wandb.config.update(config)\n",
    "\n",
    "# CIFAR-100 데이터셋 로드 - 기본 train/test 분할 사용\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(config[\"crop_size\"], padding=config[\"crop_padding\"]),  # 패딩 후 랜덤 크롭\n",
    "    transforms.RandomHorizontalFlip(),  # 수평 뒤집기\n",
    "    transforms.RandomAffine(\n",
    "        degrees=config[\"affine_degrees\"],           # 회전 각도 범위\n",
    "        translate=config[\"affine_translate\"],       # 이동 범위 (가로, 세로)\n",
    "        scale=config[\"affine_scale\"],               # 확대/축소 범위\n",
    "        shear=config[\"affine_shear\"]                # 전단 범위\n",
    "    ),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR100(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR100(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "# DataLoader 생성\n",
    "trainloader = DataLoader(trainset, batch_size=config[\"batch_size\"], shuffle=True, num_workers=16)\n",
    "testloader = DataLoader(testset, batch_size=config[\"batch_size\"], shuffle=False, num_workers=16)\n",
    "\n",
    "print(f\"Train set size: {len(trainset)}\")\n",
    "print(f\"Test set size: {len(testset)}\")\n",
    "\n",
    "# CutMix 변환 정의\n",
    "cutmix = transforms_v2.CutMix(alpha=config[\"cutmix_alpha\"], num_classes=100)  # CIFAR-100은 100개 클래스\n",
    "\n",
    "def train(model, trainloader, criterion, optimizer, device, epoch):\n",
    "    \"\"\"\n",
    "    학습 함수 (CutMix 적용)\n",
    "    \"\"\"\n",
    "    model.train()   # 모델을 학습 모드로 설정\n",
    "    start_time = time.time()  # 시간 측정 시작\n",
    "    running_loss = 0.0\n",
    "    correct_top1 = 0\n",
    "    correct_top5 = 0\n",
    "    total = 0\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(trainloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # CutMix 확률적 적용\n",
    "        if random.random() < config[\"cutmix_prob\"]:\n",
    "            inputs, labels = cutmix(inputs, labels)\n",
    "            # 이 경우 labels은 원-핫 인코딩 형태로 변환됨\n",
    "            use_cutmix = True\n",
    "        else:\n",
    "            use_cutmix = False\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # CutMix 적용 여부에 따라 손실 함수 선택\n",
    "        if use_cutmix:\n",
    "            # CutMix가 적용된 경우 (원-핫 인코딩된 레이블)\n",
    "            loss = torch.nn.functional.cross_entropy(outputs, labels)\n",
    "        else:\n",
    "            # 일반적인 경우 (정수 인덱스 레이블)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # 정확도 계산 - CutMix 적용 여부에 따라 다르게 처리\n",
    "        if use_cutmix:\n",
    "            # 원-핫 인코딩된 레이블에서 argmax를 사용해 가장 큰 값의 인덱스 추출\n",
    "            _, label_idx = labels.max(1)\n",
    "        else:\n",
    "            # 정수 인덱스 레이블 그대로 사용\n",
    "            label_idx = labels\n",
    "            \n",
    "        # top-1 정확도 계산\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += inputs.size(0)\n",
    "        correct_top1 += predicted.eq(label_idx).sum().item()\n",
    "        \n",
    "        # top-5 정확도 계산\n",
    "        _, top5_idx = outputs.topk(5, 1, largest=True, sorted=True)\n",
    "        correct_top5 += sum([1 for i in range(len(label_idx)) if label_idx[i] in top5_idx[i]])\n",
    "        \n",
    "        if (i + 1) % 50 == 0:  # 50 배치마다 출력\n",
    "            print(f'Epoch [{epoch+1}], Batch [{i+1}/{len(trainloader)}], Loss: {loss.item():.4f}')\n",
    "    \n",
    "    epoch_loss = running_loss / len(trainloader)\n",
    "    accuracy_top1 = 100.0 * correct_top1 / total\n",
    "    accuracy_top5 = 100.0 * correct_top5 / total\n",
    "    \n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    # 학습 세트에 대한 성능 출력\n",
    "    print(f'Train set: Epoch: {epoch+1}, Average loss:{epoch_loss:.4f}, LR: {optimizer.param_groups[0][\"lr\"]:.6f} '\n",
    "          f'Top-1 Accuracy: {accuracy_top1:.4f}%, Top-5 Accuracy: {accuracy_top5:.4f}%, Time consumed:{train_time:.2f}s')\n",
    "    \n",
    "    return epoch_loss, accuracy_top1, accuracy_top5\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device, epoch, phase=\"test\"):\n",
    "    \"\"\"\n",
    "    평가 함수\n",
    "    \"\"\"\n",
    "    model.eval()  # 모델을 평가 모드로 설정\n",
    "    start_time = time.time()  # 시간 측정 시작\n",
    "    \n",
    "    eval_loss = 0.0\n",
    "    correct_top1 = 0\n",
    "    correct_top5 = 0\n",
    "    total = 0\n",
    "    \n",
    "    # 그래디언트 계산 비활성화\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # 순전파\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # 손실 계산\n",
    "            loss = criterion(outputs, labels)\n",
    "            eval_loss += loss.item()\n",
    "            \n",
    "            # top-1 정확도 계산\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct_top1 += (predicted == labels).sum().item()\n",
    "            \n",
    "            # top-5 정확도 계산\n",
    "            _, top5_idx = outputs.topk(5, 1, largest=True, sorted=True)\n",
    "            correct_top5 += top5_idx.eq(labels.view(-1, 1).expand_as(top5_idx)).sum().item()\n",
    "    \n",
    "    # 평균 손실 및 정확도 계산\n",
    "    eval_loss = eval_loss / len(dataloader)\n",
    "    accuracy_top1 = 100.0 * correct_top1 / total\n",
    "    accuracy_top5 = 100.0 * correct_top5 / total\n",
    "    \n",
    "    # 평가 시간 계산\n",
    "    eval_time = time.time() - start_time\n",
    "    \n",
    "    # 테스트 세트에 대한 성능 출력\n",
    "    print(f'{phase.capitalize()} set: Epoch: {epoch+1}, Average loss:{eval_loss:.4f}, '\n",
    "          f'Top-1 Accuracy: {accuracy_top1:.4f}%, Top-5 Accuracy: {accuracy_top5:.4f}%, Time consumed:{eval_time:.2f}s')\n",
    "    print()\n",
    "    \n",
    "    return eval_loss, accuracy_top1, accuracy_top5\n",
    "\n",
    "# 메인 학습 루프\n",
    "def main_training_loop(model, trainloader, testloader, criterion, optimizer, device, num_epochs, patience, max_epochs_wait):\n",
    "    \"\"\"\n",
    "    메인 학습 루프 (accuracy 기준 early stopping)\n",
    "    \"\"\"\n",
    "    # 정확도 기반 얼리 스토핑 사용\n",
    "    early_stopping = AccuracyEarlyStopping(patience=patience, verbose=True, path='checkpoint.pt', max_epochs=max_epochs_wait)\n",
    "    \n",
    "    best_test_acc_top1 = 0.0\n",
    "    best_test_acc_top5 = 0.0\n",
    "    \n",
    "    # 테스트 정확도 기록을 위한 리스트\n",
    "    test_acc_top1_history = []\n",
    "    \n",
    "    # tqdm을 사용한 진행 상황 표시\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        # 학습\n",
    "        train_loss, train_acc_top1, train_acc_top5 = train(model, trainloader, criterion, optimizer, device, epoch)\n",
    "        \n",
    "        # 테스트 데이터로 평가\n",
    "        test_loss, test_acc_top1, test_acc_top5 = evaluate(model, testloader, criterion, device, epoch, phase=\"test\")\n",
    "        \n",
    "        # 테스트 정확도 기록\n",
    "        test_acc_top1_history.append(test_acc_top1)\n",
    "        \n",
    "        # WandB에 로깅\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_accuracy_top1\": train_acc_top1,\n",
    "            \"train_accuracy_top5\": train_acc_top5,\n",
    "            \"test_loss\": test_loss,\n",
    "            \"test_accuracy_top1\": test_acc_top1,\n",
    "            \"test_accuracy_top5\": test_acc_top5\n",
    "        })\n",
    "            \n",
    "        # 최고 정확도 모델 저장 (top-1 기준)\n",
    "        if test_acc_top1 > best_test_acc_top1:\n",
    "            best_test_acc_top1 = test_acc_top1\n",
    "            best_test_acc_top5_at_best_top1 = test_acc_top5\n",
    "            print(f'새로운 최고 top-1 정확도: {best_test_acc_top1:.2f}%, top-5 정확도: {best_test_acc_top5_at_best_top1:.2f}%')\n",
    "            # 모델 저장\n",
    "            model_path = f'best_model_{wandb.run.name}.pth'\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            \n",
    "            # WandB에 모델 아티팩트 저장\n",
    "            wandb.save(model_path)\n",
    "        \n",
    "        # top-5 accuracy 기록 업데이트\n",
    "        if test_acc_top5 > best_test_acc_top5:\n",
    "            best_test_acc_top5 = test_acc_top5\n",
    "            print(f'새로운 최고 top-5 정확도: {best_test_acc_top5:.2f}%')\n",
    "\n",
    "        # Early stopping 체크 (test_acc_top1 기준)\n",
    "        early_stopping(test_acc_top1, model, epoch)\n",
    "        if early_stopping.early_stop:\n",
    "            print(f\"에폭 {epoch+1}에서 학습 조기 종료. 최고 성능 에폭: {early_stopping.best_epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    # 훈련 완료 후 최고 모델 로드\n",
    "    print(\"테스트 정확도 기준 최고 모델 로드 중...\")\n",
    "    model_path = f'best_model_{wandb.run.name}.pth'\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    # 최종 테스트 세트 평가\n",
    "    final_test_loss, final_test_acc_top1, final_test_acc_top5 = evaluate(model, testloader, criterion, device, num_epochs-1, phase=\"test\")\n",
    "    \n",
    "    print(f'완료! 최고 테스트 top-1 정확도: {best_test_acc_top1:.2f}%, 최고 테스트 top-5 정확도: {best_test_acc_top5:.2f}%')\n",
    "    print(f'최종 테스트 top-1 정확도: {final_test_acc_top1:.2f}%, 최종 테스트 top-5 정확도: {final_test_acc_top5:.2f}%')\n",
    "    \n",
    "    # WandB에 최종 결과 기록\n",
    "    wandb.run.summary[\"best_test_accuracy_top1\"] = best_test_acc_top1\n",
    "    wandb.run.summary[\"best_test_accuracy_top5\"] = best_test_acc_top5\n",
    "    wandb.run.summary[\"final_test_accuracy_top1\"] = final_test_acc_top1\n",
    "    wandb.run.summary[\"final_test_accuracy_top5\"] = final_test_acc_top5\n",
    "\n",
    "    # Early stopping 정보 저장\n",
    "    if early_stopping.early_stop:\n",
    "        wandb.run.summary[\"early_stopped\"] = True\n",
    "        wandb.run.summary[\"early_stopped_epoch\"] = epoch+1\n",
    "        wandb.run.summary[\"best_epoch\"] = early_stopping.best_epoch+1\n",
    "    else:\n",
    "        wandb.run.summary[\"early_stopped\"] = False\n",
    "\n",
    "\n",
    "# 디바이스 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 모델 초기화\n",
    "model = resnet18().to(device)  \n",
    "criterion = nn.CrossEntropyLoss()  # 기본 CrossEntropyLoss 사용 (라벨 스무딩 없음)\n",
    "optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"])  # 옵티마이저 정의\n",
    "\n",
    "# WandB에 모델 구조 기록\n",
    "wandb.watch(model, log=\"all\")\n",
    "\n",
    "# GPU 가속\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"{torch.cuda.device_count()}개의 GPU를 사용합니다.\")\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "# 훈련 시작 시간 기록\n",
    "start_time = time.time()\n",
    "\n",
    "# 메인 학습 루프 호출\n",
    "main_training_loop(\n",
    "    model=model,\n",
    "    trainloader=trainloader,\n",
    "    testloader=testloader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    num_epochs=config[\"num_epochs\"],\n",
    "    patience=config[\"patience\"],\n",
    "    max_epochs_wait=config[\"max_epochs_wait\"]\n",
    ")\n",
    "\n",
    "# 훈련 종료 시간 기록 및 출력\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "wandb.log({\"total_training_time\": total_time})\n",
    "\n",
    "print(f\"전체 학습 시간: {total_time:.2f} 초\")\n",
    "\n",
    "# WandB 실행 종료\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57b9218-aa24-4297-bb92-473c215e6767",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
