{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516f9d5f-6361-4b03-98ee-e1ba4de86b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/guswls/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msokjh1310\u001b[0m (\u001b[33msokjh1310-hanyang-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/guswls/EEN4015_Intro2ML/pbl-2/wandb/run-20250425_023018-4ogzfe0o</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/4ogzfe0o' target=\"_blank\">wideresnet_28_20_cfc,SGD</a></strong> to <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/4ogzfe0o' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/4ogzfe0o</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Train set size: 50000\n",
      "Test set size: 10000\n",
      "Using device: cuda\n",
      "GPU 0: NVIDIA RTX A5000\n",
      "Memory Allocated: 0.00 GB\n",
      "Memory Reserved: 0.00 GB\n",
      "Max Memory Allocated: 0.00 GB\n",
      "GPU 1: NVIDIA RTX A5000\n",
      "Memory Allocated: 0.00 GB\n",
      "Memory Reserved: 0.00 GB\n",
      "Max Memory Allocated: 0.00 GB\n",
      "| Wide-Resnet 28x20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wide-ResNet-28-20 initialized with 145,950,980 parameters\n",
      "2개의 GPU를 사용합니다.\n",
      "Model: WideResNet-28-20\n",
      "Batch size: 128\n",
      "Learning rate: 0.01\n",
      "Optimizer: SGD with SAM\n",
      "Dropout rate: 0.3\n",
      "처음부터 학습을 시작합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                       | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Batch [50/391], Loss: 4.6345, LR: 0.000256\n",
      "Epoch [1], Batch [100/391], Loss: 4.5875, LR: 0.000512\n",
      "Epoch [1], Batch [150/391], Loss: 4.5854, LR: 0.000767\n",
      "Epoch [1], Batch [200/391], Loss: 4.5436, LR: 0.001023\n",
      "Epoch [1], Batch [250/391], Loss: 4.4796, LR: 0.001279\n",
      "Epoch [1], Batch [300/391], Loss: 4.4660, LR: 0.001535\n",
      "Epoch [1], Batch [350/391], Loss: 4.4533, LR: 0.001790\n",
      "Train set: Epoch: 1, Average loss:4.5475, LR: 0.002000 Top-1 Accuracy: 2.4880%, Top-5 Accuracy: 9.5760%, Time consumed:180.38s\n",
      "Test set: Epoch: 1, Average loss:4.3745, Top-1 Accuracy: 4.3900%, Top-5 Accuracy: 15.5700%, Time consumed:13.40s\n",
      "\n",
      "새로운 최고 top-1 정확도: 4.39%, top-5 정확도: 15.57%\n",
      "새로운 최고 top-5 정확도: 15.57%\n",
      "Accuracy improved (-inf% --> 4.39%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                                          | 1/300 [03:16<16:19:44, 196.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], Batch [50/391], Loss: 4.2882, LR: 0.002256\n",
      "Epoch [2], Batch [100/391], Loss: 4.2332, LR: 0.002512\n",
      "Epoch [2], Batch [150/391], Loss: 4.3352, LR: 0.002767\n",
      "Epoch [2], Batch [200/391], Loss: 4.3751, LR: 0.003023\n",
      "Epoch [2], Batch [250/391], Loss: 4.4109, LR: 0.003279\n",
      "Epoch [2], Batch [300/391], Loss: 4.0763, LR: 0.003535\n",
      "Epoch [2], Batch [350/391], Loss: 4.1307, LR: 0.003790\n",
      "Train set: Epoch: 2, Average loss:4.2912, LR: 0.004000 Top-1 Accuracy: 5.6680%, Top-5 Accuracy: 19.7240%, Time consumed:179.57s\n",
      "Test set: Epoch: 2, Average loss:4.1648, Top-1 Accuracy: 6.6700%, Top-5 Accuracy: 22.5500%, Time consumed:13.62s\n",
      "\n",
      "새로운 최고 top-1 정확도: 6.67%, top-5 정확도: 22.55%\n",
      "새로운 최고 top-5 정확도: 22.55%\n",
      "Accuracy improved (4.39% --> 6.67%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▌                                                                                          | 2/300 [06:33<16:16:20, 196.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3], Batch [50/391], Loss: 4.2782, LR: 0.004256\n",
      "Epoch [3], Batch [100/391], Loss: 4.0105, LR: 0.004512\n",
      "Epoch [3], Batch [150/391], Loss: 4.2859, LR: 0.004767\n",
      "Epoch [3], Batch [200/391], Loss: 3.8302, LR: 0.005023\n",
      "Epoch [3], Batch [250/391], Loss: 4.2935, LR: 0.005279\n",
      "Epoch [3], Batch [300/391], Loss: 3.9789, LR: 0.005535\n",
      "Epoch [3], Batch [350/391], Loss: 3.7120, LR: 0.005790\n",
      "Train set: Epoch: 3, Average loss:4.0810, LR: 0.006000 Top-1 Accuracy: 8.6660%, Top-5 Accuracy: 26.5800%, Time consumed:180.08s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▉                                                                                          | 3/300 [09:46<16:06:31, 195.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 3, Average loss:4.8951, Top-1 Accuracy: 6.2200%, Top-5 Accuracy: 20.9400%, Time consumed:13.59s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [4], Batch [50/391], Loss: 3.7105, LR: 0.006256\n",
      "Epoch [4], Batch [100/391], Loss: 4.1701, LR: 0.006512\n",
      "Epoch [4], Batch [150/391], Loss: 4.1530, LR: 0.006767\n",
      "Epoch [4], Batch [200/391], Loss: 3.8505, LR: 0.007023\n",
      "Epoch [4], Batch [250/391], Loss: 4.0149, LR: 0.007279\n",
      "Epoch [4], Batch [300/391], Loss: 3.6403, LR: 0.007535\n",
      "Epoch [4], Batch [350/391], Loss: 4.1842, LR: 0.007790\n",
      "Train set: Epoch: 4, Average loss:3.8894, LR: 0.008000 Top-1 Accuracy: 11.6140%, Top-5 Accuracy: 33.1380%, Time consumed:179.86s\n",
      "Test set: Epoch: 4, Average loss:4.1828, Top-1 Accuracy: 10.6300%, Top-5 Accuracy: 31.8800%, Time consumed:13.58s\n",
      "\n",
      "새로운 최고 top-1 정확도: 10.63%, top-5 정확도: 31.88%\n",
      "새로운 최고 top-5 정확도: 31.88%\n",
      "Accuracy improved (6.67% --> 10.63%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▏                                                                                         | 4/300 [13:03<16:05:43, 195.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5], Batch [50/391], Loss: 4.0578, LR: 0.008256\n",
      "Epoch [5], Batch [100/391], Loss: 4.1886, LR: 0.008512\n",
      "Epoch [5], Batch [150/391], Loss: 3.4735, LR: 0.008767\n",
      "Epoch [5], Batch [200/391], Loss: 3.6464, LR: 0.009023\n",
      "Epoch [5], Batch [250/391], Loss: 4.1652, LR: 0.009279\n",
      "Epoch [5], Batch [300/391], Loss: 3.3422, LR: 0.009535\n",
      "Epoch [5], Batch [350/391], Loss: 4.1815, LR: 0.009790\n",
      "Train set: Epoch: 5, Average loss:3.7139, LR: 0.010000 Top-1 Accuracy: 14.6320%, Top-5 Accuracy: 39.2120%, Time consumed:179.92s\n",
      "Test set: Epoch: 5, Average loss:4.2579, Top-1 Accuracy: 13.3600%, Top-5 Accuracy: 36.9300%, Time consumed:13.80s\n",
      "\n",
      "새로운 최고 top-1 정확도: 13.36%, top-5 정확도: 36.93%\n",
      "새로운 최고 top-5 정확도: 36.93%\n",
      "Accuracy improved (10.63% --> 13.36%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▌                                                                                         | 5/300 [16:20<16:04:19, 196.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6], Batch [50/391], Loss: 3.4250, LR: 0.010000\n",
      "Epoch [6], Batch [100/391], Loss: 3.2483, LR: 0.010000\n",
      "Epoch [6], Batch [150/391], Loss: 4.0539, LR: 0.010000\n",
      "Epoch [6], Batch [200/391], Loss: 3.1103, LR: 0.010000\n",
      "Epoch [6], Batch [250/391], Loss: 3.9076, LR: 0.010000\n",
      "Epoch [6], Batch [300/391], Loss: 3.8854, LR: 0.010000\n",
      "Epoch [6], Batch [350/391], Loss: 3.6127, LR: 0.010000\n",
      "Train set: Epoch: 6, Average loss:3.5043, LR: 0.010000 Top-1 Accuracy: 19.0060%, Top-5 Accuracy: 45.5820%, Time consumed:179.69s\n",
      "Test set: Epoch: 6, Average loss:4.7993, Top-1 Accuracy: 13.4400%, Top-5 Accuracy: 34.8200%, Time consumed:13.65s\n",
      "\n",
      "새로운 최고 top-1 정확도: 13.44%, top-5 정확도: 34.82%\n",
      "Accuracy improved (13.36% --> 13.44%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▊                                                                                         | 6/300 [19:36<16:01:47, 196.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7], Batch [50/391], Loss: 3.7770, LR: 0.010000\n",
      "Epoch [7], Batch [100/391], Loss: 3.0187, LR: 0.010000\n",
      "Epoch [7], Batch [150/391], Loss: 3.2457, LR: 0.010000\n",
      "Epoch [7], Batch [200/391], Loss: 2.7993, LR: 0.010000\n",
      "Epoch [7], Batch [250/391], Loss: 3.2389, LR: 0.010000\n",
      "Epoch [7], Batch [300/391], Loss: 3.8656, LR: 0.010000\n",
      "Epoch [7], Batch [350/391], Loss: 2.9015, LR: 0.010000\n",
      "Train set: Epoch: 7, Average loss:3.3049, LR: 0.010000 Top-1 Accuracy: 23.0480%, Top-5 Accuracy: 51.7480%, Time consumed:179.82s\n",
      "Test set: Epoch: 7, Average loss:3.3580, Top-1 Accuracy: 23.6900%, Top-5 Accuracy: 53.9300%, Time consumed:13.89s\n",
      "\n",
      "새로운 최고 top-1 정확도: 23.69%, top-5 정확도: 53.93%\n",
      "새로운 최고 top-5 정확도: 53.93%\n",
      "Accuracy improved (13.44% --> 23.69%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██                                                                                         | 7/300 [22:53<15:59:06, 196.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8], Batch [50/391], Loss: 3.4060, LR: 0.010000\n",
      "Epoch [8], Batch [100/391], Loss: 2.7283, LR: 0.010000\n",
      "Epoch [8], Batch [150/391], Loss: 2.7725, LR: 0.010000\n",
      "Epoch [8], Batch [200/391], Loss: 2.6642, LR: 0.010000\n",
      "Epoch [8], Batch [250/391], Loss: 2.6543, LR: 0.010000\n",
      "Epoch [8], Batch [300/391], Loss: 3.6245, LR: 0.010000\n",
      "Epoch [8], Batch [350/391], Loss: 4.0186, LR: 0.010000\n",
      "Train set: Epoch: 8, Average loss:3.1848, LR: 0.010000 Top-1 Accuracy: 25.1660%, Top-5 Accuracy: 54.6880%, Time consumed:179.84s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▍                                                                                        | 8/300 [26:06<15:51:19, 195.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 8, Average loss:3.4336, Top-1 Accuracy: 23.5000%, Top-5 Accuracy: 54.4000%, Time consumed:13.65s\n",
      "\n",
      "새로운 최고 top-5 정확도: 54.40%\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [9], Batch [50/391], Loss: 3.6259, LR: 0.010000\n",
      "Epoch [9], Batch [100/391], Loss: 2.4071, LR: 0.010000\n",
      "Epoch [9], Batch [150/391], Loss: 2.5007, LR: 0.010000\n",
      "Epoch [9], Batch [200/391], Loss: 3.5336, LR: 0.010000\n",
      "Epoch [9], Batch [250/391], Loss: 2.6906, LR: 0.010000\n",
      "Epoch [9], Batch [300/391], Loss: 3.7585, LR: 0.010000\n",
      "Epoch [9], Batch [350/391], Loss: 3.6987, LR: 0.010000\n",
      "Train set: Epoch: 9, Average loss:2.9660, LR: 0.010000 Top-1 Accuracy: 30.2380%, Top-5 Accuracy: 61.3100%, Time consumed:179.88s\n",
      "Test set: Epoch: 9, Average loss:3.4032, Top-1 Accuracy: 24.7000%, Top-5 Accuracy: 56.0200%, Time consumed:13.90s\n",
      "\n",
      "새로운 최고 top-1 정확도: 24.70%, top-5 정확도: 56.02%\n",
      "새로운 최고 top-5 정확도: 56.02%\n",
      "Accuracy improved (23.69% --> 24.70%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▋                                                                                        | 9/300 [29:23<15:50:13, 195.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10], Batch [50/391], Loss: 3.7679, LR: 0.010000\n",
      "Epoch [10], Batch [100/391], Loss: 3.4564, LR: 0.010000\n",
      "Epoch [10], Batch [150/391], Loss: 3.8198, LR: 0.010000\n",
      "Epoch [10], Batch [200/391], Loss: 2.3806, LR: 0.010000\n",
      "Epoch [10], Batch [250/391], Loss: 2.4883, LR: 0.010000\n",
      "Epoch [10], Batch [300/391], Loss: 2.5313, LR: 0.010000\n",
      "Epoch [10], Batch [350/391], Loss: 3.1364, LR: 0.010000\n",
      "Train set: Epoch: 10, Average loss:2.8498, LR: 0.010000 Top-1 Accuracy: 32.3820%, Top-5 Accuracy: 63.5340%, Time consumed:179.32s\n",
      "Test set: Epoch: 10, Average loss:3.1426, Top-1 Accuracy: 27.8000%, Top-5 Accuracy: 58.8100%, Time consumed:13.60s\n",
      "\n",
      "새로운 최고 top-1 정확도: 27.80%, top-5 정확도: 58.81%\n",
      "새로운 최고 top-5 정확도: 58.81%\n",
      "체크포인트가 checkpoint.pt에 저장되었습니다.\n",
      "Accuracy improved (24.70% --> 27.80%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|███                                                                                       | 10/300 [32:42<15:51:49, 196.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11], Batch [50/391], Loss: 2.1617, LR: 0.010000\n",
      "Epoch [11], Batch [100/391], Loss: 2.3398, LR: 0.010000\n",
      "Epoch [11], Batch [150/391], Loss: 2.6308, LR: 0.010000\n",
      "Epoch [11], Batch [200/391], Loss: 3.6580, LR: 0.010000\n",
      "Epoch [11], Batch [250/391], Loss: 2.4217, LR: 0.010000\n",
      "Epoch [11], Batch [300/391], Loss: 2.3550, LR: 0.010000\n",
      "Epoch [11], Batch [350/391], Loss: 3.6374, LR: 0.010000\n",
      "Train set: Epoch: 11, Average loss:2.8251, LR: 0.010000 Top-1 Accuracy: 34.4380%, Top-5 Accuracy: 65.4920%, Time consumed:179.21s\n",
      "Test set: Epoch: 11, Average loss:3.0055, Top-1 Accuracy: 30.4300%, Top-5 Accuracy: 63.8000%, Time consumed:13.93s\n",
      "\n",
      "새로운 최고 top-1 정확도: 30.43%, top-5 정확도: 63.80%\n",
      "새로운 최고 top-5 정확도: 63.80%\n",
      "Accuracy improved (27.80% --> 30.43%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▎                                                                                      | 11/300 [35:59<15:47:41, 196.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12], Batch [50/391], Loss: 2.0689, LR: 0.010000\n",
      "Epoch [12], Batch [100/391], Loss: 2.1623, LR: 0.010000\n",
      "Epoch [12], Batch [150/391], Loss: 3.5642, LR: 0.010000\n",
      "Epoch [12], Batch [200/391], Loss: 3.0696, LR: 0.010000\n",
      "Epoch [12], Batch [250/391], Loss: 2.2299, LR: 0.010000\n",
      "Epoch [12], Batch [300/391], Loss: 3.5100, LR: 0.010000\n",
      "Epoch [12], Batch [350/391], Loss: 3.4729, LR: 0.010000\n",
      "Train set: Epoch: 12, Average loss:2.7500, LR: 0.010000 Top-1 Accuracy: 36.5260%, Top-5 Accuracy: 67.2000%, Time consumed:179.60s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▌                                                                                      | 12/300 [39:12<15:39:16, 195.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 12, Average loss:3.3235, Top-1 Accuracy: 26.2000%, Top-5 Accuracy: 57.6000%, Time consumed:13.63s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [13], Batch [50/391], Loss: 3.2704, LR: 0.010000\n",
      "Epoch [13], Batch [100/391], Loss: 3.5705, LR: 0.010000\n",
      "Epoch [13], Batch [150/391], Loss: 3.6258, LR: 0.010000\n",
      "Epoch [13], Batch [200/391], Loss: 2.0887, LR: 0.010000\n",
      "Epoch [13], Batch [250/391], Loss: 2.0706, LR: 0.010000\n",
      "Epoch [13], Batch [300/391], Loss: 3.5143, LR: 0.010000\n",
      "Epoch [13], Batch [350/391], Loss: 1.9392, LR: 0.010000\n",
      "Train set: Epoch: 13, Average loss:2.6450, LR: 0.010000 Top-1 Accuracy: 38.0700%, Top-5 Accuracy: 69.1140%, Time consumed:179.93s\n",
      "Test set: Epoch: 13, Average loss:2.8848, Top-1 Accuracy: 33.5700%, Top-5 Accuracy: 65.5100%, Time consumed:13.85s\n",
      "\n",
      "새로운 최고 top-1 정확도: 33.57%, top-5 정확도: 65.51%\n",
      "새로운 최고 top-5 정확도: 65.51%\n",
      "Accuracy improved (30.43% --> 33.57%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▉                                                                                      | 13/300 [42:29<15:37:24, 195.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14], Batch [50/391], Loss: 2.0016, LR: 0.010000\n",
      "Epoch [14], Batch [100/391], Loss: 2.1553, LR: 0.010000\n",
      "Epoch [14], Batch [150/391], Loss: 1.8990, LR: 0.010000\n",
      "Epoch [14], Batch [200/391], Loss: 3.8435, LR: 0.010000\n",
      "Epoch [14], Batch [250/391], Loss: 1.5830, LR: 0.010000\n",
      "Epoch [14], Batch [300/391], Loss: 3.3872, LR: 0.010000\n",
      "Epoch [14], Batch [350/391], Loss: 2.5929, LR: 0.010000\n",
      "Train set: Epoch: 14, Average loss:2.5138, LR: 0.010000 Top-1 Accuracy: 41.0360%, Top-5 Accuracy: 72.2140%, Time consumed:179.91s\n",
      "Test set: Epoch: 14, Average loss:2.8304, Top-1 Accuracy: 35.3100%, Top-5 Accuracy: 67.2500%, Time consumed:13.60s\n",
      "\n",
      "새로운 최고 top-1 정확도: 35.31%, top-5 정확도: 67.25%\n",
      "새로운 최고 top-5 정확도: 67.25%\n",
      "Accuracy improved (33.57% --> 35.31%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▏                                                                                     | 14/300 [45:45<15:35:03, 196.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15], Batch [50/391], Loss: 1.8393, LR: 0.010000\n",
      "Epoch [15], Batch [100/391], Loss: 1.8674, LR: 0.010000\n",
      "Epoch [15], Batch [150/391], Loss: 3.6220, LR: 0.010000\n",
      "Epoch [15], Batch [200/391], Loss: 1.8969, LR: 0.010000\n",
      "Epoch [15], Batch [250/391], Loss: 2.9561, LR: 0.010000\n",
      "Epoch [15], Batch [300/391], Loss: 1.6606, LR: 0.010000\n",
      "Epoch [15], Batch [350/391], Loss: 2.8128, LR: 0.010000\n",
      "Train set: Epoch: 15, Average loss:2.4224, LR: 0.010000 Top-1 Accuracy: 43.5180%, Top-5 Accuracy: 74.2820%, Time consumed:180.46s\n",
      "Test set: Epoch: 15, Average loss:2.1694, Top-1 Accuracy: 44.8000%, Top-5 Accuracy: 75.2900%, Time consumed:22.19s\n",
      "\n",
      "새로운 최고 top-1 정확도: 44.80%, top-5 정확도: 75.29%\n",
      "새로운 최고 top-5 정확도: 75.29%\n",
      "Accuracy improved (35.31% --> 44.80%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▌                                                                                     | 15/300 [49:11<15:45:24, 199.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16], Batch [50/391], Loss: 3.5552, LR: 0.010000\n",
      "Epoch [16], Batch [100/391], Loss: 3.8180, LR: 0.010000\n",
      "Epoch [16], Batch [150/391], Loss: 3.1861, LR: 0.010000\n",
      "Epoch [16], Batch [200/391], Loss: 2.6728, LR: 0.010000\n",
      "Epoch [16], Batch [250/391], Loss: 1.5727, LR: 0.010000\n",
      "Epoch [16], Batch [300/391], Loss: 1.8736, LR: 0.010000\n",
      "Epoch [16], Batch [350/391], Loss: 1.7444, LR: 0.010000\n",
      "Train set: Epoch: 16, Average loss:2.3405, LR: 0.010000 Top-1 Accuracy: 45.5200%, Top-5 Accuracy: 75.8880%, Time consumed:179.99s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▊                                                                                     | 16/300 [52:33<15:46:33, 199.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 16, Average loss:2.2727, Top-1 Accuracy: 43.2700%, Top-5 Accuracy: 74.9600%, Time consumed:22.18s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [17], Batch [50/391], Loss: 2.5674, LR: 0.010000\n",
      "Epoch [17], Batch [100/391], Loss: 3.5155, LR: 0.010000\n",
      "Epoch [17], Batch [150/391], Loss: 2.6643, LR: 0.010000\n",
      "Epoch [17], Batch [200/391], Loss: 1.7596, LR: 0.010000\n",
      "Epoch [17], Batch [250/391], Loss: 3.6736, LR: 0.010000\n",
      "Epoch [17], Batch [300/391], Loss: 2.3850, LR: 0.010000\n",
      "Epoch [17], Batch [350/391], Loss: 3.5665, LR: 0.010000\n",
      "Train set: Epoch: 17, Average loss:2.2928, LR: 0.010000 Top-1 Accuracy: 47.1660%, Top-5 Accuracy: 77.2700%, Time consumed:179.70s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████                                                                                     | 17/300 [55:47<15:34:23, 198.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 17, Average loss:2.5057, Top-1 Accuracy: 40.4300%, Top-5 Accuracy: 73.0800%, Time consumed:14.03s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [18], Batch [50/391], Loss: 1.6601, LR: 0.010000\n",
      "Epoch [18], Batch [100/391], Loss: 3.1741, LR: 0.010000\n",
      "Epoch [18], Batch [150/391], Loss: 2.8893, LR: 0.010000\n",
      "Epoch [18], Batch [200/391], Loss: 3.3754, LR: 0.010000\n",
      "Epoch [18], Batch [250/391], Loss: 1.5484, LR: 0.010000\n",
      "Epoch [18], Batch [300/391], Loss: 1.7967, LR: 0.010000\n",
      "Epoch [18], Batch [350/391], Loss: 1.5263, LR: 0.010000\n",
      "Train set: Epoch: 18, Average loss:2.2653, LR: 0.010000 Top-1 Accuracy: 48.0640%, Top-5 Accuracy: 77.3680%, Time consumed:179.60s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████▍                                                                                    | 18/300 [59:01<15:24:47, 196.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 18, Average loss:2.4552, Top-1 Accuracy: 40.5800%, Top-5 Accuracy: 73.4600%, Time consumed:14.05s\n",
      "\n",
      "EarlyStopping 카운터: 3 / 30\n",
      "Epoch [19], Batch [50/391], Loss: 2.7214, LR: 0.010000\n",
      "Epoch [19], Batch [100/391], Loss: 1.3927, LR: 0.010000\n",
      "Epoch [19], Batch [150/391], Loss: 2.9340, LR: 0.010000\n",
      "Epoch [19], Batch [200/391], Loss: 1.5888, LR: 0.010000\n",
      "Epoch [19], Batch [250/391], Loss: 1.2531, LR: 0.010000\n",
      "Epoch [19], Batch [300/391], Loss: 3.3989, LR: 0.010000\n",
      "Epoch [19], Batch [350/391], Loss: 1.5511, LR: 0.010000\n",
      "Train set: Epoch: 19, Average loss:2.1415, LR: 0.010000 Top-1 Accuracy: 50.1240%, Top-5 Accuracy: 79.3200%, Time consumed:179.33s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████▌                                                                                  | 19/300 [1:02:14<15:16:42, 195.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 19, Average loss:2.3058, Top-1 Accuracy: 43.2400%, Top-5 Accuracy: 74.7700%, Time consumed:14.01s\n",
      "\n",
      "EarlyStopping 카운터: 4 / 30\n",
      "Epoch [20], Batch [50/391], Loss: 1.5777, LR: 0.010000\n",
      "Epoch [20], Batch [100/391], Loss: 1.9544, LR: 0.010000\n",
      "Epoch [20], Batch [150/391], Loss: 1.7973, LR: 0.010000\n",
      "Epoch [20], Batch [200/391], Loss: 1.3608, LR: 0.010000\n",
      "Epoch [20], Batch [250/391], Loss: 1.4780, LR: 0.010000\n",
      "Epoch [20], Batch [300/391], Loss: 3.0901, LR: 0.010000\n",
      "Epoch [20], Batch [350/391], Loss: 2.2096, LR: 0.010000\n",
      "Train set: Epoch: 20, Average loss:2.2035, LR: 0.010000 Top-1 Accuracy: 49.5800%, Top-5 Accuracy: 78.2380%, Time consumed:179.63s\n",
      "Test set: Epoch: 20, Average loss:2.1002, Top-1 Accuracy: 46.7700%, Top-5 Accuracy: 77.7000%, Time consumed:14.02s\n",
      "\n",
      "새로운 최고 top-1 정확도: 46.77%, top-5 정확도: 77.70%\n",
      "새로운 최고 top-5 정확도: 77.70%\n",
      "체크포인트가 checkpoint.pt에 저장되었습니다.\n",
      "Accuracy improved (44.80% --> 46.77%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████▊                                                                                  | 20/300 [1:05:34<15:19:11, 196.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21], Batch [50/391], Loss: 1.9750, LR: 0.010000\n",
      "Epoch [21], Batch [100/391], Loss: 2.6006, LR: 0.010000\n",
      "Epoch [21], Batch [150/391], Loss: 3.2462, LR: 0.010000\n",
      "Epoch [21], Batch [200/391], Loss: 1.3710, LR: 0.010000\n",
      "Epoch [21], Batch [250/391], Loss: 1.2896, LR: 0.010000\n",
      "Epoch [21], Batch [300/391], Loss: 1.4084, LR: 0.010000\n",
      "Epoch [21], Batch [350/391], Loss: 3.1331, LR: 0.010000\n",
      "Train set: Epoch: 21, Average loss:2.0570, LR: 0.010000 Top-1 Accuracy: 52.5860%, Top-5 Accuracy: 81.1540%, Time consumed:179.35s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████▏                                                                                 | 21/300 [1:08:47<15:11:23, 196.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 21, Average loss:2.5324, Top-1 Accuracy: 40.4000%, Top-5 Accuracy: 73.0300%, Time consumed:14.38s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [22], Batch [50/391], Loss: 1.4385, LR: 0.010000\n",
      "Epoch [22], Batch [100/391], Loss: 1.2056, LR: 0.010000\n",
      "Epoch [22], Batch [150/391], Loss: 1.3997, LR: 0.010000\n",
      "Epoch [22], Batch [200/391], Loss: 1.3091, LR: 0.010000\n",
      "Epoch [22], Batch [250/391], Loss: 1.6616, LR: 0.010000\n",
      "Epoch [22], Batch [300/391], Loss: 1.2412, LR: 0.010000\n",
      "Epoch [22], Batch [350/391], Loss: 2.3880, LR: 0.010000\n",
      "Train set: Epoch: 22, Average loss:2.0329, LR: 0.010000 Top-1 Accuracy: 54.5080%, Top-5 Accuracy: 81.9340%, Time consumed:179.65s\n",
      "Test set: Epoch: 22, Average loss:2.0348, Top-1 Accuracy: 50.1200%, Top-5 Accuracy: 80.8800%, Time consumed:13.71s\n",
      "\n",
      "새로운 최고 top-1 정확도: 50.12%, top-5 정확도: 80.88%\n",
      "새로운 최고 top-5 정확도: 80.88%\n",
      "Accuracy improved (46.77% --> 50.12%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████▍                                                                                 | 22/300 [1:12:04<15:08:31, 196.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23], Batch [50/391], Loss: 1.5440, LR: 0.010000\n",
      "Epoch [23], Batch [100/391], Loss: 1.5613, LR: 0.010000\n",
      "Epoch [23], Batch [150/391], Loss: 2.8007, LR: 0.010000\n",
      "Epoch [23], Batch [200/391], Loss: 1.1084, LR: 0.010000\n",
      "Epoch [23], Batch [250/391], Loss: 1.4843, LR: 0.010000\n",
      "Epoch [23], Batch [300/391], Loss: 2.7421, LR: 0.010000\n",
      "Epoch [23], Batch [350/391], Loss: 1.4667, LR: 0.010000\n",
      "Train set: Epoch: 23, Average loss:1.9976, LR: 0.010000 Top-1 Accuracy: 54.3260%, Top-5 Accuracy: 82.0920%, Time consumed:179.75s\n",
      "Test set: Epoch: 23, Average loss:1.9161, Top-1 Accuracy: 52.3200%, Top-5 Accuracy: 81.2500%, Time consumed:14.05s\n",
      "\n",
      "새로운 최고 top-1 정확도: 52.32%, top-5 정확도: 81.25%\n",
      "새로운 최고 top-5 정확도: 81.25%\n",
      "Accuracy improved (50.12% --> 52.32%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▋                                                                                 | 23/300 [1:15:21<15:06:52, 196.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24], Batch [50/391], Loss: 1.2010, LR: 0.010000\n",
      "Epoch [24], Batch [100/391], Loss: 1.3047, LR: 0.010000\n",
      "Epoch [24], Batch [150/391], Loss: 1.3324, LR: 0.010000\n",
      "Epoch [24], Batch [200/391], Loss: 1.1944, LR: 0.010000\n",
      "Epoch [24], Batch [250/391], Loss: 1.1031, LR: 0.010000\n",
      "Epoch [24], Batch [300/391], Loss: 2.9776, LR: 0.010000\n",
      "Epoch [24], Batch [350/391], Loss: 2.9275, LR: 0.010000\n",
      "Train set: Epoch: 24, Average loss:1.9438, LR: 0.010000 Top-1 Accuracy: 56.0960%, Top-5 Accuracy: 83.2320%, Time consumed:179.43s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███████                                                                                 | 24/300 [1:18:35<14:59:41, 195.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 24, Average loss:2.3781, Top-1 Accuracy: 44.7900%, Top-5 Accuracy: 76.3700%, Time consumed:14.18s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [25], Batch [50/391], Loss: 1.4200, LR: 0.010000\n",
      "Epoch [25], Batch [100/391], Loss: 2.5780, LR: 0.010000\n",
      "Epoch [25], Batch [150/391], Loss: 3.0319, LR: 0.010000\n",
      "Epoch [25], Batch [200/391], Loss: 1.6649, LR: 0.010000\n",
      "Epoch [25], Batch [250/391], Loss: 2.8199, LR: 0.010000\n",
      "Epoch [25], Batch [300/391], Loss: 2.0053, LR: 0.010000\n",
      "Epoch [25], Batch [350/391], Loss: 1.3265, LR: 0.010000\n",
      "Train set: Epoch: 25, Average loss:1.9272, LR: 0.010000 Top-1 Accuracy: 56.5980%, Top-5 Accuracy: 83.4600%, Time consumed:179.46s\n",
      "Test set: Epoch: 25, Average loss:1.8491, Top-1 Accuracy: 54.4900%, Top-5 Accuracy: 83.1500%, Time consumed:14.12s\n",
      "\n",
      "새로운 최고 top-1 정확도: 54.49%, top-5 정확도: 83.15%\n",
      "새로운 최고 top-5 정확도: 83.15%\n",
      "Accuracy improved (52.32% --> 54.49%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███████▎                                                                                | 25/300 [1:21:51<14:57:46, 195.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26], Batch [50/391], Loss: 3.0309, LR: 0.010000\n",
      "Epoch [26], Batch [100/391], Loss: 2.6003, LR: 0.010000\n",
      "Epoch [26], Batch [150/391], Loss: 2.0958, LR: 0.010000\n",
      "Epoch [26], Batch [200/391], Loss: 2.6202, LR: 0.010000\n",
      "Epoch [26], Batch [250/391], Loss: 1.3243, LR: 0.010000\n",
      "Epoch [26], Batch [300/391], Loss: 0.8275, LR: 0.010000\n",
      "Epoch [26], Batch [350/391], Loss: 1.1103, LR: 0.010000\n",
      "Train set: Epoch: 26, Average loss:1.9406, LR: 0.010000 Top-1 Accuracy: 57.2880%, Top-5 Accuracy: 83.5500%, Time consumed:179.55s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███████▋                                                                                | 26/300 [1:25:05<14:51:49, 195.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 26, Average loss:1.8570, Top-1 Accuracy: 53.8800%, Top-5 Accuracy: 82.2400%, Time consumed:14.37s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [27], Batch [50/391], Loss: 0.9910, LR: 0.010000\n",
      "Epoch [27], Batch [100/391], Loss: 2.1066, LR: 0.010000\n",
      "Epoch [27], Batch [150/391], Loss: 1.7718, LR: 0.010000\n",
      "Epoch [27], Batch [200/391], Loss: 1.0928, LR: 0.010000\n",
      "Epoch [27], Batch [250/391], Loss: 2.7440, LR: 0.010000\n",
      "Epoch [27], Batch [300/391], Loss: 3.1551, LR: 0.010000\n",
      "Epoch [27], Batch [350/391], Loss: 1.0882, LR: 0.010000\n",
      "Train set: Epoch: 27, Average loss:1.8521, LR: 0.010000 Top-1 Accuracy: 58.7680%, Top-5 Accuracy: 84.5420%, Time consumed:179.43s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███████▉                                                                                | 27/300 [1:28:19<14:46:12, 194.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 27, Average loss:1.9020, Top-1 Accuracy: 53.4800%, Top-5 Accuracy: 81.8100%, Time consumed:14.12s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [28], Batch [50/391], Loss: 3.1750, LR: 0.010000\n",
      "Epoch [28], Batch [100/391], Loss: 2.2296, LR: 0.010000\n",
      "Epoch [28], Batch [150/391], Loss: 3.2094, LR: 0.010000\n",
      "Epoch [28], Batch [200/391], Loss: 1.0634, LR: 0.010000\n",
      "Epoch [28], Batch [250/391], Loss: 2.2294, LR: 0.010000\n",
      "Epoch [28], Batch [300/391], Loss: 2.7828, LR: 0.010000\n",
      "Epoch [28], Batch [350/391], Loss: 1.1649, LR: 0.010000\n",
      "Train set: Epoch: 28, Average loss:1.8625, LR: 0.010000 Top-1 Accuracy: 58.5300%, Top-5 Accuracy: 84.3400%, Time consumed:179.55s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|████████▏                                                                               | 28/300 [1:31:33<14:41:55, 194.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 28, Average loss:2.0256, Top-1 Accuracy: 49.6500%, Top-5 Accuracy: 80.3600%, Time consumed:14.45s\n",
      "\n",
      "EarlyStopping 카운터: 3 / 30\n",
      "Epoch [29], Batch [50/391], Loss: 1.1677, LR: 0.010000\n",
      "Epoch [29], Batch [100/391], Loss: 3.1091, LR: 0.010000\n",
      "Epoch [29], Batch [150/391], Loss: 0.9641, LR: 0.010000\n",
      "Epoch [29], Batch [200/391], Loss: 0.8033, LR: 0.010000\n",
      "Epoch [29], Batch [250/391], Loss: 2.6945, LR: 0.010000\n",
      "Epoch [29], Batch [300/391], Loss: 0.8563, LR: 0.010000\n",
      "Epoch [29], Batch [350/391], Loss: 1.2766, LR: 0.010000\n",
      "Train set: Epoch: 29, Average loss:1.7360, LR: 0.010000 Top-1 Accuracy: 61.8020%, Top-5 Accuracy: 86.9880%, Time consumed:179.77s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▌                                                                               | 29/300 [1:34:46<14:37:39, 194.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 29, Average loss:2.1206, Top-1 Accuracy: 49.0900%, Top-5 Accuracy: 78.3800%, Time consumed:14.02s\n",
      "\n",
      "EarlyStopping 카운터: 4 / 30\n",
      "Epoch [30], Batch [50/391], Loss: 2.3534, LR: 0.010000\n",
      "Epoch [30], Batch [100/391], Loss: 2.4769, LR: 0.010000\n",
      "Epoch [30], Batch [150/391], Loss: 3.1724, LR: 0.010000\n",
      "Epoch [30], Batch [200/391], Loss: 0.9188, LR: 0.010000\n",
      "Epoch [30], Batch [250/391], Loss: 0.9479, LR: 0.010000\n",
      "Epoch [30], Batch [300/391], Loss: 1.0455, LR: 0.010000\n",
      "Epoch [30], Batch [350/391], Loss: 1.0088, LR: 0.010000\n",
      "Train set: Epoch: 30, Average loss:1.8436, LR: 0.010000 Top-1 Accuracy: 60.6020%, Top-5 Accuracy: 85.5000%, Time consumed:178.94s\n",
      "Test set: Epoch: 30, Average loss:2.2262, Top-1 Accuracy: 47.7500%, Top-5 Accuracy: 78.6100%, Time consumed:14.37s\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▊                                                                               | 30/300 [1:38:03<14:37:17, 194.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "체크포인트가 checkpoint.pt에 저장되었습니다.\n",
      "EarlyStopping 카운터: 5 / 30\n",
      "Epoch [31], Batch [50/391], Loss: 2.2584, LR: 0.010000\n",
      "Epoch [31], Batch [100/391], Loss: 2.1181, LR: 0.010000\n",
      "Epoch [31], Batch [150/391], Loss: 2.9595, LR: 0.010000\n",
      "Epoch [31], Batch [200/391], Loss: 1.0406, LR: 0.010000\n",
      "Epoch [31], Batch [250/391], Loss: 0.9383, LR: 0.010000\n",
      "Epoch [31], Batch [300/391], Loss: 0.8898, LR: 0.010000\n",
      "Epoch [31], Batch [350/391], Loss: 2.8616, LR: 0.010000\n",
      "Train set: Epoch: 31, Average loss:1.7434, LR: 0.010000 Top-1 Accuracy: 61.9660%, Top-5 Accuracy: 86.6500%, Time consumed:179.51s\n",
      "Test set: Epoch: 31, Average loss:1.8790, Top-1 Accuracy: 54.5200%, Top-5 Accuracy: 82.1600%, Time consumed:14.22s\n",
      "\n",
      "새로운 최고 top-1 정확도: 54.52%, top-5 정확도: 82.16%\n",
      "Accuracy improved (54.49% --> 54.52%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█████████                                                                               | 31/300 [1:41:20<14:36:44, 195.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32], Batch [50/391], Loss: 2.4650, LR: 0.005000\n",
      "Epoch [32], Batch [100/391], Loss: 0.6312, LR: 0.005000\n",
      "Epoch [32], Batch [150/391], Loss: 3.0974, LR: 0.005000\n",
      "Epoch [32], Batch [200/391], Loss: 0.6127, LR: 0.005000\n",
      "Epoch [32], Batch [250/391], Loss: 2.1208, LR: 0.005000\n",
      "Epoch [32], Batch [300/391], Loss: 0.7573, LR: 0.005000\n",
      "Epoch [32], Batch [350/391], Loss: 0.6379, LR: 0.005000\n",
      "Train set: Epoch: 32, Average loss:1.5397, LR: 0.005000 Top-1 Accuracy: 67.4620%, Top-5 Accuracy: 89.4220%, Time consumed:179.82s\n",
      "Test set: Epoch: 32, Average loss:1.8891, Top-1 Accuracy: 56.2400%, Top-5 Accuracy: 84.1900%, Time consumed:22.24s\n",
      "\n",
      "새로운 최고 top-1 정확도: 56.24%, top-5 정확도: 84.19%\n",
      "새로운 최고 top-5 정확도: 84.19%\n",
      "Accuracy improved (54.52% --> 56.24%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█████████▍                                                                              | 32/300 [1:44:45<14:46:37, 198.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33], Batch [50/391], Loss: 2.5119, LR: 0.005000\n",
      "Epoch [33], Batch [100/391], Loss: 0.9840, LR: 0.005000\n",
      "Epoch [33], Batch [150/391], Loss: 2.6290, LR: 0.005000\n",
      "Epoch [33], Batch [200/391], Loss: 2.0377, LR: 0.005000\n",
      "Epoch [33], Batch [250/391], Loss: 0.7429, LR: 0.005000\n",
      "Epoch [33], Batch [300/391], Loss: 1.4188, LR: 0.005000\n",
      "Epoch [33], Batch [350/391], Loss: 0.6789, LR: 0.005000\n",
      "Train set: Epoch: 33, Average loss:1.5823, LR: 0.005000 Top-1 Accuracy: 67.7740%, Top-5 Accuracy: 89.6200%, Time consumed:179.35s\n",
      "Test set: Epoch: 33, Average loss:1.8559, Top-1 Accuracy: 57.7200%, Top-5 Accuracy: 84.3300%, Time consumed:14.11s\n",
      "\n",
      "새로운 최고 top-1 정확도: 57.72%, top-5 정확도: 84.33%\n",
      "새로운 최고 top-5 정확도: 84.33%\n",
      "Accuracy improved (56.24% --> 57.72%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█████████▋                                                                              | 33/300 [1:48:02<14:40:46, 197.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34], Batch [50/391], Loss: 3.0627, LR: 0.005000\n",
      "Epoch [34], Batch [100/391], Loss: 0.7909, LR: 0.005000\n",
      "Epoch [34], Batch [150/391], Loss: 0.6410, LR: 0.005000\n",
      "Epoch [34], Batch [200/391], Loss: 2.8278, LR: 0.005000\n",
      "Epoch [34], Batch [250/391], Loss: 2.0864, LR: 0.005000\n",
      "Epoch [34], Batch [300/391], Loss: 0.6349, LR: 0.005000\n",
      "Epoch [34], Batch [350/391], Loss: 1.9852, LR: 0.005000\n",
      "Train set: Epoch: 34, Average loss:1.5667, LR: 0.005000 Top-1 Accuracy: 68.2440%, Top-5 Accuracy: 89.6840%, Time consumed:179.40s\n",
      "Test set: Epoch: 34, Average loss:1.5219, Top-1 Accuracy: 61.9600%, Top-5 Accuracy: 87.7700%, Time consumed:14.16s\n",
      "\n",
      "새로운 최고 top-1 정확도: 61.96%, top-5 정확도: 87.77%\n",
      "새로운 최고 top-5 정확도: 87.77%\n",
      "Accuracy improved (57.72% --> 61.96%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█████████▉                                                                              | 34/300 [1:51:19<14:35:53, 197.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35], Batch [50/391], Loss: 2.9826, LR: 0.005000\n",
      "Epoch [35], Batch [100/391], Loss: 2.2256, LR: 0.005000\n",
      "Epoch [35], Batch [150/391], Loss: 0.5833, LR: 0.005000\n",
      "Epoch [35], Batch [200/391], Loss: 2.6225, LR: 0.005000\n",
      "Epoch [35], Batch [250/391], Loss: 2.8765, LR: 0.005000\n",
      "Epoch [35], Batch [300/391], Loss: 2.9936, LR: 0.005000\n",
      "Epoch [35], Batch [350/391], Loss: 0.8946, LR: 0.005000\n",
      "Train set: Epoch: 35, Average loss:1.4569, LR: 0.005000 Top-1 Accuracy: 70.4720%, Top-5 Accuracy: 91.1340%, Time consumed:179.85s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████▎                                                                             | 35/300 [1:54:33<14:27:52, 196.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 35, Average loss:1.6945, Top-1 Accuracy: 60.5300%, Top-5 Accuracy: 86.2600%, Time consumed:14.15s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [36], Batch [50/391], Loss: 2.8331, LR: 0.005000\n",
      "Epoch [36], Batch [100/391], Loss: 2.9224, LR: 0.005000\n",
      "Epoch [36], Batch [150/391], Loss: 2.7019, LR: 0.005000\n",
      "Epoch [36], Batch [200/391], Loss: 0.6670, LR: 0.005000\n",
      "Epoch [36], Batch [250/391], Loss: 2.7781, LR: 0.005000\n",
      "Epoch [36], Batch [300/391], Loss: 0.6264, LR: 0.005000\n",
      "Epoch [36], Batch [350/391], Loss: 1.4887, LR: 0.005000\n",
      "Train set: Epoch: 36, Average loss:1.4814, LR: 0.005000 Top-1 Accuracy: 69.3680%, Top-5 Accuracy: 90.4440%, Time consumed:179.97s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████▌                                                                             | 36/300 [1:57:47<14:21:38, 195.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 36, Average loss:1.7657, Top-1 Accuracy: 60.7300%, Top-5 Accuracy: 86.1900%, Time consumed:14.28s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [37], Batch [50/391], Loss: 2.8437, LR: 0.005000\n",
      "Epoch [37], Batch [100/391], Loss: 0.8507, LR: 0.005000\n",
      "Epoch [37], Batch [150/391], Loss: 0.6840, LR: 0.005000\n",
      "Epoch [37], Batch [200/391], Loss: 0.7598, LR: 0.005000\n",
      "Epoch [37], Batch [250/391], Loss: 0.6892, LR: 0.005000\n",
      "Epoch [37], Batch [300/391], Loss: 0.6987, LR: 0.005000\n",
      "Epoch [37], Batch [350/391], Loss: 0.7643, LR: 0.005000\n",
      "Train set: Epoch: 37, Average loss:1.5214, LR: 0.005000 Top-1 Accuracy: 68.6940%, Top-5 Accuracy: 90.1840%, Time consumed:179.77s\n",
      "Test set: Epoch: 37, Average loss:1.5059, Top-1 Accuracy: 63.4100%, Top-5 Accuracy: 88.4400%, Time consumed:14.18s\n",
      "\n",
      "새로운 최고 top-1 정확도: 63.41%, top-5 정확도: 88.44%\n",
      "새로운 최고 top-5 정확도: 88.44%\n",
      "Accuracy improved (61.96% --> 63.41%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████▊                                                                             | 37/300 [2:01:04<14:19:43, 196.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38], Batch [50/391], Loss: 0.5853, LR: 0.005000\n",
      "Epoch [38], Batch [100/391], Loss: 0.4564, LR: 0.005000\n",
      "Epoch [38], Batch [150/391], Loss: 1.4125, LR: 0.005000\n",
      "Epoch [38], Batch [200/391], Loss: 0.7440, LR: 0.005000\n",
      "Epoch [38], Batch [250/391], Loss: 1.9053, LR: 0.005000\n",
      "Epoch [38], Batch [300/391], Loss: 0.6516, LR: 0.005000\n",
      "Epoch [38], Batch [350/391], Loss: 1.3431, LR: 0.005000\n",
      "Train set: Epoch: 38, Average loss:1.4235, LR: 0.005000 Top-1 Accuracy: 70.5860%, Top-5 Accuracy: 91.0160%, Time consumed:179.36s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|███████████▏                                                                            | 38/300 [2:04:17<14:12:58, 195.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 38, Average loss:1.7355, Top-1 Accuracy: 61.2000%, Top-5 Accuracy: 87.2300%, Time consumed:14.11s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [39], Batch [50/391], Loss: 2.7083, LR: 0.005000\n",
      "Epoch [39], Batch [100/391], Loss: 0.8581, LR: 0.005000\n",
      "Epoch [39], Batch [150/391], Loss: 0.5883, LR: 0.005000\n",
      "Epoch [39], Batch [200/391], Loss: 1.3584, LR: 0.005000\n",
      "Epoch [39], Batch [250/391], Loss: 2.2227, LR: 0.005000\n",
      "Epoch [39], Batch [300/391], Loss: 2.9004, LR: 0.005000\n",
      "Epoch [39], Batch [350/391], Loss: 0.6564, LR: 0.005000\n",
      "Train set: Epoch: 39, Average loss:1.3806, LR: 0.005000 Top-1 Accuracy: 72.7340%, Top-5 Accuracy: 92.0680%, Time consumed:179.57s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|███████████▍                                                                            | 39/300 [2:07:31<14:07:30, 194.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 39, Average loss:1.6231, Top-1 Accuracy: 62.2100%, Top-5 Accuracy: 88.3300%, Time consumed:14.07s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [40], Batch [50/391], Loss: 0.5686, LR: 0.005000\n",
      "Epoch [40], Batch [100/391], Loss: 2.7406, LR: 0.005000\n",
      "Epoch [40], Batch [150/391], Loss: 0.7175, LR: 0.005000\n",
      "Epoch [40], Batch [200/391], Loss: 0.6887, LR: 0.005000\n",
      "Epoch [40], Batch [250/391], Loss: 0.6494, LR: 0.005000\n",
      "Epoch [40], Batch [300/391], Loss: 0.5863, LR: 0.005000\n",
      "Epoch [40], Batch [350/391], Loss: 0.6810, LR: 0.005000\n",
      "Train set: Epoch: 40, Average loss:1.3199, LR: 0.005000 Top-1 Accuracy: 72.6800%, Top-5 Accuracy: 92.2060%, Time consumed:179.69s\n",
      "Test set: Epoch: 40, Average loss:1.7510, Top-1 Accuracy: 62.9900%, Top-5 Accuracy: 88.0800%, Time consumed:14.05s\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|███████████▋                                                                            | 40/300 [2:10:48<14:06:47, 195.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "체크포인트가 checkpoint.pt에 저장되었습니다.\n",
      "EarlyStopping 카운터: 3 / 30\n",
      "Epoch [41], Batch [50/391], Loss: 2.5451, LR: 0.005000\n",
      "Epoch [41], Batch [100/391], Loss: 2.4608, LR: 0.005000\n",
      "Epoch [41], Batch [150/391], Loss: 1.2581, LR: 0.005000\n",
      "Epoch [41], Batch [200/391], Loss: 2.6892, LR: 0.005000\n",
      "Epoch [41], Batch [250/391], Loss: 2.0594, LR: 0.005000\n",
      "Epoch [41], Batch [300/391], Loss: 0.8014, LR: 0.005000\n",
      "Epoch [41], Batch [350/391], Loss: 1.9654, LR: 0.005000\n",
      "Train set: Epoch: 41, Average loss:1.3680, LR: 0.005000 Top-1 Accuracy: 73.1960%, Top-5 Accuracy: 92.4180%, Time consumed:179.90s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████                                                                            | 41/300 [2:14:02<14:01:50, 195.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 41, Average loss:1.8053, Top-1 Accuracy: 61.6800%, Top-5 Accuracy: 87.5100%, Time consumed:14.20s\n",
      "\n",
      "EarlyStopping 카운터: 4 / 30\n",
      "Epoch [42], Batch [50/391], Loss: 0.5775, LR: 0.005000\n",
      "Epoch [42], Batch [100/391], Loss: 0.5461, LR: 0.005000\n",
      "Epoch [42], Batch [150/391], Loss: 1.4242, LR: 0.005000\n",
      "Epoch [42], Batch [200/391], Loss: 2.8056, LR: 0.005000\n",
      "Epoch [42], Batch [250/391], Loss: 1.9041, LR: 0.005000\n",
      "Epoch [42], Batch [300/391], Loss: 2.7806, LR: 0.005000\n",
      "Epoch [42], Batch [350/391], Loss: 2.8276, LR: 0.005000\n",
      "Train set: Epoch: 42, Average loss:1.3541, LR: 0.005000 Top-1 Accuracy: 72.9480%, Top-5 Accuracy: 92.0120%, Time consumed:179.43s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████▎                                                                           | 42/300 [2:17:15<13:56:43, 194.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 42, Average loss:1.7189, Top-1 Accuracy: 63.2400%, Top-5 Accuracy: 87.3300%, Time consumed:14.14s\n",
      "\n",
      "EarlyStopping 카운터: 5 / 30\n",
      "Epoch [43], Batch [50/391], Loss: 0.7711, LR: 0.005000\n",
      "Epoch [43], Batch [100/391], Loss: 1.2550, LR: 0.005000\n",
      "Epoch [43], Batch [150/391], Loss: 0.5099, LR: 0.005000\n",
      "Epoch [43], Batch [200/391], Loss: 2.2372, LR: 0.005000\n",
      "Epoch [43], Batch [250/391], Loss: 2.6284, LR: 0.005000\n",
      "Epoch [43], Batch [300/391], Loss: 2.6208, LR: 0.005000\n",
      "Epoch [43], Batch [350/391], Loss: 0.6711, LR: 0.005000\n",
      "Train set: Epoch: 43, Average loss:1.3531, LR: 0.005000 Top-1 Accuracy: 73.0920%, Top-5 Accuracy: 91.9740%, Time consumed:179.66s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████▌                                                                           | 43/300 [2:20:29<13:52:29, 194.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 43, Average loss:1.8005, Top-1 Accuracy: 61.9400%, Top-5 Accuracy: 87.0900%, Time consumed:14.16s\n",
      "\n",
      "EarlyStopping 카운터: 6 / 30\n",
      "Epoch [44], Batch [50/391], Loss: 0.3167, LR: 0.002500\n",
      "Epoch [44], Batch [100/391], Loss: 0.4274, LR: 0.002500\n",
      "Epoch [44], Batch [150/391], Loss: 0.3749, LR: 0.002500\n",
      "Epoch [44], Batch [200/391], Loss: 0.4323, LR: 0.002500\n",
      "Epoch [44], Batch [250/391], Loss: 1.9203, LR: 0.002500\n",
      "Epoch [44], Batch [300/391], Loss: 0.4451, LR: 0.002500\n",
      "Epoch [44], Batch [350/391], Loss: 0.3571, LR: 0.002500\n",
      "Train set: Epoch: 44, Average loss:1.2851, LR: 0.002500 Top-1 Accuracy: 75.7800%, Top-5 Accuracy: 92.9560%, Time consumed:179.79s\n",
      "Test set: Epoch: 44, Average loss:1.5081, Top-1 Accuracy: 66.9700%, Top-5 Accuracy: 89.4900%, Time consumed:14.09s\n",
      "\n",
      "새로운 최고 top-1 정확도: 66.97%, top-5 정확도: 89.49%\n",
      "새로운 최고 top-5 정확도: 89.49%\n",
      "Accuracy improved (63.41% --> 66.97%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████████████▉                                                                           | 44/300 [2:23:46<13:52:36, 195.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45], Batch [50/391], Loss: 0.2193, LR: 0.002500\n",
      "Epoch [45], Batch [100/391], Loss: 0.4179, LR: 0.002500\n",
      "Epoch [45], Batch [150/391], Loss: 0.5004, LR: 0.002500\n",
      "Epoch [45], Batch [200/391], Loss: 2.2912, LR: 0.002500\n",
      "Epoch [45], Batch [250/391], Loss: 2.6315, LR: 0.002500\n",
      "Epoch [45], Batch [300/391], Loss: 2.5257, LR: 0.002500\n",
      "Epoch [45], Batch [350/391], Loss: 2.0903, LR: 0.002500\n",
      "Train set: Epoch: 45, Average loss:1.1836, LR: 0.002500 Top-1 Accuracy: 78.5080%, Top-5 Accuracy: 94.1540%, Time consumed:179.33s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████████████▏                                                                          | 45/300 [2:27:00<13:47:37, 194.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 45, Average loss:1.6841, Top-1 Accuracy: 63.9400%, Top-5 Accuracy: 88.0200%, Time consumed:14.45s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [46], Batch [50/391], Loss: 0.2977, LR: 0.002500\n",
      "Epoch [46], Batch [100/391], Loss: 0.3107, LR: 0.002500\n",
      "Epoch [46], Batch [150/391], Loss: 0.3510, LR: 0.002500\n",
      "Epoch [46], Batch [200/391], Loss: 0.9832, LR: 0.002500\n",
      "Epoch [46], Batch [250/391], Loss: 0.3634, LR: 0.002500\n",
      "Epoch [46], Batch [300/391], Loss: 2.8557, LR: 0.002500\n",
      "Epoch [46], Batch [350/391], Loss: 0.3174, LR: 0.002500\n",
      "Train set: Epoch: 46, Average loss:1.1875, LR: 0.002500 Top-1 Accuracy: 77.3640%, Top-5 Accuracy: 93.3380%, Time consumed:179.83s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████████████▍                                                                          | 46/300 [2:30:14<13:43:18, 194.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 46, Average loss:1.7420, Top-1 Accuracy: 66.4100%, Top-5 Accuracy: 89.5300%, Time consumed:14.05s\n",
      "\n",
      "새로운 최고 top-5 정확도: 89.53%\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [47], Batch [50/391], Loss: 0.3361, LR: 0.002500\n",
      "Epoch [47], Batch [100/391], Loss: 2.1780, LR: 0.002500\n",
      "Epoch [47], Batch [150/391], Loss: 2.1702, LR: 0.002500\n",
      "Epoch [47], Batch [200/391], Loss: 2.6569, LR: 0.002500\n",
      "Epoch [47], Batch [250/391], Loss: 2.4937, LR: 0.002500\n",
      "Epoch [47], Batch [300/391], Loss: 0.3075, LR: 0.002500\n",
      "Epoch [47], Batch [350/391], Loss: 0.4448, LR: 0.002500\n",
      "Train set: Epoch: 47, Average loss:1.1293, LR: 0.002500 Top-1 Accuracy: 80.2940%, Top-5 Accuracy: 94.8220%, Time consumed:179.26s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█████████████▊                                                                          | 47/300 [2:33:27<13:39:02, 194.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 47, Average loss:1.6478, Top-1 Accuracy: 65.6700%, Top-5 Accuracy: 88.6100%, Time consumed:14.41s\n",
      "\n",
      "EarlyStopping 카운터: 3 / 30\n",
      "Epoch [48], Batch [50/391], Loss: 0.3037, LR: 0.002500\n",
      "Epoch [48], Batch [100/391], Loss: 0.2919, LR: 0.002500\n",
      "Epoch [48], Batch [150/391], Loss: 2.5130, LR: 0.002500\n",
      "Epoch [48], Batch [200/391], Loss: 2.5428, LR: 0.002500\n",
      "Epoch [48], Batch [250/391], Loss: 0.2869, LR: 0.002500\n",
      "Epoch [48], Batch [300/391], Loss: 0.2802, LR: 0.002500\n",
      "Epoch [48], Batch [350/391], Loss: 0.3998, LR: 0.002500\n",
      "Train set: Epoch: 48, Average loss:1.1882, LR: 0.002500 Top-1 Accuracy: 77.9520%, Top-5 Accuracy: 93.6240%, Time consumed:179.38s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████████████                                                                          | 48/300 [2:36:41<13:34:52, 194.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 48, Average loss:1.6324, Top-1 Accuracy: 65.1600%, Top-5 Accuracy: 88.9600%, Time consumed:14.12s\n",
      "\n",
      "EarlyStopping 카운터: 4 / 30\n",
      "Epoch [49], Batch [50/391], Loss: 2.4209, LR: 0.002500\n",
      "Epoch [49], Batch [100/391], Loss: 0.2754, LR: 0.002500\n",
      "Epoch [49], Batch [150/391], Loss: 1.5220, LR: 0.002500\n",
      "Epoch [49], Batch [200/391], Loss: 2.0382, LR: 0.002500\n",
      "Epoch [49], Batch [250/391], Loss: 0.3131, LR: 0.002500\n",
      "Epoch [49], Batch [300/391], Loss: 1.3543, LR: 0.002500\n",
      "Epoch [49], Batch [350/391], Loss: 0.8564, LR: 0.002500\n",
      "Train set: Epoch: 49, Average loss:1.0849, LR: 0.002500 Top-1 Accuracy: 80.9440%, Top-5 Accuracy: 95.0480%, Time consumed:179.81s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████████████▎                                                                         | 49/300 [2:40:04<13:42:32, 196.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 49, Average loss:1.5882, Top-1 Accuracy: 66.1200%, Top-5 Accuracy: 89.3000%, Time consumed:22.88s\n",
      "\n",
      "EarlyStopping 카운터: 5 / 30\n",
      "Epoch [50], Batch [50/391], Loss: 0.2264, LR: 0.002500\n",
      "Epoch [50], Batch [100/391], Loss: 0.2747, LR: 0.002500\n",
      "Epoch [50], Batch [150/391], Loss: 0.1923, LR: 0.002500\n",
      "Epoch [50], Batch [200/391], Loss: 2.4951, LR: 0.002500\n",
      "Epoch [50], Batch [250/391], Loss: 2.6777, LR: 0.002500\n",
      "Epoch [50], Batch [300/391], Loss: 0.2941, LR: 0.002500\n",
      "Epoch [50], Batch [350/391], Loss: 0.3214, LR: 0.002500\n",
      "Train set: Epoch: 50, Average loss:1.0967, LR: 0.002500 Top-1 Accuracy: 80.7520%, Top-5 Accuracy: 94.8360%, Time consumed:179.27s\n",
      "Test set: Epoch: 50, Average loss:1.6679, Top-1 Accuracy: 65.7400%, Top-5 Accuracy: 88.1700%, Time consumed:14.16s\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████████████▋                                                                         | 50/300 [2:43:20<13:38:41, 196.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "체크포인트가 checkpoint.pt에 저장되었습니다.\n",
      "EarlyStopping 카운터: 6 / 30\n",
      "Epoch [51], Batch [50/391], Loss: 0.1945, LR: 0.001250\n",
      "Epoch [51], Batch [100/391], Loss: 2.3056, LR: 0.001250\n",
      "Epoch [51], Batch [150/391], Loss: 1.9760, LR: 0.001250\n",
      "Epoch [51], Batch [200/391], Loss: 0.1453, LR: 0.001250\n",
      "Epoch [51], Batch [250/391], Loss: 0.2936, LR: 0.001250\n",
      "Epoch [51], Batch [300/391], Loss: 1.1460, LR: 0.001250\n",
      "Epoch [51], Batch [350/391], Loss: 0.2888, LR: 0.001250\n",
      "Train set: Epoch: 51, Average loss:1.1181, LR: 0.001250 Top-1 Accuracy: 81.6660%, Top-5 Accuracy: 94.7200%, Time consumed:179.11s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████████████▉                                                                         | 51/300 [2:46:33<13:31:46, 195.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 51, Average loss:1.5408, Top-1 Accuracy: 66.4100%, Top-5 Accuracy: 89.2700%, Time consumed:14.44s\n",
      "\n",
      "EarlyStopping 카운터: 7 / 30\n",
      "Epoch [52], Batch [50/391], Loss: 2.0759, LR: 0.001250\n",
      "Epoch [52], Batch [100/391], Loss: 1.4565, LR: 0.001250\n",
      "Epoch [52], Batch [150/391], Loss: 0.9169, LR: 0.001250\n",
      "Epoch [52], Batch [200/391], Loss: 0.2506, LR: 0.001250\n",
      "Epoch [52], Batch [250/391], Loss: 0.1915, LR: 0.001250\n",
      "Epoch [52], Batch [300/391], Loss: 1.4793, LR: 0.001250\n",
      "Epoch [52], Batch [350/391], Loss: 2.0070, LR: 0.001250\n",
      "Train set: Epoch: 52, Average loss:1.0293, LR: 0.001250 Top-1 Accuracy: 83.7140%, Top-5 Accuracy: 95.8840%, Time consumed:179.65s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████████████▎                                                                        | 52/300 [2:49:47<13:26:18, 195.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 52, Average loss:1.5947, Top-1 Accuracy: 66.6800%, Top-5 Accuracy: 89.3700%, Time consumed:14.18s\n",
      "\n",
      "EarlyStopping 카운터: 8 / 30\n",
      "Epoch [53], Batch [50/391], Loss: 1.6574, LR: 0.001250\n",
      "Epoch [53], Batch [100/391], Loss: 2.1692, LR: 0.001250\n",
      "Epoch [53], Batch [150/391], Loss: 2.6266, LR: 0.001250\n",
      "Epoch [53], Batch [200/391], Loss: 0.1716, LR: 0.001250\n",
      "Epoch [53], Batch [250/391], Loss: 0.1892, LR: 0.001250\n",
      "Epoch [53], Batch [300/391], Loss: 0.2127, LR: 0.001250\n",
      "Epoch [53], Batch [350/391], Loss: 1.3023, LR: 0.001250\n",
      "Train set: Epoch: 53, Average loss:1.0218, LR: 0.001250 Top-1 Accuracy: 83.7580%, Top-5 Accuracy: 95.9740%, Time consumed:179.41s\n",
      "Test set: Epoch: 53, Average loss:1.5665, Top-1 Accuracy: 67.9500%, Top-5 Accuracy: 89.6100%, Time consumed:14.49s\n",
      "\n",
      "새로운 최고 top-1 정확도: 67.95%, top-5 정확도: 89.61%\n",
      "새로운 최고 top-5 정확도: 89.61%\n",
      "Accuracy improved (66.97% --> 67.95%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████████████▌                                                                        | 53/300 [2:53:04<13:25:26, 195.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54], Batch [50/391], Loss: 0.1963, LR: 0.001250\n",
      "Epoch [54], Batch [100/391], Loss: 2.4843, LR: 0.001250\n",
      "Epoch [54], Batch [150/391], Loss: 0.1704, LR: 0.001250\n",
      "Epoch [54], Batch [200/391], Loss: 0.1321, LR: 0.001250\n",
      "Epoch [54], Batch [250/391], Loss: 2.5581, LR: 0.001250\n",
      "Epoch [54], Batch [300/391], Loss: 0.1501, LR: 0.001250\n",
      "Epoch [54], Batch [350/391], Loss: 0.7000, LR: 0.001250\n",
      "Train set: Epoch: 54, Average loss:0.9615, LR: 0.001250 Top-1 Accuracy: 84.3820%, Top-5 Accuracy: 96.0100%, Time consumed:179.73s\n",
      "Test set: Epoch: 54, Average loss:1.5187, Top-1 Accuracy: 68.7100%, Top-5 Accuracy: 90.0900%, Time consumed:14.14s\n",
      "\n",
      "새로운 최고 top-1 정확도: 68.71%, top-5 정확도: 90.09%\n",
      "새로운 최고 top-5 정확도: 90.09%\n",
      "Accuracy improved (67.95% --> 68.71%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████████████▊                                                                        | 54/300 [2:56:21<13:23:49, 196.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55], Batch [50/391], Loss: 0.1863, LR: 0.001250\n",
      "Epoch [55], Batch [100/391], Loss: 0.2002, LR: 0.001250\n",
      "Epoch [55], Batch [150/391], Loss: 2.1492, LR: 0.001250\n",
      "Epoch [55], Batch [200/391], Loss: 0.1634, LR: 0.001250\n",
      "Epoch [55], Batch [250/391], Loss: 2.4826, LR: 0.001250\n",
      "Epoch [55], Batch [300/391], Loss: 2.2256, LR: 0.001250\n",
      "Epoch [55], Batch [350/391], Loss: 0.2243, LR: 0.001250\n",
      "Train set: Epoch: 55, Average loss:1.0496, LR: 0.001250 Top-1 Accuracy: 82.8560%, Top-5 Accuracy: 95.4180%, Time consumed:179.79s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|████████████████▏                                                                       | 55/300 [2:59:35<13:17:56, 195.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 55, Average loss:1.5679, Top-1 Accuracy: 68.4100%, Top-5 Accuracy: 89.7900%, Time consumed:14.12s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [56], Batch [50/391], Loss: 0.2640, LR: 0.001250\n",
      "Epoch [56], Batch [100/391], Loss: 0.1334, LR: 0.001250\n",
      "Epoch [56], Batch [150/391], Loss: 2.1399, LR: 0.001250\n",
      "Epoch [56], Batch [200/391], Loss: 2.1945, LR: 0.001250\n",
      "Epoch [56], Batch [250/391], Loss: 0.1802, LR: 0.001250\n",
      "Epoch [56], Batch [300/391], Loss: 2.2871, LR: 0.001250\n",
      "Epoch [56], Batch [350/391], Loss: 0.1909, LR: 0.001250\n",
      "Train set: Epoch: 56, Average loss:0.9847, LR: 0.001250 Top-1 Accuracy: 84.5480%, Top-5 Accuracy: 96.0620%, Time consumed:179.79s\n",
      "Test set: Epoch: 56, Average loss:1.4772, Top-1 Accuracy: 69.1200%, Top-5 Accuracy: 90.1500%, Time consumed:14.08s\n",
      "\n",
      "새로운 최고 top-1 정확도: 69.12%, top-5 정확도: 90.15%\n",
      "새로운 최고 top-5 정확도: 90.15%\n",
      "Accuracy improved (68.71% --> 69.12%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|████████████████▍                                                                       | 56/300 [3:02:52<13:16:44, 195.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [57], Batch [50/391], Loss: 1.1236, LR: 0.001250\n",
      "Epoch [57], Batch [100/391], Loss: 0.1783, LR: 0.001250\n",
      "Epoch [57], Batch [150/391], Loss: 0.8718, LR: 0.001250\n",
      "Epoch [57], Batch [200/391], Loss: 2.5560, LR: 0.001250\n",
      "Epoch [57], Batch [250/391], Loss: 2.0513, LR: 0.001250\n",
      "Epoch [57], Batch [300/391], Loss: 1.2126, LR: 0.001250\n",
      "Epoch [57], Batch [350/391], Loss: 0.1695, LR: 0.001250\n",
      "Train set: Epoch: 57, Average loss:1.0400, LR: 0.001250 Top-1 Accuracy: 83.2740%, Top-5 Accuracy: 95.5000%, Time consumed:179.55s\n",
      "Test set: Epoch: 57, Average loss:1.4563, Top-1 Accuracy: 69.4000%, Top-5 Accuracy: 90.5500%, Time consumed:14.47s\n",
      "\n",
      "새로운 최고 top-1 정확도: 69.40%, top-5 정확도: 90.55%\n",
      "새로운 최고 top-5 정확도: 90.55%\n",
      "Accuracy improved (69.12% --> 69.40%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|████████████████▋                                                                       | 57/300 [3:06:09<13:15:04, 196.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58], Batch [50/391], Loss: 0.2907, LR: 0.001250\n",
      "Epoch [58], Batch [100/391], Loss: 0.1999, LR: 0.001250\n",
      "Epoch [58], Batch [150/391], Loss: 2.0667, LR: 0.001250\n",
      "Epoch [58], Batch [200/391], Loss: 0.1758, LR: 0.001250\n",
      "Epoch [58], Batch [250/391], Loss: 0.1588, LR: 0.001250\n",
      "Epoch [58], Batch [300/391], Loss: 0.1739, LR: 0.001250\n",
      "Epoch [58], Batch [350/391], Loss: 0.1546, LR: 0.001250\n",
      "Train set: Epoch: 58, Average loss:1.0475, LR: 0.001250 Top-1 Accuracy: 83.3820%, Top-5 Accuracy: 95.7880%, Time consumed:179.39s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█████████████████                                                                       | 58/300 [3:09:23<13:08:31, 195.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 58, Average loss:1.5048, Top-1 Accuracy: 68.3300%, Top-5 Accuracy: 90.5600%, Time consumed:14.21s\n",
      "\n",
      "새로운 최고 top-5 정확도: 90.56%\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [59], Batch [50/391], Loss: 0.1568, LR: 0.001250\n",
      "Epoch [59], Batch [100/391], Loss: 0.1088, LR: 0.001250\n",
      "Epoch [59], Batch [150/391], Loss: 0.8174, LR: 0.001250\n",
      "Epoch [59], Batch [200/391], Loss: 0.2101, LR: 0.001250\n",
      "Epoch [59], Batch [250/391], Loss: 0.2022, LR: 0.001250\n",
      "Epoch [59], Batch [300/391], Loss: 0.1915, LR: 0.001250\n",
      "Epoch [59], Batch [350/391], Loss: 0.2144, LR: 0.001250\n",
      "Train set: Epoch: 59, Average loss:1.0046, LR: 0.001250 Top-1 Accuracy: 83.9600%, Top-5 Accuracy: 95.7660%, Time consumed:180.12s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█████████████████▎                                                                      | 59/300 [3:12:37<13:03:54, 195.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 59, Average loss:1.6029, Top-1 Accuracy: 69.0200%, Top-5 Accuracy: 90.0800%, Time consumed:14.25s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [60], Batch [50/391], Loss: 2.6645, LR: 0.001250\n",
      "Epoch [60], Batch [100/391], Loss: 0.1424, LR: 0.001250\n",
      "Epoch [60], Batch [150/391], Loss: 2.1111, LR: 0.001250\n",
      "Epoch [60], Batch [200/391], Loss: 2.4497, LR: 0.001250\n",
      "Epoch [60], Batch [250/391], Loss: 2.0734, LR: 0.001250\n",
      "Epoch [60], Batch [300/391], Loss: 2.4813, LR: 0.001250\n",
      "Epoch [60], Batch [350/391], Loss: 0.1526, LR: 0.001250\n",
      "Train set: Epoch: 60, Average loss:0.9892, LR: 0.001250 Top-1 Accuracy: 83.4060%, Top-5 Accuracy: 95.2280%, Time consumed:179.61s\n",
      "Test set: Epoch: 60, Average loss:1.5700, Top-1 Accuracy: 68.6800%, Top-5 Accuracy: 90.3400%, Time consumed:14.20s\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█████████████████▌                                                                      | 60/300 [3:15:54<13:02:15, 195.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "체크포인트가 checkpoint.pt에 저장되었습니다.\n",
      "EarlyStopping 카운터: 3 / 30\n",
      "Epoch [61], Batch [50/391], Loss: 2.1963, LR: 0.001250\n",
      "Epoch [61], Batch [100/391], Loss: 0.1461, LR: 0.001250\n",
      "Epoch [61], Batch [150/391], Loss: 1.0000, LR: 0.001250\n",
      "Epoch [61], Batch [200/391], Loss: 0.1688, LR: 0.001250\n",
      "Epoch [61], Batch [250/391], Loss: 1.7554, LR: 0.001250\n",
      "Epoch [61], Batch [300/391], Loss: 0.1283, LR: 0.001250\n",
      "Epoch [61], Batch [350/391], Loss: 0.1764, LR: 0.001250\n",
      "Train set: Epoch: 61, Average loss:1.1004, LR: 0.001250 Top-1 Accuracy: 81.5640%, Top-5 Accuracy: 94.7840%, Time consumed:179.74s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█████████████████▉                                                                      | 61/300 [3:19:08<12:57:01, 195.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 61, Average loss:1.6116, Top-1 Accuracy: 68.3600%, Top-5 Accuracy: 90.0100%, Time consumed:14.17s\n",
      "\n",
      "EarlyStopping 카운터: 4 / 30\n",
      "Epoch [62], Batch [50/391], Loss: 0.1291, LR: 0.001250\n",
      "Epoch [62], Batch [100/391], Loss: 0.1075, LR: 0.001250\n",
      "Epoch [62], Batch [150/391], Loss: 0.2072, LR: 0.001250\n",
      "Epoch [62], Batch [200/391], Loss: 0.1454, LR: 0.001250\n",
      "Epoch [62], Batch [250/391], Loss: 0.1945, LR: 0.001250\n",
      "Epoch [62], Batch [300/391], Loss: 0.1379, LR: 0.001250\n",
      "Epoch [62], Batch [350/391], Loss: 1.6791, LR: 0.001250\n",
      "Train set: Epoch: 62, Average loss:0.9463, LR: 0.001250 Top-1 Accuracy: 84.2660%, Top-5 Accuracy: 95.5360%, Time consumed:179.97s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██████████████████▏                                                                     | 62/300 [3:22:22<12:52:36, 194.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 62, Average loss:1.5650, Top-1 Accuracy: 68.4900%, Top-5 Accuracy: 89.8800%, Time consumed:14.12s\n",
      "\n",
      "EarlyStopping 카운터: 5 / 30\n",
      "Epoch [63], Batch [50/391], Loss: 1.7097, LR: 0.001250\n",
      "Epoch [63], Batch [100/391], Loss: 2.5689, LR: 0.001250\n",
      "Epoch [63], Batch [150/391], Loss: 1.5329, LR: 0.001250\n",
      "Epoch [63], Batch [200/391], Loss: 0.1477, LR: 0.001250\n",
      "Epoch [63], Batch [250/391], Loss: 0.8783, LR: 0.001250\n",
      "Epoch [63], Batch [300/391], Loss: 2.1275, LR: 0.001250\n",
      "Epoch [63], Batch [350/391], Loss: 2.5628, LR: 0.001250\n",
      "Train set: Epoch: 63, Average loss:1.0460, LR: 0.001250 Top-1 Accuracy: 82.4620%, Top-5 Accuracy: 95.0280%, Time consumed:179.79s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██████████████████▍                                                                     | 63/300 [3:25:36<12:48:20, 194.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 63, Average loss:1.4959, Top-1 Accuracy: 69.2900%, Top-5 Accuracy: 90.5400%, Time consumed:14.11s\n",
      "\n",
      "EarlyStopping 카운터: 6 / 30\n",
      "Epoch [64], Batch [50/391], Loss: 2.7220, LR: 0.000625\n",
      "Epoch [64], Batch [100/391], Loss: 1.3385, LR: 0.000625\n",
      "Epoch [64], Batch [150/391], Loss: 0.1227, LR: 0.000625\n",
      "Epoch [64], Batch [200/391], Loss: 0.1265, LR: 0.000625\n",
      "Epoch [64], Batch [250/391], Loss: 0.1142, LR: 0.000625\n",
      "Epoch [64], Batch [300/391], Loss: 0.0737, LR: 0.000625\n",
      "Epoch [64], Batch [350/391], Loss: 1.2699, LR: 0.000625\n",
      "Train set: Epoch: 64, Average loss:0.8590, LR: 0.000625 Top-1 Accuracy: 86.9080%, Top-5 Accuracy: 96.6140%, Time consumed:179.46s\n",
      "Test set: Epoch: 64, Average loss:1.4652, Top-1 Accuracy: 69.6200%, Top-5 Accuracy: 90.7000%, Time consumed:13.86s\n",
      "\n",
      "새로운 최고 top-1 정확도: 69.62%, top-5 정확도: 90.70%\n",
      "새로운 최고 top-5 정확도: 90.70%\n",
      "Accuracy improved (69.40% --> 69.62%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██████████████████▊                                                                     | 64/300 [3:28:52<12:47:15, 195.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [65], Batch [50/391], Loss: 0.1590, LR: 0.000625\n",
      "Epoch [65], Batch [100/391], Loss: 0.1019, LR: 0.000625\n",
      "Epoch [65], Batch [150/391], Loss: 2.0758, LR: 0.000625\n",
      "Epoch [65], Batch [200/391], Loss: 2.3894, LR: 0.000625\n",
      "Epoch [65], Batch [250/391], Loss: 0.2212, LR: 0.000625\n",
      "Epoch [65], Batch [300/391], Loss: 2.3896, LR: 0.000625\n",
      "Epoch [65], Batch [350/391], Loss: 2.5661, LR: 0.000625\n",
      "Train set: Epoch: 65, Average loss:1.0313, LR: 0.000625 Top-1 Accuracy: 82.7560%, Top-5 Accuracy: 95.2840%, Time consumed:179.55s\n",
      "Test set: Epoch: 65, Average loss:1.4091, Top-1 Accuracy: 69.7400%, Top-5 Accuracy: 90.3200%, Time consumed:13.93s\n",
      "\n",
      "새로운 최고 top-1 정확도: 69.74%, top-5 정확도: 90.32%\n",
      "Accuracy improved (69.62% --> 69.74%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|███████████████████                                                                     | 65/300 [3:32:09<12:45:36, 195.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [66], Batch [50/391], Loss: 1.8073, LR: 0.000625\n",
      "Epoch [66], Batch [100/391], Loss: 0.1811, LR: 0.000625\n",
      "Epoch [66], Batch [150/391], Loss: 1.0971, LR: 0.000625\n",
      "Epoch [66], Batch [200/391], Loss: 0.0587, LR: 0.000625\n",
      "Epoch [66], Batch [250/391], Loss: 2.2613, LR: 0.000625\n",
      "Epoch [66], Batch [300/391], Loss: 0.0782, LR: 0.000625\n",
      "Epoch [66], Batch [350/391], Loss: 0.1281, LR: 0.000625\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.v2 as transforms_v2\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "from tools.tool import AccuracyEarlyStopping, WarmUpLR, SAM\n",
    "# Wide ResNet 모델 임포트\n",
    "from models.wideresidual import Wide_ResNet, conv_init\n",
    "\n",
    "# 중요: wideresidual.py 파일에서 \"*wide*layer\" 메서드명을 \"_wide_layer\"로 수정해야 합니다!\n",
    "\n",
    "# 체크포인트 저장 및 불러오기 함수 정의\n",
    "def save_checkpoint(model, optimizer, main_scheduler, epoch, best_acc, save_path):\n",
    "    \"\"\"모델 체크포인트를 저장합니다.\"\"\"\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.module.state_dict() if isinstance(model, nn.DataParallel) else model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': main_scheduler.state_dict() if main_scheduler else None,\n",
    "        'best_acc': best_acc\n",
    "    }\n",
    "    torch.save(checkpoint, save_path)\n",
    "    print(f\"체크포인트가 {save_path}에 저장되었습니다.\")\n",
    "\n",
    "def load_checkpoint(model, optimizer, main_scheduler, checkpoint_path):\n",
    "    \"\"\"저장된 체크포인트를 불러옵니다.\"\"\"\n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        print(f\"체크포인트 파일이 존재하지 않습니다: {checkpoint_path}\")\n",
    "        return model, optimizer, main_scheduler, 0, 0\n",
    "    \n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    \n",
    "    # 모델 가중치 불러오기\n",
    "    if isinstance(model, nn.DataParallel):\n",
    "        model.module.load_state_dict(checkpoint['model_state_dict'])\n",
    "    else:\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    # 옵티마이저 상태 불러오기\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    \n",
    "    # 스케줄러 상태 불러오기 (있는 경우)\n",
    "    if main_scheduler and checkpoint['scheduler_state_dict']:\n",
    "        main_scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    \n",
    "    print(f\"{checkpoint_path}에서 에폭 {start_epoch}의 체크포인트를 불러왔습니다.\")\n",
    "    return model, optimizer, main_scheduler, start_epoch, checkpoint['best_acc']\n",
    "\n",
    "# 학습 재개 설정 (필요에 따라 변경)\n",
    "resume_training = False  # True로 설정하면 체크포인트에서 학습 재개\n",
    "checkpoint_path = 'checkpoint.pt'  # 체크포인트 파일 경로\n",
    "\n",
    "# WandB 설정\n",
    "wandb.login(key=\"ef091b9abcea3186341ddf8995d62bde62d7469e\")\n",
    "\n",
    "# 기존 실행을 계속할지 새 실행을 시작할지 설정\n",
    "if resume_training and os.path.exists(checkpoint_path):\n",
    "    # 기존 실행 ID를 사용하려면 아래 주석을 해제하고 ID를 입력하세요\n",
    "    # wandb.init(project=\"PBL-2\", name=\"wideresnet_28_20_cfc,SGD\", id=\"기존_실행_ID\", resume=\"must\")\n",
    "    # 또는 새 실행으로 시작하되 동일한 이름 사용\n",
    "    wandb.init(project=\"PBL-2\", name=\"wideresnet_28_20_cfc,SGD\")\n",
    "else:\n",
    "    # 새 실행 시작\n",
    "    wandb.init(project=\"PBL-2\", name=\"wideresnet_28_20_cfc,SGD\")\n",
    "\n",
    "# WandB 설정 - WideResNet 28x20으로 변경\n",
    "config = {\n",
    "    \"model\": \"wideresnet\",  \n",
    "    \"depth\": 28,            \n",
    "    \"widen_factor\": 20,     # 10에서 20으로 변경\n",
    "    \"dropout_rate\": 0.3,    \n",
    "    \"batch_size\": 128,       # 메모리 부족 가능성 고려하여 더 작은 배치 크기로 조정\n",
    "    \"num_epochs\": 300,\n",
    "    \"learning_rate\": 0.01,  \n",
    "    \"optimizer\": \"SGD\",     \n",
    "    \"momentum\": 0.9,        \n",
    "    \"weight_decay\": 5e-4,   \n",
    "    \"deterministic\": False,\n",
    "    \"patience\": 30,         \n",
    "    \"max_epochs_wait\": float('inf'),\n",
    "    \"cutmix_alpha\": 1.0,    \n",
    "    \"cutmix_prob\": 0.5,     \n",
    "    \"crop_padding\": 4,      \n",
    "    \"crop_size\": 32,        \n",
    "    \"warmup_epochs\": 5,     \n",
    "}\n",
    "wandb.config.update(config)\n",
    "\n",
    "\n",
    "# CIFAR-100 데이터셋 로드 - 강화된 데이터 증강 추가\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(config[\"crop_size\"], padding=config[\"crop_padding\"]),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR100(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR100(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "# DataLoader 생성\n",
    "trainloader = DataLoader(trainset, batch_size=config[\"batch_size\"], shuffle=True, \n",
    "                        num_workers=32, pin_memory=True)  # GPU 전송 속도 향상\n",
    "testloader = DataLoader(testset, batch_size=config[\"batch_size\"], shuffle=False, \n",
    "                       num_workers=32, pin_memory=True)\n",
    "\n",
    "print(f\"Train set size: {len(trainset)}\")\n",
    "print(f\"Test set size: {len(testset)}\")\n",
    "\n",
    "# CutMix 변환 정의\n",
    "cutmix = transforms_v2.CutMix(alpha=config[\"cutmix_alpha\"], num_classes=100)  # CIFAR-100은 100개 클래스\n",
    "\n",
    "def train(model, trainloader, criterion, optimizer, device, epoch, warmup_scheduler=None, warmup_epochs=None):\n",
    "    \"\"\"\n",
    "    학습 함수 (CutMix 적용) - SGD 최적화용으로 수정\n",
    "    \"\"\"\n",
    "    if warmup_epochs is None:\n",
    "        warmup_epochs = config[\"warmup_epochs\"]\n",
    "        \n",
    "    model.train()   # 모델을 학습 모드로 설정\n",
    "    start_time = time.time()  # 시간 측정 시작\n",
    "    running_loss = 0.0\n",
    "    correct_top1 = 0\n",
    "    correct_top5 = 0\n",
    "    total = 0\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(trainloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # CutMix 확률적 적용\n",
    "        if random.random() < config[\"cutmix_prob\"]:\n",
    "            inputs, labels = cutmix(inputs, labels)\n",
    "            use_cutmix = True\n",
    "        else:\n",
    "            use_cutmix = False\n",
    "        \n",
    "        # 그래디언트 초기화\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 순전파\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # CutMix 적용 여부에 따라 손실 함수 선택\n",
    "        if use_cutmix:\n",
    "            loss = torch.nn.functional.cross_entropy(outputs, labels)\n",
    "        else:\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "        # 역전파\n",
    "        loss.backward()\n",
    "        \n",
    "        # 가중치 업데이트 (단일 스텝)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 학습률 스케줄러 업데이트\n",
    "        if epoch < warmup_epochs and warmup_scheduler is not None:\n",
    "            warmup_scheduler.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # 정확도 계산\n",
    "        if use_cutmix:\n",
    "            _, label_idx = labels.max(1)\n",
    "        else:\n",
    "            label_idx = labels\n",
    "        \n",
    "        # top-1 정확도 계산\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += inputs.size(0)\n",
    "        correct_top1 += predicted.eq(label_idx).sum().item()\n",
    "        \n",
    "        # top-5 정확도 계산\n",
    "        _, top5_idx = outputs.topk(5, 1, largest=True, sorted=True)\n",
    "        correct_top5 += sum([1 for i in range(len(label_idx)) if label_idx[i] in top5_idx[i]])\n",
    "        \n",
    "        if (i + 1) % 50 == 0:  # 50 배치마다 출력\n",
    "            print(f'Epoch [{epoch+1}], Batch [{i+1}/{len(trainloader)}], Loss: {loss.item():.4f}, LR: {optimizer.param_groups[0][\"lr\"]:.6f}')\n",
    "    \n",
    "    epoch_loss = running_loss / len(trainloader)\n",
    "    accuracy_top1 = 100.0 * correct_top1 / total\n",
    "    accuracy_top5 = 100.0 * correct_top5 / total\n",
    "    \n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    # 학습 세트에 대한 성능 출력\n",
    "    print(f'Train set: Epoch: {epoch+1}, Average loss:{epoch_loss:.4f}, LR: {optimizer.param_groups[0][\"lr\"]:.6f} '\n",
    "          f'Top-1 Accuracy: {accuracy_top1:.4f}%, Top-5 Accuracy: {accuracy_top5:.4f}%, Time consumed:{train_time:.2f}s')\n",
    "    \n",
    "    return epoch_loss, accuracy_top1, accuracy_top5\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device, epoch, phase=\"test\"):\n",
    "    \"\"\"\n",
    "    평가 함수\n",
    "    \"\"\"\n",
    "    model.eval()  # 모델을 평가 모드로 설정\n",
    "    start_time = time.time()  # 시간 측정 시작\n",
    "    \n",
    "    eval_loss = 0.0\n",
    "    correct_top1 = 0\n",
    "    correct_top5 = 0\n",
    "    total = 0\n",
    "    \n",
    "    # 그래디언트 계산 비활성화\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # 순전파\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # 손실 계산\n",
    "            loss = criterion(outputs, labels)\n",
    "            eval_loss += loss.item()\n",
    "            \n",
    "            # top-1 정확도 계산\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct_top1 += (predicted == labels).sum().item()\n",
    "            \n",
    "            # top-5 정확도 계산\n",
    "            _, top5_idx = outputs.topk(5, 1, largest=True, sorted=True)\n",
    "            correct_top5 += top5_idx.eq(labels.view(-1, 1).expand_as(top5_idx)).sum().item()\n",
    "    \n",
    "    # 평균 손실 및 정확도 계산\n",
    "    eval_loss = eval_loss / len(dataloader)\n",
    "    accuracy_top1 = 100.0 * correct_top1 / total\n",
    "    accuracy_top5 = 100.0 * correct_top5 / total\n",
    "    \n",
    "    # 평가 시간 계산\n",
    "    eval_time = time.time() - start_time\n",
    "    \n",
    "    # 테스트 세트에 대한 성능 출력\n",
    "    print(f'{phase.capitalize()} set: Epoch: {epoch+1}, Average loss:{eval_loss:.4f}, '\n",
    "          f'Top-1 Accuracy: {accuracy_top1:.4f}%, Top-5 Accuracy: {accuracy_top5:.4f}%, Time consumed:{eval_time:.2f}s')\n",
    "    print()\n",
    "    \n",
    "    return eval_loss, accuracy_top1, accuracy_top5\n",
    "\n",
    "def main_training_loop(model, trainloader, testloader, criterion, optimizer, device, \n",
    "                      num_epochs, patience, max_epochs_wait, warmup_scheduler=None, \n",
    "                      main_scheduler=None, warmup_epochs=None, resume=False, checkpoint_path='checkpoint.pt'):\n",
    "    \"\"\"\n",
    "    메인 학습 루프 (학습 재개 기능 추가)\n",
    "    \"\"\"\n",
    "    if warmup_epochs is None:\n",
    "        warmup_epochs = config[\"warmup_epochs\"]\n",
    "    \n",
    "    start_epoch = 0\n",
    "    best_test_acc_top1 = 0.0\n",
    "    best_test_acc_top5 = 0.0\n",
    "    \n",
    "    # 학습 재개 시 체크포인트 불러오기\n",
    "    if resume and os.path.exists(checkpoint_path):\n",
    "        model, optimizer, main_scheduler, start_epoch, best_test_acc_top1 = load_checkpoint(\n",
    "            model, optimizer, main_scheduler, checkpoint_path\n",
    "        )\n",
    "        print(f\"에폭 {start_epoch}부터 학습을 재개합니다. 최고 정확도: {best_test_acc_top1:.2f}%\")\n",
    "    \n",
    "    # 정확도 기반 얼리 스토핑 사용\n",
    "    early_stopping = AccuracyEarlyStopping(patience=patience, verbose=True, path='best_checkpoint.pt', max_epochs=max_epochs_wait)\n",
    "    if resume and best_test_acc_top1 > 0:\n",
    "        early_stopping.best_score = best_test_acc_top1 / 100.0  # AccuracyEarlyStopping에서 사용하는 스케일로 변환\n",
    "    \n",
    "    # 테스트 정확도 기록을 위한 리스트\n",
    "    test_acc_top1_history = []\n",
    "    \n",
    "    # tqdm을 사용한 진행 상황 표시 (시작 에폭부터)\n",
    "    for epoch in tqdm(range(start_epoch, num_epochs)):\n",
    "        # 학습\n",
    "        train_loss, train_acc_top1, train_acc_top5 = train(\n",
    "            model, trainloader, criterion, optimizer, device, epoch, \n",
    "            warmup_scheduler, warmup_epochs\n",
    "        )\n",
    "        \n",
    "        # 테스트 데이터로 평가\n",
    "        test_loss, test_acc_top1, test_acc_top5 = evaluate(model, testloader, criterion, device, epoch, phase=\"test\")\n",
    "\n",
    "        # 웜업 이후 ReduceLROnPlateau 스케줄러 업데이트 \n",
    "        if epoch >= warmup_epochs and main_scheduler is not None:\n",
    "            main_scheduler.step(test_acc_top1)  # 테스트 정확도에 따라 학습률 업데이트\n",
    "        \n",
    "        # 테스트 정확도 기록\n",
    "        test_acc_top1_history.append(test_acc_top1)\n",
    "        \n",
    "        # WandB에 로깅\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_accuracy_top1\": train_acc_top1,\n",
    "            \"train_accuracy_top5\": train_acc_top5,\n",
    "            \"test_loss\": test_loss,\n",
    "            \"test_accuracy_top1\": test_acc_top1,\n",
    "            \"test_accuracy_top5\": test_acc_top5\n",
    "        })\n",
    "        \n",
    "        # 최고 정확도 모델 저장 (top-1 기준)\n",
    "        if test_acc_top1 > best_test_acc_top1:\n",
    "            best_test_acc_top1 = test_acc_top1\n",
    "            best_test_acc_top5_at_best_top1 = test_acc_top5\n",
    "            print(f'새로운 최고 top-1 정확도: {best_test_acc_top1:.2f}%, top-5 정확도: {best_test_acc_top5_at_best_top1:.2f}%')\n",
    "            \n",
    "            # 모델 저장\n",
    "            model_path = f'best_model_{wandb.run.name}.pth'\n",
    "            if isinstance(model, nn.DataParallel):\n",
    "                torch.save(model.module.state_dict(), model_path)  # DataParallel 래퍼 제거\n",
    "            else:\n",
    "                torch.save(model.state_dict(), model_path)\n",
    "            \n",
    "            # WandB에 모델 아티팩트 저장\n",
    "            wandb.save(model_path)\n",
    "        \n",
    "        # top-5 accuracy 기록 업데이트\n",
    "        if test_acc_top5 > best_test_acc_top5:\n",
    "            best_test_acc_top5 = test_acc_top5\n",
    "            print(f'새로운 최고 top-5 정확도: {best_test_acc_top5:.2f}%')\n",
    "\n",
    "        # 정기적으로 체크포인트 저장 (예: 10 에폭마다)\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            save_checkpoint(model, optimizer, main_scheduler, epoch, best_test_acc_top1, checkpoint_path)\n",
    "        \n",
    "        # Early stopping 체크 (test_acc_top1 기준)\n",
    "        early_stopping(test_acc_top1, model, epoch)\n",
    "        if early_stopping.early_stop:\n",
    "            print(f\"에폭 {epoch+1}에서 학습 조기 종료. 최고 성능 에폭: {early_stopping.best_epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    # 학습 완료 후 최종 체크포인트 저장\n",
    "    save_checkpoint(model, optimizer, main_scheduler, epoch, best_test_acc_top1, 'final_checkpoint.pt')\n",
    "    \n",
    "    # 훈련 완료 후 최고 모델 로드\n",
    "    print(\"테스트 정확도 기준 최고 모델 로드 중...\")\n",
    "    model_path = f'best_model_{wandb.run.name}.pth'\n",
    "    \n",
    "    # 올바른 모델 로드를 위한 처리\n",
    "    if isinstance(model, nn.DataParallel):\n",
    "        model.module.load_state_dict(torch.load(model_path))\n",
    "    else:\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    # 최종 테스트 세트 평가\n",
    "    final_test_loss, final_test_acc_top1, final_test_acc_top5 = evaluate(model, testloader, criterion, device, num_epochs-1, phase=\"test\")\n",
    "    \n",
    "    print(f'완료! 최고 테스트 top-1 정확도: {best_test_acc_top1:.2f}%, 최고 테스트 top-5 정확도: {best_test_acc_top5:.2f}%')\n",
    "    print(f'최종 테스트 top-1 정확도: {final_test_acc_top1:.2f}%, 최종 테스트 top-5 정확도: {final_test_acc_top5:.2f}%')\n",
    "    \n",
    "    # WandB에 최종 결과 기록\n",
    "    wandb.run.summary[\"best_test_accuracy_top1\"] = best_test_acc_top1\n",
    "    wandb.run.summary[\"best_test_accuracy_top5\"] = best_test_acc_top5\n",
    "    wandb.run.summary[\"final_test_accuracy_top1\"] = final_test_acc_top1\n",
    "    wandb.run.summary[\"final_test_accuracy_top5\"] = final_test_acc_top5\n",
    "\n",
    "    # Early stopping 정보 저장\n",
    "    if early_stopping.early_stop:\n",
    "        wandb.run.summary[\"early_stopped\"] = True\n",
    "        wandb.run.summary[\"early_stopped_epoch\"] = epoch+1\n",
    "        wandb.run.summary[\"best_epoch\"] = early_stopping.best_epoch+1\n",
    "    else:\n",
    "        wandb.run.summary[\"early_stopped\"] = False\n",
    "\n",
    "\n",
    "# 디바이스 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 메모리 사용량 출력 함수 (디버깅용)\n",
    "def print_gpu_memory():\n",
    "    if torch.cuda.is_available():\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "            print(f\"Memory Allocated: {torch.cuda.memory_allocated(i)/1024**3:.2f} GB\")\n",
    "            print(f\"Memory Reserved: {torch.cuda.memory_reserved(i)/1024**3:.2f} GB\")\n",
    "            print(f\"Max Memory Allocated: {torch.cuda.max_memory_allocated(i)/1024**3:.2f} GB\")\n",
    "\n",
    "# GPU 메모리 초기 상태 출력\n",
    "print_gpu_memory()\n",
    "\n",
    "# Wide ResNet 모델 초기화\n",
    "model = Wide_ResNet(\n",
    "    depth=config[\"depth\"],\n",
    "    widen_factor=config[\"widen_factor\"],\n",
    "    dropout_rate=config[\"dropout_rate\"],\n",
    "    num_classes=100  # CIFAR-100은 100개 클래스\n",
    ").to(device)\n",
    "\n",
    "# 가중치 초기화 적용\n",
    "model.apply(conv_init)\n",
    "\n",
    "# 모델 파라미터 수 계산 및 출력\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "num_params = count_parameters(model)\n",
    "print(f'Wide-ResNet-{config[\"depth\"]}-{config[\"widen_factor\"]} initialized with {num_params:,} parameters')\n",
    "wandb.run.summary[\"model_parameters\"] = num_params\n",
    "\n",
    "# 손실 함수 설정 (라벨 스무딩 사용)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# SGD 옵티마이저 사용\n",
    "optimizer = optim.SGD(\n",
    "    model.parameters(), \n",
    "    lr=config[\"learning_rate\"],\n",
    "    momentum=config[\"momentum\"],\n",
    "    weight_decay=config[\"weight_decay\"],\n",
    "    nesterov=True  # Nesterov 모멘텀 사용\n",
    ")\n",
    "\n",
    "# WarmUpLR 스케줄러 초기화\n",
    "warmup_steps = config[\"warmup_epochs\"] * len(trainloader)\n",
    "warmup_scheduler = WarmUpLR(optimizer, total_iters=warmup_steps)\n",
    "\n",
    "# 웜업 이후 사용할 스케줄러 설정 \n",
    "main_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    mode='max',          \n",
    "    factor=0.5,          \n",
    "    patience=5,          \n",
    "    verbose=True,        \n",
    "    threshold=0.01,      \n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "# WandB에 모델 구조 기록\n",
    "wandb.watch(model, log=\"all\")\n",
    "\n",
    "# GPU 가속\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"{torch.cuda.device_count()}개의 GPU를 사용합니다.\")\n",
    "    model = nn.DataParallel(model)\n",
    "    \n",
    "# 모델 상태 요약 출력\n",
    "print(f\"Model: WideResNet-{config['depth']}-{config['widen_factor']}\")\n",
    "print(f\"Batch size: {config['batch_size']}\")\n",
    "print(f\"Learning rate: {config['learning_rate']}\")\n",
    "print(f\"Optimizer: {config['optimizer']} with SAM\")\n",
    "print(f\"Dropout rate: {config['dropout_rate']}\")\n",
    "\n",
    "# 학습 재개 상태 출력\n",
    "if resume_training:\n",
    "    print(f\"학습을 재개합니다. 체크포인트 파일: {checkpoint_path}\")\n",
    "else:\n",
    "    print(\"처음부터 학습을 시작합니다.\")\n",
    "\n",
    "# 훈련 시작 시간 기록\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    # 메인 학습 루프 호출\n",
    "    main_training_loop(\n",
    "        model=model,\n",
    "        trainloader=trainloader,\n",
    "        testloader=testloader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        device=device,\n",
    "        num_epochs=config[\"num_epochs\"],\n",
    "        patience=config[\"patience\"],\n",
    "        max_epochs_wait=config[\"max_epochs_wait\"],\n",
    "        warmup_scheduler=warmup_scheduler,\n",
    "        main_scheduler=main_scheduler,\n",
    "        warmup_epochs=config[\"warmup_epochs\"],\n",
    "        resume=resume_training,  # 학습 재개 여부\n",
    "        checkpoint_path=checkpoint_path  # 체크포인트 파일 경로\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"학습 중 오류 발생: {e}\")\n",
    "    # 오류 발생시 메모리 상태 출력\n",
    "    print_gpu_memory()\n",
    "    # 오류가 발생해도 체크포인트 저장을 시도\n",
    "    try:\n",
    "        save_checkpoint(model, optimizer, main_scheduler, epoch, best_test_acc_top1, 'error_checkpoint.pt')\n",
    "        print(\"오류 발생 시점의 체크포인트가 저장되었습니다.\")\n",
    "    except Exception as checkpoint_error:\n",
    "        print(f\"체크포인트 저장 실패: {checkpoint_error}\")\n",
    "    raise\n",
    "\n",
    "# 훈련 종료 시간 기록 및 출력\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "wandb.log({\"total_training_time\": total_time})\n",
    "\n",
    "print(f\"전체 학습 시간: {total_time:.2f} 초\")\n",
    "print(f\"전체 학습 시간: {total_time/3600:.2f} 시간\")\n",
    "\n",
    "# 최종 메모리 상태 출력\n",
    "print_gpu_memory()\n",
    "\n",
    "# WandB 실행 종료\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a335fa8-5b9c-49b7-9aac-11448f0e0225",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
