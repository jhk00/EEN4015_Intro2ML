{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "516f9d5f-6361-4b03-98ee-e1ba4de86b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/guswls/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msokjh1310\u001b[0m (\u001b[33msokjh1310-hanyang-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/guswls/EEN4015_Intro2ML/pbl-2/wandb/run-20250423_124736-w42pw9w1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/w42pw9w1' target=\"_blank\">resnext50_cfc,lr=0.005,factor=0.5,SGD_standard</a></strong> to <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/w42pw9w1' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/w42pw9w1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Train set size: 50000\n",
      "Test set size: 10000\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2개의 GPU를 사용합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                       | 0/300 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Batch [50/391], Loss: 4.8110, LR: 0.000064\n",
      "Epoch [1], Batch [100/391], Loss: 4.6512, LR: 0.000128\n",
      "Epoch [1], Batch [150/391], Loss: 4.6618, LR: 0.000192\n",
      "Epoch [1], Batch [200/391], Loss: 4.6499, LR: 0.000256\n",
      "Epoch [1], Batch [250/391], Loss: 4.6176, LR: 0.000320\n",
      "Epoch [1], Batch [300/391], Loss: 4.6330, LR: 0.000384\n",
      "Epoch [1], Batch [350/391], Loss: 4.6641, LR: 0.000448\n",
      "Train set: Epoch: 1, Average loss:4.6818, LR: 0.000500 Top-1 Accuracy: 0.8080%, Top-5 Accuracy: 4.1320%, Time consumed:162.49s\n",
      "Test set: Epoch: 1, Average loss:4.5241, Top-1 Accuracy: 1.8900%, Top-5 Accuracy: 8.9100%, Time consumed:12.34s\n",
      "\n",
      "새로운 최고 top-1 정확도: 1.89%, top-5 정확도: 8.91%\n",
      "새로운 최고 top-5 정확도: 8.91%\n",
      "Accuracy improved (-inf% --> 1.89%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                                          | 1/300 [02:55<14:32:51, 175.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], Batch [50/391], Loss: 4.7414, LR: 0.000564\n",
      "Epoch [2], Batch [100/391], Loss: 4.7088, LR: 0.000628\n",
      "Epoch [2], Batch [150/391], Loss: 4.6433, LR: 0.000692\n",
      "Epoch [2], Batch [200/391], Loss: 4.7946, LR: 0.000756\n",
      "Epoch [2], Batch [250/391], Loss: 4.7416, LR: 0.000820\n",
      "Epoch [2], Batch [300/391], Loss: 4.6907, LR: 0.000884\n",
      "Epoch [2], Batch [350/391], Loss: 4.7098, LR: 0.000948\n",
      "Train set: Epoch: 2, Average loss:4.7188, LR: 0.001000 Top-1 Accuracy: 0.6020%, Top-5 Accuracy: 3.4460%, Time consumed:164.13s\n",
      "Test set: Epoch: 2, Average loss:4.6058, Top-1 Accuracy: 3.1700%, Top-5 Accuracy: 11.8500%, Time consumed:12.04s\n",
      "\n",
      "새로운 최고 top-1 정확도: 3.17%, top-5 정확도: 11.85%\n",
      "새로운 최고 top-5 정확도: 11.85%\n",
      "Accuracy improved (1.89% --> 3.17%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▌                                                                                          | 2/300 [05:51<14:33:53, 175.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3], Batch [50/391], Loss: 4.7986, LR: 0.001064\n",
      "Epoch [3], Batch [100/391], Loss: 4.7120, LR: 0.001128\n",
      "Epoch [3], Batch [150/391], Loss: 4.8195, LR: 0.001192\n",
      "Epoch [3], Batch [200/391], Loss: 4.7601, LR: 0.001256\n",
      "Epoch [3], Batch [250/391], Loss: 4.7554, LR: 0.001320\n",
      "Epoch [3], Batch [300/391], Loss: 4.7872, LR: 0.001384\n",
      "Epoch [3], Batch [350/391], Loss: 4.8536, LR: 0.001448\n",
      "Train set: Epoch: 3, Average loss:4.7949, LR: 0.001500 Top-1 Accuracy: 0.6780%, Top-5 Accuracy: 3.7600%, Time consumed:159.90s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▉                                                                                          | 3/300 [08:43<14:22:44, 174.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 3, Average loss:4.5410, Top-1 Accuracy: 2.7200%, Top-5 Accuracy: 11.7300%, Time consumed:12.41s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [4], Batch [50/391], Loss: 4.7568, LR: 0.001564\n",
      "Epoch [4], Batch [100/391], Loss: 4.6879, LR: 0.001628\n",
      "Epoch [4], Batch [150/391], Loss: 4.7642, LR: 0.001692\n",
      "Epoch [4], Batch [200/391], Loss: 4.7513, LR: 0.001756\n",
      "Epoch [4], Batch [250/391], Loss: 4.5313, LR: 0.001820\n",
      "Epoch [4], Batch [300/391], Loss: 4.5970, LR: 0.001884\n",
      "Epoch [4], Batch [350/391], Loss: 4.6278, LR: 0.001948\n",
      "Train set: Epoch: 4, Average loss:4.6741, LR: 0.002000 Top-1 Accuracy: 1.5400%, Top-5 Accuracy: 7.6140%, Time consumed:163.56s\n",
      "Test set: Epoch: 4, Average loss:4.2734, Top-1 Accuracy: 6.4100%, Top-5 Accuracy: 20.8700%, Time consumed:11.90s\n",
      "\n",
      "새로운 최고 top-1 정확도: 6.41%, top-5 정확도: 20.87%\n",
      "새로운 최고 top-5 정확도: 20.87%\n",
      "Accuracy improved (3.17% --> 6.41%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▏                                                                                         | 4/300 [11:39<14:22:45, 174.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5], Batch [50/391], Loss: 4.4882, LR: 0.002064\n",
      "Epoch [5], Batch [100/391], Loss: 4.5295, LR: 0.002128\n",
      "Epoch [5], Batch [150/391], Loss: 4.3663, LR: 0.002192\n",
      "Epoch [5], Batch [200/391], Loss: 4.4452, LR: 0.002256\n",
      "Epoch [5], Batch [250/391], Loss: 4.4120, LR: 0.002320\n",
      "Epoch [5], Batch [300/391], Loss: 4.6433, LR: 0.002384\n",
      "Epoch [5], Batch [350/391], Loss: 4.2174, LR: 0.002448\n",
      "Train set: Epoch: 5, Average loss:4.4676, LR: 0.002500 Top-1 Accuracy: 3.0900%, Top-5 Accuracy: 14.0820%, Time consumed:161.27s\n",
      "Test set: Epoch: 5, Average loss:4.1491, Top-1 Accuracy: 7.8300%, Top-5 Accuracy: 26.5900%, Time consumed:12.40s\n",
      "\n",
      "새로운 최고 top-1 정확도: 7.83%, top-5 정확도: 26.59%\n",
      "새로운 최고 top-5 정확도: 26.59%\n",
      "Accuracy improved (6.41% --> 7.83%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▌                                                                                         | 5/300 [14:33<14:18:16, 174.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6], Batch [50/391], Loss: 4.3104, LR: 0.002564\n",
      "Epoch [6], Batch [100/391], Loss: 4.3617, LR: 0.002628\n",
      "Epoch [6], Batch [150/391], Loss: 4.1529, LR: 0.002692\n",
      "Epoch [6], Batch [200/391], Loss: 4.3362, LR: 0.002756\n",
      "Epoch [6], Batch [250/391], Loss: 4.3083, LR: 0.002820\n",
      "Epoch [6], Batch [300/391], Loss: 4.3393, LR: 0.002884\n",
      "Epoch [6], Batch [350/391], Loss: 4.3192, LR: 0.002948\n",
      "Train set: Epoch: 6, Average loss:4.3357, LR: 0.003000 Top-1 Accuracy: 5.1040%, Top-5 Accuracy: 19.1860%, Time consumed:161.08s\n",
      "Test set: Epoch: 6, Average loss:3.9971, Top-1 Accuracy: 10.6200%, Top-5 Accuracy: 31.4400%, Time consumed:11.71s\n",
      "\n",
      "새로운 최고 top-1 정확도: 10.62%, top-5 정확도: 31.44%\n",
      "새로운 최고 top-5 정확도: 31.44%\n",
      "Accuracy improved (7.83% --> 10.62%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▊                                                                                         | 6/300 [17:26<14:13:03, 174.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7], Batch [50/391], Loss: 4.5495, LR: 0.003064\n",
      "Epoch [7], Batch [100/391], Loss: 4.0997, LR: 0.003128\n",
      "Epoch [7], Batch [150/391], Loss: 4.2227, LR: 0.003192\n",
      "Epoch [7], Batch [200/391], Loss: 4.2861, LR: 0.003256\n",
      "Epoch [7], Batch [250/391], Loss: 4.2180, LR: 0.003320\n",
      "Epoch [7], Batch [300/391], Loss: 4.5292, LR: 0.003384\n",
      "Epoch [7], Batch [350/391], Loss: 4.0724, LR: 0.003448\n",
      "Train set: Epoch: 7, Average loss:4.2206, LR: 0.003500 Top-1 Accuracy: 7.0320%, Top-5 Accuracy: 23.7200%, Time consumed:164.90s\n",
      "Test set: Epoch: 7, Average loss:3.9143, Top-1 Accuracy: 12.5500%, Top-5 Accuracy: 34.2500%, Time consumed:13.72s\n",
      "\n",
      "새로운 최고 top-1 정확도: 12.55%, top-5 정확도: 34.25%\n",
      "새로운 최고 top-5 정확도: 34.25%\n",
      "Accuracy improved (10.62% --> 12.55%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██                                                                                         | 7/300 [20:25<14:17:57, 175.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8], Batch [50/391], Loss: 4.0714, LR: 0.003564\n",
      "Epoch [8], Batch [100/391], Loss: 4.1025, LR: 0.003628\n",
      "Epoch [8], Batch [150/391], Loss: 4.3004, LR: 0.003692\n",
      "Epoch [8], Batch [200/391], Loss: 3.9944, LR: 0.003756\n",
      "Epoch [8], Batch [250/391], Loss: 4.3496, LR: 0.003820\n",
      "Epoch [8], Batch [300/391], Loss: 4.0491, LR: 0.003884\n",
      "Epoch [8], Batch [350/391], Loss: 3.9962, LR: 0.003948\n",
      "Train set: Epoch: 8, Average loss:4.1274, LR: 0.004000 Top-1 Accuracy: 8.4320%, Top-5 Accuracy: 27.1680%, Time consumed:158.26s\n",
      "Test set: Epoch: 8, Average loss:3.7926, Top-1 Accuracy: 14.5700%, Top-5 Accuracy: 39.2300%, Time consumed:12.03s\n",
      "\n",
      "새로운 최고 top-1 정확도: 14.57%, top-5 정확도: 39.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▍                                                                                        | 8/300 [23:16<14:07:15, 174.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "새로운 최고 top-5 정확도: 39.23%\n",
      "Accuracy improved (12.55% --> 14.57%). Saving model ...\n",
      "Epoch [9], Batch [50/391], Loss: 4.1400, LR: 0.004064\n",
      "Epoch [9], Batch [100/391], Loss: 4.3684, LR: 0.004128\n",
      "Epoch [9], Batch [150/391], Loss: 3.9905, LR: 0.004192\n",
      "Epoch [9], Batch [200/391], Loss: 4.3069, LR: 0.004256\n",
      "Epoch [9], Batch [250/391], Loss: 4.1885, LR: 0.004320\n",
      "Epoch [9], Batch [300/391], Loss: 4.1209, LR: 0.004384\n",
      "Epoch [9], Batch [350/391], Loss: 3.8464, LR: 0.004448\n",
      "Train set: Epoch: 9, Average loss:4.0662, LR: 0.004500 Top-1 Accuracy: 9.7140%, Top-5 Accuracy: 30.0240%, Time consumed:160.82s\n",
      "Test set: Epoch: 9, Average loss:3.7037, Top-1 Accuracy: 17.0200%, Top-5 Accuracy: 42.7500%, Time consumed:12.27s\n",
      "\n",
      "새로운 최고 top-1 정확도: 17.02%, top-5 정확도: 42.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▋                                                                                        | 9/300 [26:10<14:03:27, 173.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "새로운 최고 top-5 정확도: 42.75%\n",
      "Accuracy improved (14.57% --> 17.02%). Saving model ...\n",
      "Epoch [10], Batch [50/391], Loss: 4.1931, LR: 0.004564\n",
      "Epoch [10], Batch [100/391], Loss: 4.3995, LR: 0.004628\n",
      "Epoch [10], Batch [150/391], Loss: 4.1011, LR: 0.004692\n",
      "Epoch [10], Batch [200/391], Loss: 4.2661, LR: 0.004756\n",
      "Epoch [10], Batch [250/391], Loss: 3.8032, LR: 0.004820\n",
      "Epoch [10], Batch [300/391], Loss: 3.8236, LR: 0.004884\n",
      "Epoch [10], Batch [350/391], Loss: 3.8741, LR: 0.004948\n",
      "Train set: Epoch: 10, Average loss:3.9732, LR: 0.005000 Top-1 Accuracy: 11.5140%, Top-5 Accuracy: 33.7360%, Time consumed:161.58s\n",
      "Test set: Epoch: 10, Average loss:3.5914, Top-1 Accuracy: 19.0000%, Top-5 Accuracy: 46.8800%, Time consumed:11.83s\n",
      "\n",
      "새로운 최고 top-1 정확도: 19.00%, top-5 정확도: 46.88%\n",
      "새로운 최고 top-5 정확도: 46.88%\n",
      "Accuracy improved (17.02% --> 19.00%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|███                                                                                       | 10/300 [29:03<14:00:22, 173.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11], Batch [50/391], Loss: 3.7795, LR: 0.005000\n",
      "Epoch [11], Batch [100/391], Loss: 4.0331, LR: 0.005000\n",
      "Epoch [11], Batch [150/391], Loss: 3.8739, LR: 0.005000\n",
      "Epoch [11], Batch [200/391], Loss: 3.9282, LR: 0.005000\n",
      "Epoch [11], Batch [250/391], Loss: 4.3760, LR: 0.005000\n",
      "Epoch [11], Batch [300/391], Loss: 3.4678, LR: 0.005000\n",
      "Epoch [11], Batch [350/391], Loss: 3.7230, LR: 0.005000\n",
      "Train set: Epoch: 11, Average loss:3.8682, LR: 0.005000 Top-1 Accuracy: 13.3900%, Top-5 Accuracy: 37.3700%, Time consumed:163.50s\n",
      "Test set: Epoch: 11, Average loss:3.4809, Top-1 Accuracy: 21.5900%, Top-5 Accuracy: 49.7100%, Time consumed:12.00s\n",
      "\n",
      "새로운 최고 top-1 정확도: 21.59%, top-5 정확도: 49.71%\n",
      "새로운 최고 top-5 정확도: 49.71%\n",
      "Accuracy improved (19.00% --> 21.59%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▎                                                                                      | 11/300 [31:59<14:00:25, 174.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12], Batch [50/391], Loss: 4.0086, LR: 0.005000\n",
      "Epoch [12], Batch [100/391], Loss: 3.9994, LR: 0.005000\n",
      "Epoch [12], Batch [150/391], Loss: 3.5448, LR: 0.005000\n",
      "Epoch [12], Batch [200/391], Loss: 4.5106, LR: 0.005000\n",
      "Epoch [12], Batch [250/391], Loss: 3.6786, LR: 0.005000\n",
      "Epoch [12], Batch [300/391], Loss: 3.6810, LR: 0.005000\n",
      "Epoch [12], Batch [350/391], Loss: 3.4574, LR: 0.005000\n",
      "Train set: Epoch: 12, Average loss:3.7807, LR: 0.005000 Top-1 Accuracy: 15.3880%, Top-5 Accuracy: 40.1980%, Time consumed:162.45s\n",
      "Test set: Epoch: 12, Average loss:3.3730, Top-1 Accuracy: 23.7300%, Top-5 Accuracy: 52.8600%, Time consumed:12.10s\n",
      "\n",
      "새로운 최고 top-1 정확도: 23.73%, top-5 정확도: 52.86%\n",
      "새로운 최고 top-5 정확도: 52.86%\n",
      "Accuracy improved (21.59% --> 23.73%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▌                                                                                      | 12/300 [34:54<13:58:08, 174.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13], Batch [50/391], Loss: 3.5173, LR: 0.005000\n",
      "Epoch [13], Batch [100/391], Loss: 3.5302, LR: 0.005000\n",
      "Epoch [13], Batch [150/391], Loss: 3.4432, LR: 0.005000\n",
      "Epoch [13], Batch [200/391], Loss: 3.3668, LR: 0.005000\n",
      "Epoch [13], Batch [250/391], Loss: 3.4737, LR: 0.005000\n",
      "Epoch [13], Batch [300/391], Loss: 3.4852, LR: 0.005000\n",
      "Epoch [13], Batch [350/391], Loss: 3.5380, LR: 0.005000\n",
      "Train set: Epoch: 13, Average loss:3.6954, LR: 0.005000 Top-1 Accuracy: 17.4880%, Top-5 Accuracy: 43.5200%, Time consumed:163.59s\n",
      "Test set: Epoch: 13, Average loss:3.2357, Top-1 Accuracy: 27.1600%, Top-5 Accuracy: 57.5300%, Time consumed:12.62s\n",
      "\n",
      "새로운 최고 top-1 정확도: 27.16%, top-5 정확도: 57.53%\n",
      "새로운 최고 top-5 정확도: 57.53%\n",
      "Accuracy improved (23.73% --> 27.16%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▉                                                                                      | 13/300 [37:51<13:58:03, 175.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14], Batch [50/391], Loss: 4.1166, LR: 0.005000\n",
      "Epoch [14], Batch [100/391], Loss: 3.4880, LR: 0.005000\n",
      "Epoch [14], Batch [150/391], Loss: 3.3477, LR: 0.005000\n",
      "Epoch [14], Batch [200/391], Loss: 2.9781, LR: 0.005000\n",
      "Epoch [14], Batch [250/391], Loss: 3.2927, LR: 0.005000\n",
      "Epoch [14], Batch [300/391], Loss: 3.9461, LR: 0.005000\n",
      "Epoch [14], Batch [350/391], Loss: 3.9593, LR: 0.005000\n",
      "Train set: Epoch: 14, Average loss:3.6161, LR: 0.005000 Top-1 Accuracy: 19.4200%, Top-5 Accuracy: 46.2020%, Time consumed:160.48s\n",
      "Test set: Epoch: 14, Average loss:3.1360, Top-1 Accuracy: 29.2200%, Top-5 Accuracy: 60.4400%, Time consumed:12.04s\n",
      "\n",
      "새로운 최고 top-1 정확도: 29.22%, top-5 정확도: 60.44%\n",
      "새로운 최고 top-5 정확도: 60.44%\n",
      "Accuracy improved (27.16% --> 29.22%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▏                                                                                     | 14/300 [40:44<13:51:47, 174.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15], Batch [50/391], Loss: 3.2713, LR: 0.005000\n",
      "Epoch [15], Batch [100/391], Loss: 3.3617, LR: 0.005000\n",
      "Epoch [15], Batch [150/391], Loss: 3.8251, LR: 0.005000\n",
      "Epoch [15], Batch [200/391], Loss: 3.2728, LR: 0.005000\n",
      "Epoch [15], Batch [250/391], Loss: 3.2329, LR: 0.005000\n",
      "Epoch [15], Batch [300/391], Loss: 3.6247, LR: 0.005000\n",
      "Epoch [15], Batch [350/391], Loss: 3.2975, LR: 0.005000\n",
      "Train set: Epoch: 15, Average loss:3.4860, LR: 0.005000 Top-1 Accuracy: 21.8680%, Top-5 Accuracy: 50.3580%, Time consumed:164.85s\n",
      "Test set: Epoch: 15, Average loss:3.0894, Top-1 Accuracy: 31.4200%, Top-5 Accuracy: 62.9500%, Time consumed:11.82s\n",
      "\n",
      "새로운 최고 top-1 정확도: 31.42%, top-5 정확도: 62.95%\n",
      "새로운 최고 top-5 정확도: 62.95%\n",
      "Accuracy improved (29.22% --> 31.42%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▌                                                                                     | 15/300 [43:41<13:52:28, 175.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16], Batch [50/391], Loss: 3.8813, LR: 0.005000\n",
      "Epoch [16], Batch [100/391], Loss: 3.1584, LR: 0.005000\n",
      "Epoch [16], Batch [150/391], Loss: 3.9666, LR: 0.005000\n",
      "Epoch [16], Batch [200/391], Loss: 3.8882, LR: 0.005000\n",
      "Epoch [16], Batch [250/391], Loss: 3.0941, LR: 0.005000\n",
      "Epoch [16], Batch [300/391], Loss: 4.0268, LR: 0.005000\n",
      "Epoch [16], Batch [350/391], Loss: 3.1098, LR: 0.005000\n",
      "Train set: Epoch: 16, Average loss:3.4238, LR: 0.005000 Top-1 Accuracy: 23.4980%, Top-5 Accuracy: 52.3040%, Time consumed:164.57s\n",
      "Test set: Epoch: 16, Average loss:2.9265, Top-1 Accuracy: 34.6500%, Top-5 Accuracy: 66.6200%, Time consumed:12.20s\n",
      "\n",
      "새로운 최고 top-1 정확도: 34.65%, top-5 정확도: 66.62%\n",
      "새로운 최고 top-5 정확도: 66.62%\n",
      "Accuracy improved (31.42% --> 34.65%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▊                                                                                     | 16/300 [46:38<13:52:15, 175.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17], Batch [50/391], Loss: 3.9929, LR: 0.005000\n",
      "Epoch [17], Batch [100/391], Loss: 3.1202, LR: 0.005000\n",
      "Epoch [17], Batch [150/391], Loss: 3.8904, LR: 0.005000\n",
      "Epoch [17], Batch [200/391], Loss: 3.0781, LR: 0.005000\n",
      "Epoch [17], Batch [250/391], Loss: 3.5226, LR: 0.005000\n",
      "Epoch [17], Batch [300/391], Loss: 2.9221, LR: 0.005000\n",
      "Epoch [17], Batch [350/391], Loss: 3.5923, LR: 0.005000\n",
      "Train set: Epoch: 17, Average loss:3.3044, LR: 0.005000 Top-1 Accuracy: 26.1360%, Top-5 Accuracy: 55.9480%, Time consumed:160.49s\n",
      "Test set: Epoch: 17, Average loss:2.8567, Top-1 Accuracy: 36.2800%, Top-5 Accuracy: 69.0700%, Time consumed:11.95s\n",
      "\n",
      "새로운 최고 top-1 정확도: 36.28%, top-5 정확도: 69.07%\n",
      "새로운 최고 top-5 정확도: 69.07%\n",
      "Accuracy improved (34.65% --> 36.28%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████                                                                                     | 17/300 [49:31<13:45:01, 174.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18], Batch [50/391], Loss: 2.9692, LR: 0.005000\n",
      "Epoch [18], Batch [100/391], Loss: 3.0427, LR: 0.005000\n",
      "Epoch [18], Batch [150/391], Loss: 3.3291, LR: 0.005000\n",
      "Epoch [18], Batch [200/391], Loss: 3.6494, LR: 0.005000\n",
      "Epoch [18], Batch [250/391], Loss: 3.1041, LR: 0.005000\n",
      "Epoch [18], Batch [300/391], Loss: 3.0556, LR: 0.005000\n",
      "Epoch [18], Batch [350/391], Loss: 2.9345, LR: 0.005000\n",
      "Train set: Epoch: 18, Average loss:3.2801, LR: 0.005000 Top-1 Accuracy: 26.9960%, Top-5 Accuracy: 56.8760%, Time consumed:163.23s\n",
      "Test set: Epoch: 18, Average loss:2.7839, Top-1 Accuracy: 38.4200%, Top-5 Accuracy: 70.6800%, Time consumed:12.30s\n",
      "\n",
      "새로운 최고 top-1 정확도: 38.42%, top-5 정확도: 70.68%\n",
      "새로운 최고 top-5 정확도: 70.68%\n",
      "Accuracy improved (36.28% --> 38.42%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████▍                                                                                    | 18/300 [52:26<13:43:28, 175.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19], Batch [50/391], Loss: 3.9881, LR: 0.005000\n",
      "Epoch [19], Batch [100/391], Loss: 2.8772, LR: 0.005000\n",
      "Epoch [19], Batch [150/391], Loss: 3.0221, LR: 0.005000\n",
      "Epoch [19], Batch [200/391], Loss: 2.9038, LR: 0.005000\n",
      "Epoch [19], Batch [250/391], Loss: 3.6474, LR: 0.005000\n",
      "Epoch [19], Batch [300/391], Loss: 3.1544, LR: 0.005000\n",
      "Epoch [19], Batch [350/391], Loss: 2.8124, LR: 0.005000\n",
      "Train set: Epoch: 19, Average loss:3.2129, LR: 0.005000 Top-1 Accuracy: 29.0540%, Top-5 Accuracy: 59.5460%, Time consumed:159.94s\n",
      "Test set: Epoch: 19, Average loss:2.7316, Top-1 Accuracy: 40.6200%, Top-5 Accuracy: 73.0700%, Time consumed:11.95s\n",
      "\n",
      "새로운 최고 top-1 정확도: 40.62%, top-5 정확도: 73.07%\n",
      "새로운 최고 top-5 정확도: 73.07%\n",
      "Accuracy improved (38.42% --> 40.62%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████▋                                                                                    | 19/300 [55:19<13:36:22, 174.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20], Batch [50/391], Loss: 4.0073, LR: 0.005000\n",
      "Epoch [20], Batch [100/391], Loss: 2.8690, LR: 0.005000\n",
      "Epoch [20], Batch [150/391], Loss: 3.2257, LR: 0.005000\n",
      "Epoch [20], Batch [200/391], Loss: 2.7893, LR: 0.005000\n",
      "Epoch [20], Batch [250/391], Loss: 2.4000, LR: 0.005000\n",
      "Epoch [20], Batch [300/391], Loss: 2.8115, LR: 0.005000\n",
      "Epoch [20], Batch [350/391], Loss: 3.5075, LR: 0.005000\n",
      "Train set: Epoch: 20, Average loss:3.1334, LR: 0.005000 Top-1 Accuracy: 31.0060%, Top-5 Accuracy: 61.3840%, Time consumed:160.06s\n",
      "Test set: Epoch: 20, Average loss:2.6423, Top-1 Accuracy: 43.0500%, Top-5 Accuracy: 74.6800%, Time consumed:12.44s\n",
      "\n",
      "새로운 최고 top-1 정확도: 43.05%, top-5 정확도: 74.68%\n",
      "새로운 최고 top-5 정확도: 74.68%\n",
      "Accuracy improved (40.62% --> 43.05%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████                                                                                    | 20/300 [58:12<13:31:24, 173.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21], Batch [50/391], Loss: 3.4087, LR: 0.005000\n",
      "Epoch [21], Batch [100/391], Loss: 2.9252, LR: 0.005000\n",
      "Epoch [21], Batch [150/391], Loss: 2.8610, LR: 0.005000\n",
      "Epoch [21], Batch [200/391], Loss: 2.4011, LR: 0.005000\n",
      "Epoch [21], Batch [250/391], Loss: 2.8038, LR: 0.005000\n",
      "Epoch [21], Batch [300/391], Loss: 2.7671, LR: 0.005000\n",
      "Epoch [21], Batch [350/391], Loss: 3.8374, LR: 0.005000\n",
      "Train set: Epoch: 21, Average loss:3.0712, LR: 0.005000 Top-1 Accuracy: 32.5560%, Top-5 Accuracy: 63.6200%, Time consumed:158.90s\n",
      "Test set: Epoch: 21, Average loss:2.5417, Top-1 Accuracy: 45.5900%, Top-5 Accuracy: 77.1100%, Time consumed:12.11s\n",
      "\n",
      "새로운 최고 top-1 정확도: 45.59%, top-5 정확도: 77.11%\n",
      "새로운 최고 top-5 정확도: 77.11%\n",
      "Accuracy improved (43.05% --> 45.59%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████▏                                                                                 | 21/300 [1:01:03<13:25:01, 173.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22], Batch [50/391], Loss: 2.6196, LR: 0.005000\n",
      "Epoch [22], Batch [100/391], Loss: 3.9992, LR: 0.005000\n",
      "Epoch [22], Batch [150/391], Loss: 3.7720, LR: 0.005000\n",
      "Epoch [22], Batch [200/391], Loss: 2.6704, LR: 0.005000\n",
      "Epoch [22], Batch [250/391], Loss: 3.5810, LR: 0.005000\n",
      "Epoch [22], Batch [300/391], Loss: 2.7545, LR: 0.005000\n",
      "Epoch [22], Batch [350/391], Loss: 3.8668, LR: 0.005000\n",
      "Train set: Epoch: 22, Average loss:3.0504, LR: 0.005000 Top-1 Accuracy: 33.4240%, Top-5 Accuracy: 64.1720%, Time consumed:164.80s\n",
      "Test set: Epoch: 22, Average loss:2.5155, Top-1 Accuracy: 46.3200%, Top-5 Accuracy: 77.6700%, Time consumed:12.25s\n",
      "\n",
      "새로운 최고 top-1 정확도: 46.32%, top-5 정확도: 77.67%\n",
      "새로운 최고 top-5 정확도: 77.67%\n",
      "Accuracy improved (45.59% --> 46.32%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████▍                                                                                 | 22/300 [1:04:00<13:28:02, 174.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23], Batch [50/391], Loss: 2.5986, LR: 0.005000\n",
      "Epoch [23], Batch [100/391], Loss: 3.7905, LR: 0.005000\n",
      "Epoch [23], Batch [150/391], Loss: 3.6907, LR: 0.005000\n",
      "Epoch [23], Batch [200/391], Loss: 2.7198, LR: 0.005000\n",
      "Epoch [23], Batch [250/391], Loss: 2.6094, LR: 0.005000\n",
      "Epoch [23], Batch [300/391], Loss: 2.5507, LR: 0.005000\n",
      "Epoch [23], Batch [350/391], Loss: 2.9603, LR: 0.005000\n",
      "Train set: Epoch: 23, Average loss:2.9569, LR: 0.005000 Top-1 Accuracy: 35.5720%, Top-5 Accuracy: 66.0980%, Time consumed:157.32s\n",
      "Test set: Epoch: 23, Average loss:2.4956, Top-1 Accuracy: 47.6800%, Top-5 Accuracy: 77.8700%, Time consumed:11.68s\n",
      "\n",
      "새로운 최고 top-1 정확도: 47.68%, top-5 정확도: 77.87%\n",
      "새로운 최고 top-5 정확도: 77.87%\n",
      "Accuracy improved (46.32% --> 47.68%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▋                                                                                 | 23/300 [1:06:50<13:18:06, 172.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24], Batch [50/391], Loss: 2.7638, LR: 0.005000\n",
      "Epoch [24], Batch [100/391], Loss: 3.0776, LR: 0.005000\n",
      "Epoch [24], Batch [150/391], Loss: 3.4801, LR: 0.005000\n",
      "Epoch [24], Batch [200/391], Loss: 2.6174, LR: 0.005000\n",
      "Epoch [24], Batch [250/391], Loss: 3.4644, LR: 0.005000\n",
      "Epoch [24], Batch [300/391], Loss: 3.0639, LR: 0.005000\n",
      "Epoch [24], Batch [350/391], Loss: 2.8556, LR: 0.005000\n",
      "Train set: Epoch: 24, Average loss:2.9263, LR: 0.005000 Top-1 Accuracy: 36.7680%, Top-5 Accuracy: 67.5460%, Time consumed:158.43s\n",
      "Test set: Epoch: 24, Average loss:2.4144, Top-1 Accuracy: 48.8000%, Top-5 Accuracy: 79.6500%, Time consumed:11.77s\n",
      "\n",
      "새로운 최고 top-1 정확도: 48.80%, top-5 정확도: 79.65%\n",
      "새로운 최고 top-5 정확도: 79.65%\n",
      "Accuracy improved (47.68% --> 48.80%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███████                                                                                 | 24/300 [1:09:40<13:11:58, 172.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25], Batch [50/391], Loss: 3.3833, LR: 0.005000\n",
      "Epoch [25], Batch [100/391], Loss: 2.7561, LR: 0.005000\n",
      "Epoch [25], Batch [150/391], Loss: 3.6470, LR: 0.005000\n",
      "Epoch [25], Batch [200/391], Loss: 2.7088, LR: 0.005000\n",
      "Epoch [25], Batch [250/391], Loss: 2.5516, LR: 0.005000\n",
      "Epoch [25], Batch [300/391], Loss: 2.4589, LR: 0.005000\n",
      "Epoch [25], Batch [350/391], Loss: 2.4871, LR: 0.005000\n",
      "Train set: Epoch: 25, Average loss:2.8615, LR: 0.005000 Top-1 Accuracy: 38.1680%, Top-5 Accuracy: 68.8340%, Time consumed:158.93s\n",
      "Test set: Epoch: 25, Average loss:2.3820, Top-1 Accuracy: 50.7600%, Top-5 Accuracy: 80.6600%, Time consumed:11.69s\n",
      "\n",
      "새로운 최고 top-1 정확도: 50.76%, top-5 정확도: 80.66%\n",
      "새로운 최고 top-5 정확도: 80.66%\n",
      "Accuracy improved (48.80% --> 50.76%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███████▎                                                                                | 25/300 [1:12:31<13:07:25, 171.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26], Batch [50/391], Loss: 2.5365, LR: 0.005000\n",
      "Epoch [26], Batch [100/391], Loss: 2.0830, LR: 0.005000\n",
      "Epoch [26], Batch [150/391], Loss: 2.3905, LR: 0.005000\n",
      "Epoch [26], Batch [200/391], Loss: 3.4487, LR: 0.005000\n",
      "Epoch [26], Batch [250/391], Loss: 2.2204, LR: 0.005000\n",
      "Epoch [26], Batch [300/391], Loss: 2.5655, LR: 0.005000\n",
      "Epoch [26], Batch [350/391], Loss: 2.4221, LR: 0.005000\n",
      "Train set: Epoch: 26, Average loss:2.8398, LR: 0.005000 Top-1 Accuracy: 38.8060%, Top-5 Accuracy: 69.1340%, Time consumed:159.99s\n",
      "Test set: Epoch: 26, Average loss:2.3586, Top-1 Accuracy: 51.4000%, Top-5 Accuracy: 80.9300%, Time consumed:12.01s\n",
      "\n",
      "새로운 최고 top-1 정확도: 51.40%, top-5 정확도: 80.93%\n",
      "새로운 최고 top-5 정확도: 80.93%\n",
      "Accuracy improved (50.76% --> 51.40%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███████▋                                                                                | 26/300 [1:15:23<13:05:20, 171.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27], Batch [50/391], Loss: 2.3313, LR: 0.005000\n",
      "Epoch [27], Batch [100/391], Loss: 3.0529, LR: 0.005000\n",
      "Epoch [27], Batch [150/391], Loss: 2.6739, LR: 0.005000\n",
      "Epoch [27], Batch [200/391], Loss: 3.5896, LR: 0.005000\n",
      "Epoch [27], Batch [250/391], Loss: 3.2562, LR: 0.005000\n",
      "Epoch [27], Batch [300/391], Loss: 3.5025, LR: 0.005000\n",
      "Epoch [27], Batch [350/391], Loss: 2.3747, LR: 0.005000\n",
      "Train set: Epoch: 27, Average loss:2.8504, LR: 0.005000 Top-1 Accuracy: 39.3200%, Top-5 Accuracy: 69.8500%, Time consumed:159.04s\n",
      "Test set: Epoch: 27, Average loss:2.3171, Top-1 Accuracy: 52.4400%, Top-5 Accuracy: 81.7200%, Time consumed:12.26s\n",
      "\n",
      "새로운 최고 top-1 정확도: 52.44%, top-5 정확도: 81.72%\n",
      "새로운 최고 top-5 정확도: 81.72%\n",
      "Accuracy improved (51.40% --> 52.44%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███████▉                                                                                | 27/300 [1:18:15<13:02:04, 171.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28], Batch [50/391], Loss: 2.4309, LR: 0.005000\n",
      "Epoch [28], Batch [100/391], Loss: 3.0509, LR: 0.005000\n",
      "Epoch [28], Batch [150/391], Loss: 3.0689, LR: 0.005000\n",
      "Epoch [28], Batch [200/391], Loss: 2.4552, LR: 0.005000\n",
      "Epoch [28], Batch [250/391], Loss: 2.3644, LR: 0.005000\n",
      "Epoch [28], Batch [300/391], Loss: 2.8389, LR: 0.005000\n",
      "Epoch [28], Batch [350/391], Loss: 3.1857, LR: 0.005000\n",
      "Train set: Epoch: 28, Average loss:2.7328, LR: 0.005000 Top-1 Accuracy: 42.1720%, Top-5 Accuracy: 72.6680%, Time consumed:162.97s\n",
      "Test set: Epoch: 28, Average loss:2.2413, Top-1 Accuracy: 54.2400%, Top-5 Accuracy: 83.6000%, Time consumed:12.34s\n",
      "\n",
      "새로운 최고 top-1 정확도: 54.24%, top-5 정확도: 83.60%\n",
      "새로운 최고 top-5 정확도: 83.60%\n",
      "Accuracy improved (52.44% --> 54.24%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|████████▏                                                                               | 28/300 [1:21:11<13:04:19, 173.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29], Batch [50/391], Loss: 3.2526, LR: 0.005000\n",
      "Epoch [29], Batch [100/391], Loss: 3.5628, LR: 0.005000\n",
      "Epoch [29], Batch [150/391], Loss: 3.4662, LR: 0.005000\n",
      "Epoch [29], Batch [200/391], Loss: 2.1357, LR: 0.005000\n",
      "Epoch [29], Batch [250/391], Loss: 3.0651, LR: 0.005000\n",
      "Epoch [29], Batch [300/391], Loss: 2.2185, LR: 0.005000\n",
      "Epoch [29], Batch [350/391], Loss: 3.3713, LR: 0.005000\n",
      "Train set: Epoch: 29, Average loss:2.6479, LR: 0.005000 Top-1 Accuracy: 44.1920%, Top-5 Accuracy: 74.7260%, Time consumed:166.47s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▌                                                                               | 29/300 [1:24:09<13:08:39, 174.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 29, Average loss:2.2805, Top-1 Accuracy: 53.4800%, Top-5 Accuracy: 83.0000%, Time consumed:11.86s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [30], Batch [50/391], Loss: 3.5664, LR: 0.005000\n",
      "Epoch [30], Batch [100/391], Loss: 2.0993, LR: 0.005000\n",
      "Epoch [30], Batch [150/391], Loss: 2.4242, LR: 0.005000\n",
      "Epoch [30], Batch [200/391], Loss: 2.3813, LR: 0.005000\n",
      "Epoch [30], Batch [250/391], Loss: 2.3485, LR: 0.005000\n",
      "Epoch [30], Batch [300/391], Loss: 2.3768, LR: 0.005000\n",
      "Epoch [30], Batch [350/391], Loss: 2.3676, LR: 0.005000\n",
      "Train set: Epoch: 30, Average loss:2.6839, LR: 0.005000 Top-1 Accuracy: 43.2760%, Top-5 Accuracy: 73.6580%, Time consumed:158.99s\n",
      "Test set: Epoch: 30, Average loss:2.2242, Top-1 Accuracy: 55.9200%, Top-5 Accuracy: 84.3000%, Time consumed:12.05s\n",
      "\n",
      "새로운 최고 top-1 정확도: 55.92%, top-5 정확도: 84.30%\n",
      "새로운 최고 top-5 정확도: 84.30%\n",
      "Accuracy improved (54.24% --> 55.92%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▊                                                                               | 30/300 [1:27:01<13:01:24, 173.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31], Batch [50/391], Loss: 3.4992, LR: 0.005000\n",
      "Epoch [31], Batch [100/391], Loss: 2.2067, LR: 0.005000\n",
      "Epoch [31], Batch [150/391], Loss: 2.1175, LR: 0.005000\n",
      "Epoch [31], Batch [200/391], Loss: 3.6168, LR: 0.005000\n",
      "Epoch [31], Batch [250/391], Loss: 2.1641, LR: 0.005000\n",
      "Epoch [31], Batch [300/391], Loss: 2.4073, LR: 0.005000\n",
      "Epoch [31], Batch [350/391], Loss: 2.2111, LR: 0.005000\n",
      "Train set: Epoch: 31, Average loss:2.6191, LR: 0.005000 Top-1 Accuracy: 45.4940%, Top-5 Accuracy: 74.7000%, Time consumed:163.49s\n",
      "Test set: Epoch: 31, Average loss:2.1748, Top-1 Accuracy: 56.0200%, Top-5 Accuracy: 84.6900%, Time consumed:12.38s\n",
      "\n",
      "새로운 최고 top-1 정확도: 56.02%, top-5 정확도: 84.69%\n",
      "새로운 최고 top-5 정확도: 84.69%\n",
      "Accuracy improved (55.92% --> 56.02%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█████████                                                                               | 31/300 [1:29:57<13:01:58, 174.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32], Batch [50/391], Loss: 2.2614, LR: 0.005000\n",
      "Epoch [32], Batch [100/391], Loss: 2.6123, LR: 0.005000\n",
      "Epoch [32], Batch [150/391], Loss: 2.3029, LR: 0.005000\n",
      "Epoch [32], Batch [200/391], Loss: 2.2643, LR: 0.005000\n",
      "Epoch [32], Batch [250/391], Loss: 2.0972, LR: 0.005000\n",
      "Epoch [32], Batch [300/391], Loss: 2.0926, LR: 0.005000\n",
      "Epoch [32], Batch [350/391], Loss: 2.0757, LR: 0.005000\n",
      "Train set: Epoch: 32, Average loss:2.5941, LR: 0.005000 Top-1 Accuracy: 46.0880%, Top-5 Accuracy: 75.6340%, Time consumed:157.90s\n",
      "Test set: Epoch: 32, Average loss:2.2213, Top-1 Accuracy: 56.6200%, Top-5 Accuracy: 84.3800%, Time consumed:12.66s\n",
      "\n",
      "새로운 최고 top-1 정확도: 56.62%, top-5 정확도: 84.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█████████▍                                                                              | 32/300 [1:32:48<12:54:27, 173.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy improved (56.02% --> 56.62%). Saving model ...\n",
      "Epoch [33], Batch [50/391], Loss: 1.9976, LR: 0.005000\n",
      "Epoch [33], Batch [100/391], Loss: 2.4320, LR: 0.005000\n",
      "Epoch [33], Batch [150/391], Loss: 2.2431, LR: 0.005000\n",
      "Epoch [33], Batch [200/391], Loss: 2.7055, LR: 0.005000\n",
      "Epoch [33], Batch [250/391], Loss: 2.7451, LR: 0.005000\n",
      "Epoch [33], Batch [300/391], Loss: 3.7102, LR: 0.005000\n",
      "Epoch [33], Batch [350/391], Loss: 2.3306, LR: 0.005000\n",
      "Train set: Epoch: 33, Average loss:2.5585, LR: 0.005000 Top-1 Accuracy: 47.5740%, Top-5 Accuracy: 77.0800%, Time consumed:157.78s\n",
      "Test set: Epoch: 33, Average loss:2.1322, Top-1 Accuracy: 57.5100%, Top-5 Accuracy: 85.3400%, Time consumed:12.07s\n",
      "\n",
      "새로운 최고 top-1 정확도: 57.51%, top-5 정확도: 85.34%\n",
      "새로운 최고 top-5 정확도: 85.34%\n",
      "Accuracy improved (56.62% --> 57.51%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█████████▋                                                                              | 33/300 [1:35:38<12:47:18, 172.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34], Batch [50/391], Loss: 2.1806, LR: 0.005000\n",
      "Epoch [34], Batch [100/391], Loss: 3.6330, LR: 0.005000\n",
      "Epoch [34], Batch [150/391], Loss: 2.9203, LR: 0.005000\n",
      "Epoch [34], Batch [200/391], Loss: 2.1965, LR: 0.005000\n",
      "Epoch [34], Batch [250/391], Loss: 2.1828, LR: 0.005000\n",
      "Epoch [34], Batch [300/391], Loss: 1.8926, LR: 0.005000\n",
      "Epoch [34], Batch [350/391], Loss: 2.3211, LR: 0.005000\n",
      "Train set: Epoch: 34, Average loss:2.5492, LR: 0.005000 Top-1 Accuracy: 47.3500%, Top-5 Accuracy: 76.2340%, Time consumed:158.88s\n",
      "Test set: Epoch: 34, Average loss:2.1331, Top-1 Accuracy: 57.9900%, Top-5 Accuracy: 85.5200%, Time consumed:12.57s\n",
      "\n",
      "새로운 최고 top-1 정확도: 57.99%, top-5 정확도: 85.52%\n",
      "새로운 최고 top-5 정확도: 85.52%\n",
      "Accuracy improved (57.51% --> 57.99%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█████████▉                                                                              | 34/300 [1:38:30<12:43:35, 172.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35], Batch [50/391], Loss: 2.0297, LR: 0.005000\n",
      "Epoch [35], Batch [100/391], Loss: 2.0498, LR: 0.005000\n",
      "Epoch [35], Batch [150/391], Loss: 3.3753, LR: 0.005000\n",
      "Epoch [35], Batch [200/391], Loss: 1.8351, LR: 0.005000\n",
      "Epoch [35], Batch [250/391], Loss: 2.7617, LR: 0.005000\n",
      "Epoch [35], Batch [300/391], Loss: 2.8933, LR: 0.005000\n",
      "Epoch [35], Batch [350/391], Loss: 2.0564, LR: 0.005000\n",
      "Train set: Epoch: 35, Average loss:2.4920, LR: 0.005000 Top-1 Accuracy: 48.4700%, Top-5 Accuracy: 77.0920%, Time consumed:164.62s\n",
      "Test set: Epoch: 35, Average loss:2.1040, Top-1 Accuracy: 58.9600%, Top-5 Accuracy: 86.2500%, Time consumed:13.14s\n",
      "\n",
      "새로운 최고 top-1 정확도: 58.96%, top-5 정확도: 86.25%\n",
      "새로운 최고 top-5 정확도: 86.25%\n",
      "Accuracy improved (57.99% --> 58.96%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████▎                                                                             | 35/300 [1:41:28<12:48:31, 174.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36], Batch [50/391], Loss: 1.9264, LR: 0.005000\n",
      "Epoch [36], Batch [100/391], Loss: 2.1542, LR: 0.005000\n",
      "Epoch [36], Batch [150/391], Loss: 2.1255, LR: 0.005000\n",
      "Epoch [36], Batch [200/391], Loss: 1.5995, LR: 0.005000\n",
      "Epoch [36], Batch [250/391], Loss: 3.2847, LR: 0.005000\n",
      "Epoch [36], Batch [300/391], Loss: 3.6415, LR: 0.005000\n",
      "Epoch [36], Batch [350/391], Loss: 2.1629, LR: 0.005000\n",
      "Train set: Epoch: 36, Average loss:2.4584, LR: 0.005000 Top-1 Accuracy: 49.9240%, Top-5 Accuracy: 78.5260%, Time consumed:158.19s\n",
      "Test set: Epoch: 36, Average loss:2.1592, Top-1 Accuracy: 59.1900%, Top-5 Accuracy: 85.8900%, Time consumed:11.90s\n",
      "\n",
      "새로운 최고 top-1 정확도: 59.19%, top-5 정확도: 85.89%\n",
      "Accuracy improved (58.96% --> 59.19%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████▌                                                                             | 36/300 [1:44:18<12:40:55, 172.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37], Batch [50/391], Loss: 3.3002, LR: 0.005000\n",
      "Epoch [37], Batch [100/391], Loss: 2.2352, LR: 0.005000\n",
      "Epoch [37], Batch [150/391], Loss: 2.0000, LR: 0.005000\n",
      "Epoch [37], Batch [200/391], Loss: 3.6271, LR: 0.005000\n",
      "Epoch [37], Batch [250/391], Loss: 1.7956, LR: 0.005000\n",
      "Epoch [37], Batch [300/391], Loss: 1.8639, LR: 0.005000\n",
      "Epoch [37], Batch [350/391], Loss: 2.6630, LR: 0.005000\n",
      "Train set: Epoch: 37, Average loss:2.4420, LR: 0.005000 Top-1 Accuracy: 50.6500%, Top-5 Accuracy: 78.9440%, Time consumed:160.84s\n",
      "Test set: Epoch: 37, Average loss:2.0435, Top-1 Accuracy: 60.5600%, Top-5 Accuracy: 86.8700%, Time consumed:12.13s\n",
      "\n",
      "새로운 최고 top-1 정확도: 60.56%, top-5 정확도: 86.87%\n",
      "새로운 최고 top-5 정확도: 86.87%\n",
      "Accuracy improved (59.19% --> 60.56%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████▊                                                                             | 37/300 [1:47:12<12:38:33, 173.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38], Batch [50/391], Loss: 1.8921, LR: 0.005000\n",
      "Epoch [38], Batch [100/391], Loss: 2.0365, LR: 0.005000\n",
      "Epoch [38], Batch [150/391], Loss: 3.3571, LR: 0.005000\n",
      "Epoch [38], Batch [200/391], Loss: 1.9077, LR: 0.005000\n",
      "Epoch [38], Batch [250/391], Loss: 2.0300, LR: 0.005000\n",
      "Epoch [38], Batch [300/391], Loss: 2.0543, LR: 0.005000\n",
      "Epoch [38], Batch [350/391], Loss: 2.0298, LR: 0.005000\n",
      "Train set: Epoch: 38, Average loss:2.4223, LR: 0.005000 Top-1 Accuracy: 51.0020%, Top-5 Accuracy: 78.6740%, Time consumed:163.38s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|███████████▏                                                                            | 38/300 [1:50:07<12:38:48, 173.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 38, Average loss:2.0336, Top-1 Accuracy: 60.4200%, Top-5 Accuracy: 87.4300%, Time consumed:12.07s\n",
      "\n",
      "새로운 최고 top-5 정확도: 87.43%\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [39], Batch [50/391], Loss: 2.0540, LR: 0.005000\n",
      "Epoch [39], Batch [100/391], Loss: 1.6553, LR: 0.005000\n",
      "Epoch [39], Batch [150/391], Loss: 1.8525, LR: 0.005000\n",
      "Epoch [39], Batch [200/391], Loss: 2.1188, LR: 0.005000\n",
      "Epoch [39], Batch [250/391], Loss: 3.6603, LR: 0.005000\n",
      "Epoch [39], Batch [300/391], Loss: 1.8898, LR: 0.005000\n",
      "Epoch [39], Batch [350/391], Loss: 3.5255, LR: 0.005000\n",
      "Train set: Epoch: 39, Average loss:2.4191, LR: 0.005000 Top-1 Accuracy: 51.5840%, Top-5 Accuracy: 79.1740%, Time consumed:166.23s\n",
      "Test set: Epoch: 39, Average loss:2.0005, Top-1 Accuracy: 61.8200%, Top-5 Accuracy: 87.7300%, Time consumed:12.92s\n",
      "\n",
      "새로운 최고 top-1 정확도: 61.82%, top-5 정확도: 87.73%\n",
      "새로운 최고 top-5 정확도: 87.73%\n",
      "Accuracy improved (60.56% --> 61.82%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|███████████▍                                                                            | 39/300 [1:53:07<12:43:23, 175.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40], Batch [50/391], Loss: 2.1085, LR: 0.005000\n",
      "Epoch [40], Batch [100/391], Loss: 1.9273, LR: 0.005000\n",
      "Epoch [40], Batch [150/391], Loss: 3.2063, LR: 0.005000\n",
      "Epoch [40], Batch [200/391], Loss: 1.7628, LR: 0.005000\n",
      "Epoch [40], Batch [250/391], Loss: 1.8952, LR: 0.005000\n",
      "Epoch [40], Batch [300/391], Loss: 1.9708, LR: 0.005000\n",
      "Epoch [40], Batch [350/391], Loss: 3.3638, LR: 0.005000\n",
      "Train set: Epoch: 40, Average loss:2.3325, LR: 0.005000 Top-1 Accuracy: 53.9960%, Top-5 Accuracy: 81.4180%, Time consumed:162.93s\n",
      "Test set: Epoch: 40, Average loss:1.9743, Top-1 Accuracy: 62.6600%, Top-5 Accuracy: 87.8200%, Time consumed:12.92s\n",
      "\n",
      "새로운 최고 top-1 정확도: 62.66%, top-5 정확도: 87.82%\n",
      "새로운 최고 top-5 정확도: 87.82%\n",
      "Accuracy improved (61.82% --> 62.66%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|███████████▋                                                                            | 40/300 [1:56:03<12:41:23, 175.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41], Batch [50/391], Loss: 1.8584, LR: 0.005000\n",
      "Epoch [41], Batch [100/391], Loss: 2.9552, LR: 0.005000\n",
      "Epoch [41], Batch [150/391], Loss: 1.9810, LR: 0.005000\n",
      "Epoch [41], Batch [200/391], Loss: 2.1515, LR: 0.005000\n",
      "Epoch [41], Batch [250/391], Loss: 3.3796, LR: 0.005000\n",
      "Epoch [41], Batch [300/391], Loss: 3.0382, LR: 0.005000\n",
      "Epoch [41], Batch [350/391], Loss: 1.6933, LR: 0.005000\n",
      "Train set: Epoch: 41, Average loss:2.3543, LR: 0.005000 Top-1 Accuracy: 53.0480%, Top-5 Accuracy: 80.6840%, Time consumed:156.85s\n",
      "Test set: Epoch: 41, Average loss:1.9775, Top-1 Accuracy: 62.7700%, Top-5 Accuracy: 88.1900%, Time consumed:12.06s\n",
      "\n",
      "새로운 최고 top-1 정확도: 62.77%, top-5 정확도: 88.19%\n",
      "새로운 최고 top-5 정확도: 88.19%\n",
      "Accuracy improved (62.66% --> 62.77%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████                                                                            | 41/300 [1:58:52<12:30:06, 173.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42], Batch [50/391], Loss: 1.8863, LR: 0.005000\n",
      "Epoch [42], Batch [100/391], Loss: 2.2599, LR: 0.005000\n",
      "Epoch [42], Batch [150/391], Loss: 2.0182, LR: 0.005000\n",
      "Epoch [42], Batch [200/391], Loss: 2.3832, LR: 0.005000\n",
      "Epoch [42], Batch [250/391], Loss: 1.9215, LR: 0.005000\n",
      "Epoch [42], Batch [300/391], Loss: 1.9099, LR: 0.005000\n",
      "Epoch [42], Batch [350/391], Loss: 2.6546, LR: 0.005000\n",
      "Train set: Epoch: 42, Average loss:2.3348, LR: 0.005000 Top-1 Accuracy: 54.1160%, Top-5 Accuracy: 81.2860%, Time consumed:158.04s\n",
      "Test set: Epoch: 42, Average loss:1.9504, Top-1 Accuracy: 63.7000%, Top-5 Accuracy: 88.5600%, Time consumed:12.72s\n",
      "\n",
      "새로운 최고 top-1 정확도: 63.70%, top-5 정확도: 88.56%\n",
      "새로운 최고 top-5 정확도: 88.56%\n",
      "Accuracy improved (62.77% --> 63.70%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████▎                                                                           | 42/300 [2:01:43<12:23:47, 172.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43], Batch [50/391], Loss: 3.4921, LR: 0.005000\n",
      "Epoch [43], Batch [100/391], Loss: 1.9032, LR: 0.005000\n",
      "Epoch [43], Batch [150/391], Loss: 1.7993, LR: 0.005000\n",
      "Epoch [43], Batch [200/391], Loss: 1.9422, LR: 0.005000\n",
      "Epoch [43], Batch [250/391], Loss: 1.6239, LR: 0.005000\n",
      "Epoch [43], Batch [300/391], Loss: 3.2455, LR: 0.005000\n",
      "Epoch [43], Batch [350/391], Loss: 2.2722, LR: 0.005000\n",
      "Train set: Epoch: 43, Average loss:2.3639, LR: 0.005000 Top-1 Accuracy: 53.1440%, Top-5 Accuracy: 80.0540%, Time consumed:156.91s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████▌                                                                           | 43/300 [2:04:32<12:16:13, 171.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 43, Average loss:1.9612, Top-1 Accuracy: 62.6900%, Top-5 Accuracy: 88.2900%, Time consumed:12.40s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [44], Batch [50/391], Loss: 1.6230, LR: 0.005000\n",
      "Epoch [44], Batch [100/391], Loss: 1.9646, LR: 0.005000\n",
      "Epoch [44], Batch [150/391], Loss: 1.8673, LR: 0.005000\n",
      "Epoch [44], Batch [200/391], Loss: 1.9679, LR: 0.005000\n",
      "Epoch [44], Batch [250/391], Loss: 2.7119, LR: 0.005000\n",
      "Epoch [44], Batch [300/391], Loss: 1.7338, LR: 0.005000\n",
      "Epoch [44], Batch [350/391], Loss: 1.7571, LR: 0.005000\n",
      "Train set: Epoch: 44, Average loss:2.2968, LR: 0.005000 Top-1 Accuracy: 55.4660%, Top-5 Accuracy: 82.0700%, Time consumed:158.50s\n",
      "Test set: Epoch: 44, Average loss:1.9217, Top-1 Accuracy: 64.0600%, Top-5 Accuracy: 89.2900%, Time consumed:12.23s\n",
      "\n",
      "새로운 최고 top-1 정확도: 64.06%, top-5 정확도: 89.29%\n",
      "새로운 최고 top-5 정확도: 89.29%\n",
      "Accuracy improved (63.70% --> 64.06%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████████████▉                                                                           | 44/300 [2:07:24<12:12:19, 171.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45], Batch [50/391], Loss: 1.6581, LR: 0.005000\n",
      "Epoch [45], Batch [100/391], Loss: 3.2548, LR: 0.005000\n",
      "Epoch [45], Batch [150/391], Loss: 3.2950, LR: 0.005000\n",
      "Epoch [45], Batch [200/391], Loss: 1.6835, LR: 0.005000\n",
      "Epoch [45], Batch [250/391], Loss: 1.9101, LR: 0.005000\n",
      "Epoch [45], Batch [300/391], Loss: 1.8301, LR: 0.005000\n",
      "Epoch [45], Batch [350/391], Loss: 1.9590, LR: 0.005000\n",
      "Train set: Epoch: 45, Average loss:2.2794, LR: 0.005000 Top-1 Accuracy: 55.3280%, Top-5 Accuracy: 81.5020%, Time consumed:162.30s\n",
      "Test set: Epoch: 45, Average loss:1.9126, Top-1 Accuracy: 64.5900%, Top-5 Accuracy: 89.0000%, Time consumed:12.68s\n",
      "\n",
      "새로운 최고 top-1 정확도: 64.59%, top-5 정확도: 89.00%\n",
      "Accuracy improved (64.06% --> 64.59%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████████████▏                                                                          | 45/300 [2:10:19<12:14:13, 172.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46], Batch [50/391], Loss: 1.7162, LR: 0.005000\n",
      "Epoch [46], Batch [100/391], Loss: 3.4762, LR: 0.005000\n",
      "Epoch [46], Batch [150/391], Loss: 1.4783, LR: 0.005000\n",
      "Epoch [46], Batch [200/391], Loss: 2.9290, LR: 0.005000\n",
      "Epoch [46], Batch [250/391], Loss: 3.1854, LR: 0.005000\n",
      "Epoch [46], Batch [300/391], Loss: 1.6975, LR: 0.005000\n",
      "Epoch [46], Batch [350/391], Loss: 3.2961, LR: 0.005000\n",
      "Train set: Epoch: 46, Average loss:2.3036, LR: 0.005000 Top-1 Accuracy: 55.5660%, Top-5 Accuracy: 81.7200%, Time consumed:163.72s\n",
      "Test set: Epoch: 46, Average loss:1.9141, Top-1 Accuracy: 64.6800%, Top-5 Accuracy: 88.9200%, Time consumed:11.94s\n",
      "\n",
      "새로운 최고 top-1 정확도: 64.68%, top-5 정확도: 88.92%\n",
      "Accuracy improved (64.59% --> 64.68%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████████████▍                                                                          | 46/300 [2:13:15<12:15:29, 173.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47], Batch [50/391], Loss: 1.6536, LR: 0.005000\n",
      "Epoch [47], Batch [100/391], Loss: 1.7858, LR: 0.005000\n",
      "Epoch [47], Batch [150/391], Loss: 1.4192, LR: 0.005000\n",
      "Epoch [47], Batch [200/391], Loss: 3.0605, LR: 0.005000\n",
      "Epoch [47], Batch [250/391], Loss: 1.6945, LR: 0.005000\n",
      "Epoch [47], Batch [300/391], Loss: 1.7026, LR: 0.005000\n",
      "Epoch [47], Batch [350/391], Loss: 1.9747, LR: 0.005000\n",
      "Train set: Epoch: 47, Average loss:2.2654, LR: 0.005000 Top-1 Accuracy: 56.2480%, Top-5 Accuracy: 82.3840%, Time consumed:163.04s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█████████████▊                                                                          | 47/300 [2:16:10<12:13:59, 174.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 47, Average loss:1.8924, Top-1 Accuracy: 64.6400%, Top-5 Accuracy: 89.2700%, Time consumed:11.79s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [48], Batch [50/391], Loss: 1.7118, LR: 0.005000\n",
      "Epoch [48], Batch [100/391], Loss: 1.8246, LR: 0.005000\n",
      "Epoch [48], Batch [150/391], Loss: 2.1649, LR: 0.005000\n",
      "Epoch [48], Batch [200/391], Loss: 2.8534, LR: 0.005000\n",
      "Epoch [48], Batch [250/391], Loss: 1.7784, LR: 0.005000\n",
      "Epoch [48], Batch [300/391], Loss: 2.9891, LR: 0.005000\n",
      "Epoch [48], Batch [350/391], Loss: 3.1376, LR: 0.005000\n",
      "Train set: Epoch: 48, Average loss:2.1837, LR: 0.005000 Top-1 Accuracy: 58.5560%, Top-5 Accuracy: 84.0300%, Time consumed:160.13s\n",
      "Test set: Epoch: 48, Average loss:1.8793, Top-1 Accuracy: 65.2800%, Top-5 Accuracy: 89.8200%, Time consumed:11.90s\n",
      "\n",
      "새로운 최고 top-1 정확도: 65.28%, top-5 정확도: 89.82%\n",
      "새로운 최고 top-5 정확도: 89.82%\n",
      "Accuracy improved (64.68% --> 65.28%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████████████                                                                          | 48/300 [2:19:02<12:08:57, 173.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49], Batch [50/391], Loss: 1.7239, LR: 0.005000\n",
      "Epoch [49], Batch [100/391], Loss: 2.2202, LR: 0.005000\n",
      "Epoch [49], Batch [150/391], Loss: 2.8385, LR: 0.005000\n",
      "Epoch [49], Batch [200/391], Loss: 1.7162, LR: 0.005000\n",
      "Epoch [49], Batch [250/391], Loss: 1.8216, LR: 0.005000\n",
      "Epoch [49], Batch [300/391], Loss: 2.7015, LR: 0.005000\n",
      "Epoch [49], Batch [350/391], Loss: 2.4028, LR: 0.005000\n",
      "Train set: Epoch: 49, Average loss:2.1783, LR: 0.005000 Top-1 Accuracy: 58.8520%, Top-5 Accuracy: 84.1660%, Time consumed:161.39s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████████████▎                                                                         | 49/300 [2:21:55<12:05:32, 173.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 49, Average loss:1.8858, Top-1 Accuracy: 64.9600%, Top-5 Accuracy: 89.5700%, Time consumed:11.75s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [50], Batch [50/391], Loss: 2.5475, LR: 0.005000\n",
      "Epoch [50], Batch [100/391], Loss: 3.4595, LR: 0.005000\n",
      "Epoch [50], Batch [150/391], Loss: 2.2638, LR: 0.005000\n",
      "Epoch [50], Batch [200/391], Loss: 1.7451, LR: 0.005000\n",
      "Epoch [50], Batch [250/391], Loss: 2.8657, LR: 0.005000\n",
      "Epoch [50], Batch [300/391], Loss: 1.9291, LR: 0.005000\n",
      "Epoch [50], Batch [350/391], Loss: 2.0231, LR: 0.005000\n",
      "Train set: Epoch: 50, Average loss:2.1623, LR: 0.005000 Top-1 Accuracy: 59.4200%, Top-5 Accuracy: 84.4960%, Time consumed:166.15s\n",
      "Test set: Epoch: 50, Average loss:1.8617, Top-1 Accuracy: 66.3400%, Top-5 Accuracy: 89.9500%, Time consumed:11.66s\n",
      "\n",
      "새로운 최고 top-1 정확도: 66.34%, top-5 정확도: 89.95%\n",
      "새로운 최고 top-5 정확도: 89.95%\n",
      "Accuracy improved (65.28% --> 66.34%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████████████▋                                                                         | 50/300 [2:24:53<12:08:31, 174.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51], Batch [50/391], Loss: 1.6290, LR: 0.005000\n",
      "Epoch [51], Batch [100/391], Loss: 2.6483, LR: 0.005000\n",
      "Epoch [51], Batch [150/391], Loss: 1.2583, LR: 0.005000\n",
      "Epoch [51], Batch [200/391], Loss: 3.2835, LR: 0.005000\n",
      "Epoch [51], Batch [250/391], Loss: 1.7406, LR: 0.005000\n",
      "Epoch [51], Batch [300/391], Loss: 1.6488, LR: 0.005000\n",
      "Epoch [51], Batch [350/391], Loss: 3.2626, LR: 0.005000\n",
      "Train set: Epoch: 51, Average loss:2.2077, LR: 0.005000 Top-1 Accuracy: 58.5600%, Top-5 Accuracy: 83.7240%, Time consumed:159.74s\n",
      "Test set: Epoch: 51, Average loss:1.8458, Top-1 Accuracy: 66.4000%, Top-5 Accuracy: 90.1400%, Time consumed:12.07s\n",
      "\n",
      "새로운 최고 top-1 정확도: 66.40%, top-5 정확도: 90.14%\n",
      "새로운 최고 top-5 정확도: 90.14%\n",
      "Accuracy improved (66.34% --> 66.40%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████████████▉                                                                         | 51/300 [2:27:46<12:02:16, 174.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52], Batch [50/391], Loss: 3.2268, LR: 0.005000\n",
      "Epoch [52], Batch [100/391], Loss: 0.8964, LR: 0.005000\n",
      "Epoch [52], Batch [150/391], Loss: 3.1441, LR: 0.005000\n",
      "Epoch [52], Batch [200/391], Loss: 1.5359, LR: 0.005000\n",
      "Epoch [52], Batch [250/391], Loss: 1.5494, LR: 0.005000\n",
      "Epoch [52], Batch [300/391], Loss: 2.8931, LR: 0.005000\n",
      "Epoch [52], Batch [350/391], Loss: 1.7315, LR: 0.005000\n",
      "Train set: Epoch: 52, Average loss:2.1752, LR: 0.005000 Top-1 Accuracy: 59.4820%, Top-5 Accuracy: 84.4780%, Time consumed:158.07s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████████████▎                                                                        | 52/300 [2:30:36<11:54:47, 172.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 52, Average loss:1.8566, Top-1 Accuracy: 66.0400%, Top-5 Accuracy: 90.0500%, Time consumed:12.27s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [53], Batch [50/391], Loss: 3.2205, LR: 0.005000\n",
      "Epoch [53], Batch [100/391], Loss: 1.7542, LR: 0.005000\n",
      "Epoch [53], Batch [150/391], Loss: 1.6897, LR: 0.005000\n",
      "Epoch [53], Batch [200/391], Loss: 1.6573, LR: 0.005000\n",
      "Epoch [53], Batch [250/391], Loss: 2.8652, LR: 0.005000\n",
      "Epoch [53], Batch [300/391], Loss: 1.6061, LR: 0.005000\n",
      "Epoch [53], Batch [350/391], Loss: 2.5608, LR: 0.005000\n",
      "Train set: Epoch: 53, Average loss:2.1180, LR: 0.005000 Top-1 Accuracy: 60.6020%, Top-5 Accuracy: 84.9980%, Time consumed:158.31s\n",
      "Test set: Epoch: 53, Average loss:1.8395, Top-1 Accuracy: 66.6800%, Top-5 Accuracy: 90.0900%, Time consumed:12.07s\n",
      "\n",
      "새로운 최고 top-1 정확도: 66.68%, top-5 정확도: 90.09%\n",
      "Accuracy improved (66.40% --> 66.68%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████████████▌                                                                        | 53/300 [2:33:27<11:49:09, 172.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54], Batch [50/391], Loss: 2.8421, LR: 0.005000\n",
      "Epoch [54], Batch [100/391], Loss: 1.6452, LR: 0.005000\n",
      "Epoch [54], Batch [150/391], Loss: 1.6091, LR: 0.005000\n",
      "Epoch [54], Batch [200/391], Loss: 1.6919, LR: 0.005000\n",
      "Epoch [54], Batch [250/391], Loss: 1.0669, LR: 0.005000\n",
      "Epoch [54], Batch [300/391], Loss: 2.6216, LR: 0.005000\n",
      "Epoch [54], Batch [350/391], Loss: 1.3807, LR: 0.005000\n",
      "Train set: Epoch: 54, Average loss:2.0883, LR: 0.005000 Top-1 Accuracy: 61.9840%, Top-5 Accuracy: 86.3080%, Time consumed:157.02s\n",
      "Test set: Epoch: 54, Average loss:1.8193, Top-1 Accuracy: 67.1100%, Top-5 Accuracy: 90.7100%, Time consumed:13.34s\n",
      "\n",
      "새로운 최고 top-1 정확도: 67.11%, top-5 정확도: 90.71%\n",
      "새로운 최고 top-5 정확도: 90.71%\n",
      "Accuracy improved (66.68% --> 67.11%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████████████▊                                                                        | 54/300 [2:36:17<11:44:25, 171.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55], Batch [50/391], Loss: 1.6033, LR: 0.005000\n",
      "Epoch [55], Batch [100/391], Loss: 3.1510, LR: 0.005000\n",
      "Epoch [55], Batch [150/391], Loss: 2.5557, LR: 0.005000\n",
      "Epoch [55], Batch [200/391], Loss: 1.5630, LR: 0.005000\n",
      "Epoch [55], Batch [250/391], Loss: 1.6837, LR: 0.005000\n",
      "Epoch [55], Batch [300/391], Loss: 1.5239, LR: 0.005000\n",
      "Epoch [55], Batch [350/391], Loss: 1.6227, LR: 0.005000\n",
      "Train set: Epoch: 55, Average loss:2.0969, LR: 0.005000 Top-1 Accuracy: 60.8880%, Top-5 Accuracy: 85.0480%, Time consumed:163.57s\n",
      "Test set: Epoch: 55, Average loss:1.8086, Top-1 Accuracy: 67.8000%, Top-5 Accuracy: 91.0000%, Time consumed:12.61s\n",
      "\n",
      "새로운 최고 top-1 정확도: 67.80%, top-5 정확도: 91.00%\n",
      "새로운 최고 top-5 정확도: 91.00%\n",
      "Accuracy improved (67.11% --> 67.80%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|████████████████▏                                                                       | 55/300 [2:39:14<11:47:22, 173.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56], Batch [50/391], Loss: 1.5822, LR: 0.005000\n",
      "Epoch [56], Batch [100/391], Loss: 3.0015, LR: 0.005000\n",
      "Epoch [56], Batch [150/391], Loss: 1.5299, LR: 0.005000\n",
      "Epoch [56], Batch [200/391], Loss: 1.7362, LR: 0.005000\n",
      "Epoch [56], Batch [250/391], Loss: 1.7012, LR: 0.005000\n",
      "Epoch [56], Batch [300/391], Loss: 2.7387, LR: 0.005000\n",
      "Epoch [56], Batch [350/391], Loss: 3.2461, LR: 0.005000\n",
      "Train set: Epoch: 56, Average loss:2.0763, LR: 0.005000 Top-1 Accuracy: 61.7020%, Top-5 Accuracy: 85.5200%, Time consumed:157.20s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|████████████████▍                                                                       | 56/300 [2:42:03<11:39:31, 172.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 56, Average loss:1.8242, Top-1 Accuracy: 67.1400%, Top-5 Accuracy: 90.0600%, Time consumed:11.96s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [57], Batch [50/391], Loss: 1.0335, LR: 0.005000\n",
      "Epoch [57], Batch [100/391], Loss: 1.9999, LR: 0.005000\n",
      "Epoch [57], Batch [150/391], Loss: 1.6120, LR: 0.005000\n",
      "Epoch [57], Batch [200/391], Loss: 3.0640, LR: 0.005000\n",
      "Epoch [57], Batch [250/391], Loss: 1.6163, LR: 0.005000\n",
      "Epoch [57], Batch [300/391], Loss: 3.1012, LR: 0.005000\n",
      "Epoch [57], Batch [350/391], Loss: 1.7114, LR: 0.005000\n",
      "Train set: Epoch: 57, Average loss:2.0988, LR: 0.005000 Top-1 Accuracy: 62.0540%, Top-5 Accuracy: 85.9220%, Time consumed:157.03s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|████████████████▋                                                                       | 57/300 [2:44:52<11:33:11, 171.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 57, Average loss:1.8024, Top-1 Accuracy: 67.6300%, Top-5 Accuracy: 91.2000%, Time consumed:12.13s\n",
      "\n",
      "새로운 최고 top-5 정확도: 91.20%\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [58], Batch [50/391], Loss: 2.8862, LR: 0.005000\n",
      "Epoch [58], Batch [100/391], Loss: 1.4871, LR: 0.005000\n",
      "Epoch [58], Batch [150/391], Loss: 2.9970, LR: 0.005000\n",
      "Epoch [58], Batch [200/391], Loss: 2.3031, LR: 0.005000\n",
      "Epoch [58], Batch [250/391], Loss: 2.4393, LR: 0.005000\n",
      "Epoch [58], Batch [300/391], Loss: 2.3548, LR: 0.005000\n",
      "Epoch [58], Batch [350/391], Loss: 1.5521, LR: 0.005000\n",
      "Train set: Epoch: 58, Average loss:2.0208, LR: 0.005000 Top-1 Accuracy: 64.2980%, Top-5 Accuracy: 87.5860%, Time consumed:157.91s\n",
      "Test set: Epoch: 58, Average loss:1.7891, Top-1 Accuracy: 68.0600%, Top-5 Accuracy: 91.1000%, Time consumed:12.07s\n",
      "\n",
      "새로운 최고 top-1 정확도: 68.06%, top-5 정확도: 91.10%\n",
      "Accuracy improved (67.80% --> 68.06%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█████████████████                                                                       | 58/300 [2:47:43<11:29:19, 170.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [59], Batch [50/391], Loss: 3.1328, LR: 0.005000\n",
      "Epoch [59], Batch [100/391], Loss: 1.4563, LR: 0.005000\n",
      "Epoch [59], Batch [150/391], Loss: 2.6926, LR: 0.005000\n",
      "Epoch [59], Batch [200/391], Loss: 3.0345, LR: 0.005000\n",
      "Epoch [59], Batch [250/391], Loss: 2.6310, LR: 0.005000\n",
      "Epoch [59], Batch [300/391], Loss: 1.5548, LR: 0.005000\n",
      "Epoch [59], Batch [350/391], Loss: 1.4702, LR: 0.005000\n",
      "Train set: Epoch: 59, Average loss:2.0935, LR: 0.005000 Top-1 Accuracy: 61.9580%, Top-5 Accuracy: 85.7020%, Time consumed:158.64s\n",
      "Test set: Epoch: 59, Average loss:1.7821, Top-1 Accuracy: 68.7600%, Top-5 Accuracy: 91.2000%, Time consumed:12.46s\n",
      "\n",
      "새로운 최고 top-1 정확도: 68.76%, top-5 정확도: 91.20%\n",
      "Accuracy improved (68.06% --> 68.76%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█████████████████▎                                                                      | 59/300 [2:50:34<11:27:07, 171.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60], Batch [50/391], Loss: 1.6187, LR: 0.005000\n",
      "Epoch [60], Batch [100/391], Loss: 2.6662, LR: 0.005000\n",
      "Epoch [60], Batch [150/391], Loss: 1.6119, LR: 0.005000\n",
      "Epoch [60], Batch [200/391], Loss: 2.9273, LR: 0.005000\n",
      "Epoch [60], Batch [250/391], Loss: 2.6509, LR: 0.005000\n",
      "Epoch [60], Batch [300/391], Loss: 3.2646, LR: 0.005000\n",
      "Epoch [60], Batch [350/391], Loss: 1.5572, LR: 0.005000\n",
      "Train set: Epoch: 60, Average loss:2.0216, LR: 0.005000 Top-1 Accuracy: 64.4200%, Top-5 Accuracy: 87.2340%, Time consumed:157.12s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█████████████████▌                                                                      | 60/300 [2:53:23<11:22:07, 170.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 60, Average loss:1.7770, Top-1 Accuracy: 68.5100%, Top-5 Accuracy: 91.2700%, Time consumed:12.14s\n",
      "\n",
      "새로운 최고 top-5 정확도: 91.27%\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [61], Batch [50/391], Loss: 1.4957, LR: 0.005000\n",
      "Epoch [61], Batch [100/391], Loss: 1.5824, LR: 0.005000\n",
      "Epoch [61], Batch [150/391], Loss: 1.5280, LR: 0.005000\n",
      "Epoch [61], Batch [200/391], Loss: 1.4718, LR: 0.005000\n",
      "Epoch [61], Batch [250/391], Loss: 1.3858, LR: 0.005000\n",
      "Epoch [61], Batch [300/391], Loss: 1.5397, LR: 0.005000\n",
      "Epoch [61], Batch [350/391], Loss: 3.1068, LR: 0.005000\n",
      "Train set: Epoch: 61, Average loss:1.9460, LR: 0.005000 Top-1 Accuracy: 66.5200%, Top-5 Accuracy: 88.9040%, Time consumed:163.16s\n",
      "Test set: Epoch: 61, Average loss:1.7810, Top-1 Accuracy: 68.9900%, Top-5 Accuracy: 90.9600%, Time consumed:12.86s\n",
      "\n",
      "새로운 최고 top-1 정확도: 68.99%, top-5 정확도: 90.96%\n",
      "Accuracy improved (68.76% --> 68.99%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█████████████████▉                                                                      | 61/300 [2:56:20<11:26:15, 172.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [62], Batch [50/391], Loss: 2.8108, LR: 0.005000\n",
      "Epoch [62], Batch [100/391], Loss: 1.2178, LR: 0.005000\n",
      "Epoch [62], Batch [150/391], Loss: 2.3305, LR: 0.005000\n",
      "Epoch [62], Batch [200/391], Loss: 1.3999, LR: 0.005000\n",
      "Epoch [62], Batch [250/391], Loss: 2.0146, LR: 0.005000\n",
      "Epoch [62], Batch [300/391], Loss: 1.5206, LR: 0.005000\n",
      "Epoch [62], Batch [350/391], Loss: 2.6612, LR: 0.005000\n",
      "Train set: Epoch: 62, Average loss:2.0309, LR: 0.005000 Top-1 Accuracy: 63.8580%, Top-5 Accuracy: 86.6000%, Time consumed:162.63s\n",
      "Test set: Epoch: 62, Average loss:1.7659, Top-1 Accuracy: 69.1300%, Top-5 Accuracy: 91.2500%, Time consumed:13.04s\n",
      "\n",
      "새로운 최고 top-1 정확도: 69.13%, top-5 정확도: 91.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██████████████████▏                                                                     | 62/300 [2:59:16<11:27:53, 173.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy improved (68.99% --> 69.13%). Saving model ...\n",
      "Epoch [63], Batch [50/391], Loss: 1.3975, LR: 0.005000\n",
      "Epoch [63], Batch [100/391], Loss: 2.8032, LR: 0.005000\n",
      "Epoch [63], Batch [150/391], Loss: 1.4855, LR: 0.005000\n",
      "Epoch [63], Batch [200/391], Loss: 1.4564, LR: 0.005000\n",
      "Epoch [63], Batch [250/391], Loss: 3.0591, LR: 0.005000\n",
      "Epoch [63], Batch [300/391], Loss: 1.4820, LR: 0.005000\n",
      "Epoch [63], Batch [350/391], Loss: 0.9313, LR: 0.005000\n",
      "Train set: Epoch: 63, Average loss:1.9481, LR: 0.005000 Top-1 Accuracy: 66.5080%, Top-5 Accuracy: 88.6380%, Time consumed:156.88s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██████████████████▍                                                                     | 63/300 [3:02:05<11:20:02, 172.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 63, Average loss:1.7620, Top-1 Accuracy: 69.0500%, Top-5 Accuracy: 91.0600%, Time consumed:12.34s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [64], Batch [50/391], Loss: 1.4599, LR: 0.005000\n",
      "Epoch [64], Batch [100/391], Loss: 1.4680, LR: 0.005000\n",
      "Epoch [64], Batch [150/391], Loss: 1.4099, LR: 0.005000\n",
      "Epoch [64], Batch [200/391], Loss: 1.4704, LR: 0.005000\n",
      "Epoch [64], Batch [250/391], Loss: 1.0891, LR: 0.005000\n",
      "Epoch [64], Batch [300/391], Loss: 1.0295, LR: 0.005000\n",
      "Epoch [64], Batch [350/391], Loss: 1.1595, LR: 0.005000\n",
      "Train set: Epoch: 64, Average loss:1.9721, LR: 0.005000 Top-1 Accuracy: 65.5380%, Top-5 Accuracy: 87.5840%, Time consumed:157.26s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██████████████████▊                                                                     | 64/300 [3:04:55<11:14:50, 171.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 64, Average loss:1.7927, Top-1 Accuracy: 68.5000%, Top-5 Accuracy: 90.8900%, Time consumed:12.93s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [65], Batch [50/391], Loss: 1.4255, LR: 0.005000\n",
      "Epoch [65], Batch [100/391], Loss: 1.8851, LR: 0.005000\n",
      "Epoch [65], Batch [150/391], Loss: 1.4576, LR: 0.005000\n",
      "Epoch [65], Batch [200/391], Loss: 1.4793, LR: 0.005000\n",
      "Epoch [65], Batch [250/391], Loss: 1.3321, LR: 0.005000\n",
      "Epoch [65], Batch [300/391], Loss: 3.0552, LR: 0.005000\n",
      "Epoch [65], Batch [350/391], Loss: 1.4401, LR: 0.005000\n",
      "Train set: Epoch: 65, Average loss:1.9317, LR: 0.005000 Top-1 Accuracy: 67.1660%, Top-5 Accuracy: 88.7720%, Time consumed:157.00s\n",
      "Test set: Epoch: 65, Average loss:1.7615, Top-1 Accuracy: 69.7000%, Top-5 Accuracy: 91.2800%, Time consumed:12.70s\n",
      "\n",
      "새로운 최고 top-1 정확도: 69.70%, top-5 정확도: 91.28%\n",
      "새로운 최고 top-5 정확도: 91.28%\n",
      "Accuracy improved (69.13% --> 69.70%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|███████████████████                                                                     | 65/300 [3:07:45<11:10:12, 171.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [66], Batch [50/391], Loss: 1.5654, LR: 0.005000\n",
      "Epoch [66], Batch [100/391], Loss: 2.8914, LR: 0.005000\n",
      "Epoch [66], Batch [150/391], Loss: 2.9343, LR: 0.005000\n",
      "Epoch [66], Batch [200/391], Loss: 3.1520, LR: 0.005000\n",
      "Epoch [66], Batch [250/391], Loss: 2.1816, LR: 0.005000\n",
      "Epoch [66], Batch [300/391], Loss: 1.4219, LR: 0.005000\n",
      "Epoch [66], Batch [350/391], Loss: 1.2009, LR: 0.005000\n",
      "Train set: Epoch: 66, Average loss:1.8611, LR: 0.005000 Top-1 Accuracy: 68.5340%, Top-5 Accuracy: 89.6900%, Time consumed:160.11s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|███████████████████▎                                                                    | 66/300 [3:10:38<11:08:49, 171.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 66, Average loss:1.7721, Top-1 Accuracy: 69.3700%, Top-5 Accuracy: 90.8600%, Time consumed:12.25s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [67], Batch [50/391], Loss: 1.4001, LR: 0.005000\n",
      "Epoch [67], Batch [100/391], Loss: 1.3592, LR: 0.005000\n",
      "Epoch [67], Batch [150/391], Loss: 2.1011, LR: 0.005000\n",
      "Epoch [67], Batch [200/391], Loss: 2.4493, LR: 0.005000\n",
      "Epoch [67], Batch [250/391], Loss: 1.4129, LR: 0.005000\n",
      "Epoch [67], Batch [300/391], Loss: 2.7260, LR: 0.005000\n",
      "Epoch [67], Batch [350/391], Loss: 1.3423, LR: 0.005000\n",
      "Train set: Epoch: 67, Average loss:1.9253, LR: 0.005000 Top-1 Accuracy: 67.3360%, Top-5 Accuracy: 88.5980%, Time consumed:159.57s\n",
      "Test set: Epoch: 67, Average loss:1.7446, Top-1 Accuracy: 70.0300%, Top-5 Accuracy: 91.4500%, Time consumed:12.71s\n",
      "\n",
      "새로운 최고 top-1 정확도: 70.03%, top-5 정확도: 91.45%\n",
      "새로운 최고 top-5 정확도: 91.45%\n",
      "Accuracy improved (69.70% --> 70.03%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|███████████████████▋                                                                    | 67/300 [3:13:30<11:07:17, 171.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [68], Batch [50/391], Loss: 2.4418, LR: 0.005000\n",
      "Epoch [68], Batch [100/391], Loss: 1.4655, LR: 0.005000\n",
      "Epoch [68], Batch [150/391], Loss: 1.3652, LR: 0.005000\n",
      "Epoch [68], Batch [200/391], Loss: 1.9494, LR: 0.005000\n",
      "Epoch [68], Batch [250/391], Loss: 2.3437, LR: 0.005000\n",
      "Epoch [68], Batch [300/391], Loss: 2.6359, LR: 0.005000\n",
      "Epoch [68], Batch [350/391], Loss: 2.9056, LR: 0.005000\n",
      "Train set: Epoch: 68, Average loss:1.9317, LR: 0.005000 Top-1 Accuracy: 67.4380%, Top-5 Accuracy: 89.0200%, Time consumed:161.79s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|███████████████████▉                                                                    | 68/300 [3:16:24<11:07:12, 172.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 68, Average loss:1.7657, Top-1 Accuracy: 69.1700%, Top-5 Accuracy: 91.0800%, Time consumed:12.43s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [69], Batch [50/391], Loss: 1.3588, LR: 0.005000\n",
      "Epoch [69], Batch [100/391], Loss: 1.4044, LR: 0.005000\n",
      "Epoch [69], Batch [150/391], Loss: 2.4309, LR: 0.005000\n",
      "Epoch [69], Batch [200/391], Loss: 1.3389, LR: 0.005000\n",
      "Epoch [69], Batch [250/391], Loss: 1.3548, LR: 0.005000\n",
      "Epoch [69], Batch [300/391], Loss: 2.5440, LR: 0.005000\n",
      "Epoch [69], Batch [350/391], Loss: 1.3737, LR: 0.005000\n",
      "Train set: Epoch: 69, Average loss:1.8922, LR: 0.005000 Top-1 Accuracy: 68.7840%, Top-5 Accuracy: 89.4720%, Time consumed:157.32s\n",
      "Test set: Epoch: 69, Average loss:1.7311, Top-1 Accuracy: 70.9500%, Top-5 Accuracy: 91.8200%, Time consumed:12.04s\n",
      "\n",
      "새로운 최고 top-1 정확도: 70.95%, top-5 정확도: 91.82%\n",
      "새로운 최고 top-5 정확도: 91.82%\n",
      "Accuracy improved (70.03% --> 70.95%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|████████████████████▏                                                                   | 69/300 [3:19:14<11:01:01, 171.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [70], Batch [50/391], Loss: 1.3135, LR: 0.005000\n",
      "Epoch [70], Batch [100/391], Loss: 1.4133, LR: 0.005000\n",
      "Epoch [70], Batch [150/391], Loss: 1.2856, LR: 0.005000\n",
      "Epoch [70], Batch [200/391], Loss: 1.5619, LR: 0.005000\n",
      "Epoch [70], Batch [250/391], Loss: 2.4905, LR: 0.005000\n",
      "Epoch [70], Batch [300/391], Loss: 1.3527, LR: 0.005000\n",
      "Epoch [70], Batch [350/391], Loss: 1.3143, LR: 0.005000\n",
      "Train set: Epoch: 70, Average loss:1.8536, LR: 0.005000 Top-1 Accuracy: 69.6920%, Top-5 Accuracy: 90.0260%, Time consumed:164.78s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|████████████████████▌                                                                   | 70/300 [3:22:11<11:04:08, 173.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 70, Average loss:1.7461, Top-1 Accuracy: 69.6300%, Top-5 Accuracy: 91.4000%, Time consumed:12.11s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [71], Batch [50/391], Loss: 1.3142, LR: 0.005000\n",
      "Epoch [71], Batch [100/391], Loss: 1.3328, LR: 0.005000\n",
      "Epoch [71], Batch [150/391], Loss: 1.3574, LR: 0.005000\n",
      "Epoch [71], Batch [200/391], Loss: 1.2879, LR: 0.005000\n",
      "Epoch [71], Batch [250/391], Loss: 1.4112, LR: 0.005000\n",
      "Epoch [71], Batch [300/391], Loss: 1.4233, LR: 0.005000\n",
      "Epoch [71], Batch [350/391], Loss: 1.4082, LR: 0.005000\n",
      "Train set: Epoch: 71, Average loss:1.8262, LR: 0.005000 Top-1 Accuracy: 70.3080%, Top-5 Accuracy: 90.4520%, Time consumed:163.09s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|████████████████████▊                                                                   | 71/300 [3:25:07<11:03:52, 173.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 71, Average loss:1.7353, Top-1 Accuracy: 70.2800%, Top-5 Accuracy: 91.5200%, Time consumed:12.45s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [72], Batch [50/391], Loss: 1.3001, LR: 0.005000\n",
      "Epoch [72], Batch [100/391], Loss: 2.0840, LR: 0.005000\n",
      "Epoch [72], Batch [150/391], Loss: 2.9301, LR: 0.005000\n",
      "Epoch [72], Batch [200/391], Loss: 1.5197, LR: 0.005000\n",
      "Epoch [72], Batch [250/391], Loss: 1.3525, LR: 0.005000\n",
      "Epoch [72], Batch [300/391], Loss: 1.3060, LR: 0.005000\n",
      "Epoch [72], Batch [350/391], Loss: 1.8951, LR: 0.005000\n",
      "Train set: Epoch: 72, Average loss:1.8012, LR: 0.005000 Top-1 Accuracy: 70.8800%, Top-5 Accuracy: 90.6320%, Time consumed:164.15s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|█████████████████████                                                                   | 72/300 [3:28:03<11:04:08, 174.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 72, Average loss:1.7392, Top-1 Accuracy: 70.0100%, Top-5 Accuracy: 91.2200%, Time consumed:12.56s\n",
      "\n",
      "EarlyStopping 카운터: 3 / 30\n",
      "Epoch [73], Batch [50/391], Loss: 1.3871, LR: 0.005000\n",
      "Epoch [73], Batch [100/391], Loss: 0.7634, LR: 0.005000\n",
      "Epoch [73], Batch [150/391], Loss: 2.6789, LR: 0.005000\n",
      "Epoch [73], Batch [200/391], Loss: 2.2754, LR: 0.005000\n",
      "Epoch [73], Batch [250/391], Loss: 1.3651, LR: 0.005000\n",
      "Epoch [73], Batch [300/391], Loss: 1.4189, LR: 0.005000\n",
      "Epoch [73], Batch [350/391], Loss: 1.2483, LR: 0.005000\n",
      "Train set: Epoch: 73, Average loss:1.8430, LR: 0.005000 Top-1 Accuracy: 69.9200%, Top-5 Accuracy: 89.9540%, Time consumed:156.75s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|█████████████████████▍                                                                  | 73/300 [3:30:52<10:54:47, 173.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 73, Average loss:1.7122, Top-1 Accuracy: 70.9300%, Top-5 Accuracy: 91.8200%, Time consumed:12.34s\n",
      "\n",
      "EarlyStopping 카운터: 4 / 30\n",
      "Epoch [74], Batch [50/391], Loss: 1.5444, LR: 0.005000\n",
      "Epoch [74], Batch [100/391], Loss: 2.3737, LR: 0.005000\n",
      "Epoch [74], Batch [150/391], Loss: 1.2979, LR: 0.005000\n",
      "Epoch [74], Batch [200/391], Loss: 1.5000, LR: 0.005000\n",
      "Epoch [74], Batch [250/391], Loss: 1.2857, LR: 0.005000\n",
      "Epoch [74], Batch [300/391], Loss: 2.3418, LR: 0.005000\n",
      "Epoch [74], Batch [350/391], Loss: 1.3428, LR: 0.005000\n",
      "Train set: Epoch: 74, Average loss:1.7528, LR: 0.005000 Top-1 Accuracy: 72.4240%, Top-5 Accuracy: 91.0820%, Time consumed:158.81s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|█████████████████████▋                                                                  | 74/300 [3:33:43<10:49:28, 172.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 74, Average loss:1.7183, Top-1 Accuracy: 70.8500%, Top-5 Accuracy: 91.9900%, Time consumed:12.09s\n",
      "\n",
      "새로운 최고 top-5 정확도: 91.99%\n",
      "EarlyStopping 카운터: 5 / 30\n",
      "Epoch [75], Batch [50/391], Loss: 2.5213, LR: 0.005000\n",
      "Epoch [75], Batch [100/391], Loss: 2.1770, LR: 0.005000\n",
      "Epoch [75], Batch [150/391], Loss: 2.2409, LR: 0.005000\n",
      "Epoch [75], Batch [200/391], Loss: 2.5868, LR: 0.005000\n",
      "Epoch [75], Batch [250/391], Loss: 1.2268, LR: 0.005000\n",
      "Epoch [75], Batch [300/391], Loss: 2.8881, LR: 0.005000\n",
      "Epoch [75], Batch [350/391], Loss: 2.9630, LR: 0.005000\n",
      "Train set: Epoch: 75, Average loss:1.8505, LR: 0.005000 Top-1 Accuracy: 70.0160%, Top-5 Accuracy: 89.9580%, Time consumed:156.89s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██████████████████████                                                                  | 75/300 [3:36:33<10:43:29, 171.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 75, Average loss:1.7303, Top-1 Accuracy: 70.7000%, Top-5 Accuracy: 91.7800%, Time consumed:12.77s\n",
      "\n",
      "EarlyStopping 카운터: 6 / 30\n",
      "Epoch [76], Batch [50/391], Loss: 1.2869, LR: 0.002500\n",
      "Epoch [76], Batch [100/391], Loss: 0.8742, LR: 0.002500\n",
      "Epoch [76], Batch [150/391], Loss: 1.2486, LR: 0.002500\n",
      "Epoch [76], Batch [200/391], Loss: 3.0619, LR: 0.002500\n",
      "Epoch [76], Batch [250/391], Loss: 1.1714, LR: 0.002500\n",
      "Epoch [76], Batch [300/391], Loss: 1.2418, LR: 0.002500\n",
      "Epoch [76], Batch [350/391], Loss: 1.2306, LR: 0.002500\n",
      "Train set: Epoch: 76, Average loss:1.7675, LR: 0.002500 Top-1 Accuracy: 73.1460%, Top-5 Accuracy: 91.1680%, Time consumed:158.03s\n",
      "Test set: Epoch: 76, Average loss:1.6667, Top-1 Accuracy: 72.4100%, Top-5 Accuracy: 92.3600%, Time consumed:12.19s\n",
      "\n",
      "새로운 최고 top-1 정확도: 72.41%, top-5 정확도: 92.36%\n",
      "새로운 최고 top-5 정확도: 92.36%\n",
      "Accuracy improved (70.95% --> 72.41%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██████████████████████▎                                                                 | 76/300 [3:39:24<10:39:28, 171.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [77], Batch [50/391], Loss: 1.1664, LR: 0.002500\n",
      "Epoch [77], Batch [100/391], Loss: 1.6329, LR: 0.002500\n",
      "Epoch [77], Batch [150/391], Loss: 1.1816, LR: 0.002500\n",
      "Epoch [77], Batch [200/391], Loss: 1.2448, LR: 0.002500\n",
      "Epoch [77], Batch [250/391], Loss: 1.1755, LR: 0.002500\n",
      "Epoch [77], Batch [300/391], Loss: 1.2054, LR: 0.002500\n",
      "Epoch [77], Batch [350/391], Loss: 2.6728, LR: 0.002500\n",
      "Train set: Epoch: 77, Average loss:1.7364, LR: 0.002500 Top-1 Accuracy: 73.7180%, Top-5 Accuracy: 91.0660%, Time consumed:160.40s\n",
      "Test set: Epoch: 77, Average loss:1.6645, Top-1 Accuracy: 72.4600%, Top-5 Accuracy: 92.8200%, Time consumed:12.50s\n",
      "\n",
      "새로운 최고 top-1 정확도: 72.46%, top-5 정확도: 92.82%\n",
      "새로운 최고 top-5 정확도: 92.82%\n",
      "Accuracy improved (72.41% --> 72.46%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██████████████████████▌                                                                 | 77/300 [3:42:17<10:38:49, 171.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [78], Batch [50/391], Loss: 1.1673, LR: 0.002500\n",
      "Epoch [78], Batch [100/391], Loss: 1.1695, LR: 0.002500\n",
      "Epoch [78], Batch [150/391], Loss: 1.2094, LR: 0.002500\n",
      "Epoch [78], Batch [200/391], Loss: 1.2958, LR: 0.002500\n",
      "Epoch [78], Batch [250/391], Loss: 2.4427, LR: 0.002500\n",
      "Epoch [78], Batch [300/391], Loss: 2.1371, LR: 0.002500\n",
      "Epoch [78], Batch [350/391], Loss: 1.2446, LR: 0.002500\n",
      "Train set: Epoch: 78, Average loss:1.7448, LR: 0.002500 Top-1 Accuracy: 74.2920%, Top-5 Accuracy: 91.4280%, Time consumed:158.56s\n",
      "Test set: Epoch: 78, Average loss:1.6603, Top-1 Accuracy: 72.8400%, Top-5 Accuracy: 92.6100%, Time consumed:12.16s\n",
      "\n",
      "새로운 최고 top-1 정확도: 72.84%, top-5 정확도: 92.61%\n",
      "Accuracy improved (72.46% --> 72.84%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██████████████████████▉                                                                 | 78/300 [3:45:08<10:35:04, 171.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [79], Batch [50/391], Loss: 1.1959, LR: 0.002500\n",
      "Epoch [79], Batch [100/391], Loss: 1.2468, LR: 0.002500\n",
      "Epoch [79], Batch [150/391], Loss: 2.2935, LR: 0.002500\n",
      "Epoch [79], Batch [200/391], Loss: 1.1317, LR: 0.002500\n",
      "Epoch [79], Batch [250/391], Loss: 1.3655, LR: 0.002500\n",
      "Epoch [79], Batch [300/391], Loss: 1.5783, LR: 0.002500\n",
      "Epoch [79], Batch [350/391], Loss: 1.2032, LR: 0.002500\n",
      "Train set: Epoch: 79, Average loss:1.7160, LR: 0.002500 Top-1 Accuracy: 74.6800%, Top-5 Accuracy: 91.8320%, Time consumed:161.68s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|███████████████████████▏                                                                | 79/300 [3:48:02<10:35:00, 172.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 79, Average loss:1.6683, Top-1 Accuracy: 72.6600%, Top-5 Accuracy: 92.4800%, Time consumed:12.48s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [80], Batch [50/391], Loss: 1.1422, LR: 0.002500\n",
      "Epoch [80], Batch [100/391], Loss: 1.3363, LR: 0.002500\n",
      "Epoch [80], Batch [150/391], Loss: 1.2260, LR: 0.002500\n",
      "Epoch [80], Batch [200/391], Loss: 2.6410, LR: 0.002500\n",
      "Epoch [80], Batch [250/391], Loss: 1.1829, LR: 0.002500\n",
      "Epoch [80], Batch [300/391], Loss: 1.2192, LR: 0.002500\n",
      "Epoch [80], Batch [350/391], Loss: 1.2214, LR: 0.002500\n",
      "Train set: Epoch: 80, Average loss:1.6955, LR: 0.002500 Top-1 Accuracy: 75.5780%, Top-5 Accuracy: 92.5480%, Time consumed:156.89s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|███████████████████████▍                                                                | 80/300 [3:50:52<10:28:50, 171.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 80, Average loss:1.6681, Top-1 Accuracy: 72.4600%, Top-5 Accuracy: 92.4500%, Time consumed:12.52s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [81], Batch [50/391], Loss: 1.1245, LR: 0.002500\n",
      "Epoch [81], Batch [100/391], Loss: 2.2973, LR: 0.002500\n",
      "Epoch [81], Batch [150/391], Loss: 1.5933, LR: 0.002500\n",
      "Epoch [81], Batch [200/391], Loss: 1.1848, LR: 0.002500\n",
      "Epoch [81], Batch [250/391], Loss: 2.8237, LR: 0.002500\n",
      "Epoch [81], Batch [300/391], Loss: 1.2067, LR: 0.002500\n",
      "Epoch [81], Batch [350/391], Loss: 1.1980, LR: 0.002500\n",
      "Train set: Epoch: 81, Average loss:1.7133, LR: 0.002500 Top-1 Accuracy: 74.8500%, Top-5 Accuracy: 91.6020%, Time consumed:157.23s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|███████████████████████▊                                                                | 81/300 [3:53:41<10:23:39, 170.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 81, Average loss:1.6662, Top-1 Accuracy: 72.2900%, Top-5 Accuracy: 92.3300%, Time consumed:12.14s\n",
      "\n",
      "EarlyStopping 카운터: 3 / 30\n",
      "Epoch [82], Batch [50/391], Loss: 1.1051, LR: 0.002500\n",
      "Epoch [82], Batch [100/391], Loss: 1.1631, LR: 0.002500\n",
      "Epoch [82], Batch [150/391], Loss: 1.9991, LR: 0.002500\n",
      "Epoch [82], Batch [200/391], Loss: 1.1797, LR: 0.002500\n",
      "Epoch [82], Batch [250/391], Loss: 1.1646, LR: 0.002500\n",
      "Epoch [82], Batch [300/391], Loss: 2.4293, LR: 0.002500\n",
      "Epoch [82], Batch [350/391], Loss: 1.2019, LR: 0.002500\n",
      "Train set: Epoch: 82, Average loss:1.6901, LR: 0.002500 Top-1 Accuracy: 75.3940%, Top-5 Accuracy: 92.1680%, Time consumed:161.53s\n",
      "Test set: Epoch: 82, Average loss:1.6624, Top-1 Accuracy: 72.9300%, Top-5 Accuracy: 92.4000%, Time consumed:12.93s\n",
      "\n",
      "새로운 최고 top-1 정확도: 72.93%, top-5 정확도: 92.40%\n",
      "Accuracy improved (72.84% --> 72.93%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|████████████████████████                                                                | 82/300 [3:56:36<10:25:04, 172.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [83], Batch [50/391], Loss: 2.5530, LR: 0.001250\n",
      "Epoch [83], Batch [100/391], Loss: 1.1365, LR: 0.001250\n",
      "Epoch [83], Batch [150/391], Loss: 1.0912, LR: 0.001250\n",
      "Epoch [83], Batch [200/391], Loss: 1.1403, LR: 0.001250\n",
      "Epoch [83], Batch [250/391], Loss: 1.1003, LR: 0.001250\n",
      "Epoch [83], Batch [300/391], Loss: 1.1071, LR: 0.001250\n",
      "Epoch [83], Batch [350/391], Loss: 2.0200, LR: 0.001250\n",
      "Train set: Epoch: 83, Average loss:1.6083, LR: 0.001250 Top-1 Accuracy: 77.1940%, Top-5 Accuracy: 92.3640%, Time consumed:161.19s\n",
      "Test set: Epoch: 83, Average loss:1.6394, Top-1 Accuracy: 73.3300%, Top-5 Accuracy: 92.6600%, Time consumed:12.39s\n",
      "\n",
      "새로운 최고 top-1 정확도: 73.33%, top-5 정확도: 92.66%\n",
      "Accuracy improved (72.93% --> 73.33%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|████████████████████████▎                                                               | 83/300 [3:59:30<10:24:17, 172.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [84], Batch [50/391], Loss: 2.5024, LR: 0.001250\n",
      "Epoch [84], Batch [100/391], Loss: 1.1572, LR: 0.001250\n",
      "Epoch [84], Batch [150/391], Loss: 1.1166, LR: 0.001250\n",
      "Epoch [84], Batch [200/391], Loss: 1.1052, LR: 0.001250\n",
      "Epoch [84], Batch [250/391], Loss: 2.1076, LR: 0.001250\n",
      "Epoch [84], Batch [300/391], Loss: 1.0976, LR: 0.001250\n",
      "Epoch [84], Batch [350/391], Loss: 1.0935, LR: 0.001250\n",
      "Train set: Epoch: 84, Average loss:1.5636, LR: 0.001250 Top-1 Accuracy: 78.8560%, Top-5 Accuracy: 93.0840%, Time consumed:160.01s\n",
      "Test set: Epoch: 84, Average loss:1.6358, Top-1 Accuracy: 73.6200%, Top-5 Accuracy: 92.9600%, Time consumed:12.44s\n",
      "\n",
      "새로운 최고 top-1 정확도: 73.62%, top-5 정확도: 92.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|████████████████████████▋                                                               | 84/300 [4:02:22<10:21:41, 172.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "새로운 최고 top-5 정확도: 92.96%\n",
      "Accuracy improved (73.33% --> 73.62%). Saving model ...\n",
      "Epoch [85], Batch [50/391], Loss: 2.5356, LR: 0.001250\n",
      "Epoch [85], Batch [100/391], Loss: 2.0911, LR: 0.001250\n",
      "Epoch [85], Batch [150/391], Loss: 1.0868, LR: 0.001250\n",
      "Epoch [85], Batch [200/391], Loss: 1.1385, LR: 0.001250\n",
      "Epoch [85], Batch [250/391], Loss: 2.0604, LR: 0.001250\n",
      "Epoch [85], Batch [300/391], Loss: 1.1401, LR: 0.001250\n",
      "Epoch [85], Batch [350/391], Loss: 2.7763, LR: 0.001250\n",
      "Train set: Epoch: 85, Average loss:1.6393, LR: 0.001250 Top-1 Accuracy: 77.5440%, Top-5 Accuracy: 92.6860%, Time consumed:161.28s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|████████████████████████▉                                                               | 85/300 [4:05:16<10:19:30, 172.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 85, Average loss:1.6398, Top-1 Accuracy: 73.3500%, Top-5 Accuracy: 92.6700%, Time consumed:12.05s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [86], Batch [50/391], Loss: 1.9537, LR: 0.001250\n",
      "Epoch [86], Batch [100/391], Loss: 1.1456, LR: 0.001250\n",
      "Epoch [86], Batch [150/391], Loss: 1.1262, LR: 0.001250\n",
      "Epoch [86], Batch [200/391], Loss: 1.0740, LR: 0.001250\n",
      "Epoch [86], Batch [250/391], Loss: 1.1150, LR: 0.001250\n",
      "Epoch [86], Batch [300/391], Loss: 0.5242, LR: 0.001250\n",
      "Epoch [86], Batch [350/391], Loss: 1.1147, LR: 0.001250\n",
      "Train set: Epoch: 86, Average loss:1.6359, LR: 0.001250 Top-1 Accuracy: 77.5120%, Top-5 Accuracy: 92.5400%, Time consumed:162.97s\n",
      "Test set: Epoch: 86, Average loss:1.6398, Top-1 Accuracy: 73.6400%, Top-5 Accuracy: 92.7700%, Time consumed:12.44s\n",
      "\n",
      "새로운 최고 top-1 정확도: 73.64%, top-5 정확도: 92.77%\n",
      "Accuracy improved (73.62% --> 73.64%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|█████████████████████████▏                                                              | 86/300 [4:08:12<10:19:41, 173.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [87], Batch [50/391], Loss: 1.1212, LR: 0.001250\n",
      "Epoch [87], Batch [100/391], Loss: 1.8545, LR: 0.001250\n",
      "Epoch [87], Batch [150/391], Loss: 1.0924, LR: 0.001250\n",
      "Epoch [87], Batch [200/391], Loss: 1.1484, LR: 0.001250\n",
      "Epoch [87], Batch [250/391], Loss: 2.4854, LR: 0.001250\n",
      "Epoch [87], Batch [300/391], Loss: 2.7442, LR: 0.001250\n",
      "Epoch [87], Batch [350/391], Loss: 1.1097, LR: 0.001250\n",
      "Train set: Epoch: 87, Average loss:1.6740, LR: 0.001250 Top-1 Accuracy: 76.5900%, Top-5 Accuracy: 92.3160%, Time consumed:158.38s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|█████████████████████████▌                                                              | 87/300 [4:11:02<10:12:56, 172.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 87, Average loss:1.6417, Top-1 Accuracy: 73.4000%, Top-5 Accuracy: 92.9100%, Time consumed:11.73s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [88], Batch [50/391], Loss: 1.1406, LR: 0.001250\n",
      "Epoch [88], Batch [100/391], Loss: 1.0831, LR: 0.001250\n",
      "Epoch [88], Batch [150/391], Loss: 2.2750, LR: 0.001250\n",
      "Epoch [88], Batch [200/391], Loss: 1.1148, LR: 0.001250\n",
      "Epoch [88], Batch [250/391], Loss: 1.1244, LR: 0.001250\n",
      "Epoch [88], Batch [300/391], Loss: 1.0841, LR: 0.001250\n",
      "Epoch [88], Batch [350/391], Loss: 2.2616, LR: 0.001250\n",
      "Train set: Epoch: 88, Average loss:1.6115, LR: 0.001250 Top-1 Accuracy: 78.6380%, Top-5 Accuracy: 93.2700%, Time consumed:165.50s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|█████████████████████████▊                                                              | 88/300 [4:13:59<10:15:17, 174.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 88, Average loss:1.6408, Top-1 Accuracy: 73.3900%, Top-5 Accuracy: 92.7200%, Time consumed:12.09s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [89], Batch [50/391], Loss: 1.1622, LR: 0.001250\n",
      "Epoch [89], Batch [100/391], Loss: 1.3291, LR: 0.001250\n",
      "Epoch [89], Batch [150/391], Loss: 2.8869, LR: 0.001250\n",
      "Epoch [89], Batch [200/391], Loss: 1.1654, LR: 0.001250\n",
      "Epoch [89], Batch [250/391], Loss: 2.2359, LR: 0.001250\n",
      "Epoch [89], Batch [300/391], Loss: 2.4097, LR: 0.001250\n",
      "Epoch [89], Batch [350/391], Loss: 2.6536, LR: 0.001250\n",
      "Train set: Epoch: 89, Average loss:1.6108, LR: 0.001250 Top-1 Accuracy: 78.5400%, Top-5 Accuracy: 93.1260%, Time consumed:160.96s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██████████████████████████                                                              | 89/300 [4:16:52<10:11:13, 173.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 89, Average loss:1.6379, Top-1 Accuracy: 73.3100%, Top-5 Accuracy: 92.6200%, Time consumed:12.07s\n",
      "\n",
      "EarlyStopping 카운터: 3 / 30\n",
      "Epoch [90], Batch [50/391], Loss: 2.4869, LR: 0.000625\n",
      "Epoch [90], Batch [100/391], Loss: 1.0495, LR: 0.000625\n",
      "Epoch [90], Batch [150/391], Loss: 1.0687, LR: 0.000625\n",
      "Epoch [90], Batch [200/391], Loss: 2.0693, LR: 0.000625\n",
      "Epoch [90], Batch [250/391], Loss: 2.2034, LR: 0.000625\n",
      "Epoch [90], Batch [300/391], Loss: 1.8469, LR: 0.000625\n",
      "Epoch [90], Batch [350/391], Loss: 1.2886, LR: 0.000625\n",
      "Train set: Epoch: 90, Average loss:1.5772, LR: 0.000625 Top-1 Accuracy: 78.9000%, Top-5 Accuracy: 93.2300%, Time consumed:158.07s\n",
      "Test set: Epoch: 90, Average loss:1.6384, Top-1 Accuracy: 73.7200%, Top-5 Accuracy: 92.5500%, Time consumed:12.14s\n",
      "\n",
      "새로운 최고 top-1 정확도: 73.72%, top-5 정확도: 92.55%\n",
      "Accuracy improved (73.64% --> 73.72%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██████████████████████████▍                                                             | 90/300 [4:19:43<10:04:55, 172.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [91], Batch [50/391], Loss: 2.2408, LR: 0.000625\n",
      "Epoch [91], Batch [100/391], Loss: 1.0765, LR: 0.000625\n",
      "Epoch [91], Batch [150/391], Loss: 3.1499, LR: 0.000625\n",
      "Epoch [91], Batch [200/391], Loss: 2.6397, LR: 0.000625\n",
      "Epoch [91], Batch [250/391], Loss: 2.5079, LR: 0.000625\n",
      "Epoch [91], Batch [300/391], Loss: 1.1321, LR: 0.000625\n",
      "Epoch [91], Batch [350/391], Loss: 2.4872, LR: 0.000625\n",
      "Train set: Epoch: 91, Average loss:1.5730, LR: 0.000625 Top-1 Accuracy: 79.4440%, Top-5 Accuracy: 92.9160%, Time consumed:159.06s\n",
      "Test set: Epoch: 91, Average loss:1.6271, Top-1 Accuracy: 73.9300%, Top-5 Accuracy: 92.9100%, Time consumed:12.70s\n",
      "\n",
      "새로운 최고 top-1 정확도: 73.93%, top-5 정확도: 92.91%\n",
      "Accuracy improved (73.72% --> 73.93%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██████████████████████████▋                                                             | 91/300 [4:22:35<10:01:18, 172.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [92], Batch [50/391], Loss: 1.1655, LR: 0.000625\n",
      "Epoch [92], Batch [100/391], Loss: 1.1054, LR: 0.000625\n",
      "Epoch [92], Batch [150/391], Loss: 2.5649, LR: 0.000625\n",
      "Epoch [92], Batch [200/391], Loss: 2.5506, LR: 0.000625\n",
      "Epoch [92], Batch [250/391], Loss: 1.0955, LR: 0.000625\n",
      "Epoch [92], Batch [300/391], Loss: 2.7773, LR: 0.000625\n",
      "Epoch [92], Batch [350/391], Loss: 1.0327, LR: 0.000625\n",
      "Train set: Epoch: 92, Average loss:1.6256, LR: 0.000625 Top-1 Accuracy: 77.9300%, Top-5 Accuracy: 92.5240%, Time consumed:157.98s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███████████████████████████▎                                                             | 92/300 [4:25:25<9:56:10, 171.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 92, Average loss:1.6339, Top-1 Accuracy: 73.5700%, Top-5 Accuracy: 92.8000%, Time consumed:12.45s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [93], Batch [50/391], Loss: 1.0623, LR: 0.000625\n",
      "Epoch [93], Batch [100/391], Loss: 1.0541, LR: 0.000625\n",
      "Epoch [93], Batch [150/391], Loss: 2.3602, LR: 0.000625\n",
      "Epoch [93], Batch [200/391], Loss: 1.0827, LR: 0.000625\n",
      "Epoch [93], Batch [250/391], Loss: 0.4733, LR: 0.000625\n",
      "Epoch [93], Batch [300/391], Loss: 2.7544, LR: 0.000625\n",
      "Epoch [93], Batch [350/391], Loss: 2.5066, LR: 0.000625\n",
      "Train set: Epoch: 93, Average loss:1.6489, LR: 0.000625 Top-1 Accuracy: 76.4040%, Top-5 Accuracy: 91.3400%, Time consumed:157.39s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███████████████████████████▌                                                             | 93/300 [4:28:15<9:51:11, 171.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 93, Average loss:1.6350, Top-1 Accuracy: 73.5900%, Top-5 Accuracy: 92.5400%, Time consumed:12.53s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [94], Batch [50/391], Loss: 1.0281, LR: 0.000625\n",
      "Epoch [94], Batch [100/391], Loss: 1.0223, LR: 0.000625\n",
      "Epoch [94], Batch [150/391], Loss: 2.0132, LR: 0.000625\n",
      "Epoch [94], Batch [200/391], Loss: 2.6717, LR: 0.000625\n",
      "Epoch [94], Batch [250/391], Loss: 1.9992, LR: 0.000625\n",
      "Epoch [94], Batch [300/391], Loss: 2.3426, LR: 0.000625\n",
      "Epoch [94], Batch [350/391], Loss: 2.3071, LR: 0.000625\n",
      "Train set: Epoch: 94, Average loss:1.6422, LR: 0.000625 Top-1 Accuracy: 78.4860%, Top-5 Accuracy: 93.1940%, Time consumed:159.41s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███████████████████████████▉                                                             | 94/300 [4:31:07<9:48:27, 171.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 94, Average loss:1.6436, Top-1 Accuracy: 73.4000%, Top-5 Accuracy: 92.7400%, Time consumed:12.06s\n",
      "\n",
      "EarlyStopping 카운터: 3 / 30\n",
      "Epoch [95], Batch [50/391], Loss: 1.0844, LR: 0.000625\n",
      "Epoch [95], Batch [100/391], Loss: 2.5794, LR: 0.000625\n",
      "Epoch [95], Batch [150/391], Loss: 1.0919, LR: 0.000625\n",
      "Epoch [95], Batch [200/391], Loss: 1.1083, LR: 0.000625\n",
      "Epoch [95], Batch [250/391], Loss: 2.6519, LR: 0.000625\n",
      "Epoch [95], Batch [300/391], Loss: 1.2004, LR: 0.000625\n",
      "Epoch [95], Batch [350/391], Loss: 2.6632, LR: 0.000625\n",
      "Train set: Epoch: 95, Average loss:1.5210, LR: 0.000625 Top-1 Accuracy: 80.3560%, Top-5 Accuracy: 93.4780%, Time consumed:165.34s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|████████████████████████████▏                                                            | 95/300 [4:34:05<9:52:47, 173.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 95, Average loss:1.6280, Top-1 Accuracy: 73.7900%, Top-5 Accuracy: 93.0100%, Time consumed:13.06s\n",
      "\n",
      "새로운 최고 top-5 정확도: 93.01%\n",
      "EarlyStopping 카운터: 4 / 30\n",
      "Epoch [96], Batch [50/391], Loss: 2.1588, LR: 0.000312\n",
      "Epoch [96], Batch [100/391], Loss: 1.0424, LR: 0.000312\n",
      "Epoch [96], Batch [150/391], Loss: 1.5686, LR: 0.000312\n",
      "Epoch [96], Batch [200/391], Loss: 1.4307, LR: 0.000312\n",
      "Epoch [96], Batch [250/391], Loss: 0.5359, LR: 0.000312\n",
      "Epoch [96], Batch [300/391], Loss: 1.0487, LR: 0.000312\n",
      "Epoch [96], Batch [350/391], Loss: 1.0783, LR: 0.000312\n",
      "Train set: Epoch: 96, Average loss:1.5230, LR: 0.000312 Top-1 Accuracy: 81.5400%, Top-5 Accuracy: 94.4860%, Time consumed:159.19s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|████████████████████████████▍                                                            | 96/300 [4:36:57<9:47:36, 172.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 96, Average loss:1.6300, Top-1 Accuracy: 73.6700%, Top-5 Accuracy: 92.7900%, Time consumed:12.06s\n",
      "\n",
      "EarlyStopping 카운터: 5 / 30\n",
      "Epoch [97], Batch [50/391], Loss: 1.0979, LR: 0.000312\n",
      "Epoch [97], Batch [100/391], Loss: 1.3848, LR: 0.000312\n",
      "Epoch [97], Batch [150/391], Loss: 1.2866, LR: 0.000312\n",
      "Epoch [97], Batch [200/391], Loss: 2.6926, LR: 0.000312\n",
      "Epoch [97], Batch [250/391], Loss: 1.0685, LR: 0.000312\n",
      "Epoch [97], Batch [300/391], Loss: 1.0492, LR: 0.000312\n",
      "Epoch [97], Batch [350/391], Loss: 0.7086, LR: 0.000312\n",
      "Train set: Epoch: 97, Average loss:1.5699, LR: 0.000312 Top-1 Accuracy: 79.6500%, Top-5 Accuracy: 93.2900%, Time consumed:164.48s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|████████████████████████████▊                                                            | 97/300 [4:39:54<9:49:32, 174.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 97, Average loss:1.6229, Top-1 Accuracy: 73.6900%, Top-5 Accuracy: 92.8700%, Time consumed:13.08s\n",
      "\n",
      "EarlyStopping 카운터: 6 / 30\n",
      "Epoch [98], Batch [50/391], Loss: 2.5174, LR: 0.000312\n",
      "Epoch [98], Batch [100/391], Loss: 1.8781, LR: 0.000312\n",
      "Epoch [98], Batch [150/391], Loss: 1.0377, LR: 0.000312\n",
      "Epoch [98], Batch [200/391], Loss: 2.6067, LR: 0.000312\n",
      "Epoch [98], Batch [250/391], Loss: 1.0751, LR: 0.000312\n",
      "Epoch [98], Batch [300/391], Loss: 1.0855, LR: 0.000312\n",
      "Epoch [98], Batch [350/391], Loss: 1.0659, LR: 0.000312\n",
      "Train set: Epoch: 98, Average loss:1.5517, LR: 0.000312 Top-1 Accuracy: 80.4840%, Top-5 Accuracy: 93.6060%, Time consumed:157.37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|█████████████████████████████                                                            | 98/300 [4:42:44<9:42:28, 173.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 98, Average loss:1.6349, Top-1 Accuracy: 73.6700%, Top-5 Accuracy: 92.6000%, Time consumed:12.74s\n",
      "\n",
      "EarlyStopping 카운터: 7 / 30\n",
      "Epoch [99], Batch [50/391], Loss: 1.9152, LR: 0.000312\n",
      "Epoch [99], Batch [100/391], Loss: 1.0455, LR: 0.000312\n",
      "Epoch [99], Batch [150/391], Loss: 2.7658, LR: 0.000312\n",
      "Epoch [99], Batch [200/391], Loss: 2.7598, LR: 0.000312\n",
      "Epoch [99], Batch [250/391], Loss: 1.0629, LR: 0.000312\n",
      "Epoch [99], Batch [300/391], Loss: 2.4307, LR: 0.000312\n",
      "Epoch [99], Batch [350/391], Loss: 1.0289, LR: 0.000312\n",
      "Train set: Epoch: 99, Average loss:1.5942, LR: 0.000312 Top-1 Accuracy: 78.2820%, Top-5 Accuracy: 92.3420%, Time consumed:158.92s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|█████████████████████████████▎                                                           | 99/300 [4:45:36<9:38:11, 172.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 99, Average loss:1.6276, Top-1 Accuracy: 73.7100%, Top-5 Accuracy: 92.8100%, Time consumed:12.70s\n",
      "\n",
      "EarlyStopping 카운터: 8 / 30\n",
      "Epoch [100], Batch [50/391], Loss: 1.0558, LR: 0.000312\n",
      "Epoch [100], Batch [100/391], Loss: 1.7851, LR: 0.000312\n",
      "Epoch [100], Batch [150/391], Loss: 1.0549, LR: 0.000312\n",
      "Epoch [100], Batch [200/391], Loss: 1.4995, LR: 0.000312\n",
      "Epoch [100], Batch [250/391], Loss: 2.5630, LR: 0.000312\n",
      "Epoch [100], Batch [300/391], Loss: 1.0593, LR: 0.000312\n",
      "Epoch [100], Batch [350/391], Loss: 1.0068, LR: 0.000312\n",
      "Train set: Epoch: 100, Average loss:1.5659, LR: 0.000312 Top-1 Accuracy: 80.0020%, Top-5 Accuracy: 93.5580%, Time consumed:160.60s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|█████████████████████████████▎                                                          | 100/300 [4:48:29<9:35:32, 172.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 100, Average loss:1.6351, Top-1 Accuracy: 73.6100%, Top-5 Accuracy: 92.7700%, Time consumed:12.22s\n",
      "\n",
      "EarlyStopping 카운터: 9 / 30\n",
      "Epoch [101], Batch [50/391], Loss: 1.0520, LR: 0.000312\n",
      "Epoch [101], Batch [100/391], Loss: 1.2776, LR: 0.000312\n",
      "Epoch [101], Batch [150/391], Loss: 1.0423, LR: 0.000312\n",
      "Epoch [101], Batch [200/391], Loss: 1.6241, LR: 0.000312\n",
      "Epoch [101], Batch [250/391], Loss: 1.7291, LR: 0.000312\n",
      "Epoch [101], Batch [300/391], Loss: 2.3248, LR: 0.000312\n",
      "Epoch [101], Batch [350/391], Loss: 2.7633, LR: 0.000312\n",
      "Train set: Epoch: 101, Average loss:1.5766, LR: 0.000312 Top-1 Accuracy: 79.6760%, Top-5 Accuracy: 93.2020%, Time consumed:159.92s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|█████████████████████████████▋                                                          | 101/300 [4:51:21<9:31:58, 172.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 101, Average loss:1.6279, Top-1 Accuracy: 73.5800%, Top-5 Accuracy: 92.8000%, Time consumed:12.03s\n",
      "\n",
      "EarlyStopping 카운터: 10 / 30\n",
      "Epoch [102], Batch [50/391], Loss: 2.6529, LR: 0.000156\n",
      "Epoch [102], Batch [100/391], Loss: 1.0453, LR: 0.000156\n",
      "Epoch [102], Batch [150/391], Loss: 1.2329, LR: 0.000156\n",
      "Epoch [102], Batch [200/391], Loss: 0.7201, LR: 0.000156\n",
      "Epoch [102], Batch [250/391], Loss: 2.7431, LR: 0.000156\n",
      "Epoch [102], Batch [300/391], Loss: 1.5707, LR: 0.000156\n",
      "Epoch [102], Batch [350/391], Loss: 1.0412, LR: 0.000156\n",
      "Train set: Epoch: 102, Average loss:1.5822, LR: 0.000156 Top-1 Accuracy: 79.5080%, Top-5 Accuracy: 93.5520%, Time consumed:159.59s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|█████████████████████████████▉                                                          | 102/300 [4:54:13<9:28:29, 172.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 102, Average loss:1.6558, Top-1 Accuracy: 73.0800%, Top-5 Accuracy: 92.3900%, Time consumed:12.26s\n",
      "\n",
      "EarlyStopping 카운터: 11 / 30\n",
      "Epoch [103], Batch [50/391], Loss: 2.5018, LR: 0.000156\n",
      "Epoch [103], Batch [100/391], Loss: 2.4962, LR: 0.000156\n",
      "Epoch [103], Batch [150/391], Loss: 2.6064, LR: 0.000156\n",
      "Epoch [103], Batch [200/391], Loss: 1.8898, LR: 0.000156\n",
      "Epoch [103], Batch [250/391], Loss: 1.0688, LR: 0.000156\n",
      "Epoch [103], Batch [300/391], Loss: 1.5033, LR: 0.000156\n",
      "Epoch [103], Batch [350/391], Loss: 1.9828, LR: 0.000156\n",
      "Train set: Epoch: 103, Average loss:1.5512, LR: 0.000156 Top-1 Accuracy: 80.8540%, Top-5 Accuracy: 93.8580%, Time consumed:161.70s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|██████████████████████████████▏                                                         | 103/300 [4:57:07<9:27:20, 172.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 103, Average loss:1.6229, Top-1 Accuracy: 73.7300%, Top-5 Accuracy: 92.9500%, Time consumed:12.30s\n",
      "\n",
      "EarlyStopping 카운터: 12 / 30\n",
      "Epoch [104], Batch [50/391], Loss: 1.0175, LR: 0.000156\n",
      "Epoch [104], Batch [100/391], Loss: 2.3445, LR: 0.000156\n",
      "Epoch [104], Batch [150/391], Loss: 1.0687, LR: 0.000156\n",
      "Epoch [104], Batch [200/391], Loss: 0.4965, LR: 0.000156\n",
      "Epoch [104], Batch [250/391], Loss: 1.0444, LR: 0.000156\n",
      "Epoch [104], Batch [300/391], Loss: 1.0587, LR: 0.000156\n",
      "Epoch [104], Batch [350/391], Loss: 1.7791, LR: 0.000156\n",
      "Train set: Epoch: 104, Average loss:1.5239, LR: 0.000156 Top-1 Accuracy: 81.2840%, Top-5 Accuracy: 93.8120%, Time consumed:165.04s\n",
      "Test set: Epoch: 104, Average loss:1.6211, Top-1 Accuracy: 73.9400%, Top-5 Accuracy: 92.9600%, Time consumed:12.31s\n",
      "\n",
      "새로운 최고 top-1 정확도: 73.94%, top-5 정확도: 92.96%\n",
      "Accuracy improved (73.93% --> 73.94%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|██████████████████████████████▌                                                         | 104/300 [5:00:04<9:29:16, 174.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [105], Batch [50/391], Loss: 1.1556, LR: 0.000156\n",
      "Epoch [105], Batch [100/391], Loss: 1.0227, LR: 0.000156\n",
      "Epoch [105], Batch [150/391], Loss: 1.0323, LR: 0.000156\n",
      "Epoch [105], Batch [200/391], Loss: 2.5063, LR: 0.000156\n",
      "Epoch [105], Batch [250/391], Loss: 2.5657, LR: 0.000156\n",
      "Epoch [105], Batch [300/391], Loss: 2.5329, LR: 0.000156\n",
      "Epoch [105], Batch [350/391], Loss: 1.0288, LR: 0.000156\n",
      "Train set: Epoch: 105, Average loss:1.5413, LR: 0.000156 Top-1 Accuracy: 80.6960%, Top-5 Accuracy: 94.0900%, Time consumed:163.50s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|██████████████████████████████▊                                                         | 105/300 [5:03:00<9:28:02, 174.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 105, Average loss:1.6248, Top-1 Accuracy: 73.9200%, Top-5 Accuracy: 92.8100%, Time consumed:12.48s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [106], Batch [50/391], Loss: 1.1742, LR: 0.000156\n",
      "Epoch [106], Batch [100/391], Loss: 1.0947, LR: 0.000156\n",
      "Epoch [106], Batch [150/391], Loss: 2.5690, LR: 0.000156\n",
      "Epoch [106], Batch [200/391], Loss: 1.0570, LR: 0.000156\n",
      "Epoch [106], Batch [250/391], Loss: 1.0507, LR: 0.000156\n",
      "Epoch [106], Batch [300/391], Loss: 1.0551, LR: 0.000156\n",
      "Epoch [106], Batch [350/391], Loss: 1.0675, LR: 0.000156\n",
      "Train set: Epoch: 106, Average loss:1.5960, LR: 0.000156 Top-1 Accuracy: 78.9000%, Top-5 Accuracy: 92.8420%, Time consumed:162.98s\n",
      "Test set: Epoch: 106, Average loss:1.6266, Top-1 Accuracy: 73.9600%, Top-5 Accuracy: 92.8100%, Time consumed:12.31s\n",
      "\n",
      "새로운 최고 top-1 정확도: 73.96%, top-5 정확도: 92.81%\n",
      "Accuracy improved (73.94% --> 73.96%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███████████████████████████████                                                         | 106/300 [5:05:56<9:25:57, 175.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [107], Batch [50/391], Loss: 0.7221, LR: 0.000156\n",
      "Epoch [107], Batch [100/391], Loss: 1.0470, LR: 0.000156\n",
      "Epoch [107], Batch [150/391], Loss: 1.0464, LR: 0.000156\n",
      "Epoch [107], Batch [200/391], Loss: 1.8868, LR: 0.000156\n",
      "Epoch [107], Batch [250/391], Loss: 2.7746, LR: 0.000156\n",
      "Epoch [107], Batch [300/391], Loss: 0.7598, LR: 0.000156\n",
      "Epoch [107], Batch [350/391], Loss: 1.0706, LR: 0.000156\n",
      "Train set: Epoch: 107, Average loss:1.4812, LR: 0.000156 Top-1 Accuracy: 82.1920%, Top-5 Accuracy: 94.3440%, Time consumed:164.70s\n",
      "Test set: Epoch: 107, Average loss:1.6204, Top-1 Accuracy: 74.1100%, Top-5 Accuracy: 92.9500%, Time consumed:12.18s\n",
      "\n",
      "새로운 최고 top-1 정확도: 74.11%, top-5 정확도: 92.95%\n",
      "Accuracy improved (73.96% --> 74.11%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███████████████████████████████▍                                                        | 107/300 [5:08:53<9:25:10, 175.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [108], Batch [50/391], Loss: 1.0246, LR: 0.000156\n",
      "Epoch [108], Batch [100/391], Loss: 2.8012, LR: 0.000156\n",
      "Epoch [108], Batch [150/391], Loss: 1.0719, LR: 0.000156\n",
      "Epoch [108], Batch [200/391], Loss: 2.3009, LR: 0.000156\n",
      "Epoch [108], Batch [250/391], Loss: 1.3882, LR: 0.000156\n",
      "Epoch [108], Batch [300/391], Loss: 1.0572, LR: 0.000156\n",
      "Epoch [108], Batch [350/391], Loss: 2.1818, LR: 0.000156\n",
      "Train set: Epoch: 108, Average loss:1.5431, LR: 0.000156 Top-1 Accuracy: 81.1440%, Top-5 Accuracy: 93.9280%, Time consumed:163.74s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███████████████████████████████▋                                                        | 108/300 [5:11:49<9:22:13, 175.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 108, Average loss:1.6235, Top-1 Accuracy: 73.8600%, Top-5 Accuracy: 92.8200%, Time consumed:11.94s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [109], Batch [50/391], Loss: 1.0212, LR: 0.000156\n",
      "Epoch [109], Batch [100/391], Loss: 1.1635, LR: 0.000156\n",
      "Epoch [109], Batch [150/391], Loss: 1.0668, LR: 0.000156\n",
      "Epoch [109], Batch [200/391], Loss: 2.1032, LR: 0.000156\n",
      "Epoch [109], Batch [250/391], Loss: 1.9383, LR: 0.000156\n",
      "Epoch [109], Batch [300/391], Loss: 2.5963, LR: 0.000156\n",
      "Epoch [109], Batch [350/391], Loss: 0.9923, LR: 0.000156\n",
      "Train set: Epoch: 109, Average loss:1.5656, LR: 0.000156 Top-1 Accuracy: 80.3260%, Top-5 Accuracy: 93.5240%, Time consumed:160.98s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███████████████████████████████▉                                                        | 109/300 [5:14:42<9:16:30, 174.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 109, Average loss:1.6204, Top-1 Accuracy: 73.6800%, Top-5 Accuracy: 92.9200%, Time consumed:11.78s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [110], Batch [50/391], Loss: 1.0342, LR: 0.000156\n",
      "Epoch [110], Batch [100/391], Loss: 2.6301, LR: 0.000156\n",
      "Epoch [110], Batch [150/391], Loss: 2.5077, LR: 0.000156\n",
      "Epoch [110], Batch [200/391], Loss: 1.0489, LR: 0.000156\n",
      "Epoch [110], Batch [250/391], Loss: 1.0101, LR: 0.000156\n",
      "Epoch [110], Batch [300/391], Loss: 2.4465, LR: 0.000156\n",
      "Epoch [110], Batch [350/391], Loss: 1.0529, LR: 0.000156\n",
      "Train set: Epoch: 110, Average loss:1.5619, LR: 0.000156 Top-1 Accuracy: 80.0440%, Top-5 Accuracy: 93.4140%, Time consumed:161.64s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|████████████████████████████████▎                                                       | 110/300 [5:17:35<9:12:22, 174.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 110, Average loss:1.6178, Top-1 Accuracy: 73.9300%, Top-5 Accuracy: 92.8900%, Time consumed:11.88s\n",
      "\n",
      "EarlyStopping 카운터: 3 / 30\n",
      "Epoch [111], Batch [50/391], Loss: 1.3982, LR: 0.000156\n",
      "Epoch [111], Batch [100/391], Loss: 2.7630, LR: 0.000156\n",
      "Epoch [111], Batch [150/391], Loss: 1.7568, LR: 0.000156\n",
      "Epoch [111], Batch [200/391], Loss: 1.0723, LR: 0.000156\n",
      "Epoch [111], Batch [250/391], Loss: 1.3626, LR: 0.000156\n",
      "Epoch [111], Batch [300/391], Loss: 1.0533, LR: 0.000156\n",
      "Epoch [111], Batch [350/391], Loss: 1.0325, LR: 0.000156\n",
      "Train set: Epoch: 111, Average loss:1.4735, LR: 0.000156 Top-1 Accuracy: 83.0480%, Top-5 Accuracy: 94.9340%, Time consumed:158.75s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|████████████████████████████████▌                                                       | 111/300 [5:20:26<9:06:29, 173.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 111, Average loss:1.6201, Top-1 Accuracy: 73.8800%, Top-5 Accuracy: 92.8300%, Time consumed:12.54s\n",
      "\n",
      "EarlyStopping 카운터: 4 / 30\n",
      "Epoch [112], Batch [50/391], Loss: 2.6133, LR: 0.000156\n",
      "Epoch [112], Batch [100/391], Loss: 2.5134, LR: 0.000156\n",
      "Epoch [112], Batch [150/391], Loss: 2.2338, LR: 0.000156\n",
      "Epoch [112], Batch [200/391], Loss: 0.9257, LR: 0.000156\n",
      "Epoch [112], Batch [250/391], Loss: 1.0435, LR: 0.000156\n",
      "Epoch [112], Batch [300/391], Loss: 1.5212, LR: 0.000156\n",
      "Epoch [112], Batch [350/391], Loss: 1.0104, LR: 0.000156\n",
      "Train set: Epoch: 112, Average loss:1.5327, LR: 0.000156 Top-1 Accuracy: 80.7100%, Top-5 Accuracy: 93.7740%, Time consumed:166.29s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|████████████████████████████████▊                                                       | 112/300 [5:23:25<9:08:17, 174.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 112, Average loss:1.6246, Top-1 Accuracy: 73.9600%, Top-5 Accuracy: 92.7300%, Time consumed:12.19s\n",
      "\n",
      "EarlyStopping 카운터: 5 / 30\n",
      "Epoch [113], Batch [50/391], Loss: 0.4267, LR: 0.000156\n",
      "Epoch [113], Batch [100/391], Loss: 2.5834, LR: 0.000156\n",
      "Epoch [113], Batch [150/391], Loss: 0.7102, LR: 0.000156\n",
      "Epoch [113], Batch [200/391], Loss: 2.1779, LR: 0.000156\n",
      "Epoch [113], Batch [250/391], Loss: 2.5740, LR: 0.000156\n",
      "Epoch [113], Batch [300/391], Loss: 1.0629, LR: 0.000156\n",
      "Epoch [113], Batch [350/391], Loss: 2.3899, LR: 0.000156\n",
      "Train set: Epoch: 113, Average loss:1.5571, LR: 0.000156 Top-1 Accuracy: 80.2600%, Top-5 Accuracy: 93.4940%, Time consumed:156.87s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|█████████████████████████████████▏                                                      | 113/300 [5:26:14<9:00:05, 173.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 113, Average loss:1.6204, Top-1 Accuracy: 73.9000%, Top-5 Accuracy: 93.0200%, Time consumed:12.45s\n",
      "\n",
      "새로운 최고 top-5 정확도: 93.02%\n",
      "EarlyStopping 카운터: 6 / 30\n",
      "Epoch [114], Batch [50/391], Loss: 1.0624, LR: 0.000078\n",
      "Epoch [114], Batch [100/391], Loss: 1.0690, LR: 0.000078\n",
      "Epoch [114], Batch [150/391], Loss: 1.0061, LR: 0.000078\n",
      "Epoch [114], Batch [200/391], Loss: 1.0252, LR: 0.000078\n",
      "Epoch [114], Batch [250/391], Loss: 1.0661, LR: 0.000078\n",
      "Epoch [114], Batch [300/391], Loss: 1.0291, LR: 0.000078\n",
      "Epoch [114], Batch [350/391], Loss: 1.0215, LR: 0.000078\n",
      "Train set: Epoch: 114, Average loss:1.5607, LR: 0.000078 Top-1 Accuracy: 80.4880%, Top-5 Accuracy: 93.8260%, Time consumed:159.17s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|█████████████████████████████████▍                                                      | 114/300 [5:29:05<8:55:21, 172.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 114, Average loss:1.6274, Top-1 Accuracy: 73.7300%, Top-5 Accuracy: 92.7400%, Time consumed:12.13s\n",
      "\n",
      "EarlyStopping 카운터: 7 / 30\n",
      "Epoch [115], Batch [50/391], Loss: 2.9192, LR: 0.000078\n",
      "Epoch [115], Batch [100/391], Loss: 1.0710, LR: 0.000078\n",
      "Epoch [115], Batch [150/391], Loss: 1.7883, LR: 0.000078\n",
      "Epoch [115], Batch [200/391], Loss: 2.9143, LR: 0.000078\n",
      "Epoch [115], Batch [250/391], Loss: 1.0604, LR: 0.000078\n",
      "Epoch [115], Batch [300/391], Loss: 1.0856, LR: 0.000078\n",
      "Epoch [115], Batch [350/391], Loss: 3.0985, LR: 0.000078\n",
      "Train set: Epoch: 115, Average loss:1.5887, LR: 0.000078 Top-1 Accuracy: 78.2420%, Top-5 Accuracy: 92.3160%, Time consumed:158.08s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|█████████████████████████████████▋                                                      | 115/300 [5:31:56<8:50:20, 172.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 115, Average loss:1.6223, Top-1 Accuracy: 73.9600%, Top-5 Accuracy: 92.8700%, Time consumed:12.30s\n",
      "\n",
      "EarlyStopping 카운터: 8 / 30\n",
      "Epoch [116], Batch [50/391], Loss: 2.6055, LR: 0.000078\n",
      "Epoch [116], Batch [100/391], Loss: 2.3384, LR: 0.000078\n",
      "Epoch [116], Batch [150/391], Loss: 1.0765, LR: 0.000078\n",
      "Epoch [116], Batch [200/391], Loss: 0.3778, LR: 0.000078\n",
      "Epoch [116], Batch [250/391], Loss: 2.7364, LR: 0.000078\n",
      "Epoch [116], Batch [300/391], Loss: 2.6932, LR: 0.000078\n",
      "Epoch [116], Batch [350/391], Loss: 1.0690, LR: 0.000078\n",
      "Train set: Epoch: 116, Average loss:1.5585, LR: 0.000078 Top-1 Accuracy: 80.6260%, Top-5 Accuracy: 93.9580%, Time consumed:160.13s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|██████████████████████████████████                                                      | 116/300 [5:34:49<8:48:19, 172.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 116, Average loss:1.6351, Top-1 Accuracy: 73.5900%, Top-5 Accuracy: 92.6900%, Time consumed:12.79s\n",
      "\n",
      "EarlyStopping 카운터: 9 / 30\n",
      "Epoch [117], Batch [50/391], Loss: 1.0156, LR: 0.000078\n",
      "Epoch [117], Batch [100/391], Loss: 2.8918, LR: 0.000078\n",
      "Epoch [117], Batch [150/391], Loss: 1.0666, LR: 0.000078\n",
      "Epoch [117], Batch [200/391], Loss: 1.0356, LR: 0.000078\n",
      "Epoch [117], Batch [250/391], Loss: 1.0269, LR: 0.000078\n",
      "Epoch [117], Batch [300/391], Loss: 2.4513, LR: 0.000078\n",
      "Epoch [117], Batch [350/391], Loss: 0.5405, LR: 0.000078\n",
      "Train set: Epoch: 117, Average loss:1.5379, LR: 0.000078 Top-1 Accuracy: 79.6280%, Top-5 Accuracy: 93.0000%, Time consumed:168.27s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|██████████████████████████████████▎                                                     | 117/300 [5:37:49<8:52:45, 174.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 117, Average loss:1.6417, Top-1 Accuracy: 73.6900%, Top-5 Accuracy: 92.6500%, Time consumed:11.98s\n",
      "\n",
      "EarlyStopping 카운터: 10 / 30\n",
      "Epoch [118], Batch [50/391], Loss: 1.5880, LR: 0.000078\n",
      "Epoch [118], Batch [100/391], Loss: 1.0572, LR: 0.000078\n",
      "Epoch [118], Batch [150/391], Loss: 1.0742, LR: 0.000078\n",
      "Epoch [118], Batch [200/391], Loss: 2.9855, LR: 0.000078\n",
      "Epoch [118], Batch [250/391], Loss: 1.0568, LR: 0.000078\n",
      "Epoch [118], Batch [300/391], Loss: 1.0567, LR: 0.000078\n",
      "Epoch [118], Batch [350/391], Loss: 1.0614, LR: 0.000078\n",
      "Train set: Epoch: 118, Average loss:1.4904, LR: 0.000078 Top-1 Accuracy: 81.2020%, Top-5 Accuracy: 94.0260%, Time consumed:157.28s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|██████████████████████████████████▌                                                     | 118/300 [5:40:39<8:45:16, 173.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 118, Average loss:1.6256, Top-1 Accuracy: 73.6800%, Top-5 Accuracy: 92.7900%, Time consumed:12.36s\n",
      "\n",
      "EarlyStopping 카운터: 11 / 30\n",
      "Epoch [119], Batch [50/391], Loss: 2.2520, LR: 0.000078\n",
      "Epoch [119], Batch [100/391], Loss: 2.5384, LR: 0.000078\n",
      "Epoch [119], Batch [150/391], Loss: 1.6310, LR: 0.000078\n",
      "Epoch [119], Batch [200/391], Loss: 1.9271, LR: 0.000078\n",
      "Epoch [119], Batch [250/391], Loss: 2.0759, LR: 0.000078\n",
      "Epoch [119], Batch [300/391], Loss: 1.0444, LR: 0.000078\n",
      "Epoch [119], Batch [350/391], Loss: 1.4983, LR: 0.000078\n",
      "Train set: Epoch: 119, Average loss:1.5120, LR: 0.000078 Top-1 Accuracy: 82.0740%, Top-5 Accuracy: 94.3300%, Time consumed:161.22s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████████▉                                                     | 119/300 [5:43:32<8:42:26, 173.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 119, Average loss:1.6211, Top-1 Accuracy: 74.0100%, Top-5 Accuracy: 92.8700%, Time consumed:12.00s\n",
      "\n",
      "EarlyStopping 카운터: 12 / 30\n",
      "Epoch [120], Batch [50/391], Loss: 1.0437, LR: 0.000039\n",
      "Epoch [120], Batch [100/391], Loss: 1.0721, LR: 0.000039\n",
      "Epoch [120], Batch [150/391], Loss: 2.4426, LR: 0.000039\n",
      "Epoch [120], Batch [200/391], Loss: 2.1751, LR: 0.000039\n",
      "Epoch [120], Batch [250/391], Loss: 0.8721, LR: 0.000039\n",
      "Epoch [120], Batch [300/391], Loss: 1.0565, LR: 0.000039\n",
      "Epoch [120], Batch [350/391], Loss: 0.7189, LR: 0.000039\n",
      "Train set: Epoch: 120, Average loss:1.5459, LR: 0.000039 Top-1 Accuracy: 81.1680%, Top-5 Accuracy: 94.0120%, Time consumed:161.85s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███████████████████████████████████▏                                                    | 120/300 [5:46:26<8:40:31, 173.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 120, Average loss:1.6207, Top-1 Accuracy: 73.8000%, Top-5 Accuracy: 92.7500%, Time consumed:12.41s\n",
      "\n",
      "EarlyStopping 카운터: 13 / 30\n",
      "Epoch [121], Batch [50/391], Loss: 2.5836, LR: 0.000039\n",
      "Epoch [121], Batch [100/391], Loss: 2.4748, LR: 0.000039\n",
      "Epoch [121], Batch [150/391], Loss: 1.0383, LR: 0.000039\n",
      "Epoch [121], Batch [200/391], Loss: 2.8042, LR: 0.000039\n",
      "Epoch [121], Batch [250/391], Loss: 3.0772, LR: 0.000039\n",
      "Epoch [121], Batch [300/391], Loss: 1.0486, LR: 0.000039\n",
      "Epoch [121], Batch [350/391], Loss: 0.6827, LR: 0.000039\n",
      "Train set: Epoch: 121, Average loss:1.5992, LR: 0.000039 Top-1 Accuracy: 78.8500%, Top-5 Accuracy: 92.8500%, Time consumed:159.17s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███████████████████████████████████▍                                                    | 121/300 [5:49:18<8:35:45, 172.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 121, Average loss:1.6216, Top-1 Accuracy: 73.6200%, Top-5 Accuracy: 93.0500%, Time consumed:12.24s\n",
      "\n",
      "새로운 최고 top-5 정확도: 93.05%\n",
      "EarlyStopping 카운터: 14 / 30\n",
      "Epoch [122], Batch [50/391], Loss: 0.2975, LR: 0.000039\n",
      "Epoch [122], Batch [100/391], Loss: 1.0573, LR: 0.000039\n",
      "Epoch [122], Batch [150/391], Loss: 1.0364, LR: 0.000039\n",
      "Epoch [122], Batch [200/391], Loss: 1.6594, LR: 0.000039\n",
      "Epoch [122], Batch [250/391], Loss: 2.0686, LR: 0.000039\n",
      "Epoch [122], Batch [300/391], Loss: 1.1039, LR: 0.000039\n",
      "Epoch [122], Batch [350/391], Loss: 2.7336, LR: 0.000039\n",
      "Train set: Epoch: 122, Average loss:1.5494, LR: 0.000039 Top-1 Accuracy: 80.1700%, Top-5 Accuracy: 93.7880%, Time consumed:156.73s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|███████████████████████████████████▊                                                    | 122/300 [5:52:07<8:29:28, 171.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 122, Average loss:1.6167, Top-1 Accuracy: 74.0400%, Top-5 Accuracy: 93.0400%, Time consumed:12.31s\n",
      "\n",
      "EarlyStopping 카운터: 15 / 30\n",
      "Epoch [123], Batch [50/391], Loss: 1.7495, LR: 0.000039\n",
      "Epoch [123], Batch [100/391], Loss: 2.1921, LR: 0.000039\n",
      "Epoch [123], Batch [150/391], Loss: 1.0135, LR: 0.000039\n",
      "Epoch [123], Batch [200/391], Loss: 2.5359, LR: 0.000039\n",
      "Epoch [123], Batch [250/391], Loss: 1.0479, LR: 0.000039\n",
      "Epoch [123], Batch [300/391], Loss: 3.0387, LR: 0.000039\n",
      "Epoch [123], Batch [350/391], Loss: 1.0468, LR: 0.000039\n",
      "Train set: Epoch: 123, Average loss:1.5435, LR: 0.000039 Top-1 Accuracy: 80.1580%, Top-5 Accuracy: 93.2240%, Time consumed:156.86s\n",
      "Test set: Epoch: 123, Average loss:1.6199, Top-1 Accuracy: 74.1700%, Top-5 Accuracy: 92.9300%, Time consumed:12.53s\n",
      "\n",
      "새로운 최고 top-1 정확도: 74.17%, top-5 정확도: 92.93%\n",
      "Accuracy improved (74.11% --> 74.17%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████████████████████████████████████                                                    | 123/300 [5:54:56<8:24:50, 171.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [124], Batch [50/391], Loss: 1.0064, LR: 0.000039\n",
      "Epoch [124], Batch [100/391], Loss: 1.9594, LR: 0.000039\n",
      "Epoch [124], Batch [150/391], Loss: 1.0111, LR: 0.000039\n",
      "Epoch [124], Batch [200/391], Loss: 0.8937, LR: 0.000039\n",
      "Epoch [124], Batch [250/391], Loss: 2.7377, LR: 0.000039\n",
      "Epoch [124], Batch [300/391], Loss: 1.0702, LR: 0.000039\n",
      "Epoch [124], Batch [350/391], Loss: 0.8766, LR: 0.000039\n",
      "Train set: Epoch: 124, Average loss:1.5667, LR: 0.000039 Top-1 Accuracy: 79.2240%, Top-5 Accuracy: 92.9900%, Time consumed:160.69s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████████████████████████████████████▎                                                   | 124/300 [5:57:49<8:23:23, 171.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 124, Average loss:1.6352, Top-1 Accuracy: 73.7700%, Top-5 Accuracy: 92.5600%, Time consumed:12.04s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [125], Batch [50/391], Loss: 1.1227, LR: 0.000039\n",
      "Epoch [125], Batch [100/391], Loss: 2.3427, LR: 0.000039\n",
      "Epoch [125], Batch [150/391], Loss: 1.1115, LR: 0.000039\n",
      "Epoch [125], Batch [200/391], Loss: 1.1311, LR: 0.000039\n",
      "Epoch [125], Batch [250/391], Loss: 1.0897, LR: 0.000039\n",
      "Epoch [125], Batch [300/391], Loss: 2.6362, LR: 0.000039\n",
      "Epoch [125], Batch [350/391], Loss: 2.5153, LR: 0.000039\n",
      "Train set: Epoch: 125, Average loss:1.4942, LR: 0.000039 Top-1 Accuracy: 81.7340%, Top-5 Accuracy: 94.1960%, Time consumed:162.05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████████████████████████████████████▋                                                   | 125/300 [6:00:43<8:22:53, 172.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 125, Average loss:1.6173, Top-1 Accuracy: 74.0400%, Top-5 Accuracy: 92.9400%, Time consumed:12.26s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [126], Batch [50/391], Loss: 2.2018, LR: 0.000020\n",
      "Epoch [126], Batch [100/391], Loss: 2.5126, LR: 0.000020\n",
      "Epoch [126], Batch [150/391], Loss: 1.0310, LR: 0.000020\n",
      "Epoch [126], Batch [200/391], Loss: 2.7084, LR: 0.000020\n",
      "Epoch [126], Batch [250/391], Loss: 1.0344, LR: 0.000020\n",
      "Epoch [126], Batch [300/391], Loss: 1.0022, LR: 0.000020\n",
      "Epoch [126], Batch [350/391], Loss: 1.0303, LR: 0.000020\n",
      "Train set: Epoch: 126, Average loss:1.5777, LR: 0.000020 Top-1 Accuracy: 79.4800%, Top-5 Accuracy: 93.3460%, Time consumed:160.61s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████████████████████████████████████▉                                                   | 126/300 [6:03:36<8:20:28, 172.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 126, Average loss:1.6363, Top-1 Accuracy: 73.6300%, Top-5 Accuracy: 92.6700%, Time consumed:12.32s\n",
      "\n",
      "EarlyStopping 카운터: 3 / 30\n",
      "Epoch [127], Batch [50/391], Loss: 2.3361, LR: 0.000020\n",
      "Epoch [127], Batch [100/391], Loss: 1.0754, LR: 0.000020\n",
      "Epoch [127], Batch [150/391], Loss: 1.0527, LR: 0.000020\n",
      "Epoch [127], Batch [200/391], Loss: 1.0347, LR: 0.000020\n",
      "Epoch [127], Batch [250/391], Loss: 3.1730, LR: 0.000020\n",
      "Epoch [127], Batch [300/391], Loss: 1.6529, LR: 0.000020\n",
      "Epoch [127], Batch [350/391], Loss: 2.4645, LR: 0.000020\n",
      "Train set: Epoch: 127, Average loss:1.5789, LR: 0.000020 Top-1 Accuracy: 80.1380%, Top-5 Accuracy: 93.4600%, Time consumed:162.15s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|█████████████████████████████████████▎                                                  | 127/300 [6:06:31<8:19:42, 173.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 127, Average loss:1.6319, Top-1 Accuracy: 73.6700%, Top-5 Accuracy: 92.6700%, Time consumed:12.87s\n",
      "\n",
      "EarlyStopping 카운터: 4 / 30\n",
      "Epoch [128], Batch [50/391], Loss: 1.8834, LR: 0.000020\n",
      "Epoch [128], Batch [100/391], Loss: 1.0384, LR: 0.000020\n",
      "Epoch [128], Batch [150/391], Loss: 1.0336, LR: 0.000020\n",
      "Epoch [128], Batch [200/391], Loss: 1.8070, LR: 0.000020\n",
      "Epoch [128], Batch [250/391], Loss: 1.0660, LR: 0.000020\n",
      "Epoch [128], Batch [300/391], Loss: 2.9152, LR: 0.000020\n",
      "Epoch [128], Batch [350/391], Loss: 1.0222, LR: 0.000020\n",
      "Train set: Epoch: 128, Average loss:1.4917, LR: 0.000020 Top-1 Accuracy: 82.4200%, Top-5 Accuracy: 94.7140%, Time consumed:167.53s\n",
      "Test set: Epoch: 128, Average loss:1.6152, Top-1 Accuracy: 74.3300%, Top-5 Accuracy: 93.1500%, Time consumed:12.28s\n",
      "\n",
      "새로운 최고 top-1 정확도: 74.33%, top-5 정확도: 93.15%\n",
      "새로운 최고 top-5 정확도: 93.15%\n",
      "Accuracy improved (74.17% --> 74.33%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|█████████████████████████████████████▌                                                  | 128/300 [6:09:32<8:22:42, 175.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [129], Batch [50/391], Loss: 1.1195, LR: 0.000020\n",
      "Epoch [129], Batch [100/391], Loss: 1.1601, LR: 0.000020\n",
      "Epoch [129], Batch [150/391], Loss: 1.7414, LR: 0.000020\n",
      "Epoch [129], Batch [200/391], Loss: 1.0683, LR: 0.000020\n",
      "Epoch [129], Batch [250/391], Loss: 1.0119, LR: 0.000020\n",
      "Epoch [129], Batch [300/391], Loss: 2.6496, LR: 0.000020\n",
      "Epoch [129], Batch [350/391], Loss: 1.0575, LR: 0.000020\n",
      "Train set: Epoch: 129, Average loss:1.4954, LR: 0.000020 Top-1 Accuracy: 82.6500%, Top-5 Accuracy: 94.9420%, Time consumed:158.89s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|█████████████████████████████████████▊                                                  | 129/300 [6:12:23<8:16:11, 174.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 129, Average loss:1.6175, Top-1 Accuracy: 73.8400%, Top-5 Accuracy: 93.0500%, Time consumed:12.25s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [130], Batch [50/391], Loss: 1.0003, LR: 0.000020\n",
      "Epoch [130], Batch [100/391], Loss: 1.0561, LR: 0.000020\n",
      "Epoch [130], Batch [150/391], Loss: 2.5048, LR: 0.000020\n",
      "Epoch [130], Batch [200/391], Loss: 1.0367, LR: 0.000020\n",
      "Epoch [130], Batch [250/391], Loss: 1.1524, LR: 0.000020\n",
      "Epoch [130], Batch [300/391], Loss: 2.7952, LR: 0.000020\n",
      "Epoch [130], Batch [350/391], Loss: 0.3760, LR: 0.000020\n",
      "Train set: Epoch: 130, Average loss:1.5439, LR: 0.000020 Top-1 Accuracy: 81.0260%, Top-5 Accuracy: 93.8740%, Time consumed:160.31s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|██████████████████████████████████████▏                                                 | 130/300 [6:15:15<8:11:47, 173.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 130, Average loss:1.6269, Top-1 Accuracy: 73.7500%, Top-5 Accuracy: 92.7800%, Time consumed:12.01s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [131], Batch [50/391], Loss: 2.5066, LR: 0.000020\n",
      "Epoch [131], Batch [100/391], Loss: 1.0531, LR: 0.000020\n",
      "Epoch [131], Batch [150/391], Loss: 0.7008, LR: 0.000020\n",
      "Epoch [131], Batch [200/391], Loss: 1.0148, LR: 0.000020\n",
      "Epoch [131], Batch [250/391], Loss: 1.0169, LR: 0.000020\n",
      "Epoch [131], Batch [300/391], Loss: 1.2929, LR: 0.000020\n",
      "Epoch [131], Batch [350/391], Loss: 2.8361, LR: 0.000020\n",
      "Train set: Epoch: 131, Average loss:1.5552, LR: 0.000020 Top-1 Accuracy: 80.5480%, Top-5 Accuracy: 93.6440%, Time consumed:158.48s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|██████████████████████████████████████▍                                                 | 131/300 [6:18:06<8:06:26, 172.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 131, Average loss:1.6186, Top-1 Accuracy: 74.2800%, Top-5 Accuracy: 92.9300%, Time consumed:12.18s\n",
      "\n",
      "EarlyStopping 카운터: 3 / 30\n",
      "Epoch [132], Batch [50/391], Loss: 1.0421, LR: 0.000010\n",
      "Epoch [132], Batch [100/391], Loss: 1.0863, LR: 0.000010\n",
      "Epoch [132], Batch [150/391], Loss: 1.0265, LR: 0.000010\n",
      "Epoch [132], Batch [200/391], Loss: 2.6711, LR: 0.000010\n",
      "Epoch [132], Batch [250/391], Loss: 2.8696, LR: 0.000010\n",
      "Epoch [132], Batch [300/391], Loss: 1.0625, LR: 0.000010\n",
      "Epoch [132], Batch [350/391], Loss: 1.9047, LR: 0.000010\n",
      "Train set: Epoch: 132, Average loss:1.4802, LR: 0.000010 Top-1 Accuracy: 82.0260%, Top-5 Accuracy: 94.3960%, Time consumed:158.08s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|██████████████████████████████████████▋                                                 | 132/300 [6:20:56<8:01:55, 172.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 132, Average loss:1.6237, Top-1 Accuracy: 73.8500%, Top-5 Accuracy: 92.7600%, Time consumed:12.67s\n",
      "\n",
      "EarlyStopping 카운터: 4 / 30\n",
      "Epoch [133], Batch [50/391], Loss: 1.0995, LR: 0.000010\n",
      "Epoch [133], Batch [100/391], Loss: 1.0536, LR: 0.000010\n",
      "Epoch [133], Batch [150/391], Loss: 2.5435, LR: 0.000010\n",
      "Epoch [133], Batch [200/391], Loss: 2.3878, LR: 0.000010\n",
      "Epoch [133], Batch [250/391], Loss: 1.5095, LR: 0.000010\n",
      "Epoch [133], Batch [300/391], Loss: 1.0788, LR: 0.000010\n",
      "Epoch [133], Batch [350/391], Loss: 1.3941, LR: 0.000010\n",
      "Train set: Epoch: 133, Average loss:1.5540, LR: 0.000010 Top-1 Accuracy: 80.4420%, Top-5 Accuracy: 93.6660%, Time consumed:161.03s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|███████████████████████████████████████                                                 | 133/300 [6:23:50<8:00:22, 172.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 133, Average loss:1.6277, Top-1 Accuracy: 73.8600%, Top-5 Accuracy: 92.7700%, Time consumed:12.66s\n",
      "\n",
      "EarlyStopping 카운터: 5 / 30\n",
      "Epoch [134], Batch [50/391], Loss: 2.5542, LR: 0.000010\n",
      "Epoch [134], Batch [100/391], Loss: 1.0474, LR: 0.000010\n",
      "Epoch [134], Batch [150/391], Loss: 2.6764, LR: 0.000010\n",
      "Epoch [134], Batch [200/391], Loss: 1.0487, LR: 0.000010\n",
      "Epoch [134], Batch [250/391], Loss: 0.7494, LR: 0.000010\n",
      "Epoch [134], Batch [300/391], Loss: 2.0872, LR: 0.000010\n",
      "Epoch [134], Batch [350/391], Loss: 2.6637, LR: 0.000010\n",
      "Train set: Epoch: 134, Average loss:1.4960, LR: 0.000010 Top-1 Accuracy: 81.8140%, Top-5 Accuracy: 94.1640%, Time consumed:159.42s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|███████████████████████████████████████▎                                                | 134/300 [6:26:42<7:56:53, 172.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 134, Average loss:1.6159, Top-1 Accuracy: 74.1300%, Top-5 Accuracy: 92.9900%, Time consumed:12.44s\n",
      "\n",
      "EarlyStopping 카운터: 6 / 30\n",
      "Epoch [135], Batch [50/391], Loss: 1.2209, LR: 0.000010\n",
      "Epoch [135], Batch [100/391], Loss: 0.8875, LR: 0.000010\n",
      "Epoch [135], Batch [150/391], Loss: 1.0505, LR: 0.000010\n",
      "Epoch [135], Batch [200/391], Loss: 1.1104, LR: 0.000010\n",
      "Epoch [135], Batch [250/391], Loss: 1.0123, LR: 0.000010\n",
      "Epoch [135], Batch [300/391], Loss: 1.0704, LR: 0.000010\n",
      "Epoch [135], Batch [350/391], Loss: 1.0308, LR: 0.000010\n",
      "Train set: Epoch: 135, Average loss:1.5090, LR: 0.000010 Top-1 Accuracy: 81.7460%, Top-5 Accuracy: 94.0840%, Time consumed:157.60s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|███████████████████████████████████████▌                                                | 135/300 [6:29:32<7:51:52, 171.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 135, Average loss:1.6200, Top-1 Accuracy: 73.8900%, Top-5 Accuracy: 92.9200%, Time consumed:12.15s\n",
      "\n",
      "EarlyStopping 카운터: 7 / 30\n",
      "Epoch [136], Batch [50/391], Loss: 1.0229, LR: 0.000010\n",
      "Epoch [136], Batch [100/391], Loss: 1.0973, LR: 0.000010\n",
      "Epoch [136], Batch [150/391], Loss: 1.0591, LR: 0.000010\n",
      "Epoch [136], Batch [200/391], Loss: 1.0206, LR: 0.000010\n",
      "Epoch [136], Batch [250/391], Loss: 1.0736, LR: 0.000010\n",
      "Epoch [136], Batch [300/391], Loss: 2.4737, LR: 0.000010\n",
      "Epoch [136], Batch [350/391], Loss: 2.8385, LR: 0.000010\n",
      "Train set: Epoch: 136, Average loss:1.5263, LR: 0.000010 Top-1 Accuracy: 81.4380%, Top-5 Accuracy: 94.0500%, Time consumed:160.51s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|███████████████████████████████████████▉                                                | 136/300 [6:32:25<7:49:56, 171.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 136, Average loss:1.6189, Top-1 Accuracy: 74.0800%, Top-5 Accuracy: 92.9500%, Time consumed:12.21s\n",
      "\n",
      "EarlyStopping 카운터: 8 / 30\n",
      "Epoch [137], Batch [50/391], Loss: 0.5618, LR: 0.000010\n",
      "Epoch [137], Batch [100/391], Loss: 2.6059, LR: 0.000010\n",
      "Epoch [137], Batch [150/391], Loss: 0.8751, LR: 0.000010\n",
      "Epoch [137], Batch [200/391], Loss: 1.0472, LR: 0.000010\n",
      "Epoch [137], Batch [250/391], Loss: 1.0741, LR: 0.000010\n",
      "Epoch [137], Batch [300/391], Loss: 2.5288, LR: 0.000010\n",
      "Epoch [137], Batch [350/391], Loss: 0.3704, LR: 0.000010\n",
      "Train set: Epoch: 137, Average loss:1.4790, LR: 0.000010 Top-1 Accuracy: 82.0060%, Top-5 Accuracy: 94.2780%, Time consumed:161.34s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████████████████████████████████████████▏                                               | 137/300 [6:35:18<7:48:27, 172.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 137, Average loss:1.6154, Top-1 Accuracy: 74.2900%, Top-5 Accuracy: 93.0100%, Time consumed:12.29s\n",
      "\n",
      "EarlyStopping 카운터: 9 / 30\n",
      "Epoch [138], Batch [50/391], Loss: 1.0768, LR: 0.000005\n",
      "Epoch [138], Batch [100/391], Loss: 1.9191, LR: 0.000005\n",
      "Epoch [138], Batch [150/391], Loss: 1.0361, LR: 0.000005\n",
      "Epoch [138], Batch [200/391], Loss: 2.8655, LR: 0.000005\n",
      "Epoch [138], Batch [250/391], Loss: 1.0187, LR: 0.000005\n",
      "Epoch [138], Batch [300/391], Loss: 1.0286, LR: 0.000005\n",
      "Epoch [138], Batch [350/391], Loss: 1.1340, LR: 0.000005\n",
      "Train set: Epoch: 138, Average loss:1.5243, LR: 0.000005 Top-1 Accuracy: 80.7480%, Top-5 Accuracy: 93.5580%, Time consumed:157.83s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████████████████████████████████████████▍                                               | 138/300 [6:38:08<7:43:44, 171.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 138, Average loss:1.6288, Top-1 Accuracy: 73.9100%, Top-5 Accuracy: 92.6700%, Time consumed:12.32s\n",
      "\n",
      "EarlyStopping 카운터: 10 / 30\n",
      "Epoch [139], Batch [50/391], Loss: 1.8410, LR: 0.000005\n",
      "Epoch [139], Batch [100/391], Loss: 1.0020, LR: 0.000005\n",
      "Epoch [139], Batch [150/391], Loss: 2.7454, LR: 0.000005\n",
      "Epoch [139], Batch [200/391], Loss: 1.0791, LR: 0.000005\n",
      "Epoch [139], Batch [250/391], Loss: 0.4556, LR: 0.000005\n",
      "Epoch [139], Batch [300/391], Loss: 2.1130, LR: 0.000005\n",
      "Epoch [139], Batch [350/391], Loss: 1.7082, LR: 0.000005\n",
      "Train set: Epoch: 139, Average loss:1.4984, LR: 0.000005 Top-1 Accuracy: 82.3440%, Top-5 Accuracy: 94.4380%, Time consumed:156.63s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████████████████████████████████████████▊                                               | 139/300 [6:40:57<7:38:42, 170.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 139, Average loss:1.6161, Top-1 Accuracy: 74.2600%, Top-5 Accuracy: 93.0500%, Time consumed:12.43s\n",
      "\n",
      "EarlyStopping 카운터: 11 / 30\n",
      "Epoch [140], Batch [50/391], Loss: 0.9978, LR: 0.000005\n",
      "Epoch [140], Batch [100/391], Loss: 1.0963, LR: 0.000005\n",
      "Epoch [140], Batch [150/391], Loss: 1.0222, LR: 0.000005\n",
      "Epoch [140], Batch [200/391], Loss: 2.7261, LR: 0.000005\n",
      "Epoch [140], Batch [250/391], Loss: 1.0756, LR: 0.000005\n",
      "Epoch [140], Batch [300/391], Loss: 1.0316, LR: 0.000005\n",
      "Epoch [140], Batch [350/391], Loss: 1.0235, LR: 0.000005\n",
      "Train set: Epoch: 140, Average loss:1.5393, LR: 0.000005 Top-1 Accuracy: 80.7140%, Top-5 Accuracy: 93.5740%, Time consumed:164.87s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|█████████████████████████████████████████                                               | 140/300 [6:43:56<7:41:43, 173.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 140, Average loss:1.6313, Top-1 Accuracy: 73.8900%, Top-5 Accuracy: 92.6200%, Time consumed:13.40s\n",
      "\n",
      "EarlyStopping 카운터: 12 / 30\n",
      "Epoch [141], Batch [50/391], Loss: 1.0405, LR: 0.000005\n",
      "Epoch [141], Batch [100/391], Loss: 1.0266, LR: 0.000005\n",
      "Epoch [141], Batch [150/391], Loss: 1.2938, LR: 0.000005\n",
      "Epoch [141], Batch [200/391], Loss: 2.6611, LR: 0.000005\n",
      "Epoch [141], Batch [250/391], Loss: 2.2737, LR: 0.000005\n",
      "Epoch [141], Batch [300/391], Loss: 1.0727, LR: 0.000005\n",
      "Epoch [141], Batch [350/391], Loss: 1.0364, LR: 0.000005\n",
      "Train set: Epoch: 141, Average loss:1.5217, LR: 0.000005 Top-1 Accuracy: 81.3940%, Top-5 Accuracy: 93.8820%, Time consumed:156.54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|█████████████████████████████████████████▎                                              | 141/300 [6:46:44<7:35:13, 171.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 141, Average loss:1.6202, Top-1 Accuracy: 73.9600%, Top-5 Accuracy: 92.8300%, Time consumed:12.06s\n",
      "\n",
      "EarlyStopping 카운터: 13 / 30\n",
      "Epoch [142], Batch [50/391], Loss: 1.0617, LR: 0.000005\n",
      "Epoch [142], Batch [100/391], Loss: 0.9991, LR: 0.000005\n",
      "Epoch [142], Batch [150/391], Loss: 1.0339, LR: 0.000005\n",
      "Epoch [142], Batch [200/391], Loss: 1.0112, LR: 0.000005\n",
      "Epoch [142], Batch [250/391], Loss: 1.0066, LR: 0.000005\n",
      "Epoch [142], Batch [300/391], Loss: 0.2875, LR: 0.000005\n",
      "Epoch [142], Batch [350/391], Loss: 0.7662, LR: 0.000005\n",
      "Train set: Epoch: 142, Average loss:1.5721, LR: 0.000005 Top-1 Accuracy: 80.3660%, Top-5 Accuracy: 93.6600%, Time consumed:158.13s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|█████████████████████████████████████████▋                                              | 142/300 [6:49:35<7:31:09, 171.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 142, Average loss:1.6293, Top-1 Accuracy: 73.8600%, Top-5 Accuracy: 92.7500%, Time consumed:12.11s\n",
      "\n",
      "EarlyStopping 카운터: 14 / 30\n",
      "Epoch [143], Batch [50/391], Loss: 2.6159, LR: 0.000005\n",
      "Epoch [143], Batch [100/391], Loss: 1.0060, LR: 0.000005\n",
      "Epoch [143], Batch [150/391], Loss: 0.6523, LR: 0.000005\n",
      "Epoch [143], Batch [200/391], Loss: 1.4823, LR: 0.000005\n",
      "Epoch [143], Batch [250/391], Loss: 2.7315, LR: 0.000005\n",
      "Epoch [143], Batch [300/391], Loss: 1.0367, LR: 0.000005\n",
      "Epoch [143], Batch [350/391], Loss: 1.0598, LR: 0.000005\n",
      "Train set: Epoch: 143, Average loss:1.4929, LR: 0.000005 Top-1 Accuracy: 81.6740%, Top-5 Accuracy: 94.0040%, Time consumed:159.46s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|█████████████████████████████████████████▉                                              | 143/300 [6:52:26<7:28:45, 171.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 143, Average loss:1.6391, Top-1 Accuracy: 73.3800%, Top-5 Accuracy: 92.5500%, Time consumed:12.45s\n",
      "\n",
      "EarlyStopping 카운터: 15 / 30\n",
      "Epoch [144], Batch [50/391], Loss: 1.0716, LR: 0.000002\n",
      "Epoch [144], Batch [100/391], Loss: 0.8816, LR: 0.000002\n",
      "Epoch [144], Batch [150/391], Loss: 1.0664, LR: 0.000002\n",
      "Epoch [144], Batch [200/391], Loss: 2.0398, LR: 0.000002\n",
      "Epoch [144], Batch [250/391], Loss: 1.6395, LR: 0.000002\n",
      "Epoch [144], Batch [300/391], Loss: 0.6906, LR: 0.000002\n",
      "Epoch [144], Batch [350/391], Loss: 1.0346, LR: 0.000002\n",
      "Train set: Epoch: 144, Average loss:1.5252, LR: 0.000002 Top-1 Accuracy: 80.7100%, Top-5 Accuracy: 93.6420%, Time consumed:157.89s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|██████████████████████████████████████████▏                                             | 144/300 [6:55:16<7:24:46, 171.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 144, Average loss:1.6248, Top-1 Accuracy: 73.7700%, Top-5 Accuracy: 92.7600%, Time consumed:12.16s\n",
      "\n",
      "EarlyStopping 카운터: 16 / 30\n",
      "Epoch [145], Batch [50/391], Loss: 1.0235, LR: 0.000002\n",
      "Epoch [145], Batch [100/391], Loss: 1.0442, LR: 0.000002\n",
      "Epoch [145], Batch [150/391], Loss: 1.0201, LR: 0.000002\n",
      "Epoch [145], Batch [200/391], Loss: 1.4538, LR: 0.000002\n",
      "Epoch [145], Batch [250/391], Loss: 1.0484, LR: 0.000002\n",
      "Epoch [145], Batch [300/391], Loss: 2.7141, LR: 0.000002\n",
      "Epoch [145], Batch [350/391], Loss: 1.0412, LR: 0.000002\n",
      "Train set: Epoch: 145, Average loss:1.5598, LR: 0.000002 Top-1 Accuracy: 79.5160%, Top-5 Accuracy: 93.0100%, Time consumed:159.15s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|██████████████████████████████████████████▌                                             | 145/300 [6:58:08<7:22:38, 171.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 145, Average loss:1.6201, Top-1 Accuracy: 74.1500%, Top-5 Accuracy: 93.0500%, Time consumed:12.84s\n",
      "\n",
      "EarlyStopping 카운터: 17 / 30\n",
      "Epoch [146], Batch [50/391], Loss: 2.6181, LR: 0.000002\n",
      "Epoch [146], Batch [100/391], Loss: 2.3237, LR: 0.000002\n",
      "Epoch [146], Batch [150/391], Loss: 2.4096, LR: 0.000002\n",
      "Epoch [146], Batch [200/391], Loss: 1.0592, LR: 0.000002\n",
      "Epoch [146], Batch [250/391], Loss: 1.3879, LR: 0.000002\n",
      "Epoch [146], Batch [300/391], Loss: 1.0162, LR: 0.000002\n",
      "Epoch [146], Batch [350/391], Loss: 2.8035, LR: 0.000002\n",
      "Train set: Epoch: 146, Average loss:1.5795, LR: 0.000002 Top-1 Accuracy: 78.7180%, Top-5 Accuracy: 92.8000%, Time consumed:160.09s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|██████████████████████████████████████████▊                                             | 146/300 [7:01:01<7:20:27, 171.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 146, Average loss:1.6373, Top-1 Accuracy: 73.6200%, Top-5 Accuracy: 92.6800%, Time consumed:12.11s\n",
      "\n",
      "EarlyStopping 카운터: 18 / 30\n",
      "Epoch [147], Batch [50/391], Loss: 1.0512, LR: 0.000002\n",
      "Epoch [147], Batch [100/391], Loss: 0.6028, LR: 0.000002\n",
      "Epoch [147], Batch [150/391], Loss: 2.2145, LR: 0.000002\n",
      "Epoch [147], Batch [200/391], Loss: 1.0482, LR: 0.000002\n",
      "Epoch [147], Batch [250/391], Loss: 1.0646, LR: 0.000002\n",
      "Epoch [147], Batch [300/391], Loss: 0.6375, LR: 0.000002\n",
      "Epoch [147], Batch [350/391], Loss: 1.2623, LR: 0.000002\n",
      "Train set: Epoch: 147, Average loss:1.5358, LR: 0.000002 Top-1 Accuracy: 81.3980%, Top-5 Accuracy: 94.1140%, Time consumed:158.10s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|███████████████████████████████████████████                                             | 147/300 [7:03:51<7:16:39, 171.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 147, Average loss:1.6249, Top-1 Accuracy: 73.8500%, Top-5 Accuracy: 92.7600%, Time consumed:12.28s\n",
      "\n",
      "EarlyStopping 카운터: 19 / 30\n",
      "Epoch [148], Batch [50/391], Loss: 1.0478, LR: 0.000002\n",
      "Epoch [148], Batch [100/391], Loss: 1.0556, LR: 0.000002\n",
      "Epoch [148], Batch [150/391], Loss: 1.0221, LR: 0.000002\n",
      "Epoch [148], Batch [200/391], Loss: 1.5813, LR: 0.000002\n",
      "Epoch [148], Batch [250/391], Loss: 1.0156, LR: 0.000002\n",
      "Epoch [148], Batch [300/391], Loss: 1.0757, LR: 0.000002\n",
      "Epoch [148], Batch [350/391], Loss: 1.0884, LR: 0.000002\n",
      "Train set: Epoch: 148, Average loss:1.4566, LR: 0.000002 Top-1 Accuracy: 83.4200%, Top-5 Accuracy: 95.0460%, Time consumed:158.52s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|███████████████████████████████████████████▍                                            | 148/300 [7:06:42<7:13:40, 171.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 148, Average loss:1.6241, Top-1 Accuracy: 73.7600%, Top-5 Accuracy: 92.9000%, Time consumed:12.54s\n",
      "\n",
      "EarlyStopping 카운터: 20 / 30\n",
      "Epoch [149], Batch [50/391], Loss: 1.0360, LR: 0.000002\n",
      "Epoch [149], Batch [100/391], Loss: 1.0443, LR: 0.000002\n",
      "Epoch [149], Batch [150/391], Loss: 2.1578, LR: 0.000002\n",
      "Epoch [149], Batch [200/391], Loss: 1.0394, LR: 0.000002\n",
      "Epoch [149], Batch [250/391], Loss: 1.1189, LR: 0.000002\n",
      "Epoch [149], Batch [300/391], Loss: 1.0361, LR: 0.000002\n",
      "Epoch [149], Batch [350/391], Loss: 1.0634, LR: 0.000002\n",
      "Train set: Epoch: 149, Average loss:1.5687, LR: 0.000002 Top-1 Accuracy: 79.9780%, Top-5 Accuracy: 93.1780%, Time consumed:163.22s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████████████████████████████▋                                            | 149/300 [7:09:38<7:14:11, 172.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 149, Average loss:1.6210, Top-1 Accuracy: 73.9100%, Top-5 Accuracy: 92.8600%, Time consumed:12.44s\n",
      "\n",
      "EarlyStopping 카운터: 21 / 30\n",
      "Epoch [150], Batch [50/391], Loss: 1.0188, LR: 0.000001\n",
      "Epoch [150], Batch [100/391], Loss: 1.0250, LR: 0.000001\n",
      "Epoch [150], Batch [150/391], Loss: 1.0713, LR: 0.000001\n",
      "Epoch [150], Batch [200/391], Loss: 2.3456, LR: 0.000001\n",
      "Epoch [150], Batch [250/391], Loss: 2.1556, LR: 0.000001\n",
      "Epoch [150], Batch [300/391], Loss: 1.0371, LR: 0.000001\n",
      "Epoch [150], Batch [350/391], Loss: 1.0534, LR: 0.000001\n",
      "Train set: Epoch: 150, Average loss:1.5424, LR: 0.000001 Top-1 Accuracy: 81.0380%, Top-5 Accuracy: 94.0420%, Time consumed:157.38s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████████████████████████████████                                            | 150/300 [7:12:28<7:09:54, 171.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 150, Average loss:1.6317, Top-1 Accuracy: 73.6700%, Top-5 Accuracy: 92.6400%, Time consumed:13.26s\n",
      "\n",
      "EarlyStopping 카운터: 22 / 30\n",
      "Epoch [151], Batch [50/391], Loss: 1.0486, LR: 0.000001\n",
      "Epoch [151], Batch [100/391], Loss: 0.4088, LR: 0.000001\n",
      "Epoch [151], Batch [150/391], Loss: 1.0638, LR: 0.000001\n",
      "Epoch [151], Batch [200/391], Loss: 2.1240, LR: 0.000001\n",
      "Epoch [151], Batch [250/391], Loss: 1.0471, LR: 0.000001\n",
      "Epoch [151], Batch [300/391], Loss: 1.9442, LR: 0.000001\n",
      "Epoch [151], Batch [350/391], Loss: 1.0636, LR: 0.000001\n",
      "Train set: Epoch: 151, Average loss:1.5042, LR: 0.000001 Top-1 Accuracy: 81.6220%, Top-5 Accuracy: 94.1100%, Time consumed:158.54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████████████████████████████████▎                                           | 151/300 [7:15:20<7:06:54, 171.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 151, Average loss:1.6262, Top-1 Accuracy: 73.8500%, Top-5 Accuracy: 92.7600%, Time consumed:13.23s\n",
      "\n",
      "EarlyStopping 카운터: 23 / 30\n",
      "Epoch [152], Batch [50/391], Loss: 1.1918, LR: 0.000001\n",
      "Epoch [152], Batch [100/391], Loss: 2.5909, LR: 0.000001\n",
      "Epoch [152], Batch [150/391], Loss: 1.0504, LR: 0.000001\n",
      "Epoch [152], Batch [200/391], Loss: 1.0276, LR: 0.000001\n",
      "Epoch [152], Batch [250/391], Loss: 2.5383, LR: 0.000001\n",
      "Epoch [152], Batch [300/391], Loss: 1.0872, LR: 0.000001\n",
      "Epoch [152], Batch [350/391], Loss: 2.6181, LR: 0.000001\n",
      "Train set: Epoch: 152, Average loss:1.5465, LR: 0.000001 Top-1 Accuracy: 79.9540%, Top-5 Accuracy: 93.3360%, Time consumed:157.52s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|████████████████████████████████████████████▌                                           | 152/300 [7:18:10<7:02:20, 171.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 152, Average loss:1.6204, Top-1 Accuracy: 74.0800%, Top-5 Accuracy: 92.8800%, Time consumed:12.09s\n",
      "\n",
      "EarlyStopping 카운터: 24 / 30\n",
      "Epoch [153], Batch [50/391], Loss: 2.5789, LR: 0.000001\n",
      "Epoch [153], Batch [100/391], Loss: 2.6009, LR: 0.000001\n",
      "Epoch [153], Batch [150/391], Loss: 2.8899, LR: 0.000001\n",
      "Epoch [153], Batch [200/391], Loss: 1.0424, LR: 0.000001\n",
      "Epoch [153], Batch [250/391], Loss: 2.5017, LR: 0.000001\n",
      "Epoch [153], Batch [300/391], Loss: 1.0571, LR: 0.000001\n",
      "Epoch [153], Batch [350/391], Loss: 1.0605, LR: 0.000001\n",
      "Train set: Epoch: 153, Average loss:1.5207, LR: 0.000001 Top-1 Accuracy: 81.5680%, Top-5 Accuracy: 93.9600%, Time consumed:158.80s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|████████████████████████████████████████████▉                                           | 153/300 [7:21:01<6:59:27, 171.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 153, Average loss:1.6166, Top-1 Accuracy: 74.2800%, Top-5 Accuracy: 93.0100%, Time consumed:12.37s\n",
      "\n",
      "EarlyStopping 카운터: 25 / 30\n",
      "Epoch [154], Batch [50/391], Loss: 0.3686, LR: 0.000001\n",
      "Epoch [154], Batch [100/391], Loss: 2.1921, LR: 0.000001\n",
      "Epoch [154], Batch [150/391], Loss: 1.0639, LR: 0.000001\n",
      "Epoch [154], Batch [200/391], Loss: 2.2724, LR: 0.000001\n",
      "Epoch [154], Batch [250/391], Loss: 1.9254, LR: 0.000001\n",
      "Epoch [154], Batch [300/391], Loss: 1.5161, LR: 0.000001\n",
      "Epoch [154], Batch [350/391], Loss: 1.0507, LR: 0.000001\n",
      "Train set: Epoch: 154, Average loss:1.5440, LR: 0.000001 Top-1 Accuracy: 81.4640%, Top-5 Accuracy: 94.0020%, Time consumed:157.75s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████████████████████████████████████████████▏                                          | 154/300 [7:23:51<6:55:47, 170.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 154, Average loss:1.6252, Top-1 Accuracy: 73.6400%, Top-5 Accuracy: 92.8700%, Time consumed:12.33s\n",
      "\n",
      "EarlyStopping 카운터: 26 / 30\n",
      "Epoch [155], Batch [50/391], Loss: 1.0569, LR: 0.000001\n",
      "Epoch [155], Batch [100/391], Loss: 1.0726, LR: 0.000001\n",
      "Epoch [155], Batch [150/391], Loss: 1.4116, LR: 0.000001\n",
      "Epoch [155], Batch [200/391], Loss: 2.5408, LR: 0.000001\n",
      "Epoch [155], Batch [250/391], Loss: 1.0088, LR: 0.000001\n",
      "Epoch [155], Batch [300/391], Loss: 1.0725, LR: 0.000001\n",
      "Epoch [155], Batch [350/391], Loss: 1.0435, LR: 0.000001\n",
      "Train set: Epoch: 155, Average loss:1.4820, LR: 0.000001 Top-1 Accuracy: 82.2200%, Top-5 Accuracy: 94.3940%, Time consumed:158.17s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████████████████████████████████████████████▍                                          | 155/300 [7:26:42<6:52:38, 170.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 155, Average loss:1.6191, Top-1 Accuracy: 74.0400%, Top-5 Accuracy: 92.8400%, Time consumed:12.27s\n",
      "\n",
      "EarlyStopping 카운터: 27 / 30\n",
      "Epoch [156], Batch [50/391], Loss: 2.4778, LR: 0.000001\n",
      "Epoch [156], Batch [100/391], Loss: 1.6027, LR: 0.000001\n",
      "Epoch [156], Batch [150/391], Loss: 1.3760, LR: 0.000001\n",
      "Epoch [156], Batch [200/391], Loss: 1.0228, LR: 0.000001\n",
      "Epoch [156], Batch [250/391], Loss: 2.5518, LR: 0.000001\n",
      "Epoch [156], Batch [300/391], Loss: 1.0349, LR: 0.000001\n",
      "Epoch [156], Batch [350/391], Loss: 1.0395, LR: 0.000001\n",
      "Train set: Epoch: 156, Average loss:1.4913, LR: 0.000001 Top-1 Accuracy: 82.5300%, Top-5 Accuracy: 94.6640%, Time consumed:164.97s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████████████████████████████████████████████▊                                          | 156/300 [7:29:40<6:55:00, 172.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 156, Average loss:1.6246, Top-1 Accuracy: 73.9600%, Top-5 Accuracy: 92.6900%, Time consumed:13.01s\n",
      "\n",
      "EarlyStopping 카운터: 28 / 30\n",
      "Epoch [157], Batch [50/391], Loss: 1.1099, LR: 0.000001\n",
      "Epoch [157], Batch [100/391], Loss: 2.7721, LR: 0.000001\n",
      "Epoch [157], Batch [150/391], Loss: 1.0388, LR: 0.000001\n",
      "Epoch [157], Batch [200/391], Loss: 1.0321, LR: 0.000001\n",
      "Epoch [157], Batch [250/391], Loss: 2.8858, LR: 0.000001\n",
      "Epoch [157], Batch [300/391], Loss: 2.3191, LR: 0.000001\n",
      "Epoch [157], Batch [350/391], Loss: 1.0318, LR: 0.000001\n",
      "Train set: Epoch: 157, Average loss:1.6119, LR: 0.000001 Top-1 Accuracy: 78.6140%, Top-5 Accuracy: 92.6620%, Time consumed:156.78s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|██████████████████████████████████████████████                                          | 157/300 [7:32:29<6:49:59, 172.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 157, Average loss:1.6405, Top-1 Accuracy: 73.5300%, Top-5 Accuracy: 92.4600%, Time consumed:13.15s\n",
      "\n",
      "EarlyStopping 카운터: 29 / 30\n",
      "Epoch [158], Batch [50/391], Loss: 2.3909, LR: 0.000001\n",
      "Epoch [158], Batch [100/391], Loss: 1.4701, LR: 0.000001\n",
      "Epoch [158], Batch [150/391], Loss: 1.0145, LR: 0.000001\n",
      "Epoch [158], Batch [200/391], Loss: 2.0918, LR: 0.000001\n",
      "Epoch [158], Batch [250/391], Loss: 1.0371, LR: 0.000001\n",
      "Epoch [158], Batch [300/391], Loss: 1.7903, LR: 0.000001\n",
      "Epoch [158], Batch [350/391], Loss: 1.0437, LR: 0.000001\n",
      "Train set: Epoch: 158, Average loss:1.5936, LR: 0.000001 Top-1 Accuracy: 79.6540%, Top-5 Accuracy: 93.3840%, Time consumed:157.84s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|██████████████████████████████████████████████                                          | 157/300 [7:35:20<6:54:44, 174.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 158, Average loss:1.6250, Top-1 Accuracy: 73.7900%, Top-5 Accuracy: 92.7900%, Time consumed:12.38s\n",
      "\n",
      "EarlyStopping 카운터: 30 / 30\n",
      "에폭 158에서 학습 조기 종료. 최고 성능 에폭: 128\n",
      "테스트 정확도 기준 최고 모델 로드 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 300, Average loss:1.6152, Top-1 Accuracy: 74.3300%, Top-5 Accuracy: 93.1500%, Time consumed:12.21s\n",
      "\n",
      "완료! 최고 테스트 top-1 정확도: 74.33%, 최고 테스트 top-5 정확도: 93.15%\n",
      "최종 테스트 top-1 정확도: 74.33%, 최종 테스트 top-5 정확도: 93.15%\n",
      "전체 학습 시간: 27332.58 초\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇██</td></tr><tr><td>learning_rate</td><td>▂▂▄▄▆██████████████████▄▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_accuracy_top1</td><td>▁▁▃▄▄▄▅▆▆▆▆▇▇▇▇▇▇███████████████████████</td></tr><tr><td>test_accuracy_top5</td><td>▁▃▄▆▇▇▇█████████████████████████████████</td></tr><tr><td>test_loss</td><td>███▇▇▅▄▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>total_training_time</td><td>▁</td></tr><tr><td>train_accuracy_top1</td><td>▁▁▃▃▃▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇████████████████████</td></tr><tr><td>train_accuracy_top5</td><td>▁▂▂▂▃▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇▇█▇▇████████████████</td></tr><tr><td>train_loss</td><td>█▇▆▅▅▅▅▄▄▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>128</td></tr><tr><td>best_test_accuracy_top1</td><td>74.33</td></tr><tr><td>best_test_accuracy_top5</td><td>93.15</td></tr><tr><td>early_stopped</td><td>True</td></tr><tr><td>early_stopped_epoch</td><td>158</td></tr><tr><td>epoch</td><td>158</td></tr><tr><td>final_test_accuracy_top1</td><td>74.33</td></tr><tr><td>final_test_accuracy_top5</td><td>93.15</td></tr><tr><td>learning_rate</td><td>0.0</td></tr><tr><td>test_accuracy_top1</td><td>73.79</td></tr><tr><td>test_accuracy_top5</td><td>92.79</td></tr><tr><td>test_loss</td><td>1.62499</td></tr><tr><td>total_training_time</td><td>27332.58025</td></tr><tr><td>train_accuracy_top1</td><td>79.654</td></tr><tr><td>train_accuracy_top5</td><td>93.384</td></tr><tr><td>train_loss</td><td>1.59365</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">resnext50_cfc,lr=0.005,factor=0.5,SGD_standard</strong> at: <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/w42pw9w1' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/w42pw9w1</a><br> View project at: <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250423_124736-w42pw9w1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.v2 as transforms_v2  # CutMix를 위한 v2 transforms 추가\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "from tools.tool import AccuracyEarlyStopping, WarmUpLR, SAM  # 수정된 AccuracyEarlyStopping 클래스 임포트\n",
    "from models.resnext import resnext50  # ResNeXt-50 모델 임포트\n",
    "\n",
    "wandb.login(key=\"ef091b9abcea3186341ddf8995d62bde62d7469e\")\n",
    "wandb.init(project=\"PBL-2\", name=\"resnext50_cfc,lr=0.005,factor=0.5,SGD_standard\")  \n",
    "\n",
    "# WandB 설정\n",
    "config = {\n",
    "    \"model\": \"resnext50\",  # ResNeXt-50 사용\n",
    "    \"batch_size\": 128,     # A4000 두 장에 충분한 배치 크기\n",
    "    \"num_epochs\": 300,\n",
    "    \"learning_rate\": 0.005,  # ResNeXt에 적합한 학습률로 조정\n",
    "    \"optimizer\": \"SGD\",      # SGD 사용\n",
    "    \"seed\": 2025,\n",
    "    \"deterministic\": False,\n",
    "    \"patience\": 30,          # early stopping patience\n",
    "    \"max_epochs_wait\": float('inf'),\n",
    "    \"cutmix_alpha\": 1.0,     # CutMix 알파 파라미터\n",
    "    \"cutmix_prob\": 0.5,      # CutMix 적용 확률\n",
    "    \"crop_padding\": 4,       # RandomCrop 패딩 크기\n",
    "    \"crop_size\": 32,         # RandomCrop 크기 (CIFAR-100 이미지 크기는 32x32)\n",
    "    \"warmup_epochs\": 10,     # ResNeXt에는 더 긴 웜업 기간 사용\n",
    "}\n",
    "wandb.config.update(config)\n",
    "\n",
    "# CIFAR-100 데이터셋 로드 - 기본 train/test 분할 사용d\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(config[\"crop_size\"], padding=config[\"crop_padding\"]),  # 패딩 후 랜덤 크롭\n",
    "    transforms.RandomHorizontalFlip(),  # 수평 뒤집기\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR100(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR100(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "# DataLoader 생성\n",
    "trainloader = DataLoader(trainset, batch_size=config[\"batch_size\"], shuffle=True, num_workers=32)\n",
    "testloader = DataLoader(testset, batch_size=config[\"batch_size\"], shuffle=False, num_workers=32)\n",
    "\n",
    "print(f\"Train set size: {len(trainset)}\")\n",
    "print(f\"Test set size: {len(testset)}\")\n",
    "\n",
    "# CutMix 변환 정의\n",
    "cutmix = transforms_v2.CutMix(alpha=config[\"cutmix_alpha\"], num_classes=100)  # CIFAR-100은 100개 클래스\n",
    "\n",
    "def train(model, trainloader, criterion, optimizer, device, epoch, warmup_scheduler=None, warmup_epochs=10):\n",
    "    \"\"\"\n",
    "    학습 함수 (CutMix 적용)\n",
    "    \"\"\"\n",
    "    model.train()   # 모델을 학습 모드로 설정\n",
    "    start_time = time.time()  # 시간 측정 시작\n",
    "    running_loss = 0.0\n",
    "    correct_top1 = 0\n",
    "    correct_top5 = 0\n",
    "    total = 0\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(trainloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # CutMix 확률적 적용\n",
    "        if random.random() < config[\"cutmix_prob\"]:\n",
    "            inputs, labels = cutmix(inputs, labels)\n",
    "            # 이 경우 labels은 원-핫 인코딩 형태로 변환됨\n",
    "            use_cutmix = True\n",
    "        else:\n",
    "            use_cutmix = False\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # CutMix 적용 여부에 따라 손실 함수 선택\n",
    "        if use_cutmix:\n",
    "            # CutMix가 적용된 경우 (원-핫 인코딩된 레이블)\n",
    "            loss = torch.nn.functional.cross_entropy(outputs, labels)\n",
    "        else:\n",
    "            # 일반적인 경우 (정수 인덱스 레이블)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "        loss.backward()\n",
    "        optimizer.first_step(zero_grad=True)\n",
    "        \n",
    "        # 두 번째 forward-backward 패스\n",
    "        if use_cutmix:\n",
    "            # 새로운 forward 패스 필요\n",
    "            outputs = model(inputs)\n",
    "            loss = torch.nn.functional.cross_entropy(outputs, labels)\n",
    "        else:\n",
    "            # 새로운 forward 패스 필요\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.second_step(zero_grad=True)\n",
    "        \n",
    "        # 학습률 스케줄러 업데이트 - optimizer.step() 이후에 호출\n",
    "        if epoch < warmup_epochs and warmup_scheduler is not None:\n",
    "            warmup_scheduler.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # 정확도 계산 - CutMix 적용 여부에 따라 다르게 처리\n",
    "        if use_cutmix:\n",
    "            # 원-핫 인코딩된 레이블에서 argmax를 사용해 가장 큰 값의 인덱스 추출\n",
    "            _, label_idx = labels.max(1)\n",
    "        else:\n",
    "            # 정수 인덱스 레이블 그대로 사용\n",
    "            label_idx = labels\n",
    "        \n",
    "    \n",
    "        # top-1 정확도 계산\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += inputs.size(0)\n",
    "        correct_top1 += predicted.eq(label_idx).sum().item()\n",
    "        \n",
    "        # top-5 정확도 계산\n",
    "        _, top5_idx = outputs.topk(5, 1, largest=True, sorted=True)\n",
    "        correct_top5 += sum([1 for i in range(len(label_idx)) if label_idx[i] in top5_idx[i]])\n",
    "        \n",
    "        if (i + 1) % 50 == 0:  # 50 배치마다 출력\n",
    "            print(f'Epoch [{epoch+1}], Batch [{i+1}/{len(trainloader)}], Loss: {loss.item():.4f}, LR: {optimizer.param_groups[0][\"lr\"]:.6f}')\n",
    "    \n",
    "    epoch_loss = running_loss / len(trainloader)\n",
    "    accuracy_top1 = 100.0 * correct_top1 / total\n",
    "    accuracy_top5 = 100.0 * correct_top5 / total\n",
    "    \n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    # 학습 세트에 대한 성능 출력\n",
    "    print(f'Train set: Epoch: {epoch+1}, Average loss:{epoch_loss:.4f}, LR: {optimizer.param_groups[0][\"lr\"]:.6f} '\n",
    "          f'Top-1 Accuracy: {accuracy_top1:.4f}%, Top-5 Accuracy: {accuracy_top5:.4f}%, Time consumed:{train_time:.2f}s')\n",
    "    \n",
    "    return epoch_loss, accuracy_top1, accuracy_top5\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device, epoch, phase=\"test\"):\n",
    "    \"\"\"\n",
    "    평가 함수\n",
    "    \"\"\"\n",
    "    model.eval()  # 모델을 평가 모드로 설정\n",
    "    start_time = time.time()  # 시간 측정 시작\n",
    "    \n",
    "    eval_loss = 0.0\n",
    "    correct_top1 = 0\n",
    "    correct_top5 = 0\n",
    "    total = 0\n",
    "    \n",
    "    # 그래디언트 계산 비활성화\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # 순전파\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # 손실 계산\n",
    "            loss = criterion(outputs, labels)\n",
    "            eval_loss += loss.item()\n",
    "            \n",
    "            # top-1 정확도 계산\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct_top1 += (predicted == labels).sum().item()\n",
    "            \n",
    "            # top-5 정확도 계산\n",
    "            _, top5_idx = outputs.topk(5, 1, largest=True, sorted=True)\n",
    "            correct_top5 += top5_idx.eq(labels.view(-1, 1).expand_as(top5_idx)).sum().item()\n",
    "    \n",
    "    # 평균 손실 및 정확도 계산\n",
    "    eval_loss = eval_loss / len(dataloader)\n",
    "    accuracy_top1 = 100.0 * correct_top1 / total\n",
    "    accuracy_top5 = 100.0 * correct_top5 / total\n",
    "    \n",
    "    # 평가 시간 계산\n",
    "    eval_time = time.time() - start_time\n",
    "    \n",
    "    # 테스트 세트에 대한 성능 출력\n",
    "    print(f'{phase.capitalize()} set: Epoch: {epoch+1}, Average loss:{eval_loss:.4f}, '\n",
    "          f'Top-1 Accuracy: {accuracy_top1:.4f}%, Top-5 Accuracy: {accuracy_top5:.4f}%, Time consumed:{eval_time:.2f}s')\n",
    "    print()\n",
    "    \n",
    "    return eval_loss, accuracy_top1, accuracy_top5\n",
    "\n",
    "# 메인 학습 루프\n",
    "def main_training_loop(model, trainloader, testloader, criterion, optimizer, device, num_epochs, patience, max_epochs_wait, warmup_scheduler=None, main_scheduler=None, warmup_epochs=10):\n",
    "    \"\"\"\n",
    "    메인 학습 루프 (accuracy 기준 early stopping)\n",
    "    \"\"\"\n",
    "    # 정확도 기반 얼리 스토핑 사용\n",
    "    early_stopping = AccuracyEarlyStopping(patience=patience, verbose=True, path='checkpoint.pt', max_epochs=max_epochs_wait)\n",
    "    \n",
    "    best_test_acc_top1 = 0.0\n",
    "    best_test_acc_top5 = 0.0\n",
    "    \n",
    "    # 테스트 정확도 기록을 위한 리스트\n",
    "    test_acc_top1_history = []\n",
    "    \n",
    "    # tqdm을 사용한 진행 상황 표시\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        # 학습\n",
    "        train_loss, train_acc_top1, train_acc_top5 = train(\n",
    "            model, \n",
    "            trainloader, \n",
    "            criterion, \n",
    "            optimizer, \n",
    "            device, \n",
    "            epoch, \n",
    "            warmup_scheduler, \n",
    "            warmup_epochs\n",
    "        )\n",
    "        \n",
    "        # 테스트 데이터로 평가\n",
    "        test_loss, test_acc_top1, test_acc_top5 = evaluate(model, testloader, criterion, device, epoch, phase=\"test\")\n",
    "\n",
    "        # 웜업 이후 ReduceLROnPlateau 스케줄러 업데이트 \n",
    "        if epoch >= warmup_epochs and main_scheduler is not None:\n",
    "            main_scheduler.step(test_acc_top1)  # 테스트 정확도에 따라 학습률 업데이트       \n",
    "            \n",
    "        # 테스트 정확도 기록\n",
    "        test_acc_top1_history.append(test_acc_top1)\n",
    "        \n",
    "        # WandB에 로깅\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_accuracy_top1\": train_acc_top1,\n",
    "            \"train_accuracy_top5\": train_acc_top5,\n",
    "            \"test_loss\": test_loss,\n",
    "            \"test_accuracy_top1\": test_acc_top1,\n",
    "            \"test_accuracy_top5\": test_acc_top5\n",
    "        })\n",
    "            \n",
    "        # 최고 정확도 모델 저장 (top-1 기준)\n",
    "        if test_acc_top1 > best_test_acc_top1:\n",
    "            best_test_acc_top1 = test_acc_top1\n",
    "            best_test_acc_top5_at_best_top1 = test_acc_top5\n",
    "            print(f'새로운 최고 top-1 정확도: {best_test_acc_top1:.2f}%, top-5 정확도: {best_test_acc_top5_at_best_top1:.2f}%')\n",
    "            # 모델 저장\n",
    "            model_path = f'best_model_{wandb.run.name}.pth'\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            \n",
    "            # WandB에 모델 아티팩트 저장\n",
    "            wandb.save(model_path)\n",
    "        \n",
    "        # top-5 accuracy 기록 업데이트\n",
    "        if test_acc_top5 > best_test_acc_top5:\n",
    "            best_test_acc_top5 = test_acc_top5\n",
    "            print(f'새로운 최고 top-5 정확도: {best_test_acc_top5:.2f}%')\n",
    "\n",
    "        # Early stopping 체크 (test_acc_top1 기준)\n",
    "        early_stopping(test_acc_top1, model, epoch)\n",
    "        if early_stopping.early_stop:\n",
    "            print(f\"에폭 {epoch+1}에서 학습 조기 종료. 최고 성능 에폭: {early_stopping.best_epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    # 훈련 완료 후 최고 모델 로드\n",
    "    print(\"테스트 정확도 기준 최고 모델 로드 중...\")\n",
    "    model_path = f'best_model_{wandb.run.name}.pth'\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    # 최종 테스트 세트 평가\n",
    "    final_test_loss, final_test_acc_top1, final_test_acc_top5 = evaluate(model, testloader, criterion, device, num_epochs-1, phase=\"test\")\n",
    "    \n",
    "    print(f'완료! 최고 테스트 top-1 정확도: {best_test_acc_top1:.2f}%, 최고 테스트 top-5 정확도: {best_test_acc_top5:.2f}%')\n",
    "    print(f'최종 테스트 top-1 정확도: {final_test_acc_top1:.2f}%, 최종 테스트 top-5 정확도: {final_test_acc_top5:.2f}%')\n",
    "    \n",
    "    # WandB에 최종 결과 기록\n",
    "    wandb.run.summary[\"best_test_accuracy_top1\"] = best_test_acc_top1\n",
    "    wandb.run.summary[\"best_test_accuracy_top5\"] = best_test_acc_top5\n",
    "    wandb.run.summary[\"final_test_accuracy_top1\"] = final_test_acc_top1\n",
    "    wandb.run.summary[\"final_test_accuracy_top5\"] = final_test_acc_top5\n",
    "\n",
    "    # Early stopping 정보 저장\n",
    "    if early_stopping.early_stop:\n",
    "        wandb.run.summary[\"early_stopped\"] = True\n",
    "        wandb.run.summary[\"early_stopped_epoch\"] = epoch+1\n",
    "        wandb.run.summary[\"best_epoch\"] = early_stopping.best_epoch+1\n",
    "    else:\n",
    "        wandb.run.summary[\"early_stopped\"] = False\n",
    "\n",
    "\n",
    "# 디바이스 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ResNeXt-50 모델 초기화\n",
    "model = resnext50().to(device)\n",
    "\n",
    "# 손실 함수 설정 (라벨 스무딩 사용)\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "# SGD 옵티마이저 사용 (ResNeXt에 적합)\n",
    "base_optimizer = optim.SGD\n",
    "optimizer = SAM(\n",
    "    model.parameters(), \n",
    "    base_optimizer, \n",
    "    lr=config[\"learning_rate\"],\n",
    "    momentum=0.9,\n",
    "    weight_decay=5e-4\n",
    ")\n",
    "\n",
    "# WarmUpLR 스케줄러 초기화\n",
    "# 웜업할 총 iteration 수 계산 (웜업 에폭 × 배치 수)\n",
    "warmup_steps = config[\"warmup_epochs\"] * len(trainloader)\n",
    "warmup_scheduler = WarmUpLR(optimizer, total_iters=warmup_steps)\n",
    "\n",
    "# 웜업 이후 사용할 스케줄러 설정 \n",
    "main_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    mode='max',           # 정확도를 모니터링하므로 'max' 모드 사용\n",
    "    factor=0.5,           # 학습률 감소 비율\n",
    "    patience=5,           # 몇 에폭 동안 개선이 없을 때 감소시킬지\n",
    "    verbose=True,         # 학습률 변경 시 출력\n",
    "    threshold=0.01,       # 개선으로 간주할 최소 변화량\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "# WandB에 모델 구조 기록\n",
    "wandb.watch(model, log=\"all\")\n",
    "\n",
    "# GPU 가속 - A4000 두 장 활용\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"{torch.cuda.device_count()}개의 GPU를 사용합니다.\")\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "# 훈련 시작 시간 기록\n",
    "start_time = time.time()\n",
    "\n",
    "# 메인 학습 루프 호출\n",
    "main_training_loop(\n",
    "    model=model,\n",
    "    trainloader=trainloader,\n",
    "    testloader=testloader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    num_epochs=config[\"num_epochs\"],\n",
    "    patience=config[\"patience\"],\n",
    "    max_epochs_wait=config[\"max_epochs_wait\"],\n",
    "    warmup_scheduler=warmup_scheduler,\n",
    "    main_scheduler=main_scheduler,\n",
    "    warmup_epochs=config[\"warmup_epochs\"]\n",
    ")\n",
    "\n",
    "# 훈련 종료 시간 기록 및 출력\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "wandb.log({\"total_training_time\": total_time})\n",
    "\n",
    "print(f\"전체 학습 시간: {total_time:.2f} 초\")\n",
    "\n",
    "# WandB 실행 종료\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5d49c2-e2b6-4bd0-8479-fc9f9c36cfa3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
