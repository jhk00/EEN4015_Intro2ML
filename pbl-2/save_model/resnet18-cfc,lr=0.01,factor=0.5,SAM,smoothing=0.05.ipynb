{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516f9d5f-6361-4b03-98ee-e1ba4de86b92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▃▃▃▄▄▅▅▅▆▆▆▇▇██</td></tr><tr><td>learning_rate</td><td>▁▃▅▆███████████████</td></tr><tr><td>test_accuracy_top1</td><td>▁▂▂▃▄▅▅▆▆▆▇▇▇▇▇████</td></tr><tr><td>test_accuracy_top5</td><td>▁▃▃▅▅▆▆▆▇▇▇▇███████</td></tr><tr><td>test_loss</td><td>█▇▆▅▅▄▃▃▃▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>train_accuracy_top1</td><td>▁▂▂▃▃▄▅▅▆▆▆▇▇▇▇████</td></tr><tr><td>train_accuracy_top5</td><td>▁▃▃▄▅▅▆▆▇▇▇▇▇██████</td></tr><tr><td>train_loss</td><td>█▇▆▅▅▄▄▃▃▃▂▂▂▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>19</td></tr><tr><td>learning_rate</td><td>0.01</td></tr><tr><td>test_accuracy_top1</td><td>61.97</td></tr><tr><td>test_accuracy_top5</td><td>88</td></tr><tr><td>test_loss</td><td>1.99569</td></tr><tr><td>train_accuracy_top1</td><td>53.288</td></tr><tr><td>train_accuracy_top5</td><td>81.148</td></tr><tr><td>train_loss</td><td>2.37242</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">resnet18_cfc,lr=0.01,factor=0.5,SGD_standard</strong> at: <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/mt1f1n7z' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/mt1f1n7z</a><br> View project at: <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250421_113803-mt1f1n7z/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/guswls/EEN4015_Intro2ML/pbl-2/wandb/run-20250421_123748-60oll6tp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/60oll6tp' target=\"_blank\">resnet18_cfc,lr=0.01,factor=0.5,smoothing,SGD_standard</a></strong> to <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/60oll6tp' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/60oll6tp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 50000\n",
      "Test set size: 10000\n",
      "Using device: cuda\n",
      "2개의 GPU를 사용합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                       | 0/300 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Batch [50/196], Loss: 4.7584, LR: 0.000510\n",
      "Epoch [1], Batch [100/196], Loss: 4.6473, LR: 0.001020\n",
      "Epoch [1], Batch [150/196], Loss: 4.4385, LR: 0.001531\n",
      "Train set: Epoch: 1, Average loss:4.6431, LR: 0.002000 Top-1 Accuracy: 1.4560%, Top-5 Accuracy: 6.6920%, Time consumed:167.11s\n",
      "Test set: Epoch: 1, Average loss:4.1733, Top-1 Accuracy: 8.0200%, Top-5 Accuracy: 25.9100%, Time consumed:15.23s\n",
      "\n",
      "새로운 최고 top-1 정확도: 8.02%, top-5 정확도: 25.91%\n",
      "새로운 최고 top-5 정확도: 25.91%\n",
      "Accuracy improved (-inf% --> 8.02%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                                          | 1/300 [03:02<15:09:48, 182.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], Batch [50/196], Loss: 4.4789, LR: 0.002510\n",
      "Epoch [2], Batch [100/196], Loss: 4.1394, LR: 0.003020\n",
      "Epoch [2], Batch [150/196], Loss: 4.0950, LR: 0.003531\n",
      "Train set: Epoch: 2, Average loss:4.2247, LR: 0.004000 Top-1 Accuracy: 6.7740%, Top-5 Accuracy: 23.3360%, Time consumed:172.80s\n",
      "Test set: Epoch: 2, Average loss:3.8359, Top-1 Accuracy: 13.3400%, Top-5 Accuracy: 37.5200%, Time consumed:15.33s\n",
      "\n",
      "새로운 최고 top-1 정확도: 13.34%, top-5 정확도: 37.52%\n",
      "새로운 최고 top-5 정확도: 37.52%\n",
      "Accuracy improved (8.02% --> 13.34%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▌                                                                                          | 2/300 [06:10<15:23:50, 186.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3], Batch [50/196], Loss: 3.9128, LR: 0.004510\n",
      "Epoch [3], Batch [100/196], Loss: 3.8039, LR: 0.005020\n",
      "Epoch [3], Batch [150/196], Loss: 3.8326, LR: 0.005531\n",
      "Train set: Epoch: 3, Average loss:3.9981, LR: 0.006000 Top-1 Accuracy: 10.7840%, Top-5 Accuracy: 32.4160%, Time consumed:170.71s\n",
      "Test set: Epoch: 3, Average loss:3.6226, Top-1 Accuracy: 19.1900%, Top-5 Accuracy: 45.5100%, Time consumed:14.99s\n",
      "\n",
      "새로운 최고 top-1 정확도: 19.19%, top-5 정확도: 45.51%\n",
      "새로운 최고 top-5 정확도: 45.51%\n",
      "Accuracy improved (13.34% --> 19.19%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▉                                                                                          | 3/300 [09:16<15:20:37, 185.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4], Batch [50/196], Loss: 4.0871, LR: 0.006510\n",
      "Epoch [4], Batch [100/196], Loss: 4.0906, LR: 0.007020\n",
      "Epoch [4], Batch [150/196], Loss: 4.1304, LR: 0.007531\n",
      "Train set: Epoch: 4, Average loss:3.8438, LR: 0.008000 Top-1 Accuracy: 14.3040%, Top-5 Accuracy: 38.3920%, Time consumed:170.09s\n",
      "Test set: Epoch: 4, Average loss:3.4201, Top-1 Accuracy: 22.8200%, Top-5 Accuracy: 52.5700%, Time consumed:15.90s\n",
      "\n",
      "새로운 최고 top-1 정확도: 22.82%, top-5 정확도: 52.57%\n",
      "새로운 최고 top-5 정확도: 52.57%\n",
      "Accuracy improved (19.19% --> 22.82%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▏                                                                                         | 4/300 [12:23<15:18:02, 186.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5], Batch [50/196], Loss: 4.3078, LR: 0.008510\n",
      "Epoch [5], Batch [100/196], Loss: 3.4307, LR: 0.009020\n",
      "Epoch [5], Batch [150/196], Loss: 4.1662, LR: 0.009531\n",
      "Train set: Epoch: 5, Average loss:3.6121, LR: 0.010000 Top-1 Accuracy: 19.3020%, Top-5 Accuracy: 46.2980%, Time consumed:170.60s\n",
      "Test set: Epoch: 5, Average loss:3.1435, Top-1 Accuracy: 29.7700%, Top-5 Accuracy: 60.4500%, Time consumed:16.01s\n",
      "\n",
      "새로운 최고 top-1 정확도: 29.77%, top-5 정확도: 60.45%\n",
      "새로운 최고 top-5 정확도: 60.45%\n",
      "Accuracy improved (22.82% --> 29.77%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▌                                                                                         | 5/300 [15:30<15:16:19, 186.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6], Batch [50/196], Loss: 3.0544, LR: 0.010000\n",
      "Epoch [6], Batch [100/196], Loss: 3.1853, LR: 0.010000\n",
      "Epoch [6], Batch [150/196], Loss: 3.0539, LR: 0.010000\n",
      "Train set: Epoch: 6, Average loss:3.4719, LR: 0.010000 Top-1 Accuracy: 23.0500%, Top-5 Accuracy: 51.5640%, Time consumed:167.48s\n",
      "Test set: Epoch: 6, Average loss:3.0018, Top-1 Accuracy: 34.0500%, Top-5 Accuracy: 65.3900%, Time consumed:14.73s\n",
      "\n",
      "새로운 최고 top-1 정확도: 34.05%, top-5 정확도: 65.39%\n",
      "새로운 최고 top-5 정확도: 65.39%\n",
      "Accuracy improved (29.77% --> 34.05%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▊                                                                                         | 6/300 [18:32<15:06:42, 185.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7], Batch [50/196], Loss: 2.9820, LR: 0.010000\n",
      "Epoch [7], Batch [100/196], Loss: 3.7217, LR: 0.010000\n",
      "Epoch [7], Batch [150/196], Loss: 2.6230, LR: 0.010000\n",
      "Train set: Epoch: 7, Average loss:3.2896, LR: 0.010000 Top-1 Accuracy: 27.4720%, Top-5 Accuracy: 57.5740%, Time consumed:171.95s\n",
      "Test set: Epoch: 7, Average loss:2.7692, Top-1 Accuracy: 39.3600%, Top-5 Accuracy: 70.7000%, Time consumed:16.01s\n",
      "\n",
      "새로운 최고 top-1 정확도: 39.36%, top-5 정확도: 70.70%\n",
      "새로운 최고 top-5 정확도: 70.70%\n",
      "Accuracy improved (34.05% --> 39.36%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██                                                                                         | 7/300 [21:40<15:08:40, 186.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8], Batch [50/196], Loss: 2.6980, LR: 0.010000\n",
      "Epoch [8], Batch [100/196], Loss: 2.7948, LR: 0.010000\n",
      "Epoch [8], Batch [150/196], Loss: 2.8236, LR: 0.010000\n",
      "Train set: Epoch: 8, Average loss:3.1282, LR: 0.010000 Top-1 Accuracy: 31.4560%, Top-5 Accuracy: 61.2880%, Time consumed:171.37s\n",
      "Test set: Epoch: 8, Average loss:2.6357, Top-1 Accuracy: 43.0200%, Top-5 Accuracy: 75.0700%, Time consumed:14.91s\n",
      "\n",
      "새로운 최고 top-1 정확도: 43.02%, top-5 정확도: 75.07%\n",
      "새로운 최고 top-5 정확도: 75.07%\n",
      "Accuracy improved (39.36% --> 43.02%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▍                                                                                        | 8/300 [24:47<15:06:16, 186.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9], Batch [50/196], Loss: 2.6649, LR: 0.010000\n",
      "Epoch [9], Batch [100/196], Loss: 2.7233, LR: 0.010000\n",
      "Epoch [9], Batch [150/196], Loss: 2.7131, LR: 0.010000\n",
      "Train set: Epoch: 9, Average loss:3.0324, LR: 0.010000 Top-1 Accuracy: 34.2220%, Top-5 Accuracy: 64.9100%, Time consumed:166.99s\n",
      "Test set: Epoch: 9, Average loss:2.5487, Top-1 Accuracy: 45.0600%, Top-5 Accuracy: 76.8000%, Time consumed:14.68s\n",
      "\n",
      "새로운 최고 top-1 정확도: 45.06%, top-5 정확도: 76.80%\n",
      "새로운 최고 top-5 정확도: 76.80%\n",
      "Accuracy improved (43.02% --> 45.06%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▋                                                                                        | 9/300 [27:49<14:56:38, 184.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10], Batch [50/196], Loss: 3.6222, LR: 0.010000\n",
      "Epoch [10], Batch [100/196], Loss: 3.3948, LR: 0.010000\n",
      "Epoch [10], Batch [150/196], Loss: 2.5644, LR: 0.010000\n",
      "Train set: Epoch: 10, Average loss:2.9403, LR: 0.010000 Top-1 Accuracy: 36.6880%, Top-5 Accuracy: 67.0240%, Time consumed:168.56s\n",
      "Test set: Epoch: 10, Average loss:2.4947, Top-1 Accuracy: 47.3900%, Top-5 Accuracy: 77.6000%, Time consumed:14.81s\n",
      "\n",
      "새로운 최고 top-1 정확도: 47.39%, top-5 정확도: 77.60%\n",
      "새로운 최고 top-5 정확도: 77.60%\n",
      "Accuracy improved (45.06% --> 47.39%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|███                                                                                       | 10/300 [30:52<14:51:40, 184.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11], Batch [50/196], Loss: 3.6523, LR: 0.010000\n",
      "Epoch [11], Batch [100/196], Loss: 3.3639, LR: 0.010000\n",
      "Epoch [11], Batch [150/196], Loss: 2.3258, LR: 0.010000\n",
      "Train set: Epoch: 11, Average loss:2.7336, LR: 0.010000 Top-1 Accuracy: 41.8660%, Top-5 Accuracy: 72.3200%, Time consumed:168.61s\n",
      "Test set: Epoch: 11, Average loss:2.4175, Top-1 Accuracy: 49.4900%, Top-5 Accuracy: 79.5700%, Time consumed:16.19s\n",
      "\n",
      "새로운 최고 top-1 정확도: 49.49%, top-5 정확도: 79.57%\n",
      "새로운 최고 top-5 정확도: 79.57%\n",
      "Accuracy improved (47.39% --> 49.49%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▎                                                                                      | 11/300 [33:57<14:49:26, 184.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12], Batch [50/196], Loss: 2.4561, LR: 0.010000\n",
      "Epoch [12], Batch [100/196], Loss: 2.3750, LR: 0.010000\n",
      "Epoch [12], Batch [150/196], Loss: 3.6427, LR: 0.010000\n",
      "Train set: Epoch: 12, Average loss:2.7509, LR: 0.010000 Top-1 Accuracy: 41.9040%, Top-5 Accuracy: 71.6500%, Time consumed:167.70s\n",
      "Test set: Epoch: 12, Average loss:2.2801, Top-1 Accuracy: 53.2400%, Top-5 Accuracy: 81.9300%, Time consumed:14.94s\n",
      "\n",
      "새로운 최고 top-1 정확도: 53.24%, top-5 정확도: 81.93%\n",
      "새로운 최고 top-5 정확도: 81.93%\n",
      "Accuracy improved (49.49% --> 53.24%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▌                                                                                      | 12/300 [37:00<14:43:45, 184.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13], Batch [50/196], Loss: 2.3086, LR: 0.010000\n",
      "Epoch [13], Batch [100/196], Loss: 2.2112, LR: 0.010000\n",
      "Epoch [13], Batch [150/196], Loss: 2.4000, LR: 0.010000\n",
      "Train set: Epoch: 13, Average loss:2.6540, LR: 0.010000 Top-1 Accuracy: 44.8440%, Top-5 Accuracy: 74.6960%, Time consumed:168.06s\n",
      "Test set: Epoch: 13, Average loss:2.2670, Top-1 Accuracy: 53.6400%, Top-5 Accuracy: 82.5700%, Time consumed:15.04s\n",
      "\n",
      "새로운 최고 top-1 정확도: 53.64%, top-5 정확도: 82.57%\n",
      "새로운 최고 top-5 정확도: 82.57%\n",
      "Accuracy improved (53.24% --> 53.64%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▉                                                                                      | 13/300 [40:04<14:39:38, 183.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14], Batch [50/196], Loss: 3.5488, LR: 0.010000\n",
      "Epoch [14], Batch [100/196], Loss: 2.4254, LR: 0.010000\n",
      "Epoch [14], Batch [150/196], Loss: 2.3459, LR: 0.010000\n",
      "Train set: Epoch: 14, Average loss:2.5878, LR: 0.010000 Top-1 Accuracy: 46.5320%, Top-5 Accuracy: 75.4620%, Time consumed:180.07s\n",
      "Test set: Epoch: 14, Average loss:2.1740, Top-1 Accuracy: 56.7100%, Top-5 Accuracy: 84.0500%, Time consumed:15.00s\n",
      "\n",
      "새로운 최고 top-1 정확도: 56.71%, top-5 정확도: 84.05%\n",
      "새로운 최고 top-5 정확도: 84.05%\n",
      "Accuracy improved (53.64% --> 56.71%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▏                                                                                     | 14/300 [43:19<14:53:06, 187.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15], Batch [50/196], Loss: 3.0674, LR: 0.010000\n",
      "Epoch [15], Batch [100/196], Loss: 2.8728, LR: 0.010000\n",
      "Epoch [15], Batch [150/196], Loss: 2.1720, LR: 0.010000\n",
      "Train set: Epoch: 15, Average loss:2.6483, LR: 0.010000 Top-1 Accuracy: 45.7740%, Top-5 Accuracy: 74.8540%, Time consumed:167.35s\n",
      "Test set: Epoch: 15, Average loss:2.1244, Top-1 Accuracy: 57.7000%, Top-5 Accuracy: 85.4900%, Time consumed:14.58s\n",
      "\n",
      "새로운 최고 top-1 정확도: 57.70%, top-5 정확도: 85.49%\n",
      "새로운 최고 top-5 정확도: 85.49%\n",
      "Accuracy improved (56.71% --> 57.70%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▌                                                                                     | 15/300 [46:21<14:42:33, 185.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16], Batch [50/196], Loss: 2.1746, LR: 0.010000\n",
      "Epoch [16], Batch [100/196], Loss: 2.2008, LR: 0.010000\n",
      "Epoch [16], Batch [150/196], Loss: 3.5029, LR: 0.010000\n",
      "Train set: Epoch: 16, Average loss:2.5695, LR: 0.010000 Top-1 Accuracy: 47.0680%, Top-5 Accuracy: 76.1240%, Time consumed:170.79s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▊                                                                                     | 16/300 [49:27<14:38:59, 185.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 16, Average loss:2.1449, Top-1 Accuracy: 57.5000%, Top-5 Accuracy: 85.3600%, Time consumed:14.67s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [17], Batch [50/196], Loss: 3.5511, LR: 0.010000\n",
      "Epoch [17], Batch [100/196], Loss: 2.5840, LR: 0.010000\n",
      "Epoch [17], Batch [150/196], Loss: 2.0467, LR: 0.010000\n",
      "Train set: Epoch: 17, Average loss:2.5349, LR: 0.010000 Top-1 Accuracy: 49.1500%, Top-5 Accuracy: 77.8160%, Time consumed:168.89s\n",
      "Test set: Epoch: 17, Average loss:2.0506, Top-1 Accuracy: 59.8100%, Top-5 Accuracy: 86.9100%, Time consumed:14.89s\n",
      "\n",
      "새로운 최고 top-1 정확도: 59.81%, top-5 정확도: 86.91%\n",
      "새로운 최고 top-5 정확도: 86.91%\n",
      "Accuracy improved (57.70% --> 59.81%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████                                                                                     | 17/300 [52:31<14:33:31, 185.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18], Batch [50/196], Loss: 2.6116, LR: 0.010000\n",
      "Epoch [18], Batch [100/196], Loss: 1.9886, LR: 0.010000\n",
      "Epoch [18], Batch [150/196], Loss: 2.0360, LR: 0.010000\n",
      "Train set: Epoch: 18, Average loss:2.4677, LR: 0.010000 Top-1 Accuracy: 50.0280%, Top-5 Accuracy: 78.3960%, Time consumed:169.36s\n",
      "Test set: Epoch: 18, Average loss:2.0413, Top-1 Accuracy: 60.6100%, Top-5 Accuracy: 87.2500%, Time consumed:15.39s\n",
      "\n",
      "새로운 최고 top-1 정확도: 60.61%, top-5 정확도: 87.25%\n",
      "새로운 최고 top-5 정확도: 87.25%\n",
      "Accuracy improved (59.81% --> 60.61%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████▍                                                                                    | 18/300 [55:36<14:30:11, 185.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19], Batch [50/196], Loss: 2.7314, LR: 0.010000\n",
      "Epoch [19], Batch [100/196], Loss: 3.4094, LR: 0.010000\n",
      "Epoch [19], Batch [150/196], Loss: 3.1062, LR: 0.010000\n",
      "Train set: Epoch: 19, Average loss:2.4080, LR: 0.010000 Top-1 Accuracy: 52.2460%, Top-5 Accuracy: 80.0680%, Time consumed:168.17s\n",
      "Test set: Epoch: 19, Average loss:2.0269, Top-1 Accuracy: 61.3500%, Top-5 Accuracy: 87.1700%, Time consumed:15.39s\n",
      "\n",
      "새로운 최고 top-1 정확도: 61.35%, top-5 정확도: 87.17%\n",
      "Accuracy improved (60.61% --> 61.35%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████▋                                                                                    | 19/300 [58:40<14:25:18, 184.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20], Batch [50/196], Loss: 1.9503, LR: 0.010000\n",
      "Epoch [20], Batch [100/196], Loss: 2.0374, LR: 0.010000\n",
      "Epoch [20], Batch [150/196], Loss: 3.2281, LR: 0.010000\n",
      "Train set: Epoch: 20, Average loss:2.3250, LR: 0.010000 Top-1 Accuracy: 54.0540%, Top-5 Accuracy: 81.5200%, Time consumed:169.30s\n",
      "Test set: Epoch: 20, Average loss:1.9612, Top-1 Accuracy: 62.7300%, Top-5 Accuracy: 88.4000%, Time consumed:14.66s\n",
      "\n",
      "새로운 최고 top-1 정확도: 62.73%, top-5 정확도: 88.40%\n",
      "새로운 최고 top-5 정확도: 88.40%\n",
      "Accuracy improved (61.35% --> 62.73%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████▊                                                                                  | 20/300 [1:01:44<14:21:25, 184.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21], Batch [50/196], Loss: 3.3562, LR: 0.010000\n",
      "Epoch [21], Batch [100/196], Loss: 3.1996, LR: 0.010000\n",
      "Epoch [21], Batch [150/196], Loss: 2.5548, LR: 0.010000\n",
      "Train set: Epoch: 21, Average loss:2.3847, LR: 0.010000 Top-1 Accuracy: 53.6900%, Top-5 Accuracy: 81.1000%, Time consumed:170.96s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████▏                                                                                 | 21/300 [1:04:50<14:20:08, 184.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 21, Average loss:2.0104, Top-1 Accuracy: 61.4700%, Top-5 Accuracy: 87.6300%, Time consumed:14.90s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [22], Batch [50/196], Loss: 1.8729, LR: 0.010000\n",
      "Epoch [22], Batch [100/196], Loss: 1.8485, LR: 0.010000\n",
      "Epoch [22], Batch [150/196], Loss: 1.8821, LR: 0.010000\n",
      "Train set: Epoch: 22, Average loss:2.3392, LR: 0.010000 Top-1 Accuracy: 54.8140%, Top-5 Accuracy: 81.8100%, Time consumed:167.12s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████▍                                                                                 | 22/300 [1:07:53<14:14:31, 184.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 22, Average loss:1.9890, Top-1 Accuracy: 62.2200%, Top-5 Accuracy: 87.6400%, Time consumed:16.03s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [23], Batch [50/196], Loss: 1.8530, LR: 0.010000\n",
      "Epoch [23], Batch [100/196], Loss: 3.0256, LR: 0.010000\n",
      "Epoch [23], Batch [150/196], Loss: 2.0008, LR: 0.010000\n",
      "Train set: Epoch: 23, Average loss:2.2719, LR: 0.010000 Top-1 Accuracy: 55.3620%, Top-5 Accuracy: 81.9220%, Time consumed:170.91s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▋                                                                                 | 23/300 [1:10:58<14:12:37, 184.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 23, Average loss:2.0034, Top-1 Accuracy: 61.9800%, Top-5 Accuracy: 87.8600%, Time consumed:14.36s\n",
      "\n",
      "EarlyStopping 카운터: 3 / 30\n",
      "Epoch [24], Batch [50/196], Loss: 1.7743, LR: 0.010000\n",
      "Epoch [24], Batch [100/196], Loss: 1.7454, LR: 0.010000\n",
      "Epoch [24], Batch [150/196], Loss: 2.0709, LR: 0.010000\n",
      "Train set: Epoch: 24, Average loss:2.2661, LR: 0.010000 Top-1 Accuracy: 56.8200%, Top-5 Accuracy: 83.3160%, Time consumed:170.34s\n",
      "Test set: Epoch: 24, Average loss:1.9437, Top-1 Accuracy: 63.7000%, Top-5 Accuracy: 88.9500%, Time consumed:15.35s\n",
      "\n",
      "새로운 최고 top-1 정확도: 63.70%, top-5 정확도: 88.95%\n",
      "새로운 최고 top-5 정확도: 88.95%\n",
      "Accuracy improved (62.73% --> 63.70%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███████                                                                                 | 24/300 [1:14:04<14:11:14, 185.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25], Batch [50/196], Loss: 1.8131, LR: 0.010000\n",
      "Epoch [25], Batch [100/196], Loss: 1.7499, LR: 0.010000\n",
      "Epoch [25], Batch [150/196], Loss: 1.8040, LR: 0.010000\n",
      "Train set: Epoch: 25, Average loss:2.1828, LR: 0.010000 Top-1 Accuracy: 59.5960%, Top-5 Accuracy: 84.9180%, Time consumed:166.74s\n",
      "Test set: Epoch: 25, Average loss:1.9021, Top-1 Accuracy: 65.7100%, Top-5 Accuracy: 89.3700%, Time consumed:14.69s\n",
      "\n",
      "새로운 최고 top-1 정확도: 65.71%, top-5 정확도: 89.37%\n",
      "새로운 최고 top-5 정확도: 89.37%\n",
      "Accuracy improved (63.70% --> 65.71%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███████▎                                                                                | 25/300 [1:17:06<14:03:30, 184.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26], Batch [50/196], Loss: 3.0559, LR: 0.010000\n",
      "Epoch [26], Batch [100/196], Loss: 1.5397, LR: 0.010000\n",
      "Epoch [26], Batch [150/196], Loss: 2.4274, LR: 0.010000\n",
      "Train set: Epoch: 26, Average loss:2.1754, LR: 0.010000 Top-1 Accuracy: 59.5480%, Top-5 Accuracy: 85.0860%, Time consumed:166.33s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███████▋                                                                                | 26/300 [1:20:07<13:56:57, 183.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 26, Average loss:1.8932, Top-1 Accuracy: 65.6100%, Top-5 Accuracy: 89.6100%, Time consumed:15.16s\n",
      "\n",
      "새로운 최고 top-5 정확도: 89.61%\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [27], Batch [50/196], Loss: 1.6741, LR: 0.010000\n",
      "Epoch [27], Batch [100/196], Loss: 2.4840, LR: 0.010000\n",
      "Epoch [27], Batch [150/196], Loss: 3.5209, LR: 0.010000\n",
      "Train set: Epoch: 27, Average loss:2.1994, LR: 0.010000 Top-1 Accuracy: 59.1700%, Top-5 Accuracy: 84.5080%, Time consumed:168.81s\n",
      "Test set: Epoch: 27, Average loss:1.8661, Top-1 Accuracy: 66.0500%, Top-5 Accuracy: 90.0000%, Time consumed:14.80s\n",
      "\n",
      "새로운 최고 top-1 정확도: 66.05%, top-5 정확도: 90.00%\n",
      "새로운 최고 top-5 정확도: 90.00%\n",
      "Accuracy improved (65.71% --> 66.05%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███████▉                                                                                | 27/300 [1:23:11<13:54:41, 183.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28], Batch [50/196], Loss: 2.3570, LR: 0.010000\n",
      "Epoch [28], Batch [100/196], Loss: 3.3102, LR: 0.010000\n",
      "Epoch [28], Batch [150/196], Loss: 3.2794, LR: 0.010000\n",
      "Train set: Epoch: 28, Average loss:2.1686, LR: 0.010000 Top-1 Accuracy: 59.2880%, Top-5 Accuracy: 84.7120%, Time consumed:166.38s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|████████▏                                                                               | 28/300 [1:26:13<13:49:16, 182.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 28, Average loss:1.8990, Top-1 Accuracy: 64.8400%, Top-5 Accuracy: 89.3500%, Time consumed:15.33s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [29], Batch [50/196], Loss: 2.6928, LR: 0.010000\n",
      "Epoch [29], Batch [100/196], Loss: 1.9490, LR: 0.010000\n",
      "Epoch [29], Batch [150/196], Loss: 1.6243, LR: 0.010000\n",
      "Train set: Epoch: 29, Average loss:2.0581, LR: 0.010000 Top-1 Accuracy: 62.7600%, Top-5 Accuracy: 86.9140%, Time consumed:172.31s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▌                                                                               | 29/300 [1:29:20<13:51:40, 184.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 29, Average loss:1.8662, Top-1 Accuracy: 66.0300%, Top-5 Accuracy: 89.6900%, Time consumed:14.63s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [30], Batch [50/196], Loss: 2.3017, LR: 0.010000\n",
      "Epoch [30], Batch [100/196], Loss: 1.1457, LR: 0.010000\n",
      "Epoch [30], Batch [150/196], Loss: 1.6908, LR: 0.010000\n",
      "Train set: Epoch: 30, Average loss:2.1233, LR: 0.010000 Top-1 Accuracy: 59.9940%, Top-5 Accuracy: 84.7580%, Time consumed:168.89s\n",
      "Test set: Epoch: 30, Average loss:1.8508, Top-1 Accuracy: 66.3500%, Top-5 Accuracy: 90.3600%, Time consumed:14.63s\n",
      "\n",
      "새로운 최고 top-1 정확도: 66.35%, top-5 정확도: 90.36%\n",
      "새로운 최고 top-5 정확도: 90.36%\n",
      "Accuracy improved (66.05% --> 66.35%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▊                                                                               | 30/300 [1:32:23<13:48:05, 184.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31], Batch [50/196], Loss: 2.8842, LR: 0.010000\n",
      "Epoch [31], Batch [100/196], Loss: 3.0661, LR: 0.010000\n",
      "Epoch [31], Batch [150/196], Loss: 1.6577, LR: 0.010000\n",
      "Train set: Epoch: 31, Average loss:2.1274, LR: 0.010000 Top-1 Accuracy: 61.6620%, Top-5 Accuracy: 86.1340%, Time consumed:167.79s\n",
      "Test set: Epoch: 31, Average loss:1.8075, Top-1 Accuracy: 68.2100%, Top-5 Accuracy: 90.7500%, Time consumed:15.34s\n",
      "\n",
      "새로운 최고 top-1 정확도: 68.21%, top-5 정확도: 90.75%\n",
      "새로운 최고 top-5 정확도: 90.75%\n",
      "Accuracy improved (66.35% --> 68.21%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█████████                                                                               | 31/300 [1:35:27<13:44:08, 183.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32], Batch [50/196], Loss: 3.4290, LR: 0.010000\n",
      "Epoch [32], Batch [100/196], Loss: 1.7048, LR: 0.010000\n",
      "Epoch [32], Batch [150/196], Loss: 1.6044, LR: 0.010000\n",
      "Train set: Epoch: 32, Average loss:1.9701, LR: 0.010000 Top-1 Accuracy: 64.8100%, Top-5 Accuracy: 88.3600%, Time consumed:167.94s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█████████▍                                                                              | 32/300 [1:38:29<13:39:08, 183.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 32, Average loss:1.8101, Top-1 Accuracy: 67.9000%, Top-5 Accuracy: 91.0500%, Time consumed:14.44s\n",
      "\n",
      "새로운 최고 top-5 정확도: 91.05%\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [33], Batch [50/196], Loss: 2.8439, LR: 0.010000\n",
      "Epoch [33], Batch [100/196], Loss: 1.6137, LR: 0.010000\n",
      "Epoch [33], Batch [150/196], Loss: 1.5736, LR: 0.010000\n",
      "Train set: Epoch: 33, Average loss:2.0537, LR: 0.010000 Top-1 Accuracy: 63.0280%, Top-5 Accuracy: 86.7280%, Time consumed:166.36s\n",
      "Test set: Epoch: 33, Average loss:1.8002, Top-1 Accuracy: 68.5000%, Top-5 Accuracy: 91.0200%, Time consumed:14.47s\n",
      "\n",
      "새로운 최고 top-1 정확도: 68.50%, top-5 정확도: 91.02%\n",
      "Accuracy improved (68.21% --> 68.50%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█████████▋                                                                              | 33/300 [1:41:30<13:33:00, 182.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34], Batch [50/196], Loss: 1.4812, LR: 0.010000\n",
      "Epoch [34], Batch [100/196], Loss: 2.5297, LR: 0.010000\n",
      "Epoch [34], Batch [150/196], Loss: 1.6274, LR: 0.010000\n",
      "Train set: Epoch: 34, Average loss:2.0241, LR: 0.010000 Top-1 Accuracy: 63.3500%, Top-5 Accuracy: 86.5700%, Time consumed:168.22s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█████████▉                                                                              | 34/300 [1:44:33<13:30:30, 182.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 34, Average loss:1.8103, Top-1 Accuracy: 68.1100%, Top-5 Accuracy: 90.7800%, Time consumed:14.87s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [35], Batch [50/196], Loss: 3.0936, LR: 0.010000\n",
      "Epoch [35], Batch [100/196], Loss: 1.5617, LR: 0.010000\n",
      "Epoch [35], Batch [150/196], Loss: 1.5156, LR: 0.010000\n",
      "Train set: Epoch: 35, Average loss:2.0413, LR: 0.010000 Top-1 Accuracy: 64.0680%, Top-5 Accuracy: 87.4720%, Time consumed:165.09s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████▎                                                                             | 35/300 [1:47:33<13:23:06, 181.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 35, Average loss:1.8005, Top-1 Accuracy: 68.2200%, Top-5 Accuracy: 90.8400%, Time consumed:14.44s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [36], Batch [50/196], Loss: 1.9548, LR: 0.010000\n",
      "Epoch [36], Batch [100/196], Loss: 1.4913, LR: 0.010000\n",
      "Epoch [36], Batch [150/196], Loss: 1.5530, LR: 0.010000\n",
      "Train set: Epoch: 36, Average loss:2.0392, LR: 0.010000 Top-1 Accuracy: 63.4340%, Top-5 Accuracy: 86.7020%, Time consumed:168.39s\n",
      "Test set: Epoch: 36, Average loss:1.7599, Top-1 Accuracy: 69.3700%, Top-5 Accuracy: 91.5500%, Time consumed:14.92s\n",
      "\n",
      "새로운 최고 top-1 정확도: 69.37%, top-5 정확도: 91.55%\n",
      "새로운 최고 top-5 정확도: 91.55%\n",
      "Accuracy improved (68.50% --> 69.37%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████▌                                                                             | 36/300 [1:50:36<13:22:21, 182.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37], Batch [50/196], Loss: 1.4895, LR: 0.010000\n",
      "Epoch [37], Batch [100/196], Loss: 2.8633, LR: 0.010000\n",
      "Epoch [37], Batch [150/196], Loss: 2.9580, LR: 0.010000\n",
      "Train set: Epoch: 37, Average loss:2.0421, LR: 0.010000 Top-1 Accuracy: 64.6760%, Top-5 Accuracy: 87.6200%, Time consumed:172.16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████▊                                                                             | 37/300 [1:53:45<13:27:09, 184.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 37, Average loss:1.7857, Top-1 Accuracy: 68.6700%, Top-5 Accuracy: 91.4800%, Time consumed:16.15s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [38], Batch [50/196], Loss: 1.4014, LR: 0.010000\n",
      "Epoch [38], Batch [100/196], Loss: 1.5741, LR: 0.010000\n",
      "Epoch [38], Batch [150/196], Loss: 1.5453, LR: 0.010000\n",
      "Train set: Epoch: 38, Average loss:1.9490, LR: 0.010000 Top-1 Accuracy: 66.0540%, Top-5 Accuracy: 88.4540%, Time consumed:170.56s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|███████████▏                                                                            | 38/300 [1:56:51<13:26:20, 184.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 38, Average loss:1.7888, Top-1 Accuracy: 68.1400%, Top-5 Accuracy: 91.0100%, Time consumed:15.29s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [39], Batch [50/196], Loss: 2.9635, LR: 0.010000\n",
      "Epoch [39], Batch [100/196], Loss: 3.0976, LR: 0.010000\n",
      "Epoch [39], Batch [150/196], Loss: 2.8832, LR: 0.010000\n",
      "Train set: Epoch: 39, Average loss:2.0010, LR: 0.010000 Top-1 Accuracy: 64.8260%, Top-5 Accuracy: 87.6460%, Time consumed:167.32s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|███████████▍                                                                            | 39/300 [1:59:52<13:19:13, 183.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 39, Average loss:1.7874, Top-1 Accuracy: 68.6800%, Top-5 Accuracy: 90.7600%, Time consumed:14.25s\n",
      "\n",
      "EarlyStopping 카운터: 3 / 30\n",
      "Epoch [40], Batch [50/196], Loss: 1.4478, LR: 0.010000\n",
      "Epoch [40], Batch [100/196], Loss: 3.1066, LR: 0.010000\n",
      "Epoch [40], Batch [150/196], Loss: 1.4613, LR: 0.010000\n",
      "Train set: Epoch: 40, Average loss:2.0182, LR: 0.010000 Top-1 Accuracy: 65.1360%, Top-5 Accuracy: 87.5440%, Time consumed:168.79s\n",
      "Test set: Epoch: 40, Average loss:1.7622, Top-1 Accuracy: 69.4500%, Top-5 Accuracy: 91.4400%, Time consumed:14.40s\n",
      "\n",
      "새로운 최고 top-1 정확도: 69.45%, top-5 정확도: 91.44%\n",
      "Accuracy improved (69.37% --> 69.45%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|███████████▋                                                                            | 40/300 [2:02:56<13:15:45, 183.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41], Batch [50/196], Loss: 1.4968, LR: 0.010000\n",
      "Epoch [41], Batch [100/196], Loss: 1.5209, LR: 0.010000\n",
      "Epoch [41], Batch [150/196], Loss: 1.4645, LR: 0.010000\n",
      "Train set: Epoch: 41, Average loss:1.8499, LR: 0.010000 Top-1 Accuracy: 70.1060%, Top-5 Accuracy: 90.8780%, Time consumed:171.14s\n",
      "Test set: Epoch: 41, Average loss:1.7275, Top-1 Accuracy: 70.4200%, Top-5 Accuracy: 91.7600%, Time consumed:14.64s\n",
      "\n",
      "새로운 최고 top-1 정확도: 70.42%, top-5 정확도: 91.76%\n",
      "새로운 최고 top-5 정확도: 91.76%\n",
      "Accuracy improved (69.45% --> 70.42%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████                                                                            | 41/300 [2:06:02<13:15:47, 184.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42], Batch [50/196], Loss: 1.4240, LR: 0.010000\n",
      "Epoch [42], Batch [100/196], Loss: 2.4265, LR: 0.010000\n",
      "Epoch [42], Batch [150/196], Loss: 2.7106, LR: 0.010000\n",
      "Train set: Epoch: 42, Average loss:1.9319, LR: 0.010000 Top-1 Accuracy: 67.6980%, Top-5 Accuracy: 89.4580%, Time consumed:165.71s\n",
      "Test set: Epoch: 42, Average loss:1.7402, Top-1 Accuracy: 70.6500%, Top-5 Accuracy: 92.0600%, Time consumed:14.30s\n",
      "\n",
      "새로운 최고 top-1 정확도: 70.65%, top-5 정확도: 92.06%\n",
      "새로운 최고 top-5 정확도: 92.06%\n",
      "Accuracy improved (70.42% --> 70.65%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████▎                                                                           | 42/300 [2:09:02<13:07:24, 183.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43], Batch [50/196], Loss: 1.6311, LR: 0.010000\n",
      "Epoch [43], Batch [100/196], Loss: 1.4174, LR: 0.010000\n",
      "Epoch [43], Batch [150/196], Loss: 1.6521, LR: 0.010000\n",
      "Train set: Epoch: 43, Average loss:1.8543, LR: 0.010000 Top-1 Accuracy: 69.9380%, Top-5 Accuracy: 90.6140%, Time consumed:167.43s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████▌                                                                           | 43/300 [2:12:04<13:03:03, 182.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 43, Average loss:1.7877, Top-1 Accuracy: 68.3800%, Top-5 Accuracy: 90.8100%, Time consumed:14.68s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [44], Batch [50/196], Loss: 2.8907, LR: 0.010000\n",
      "Epoch [44], Batch [100/196], Loss: 2.9360, LR: 0.010000\n",
      "Epoch [44], Batch [150/196], Loss: 1.9743, LR: 0.010000\n",
      "Train set: Epoch: 44, Average loss:1.8294, LR: 0.010000 Top-1 Accuracy: 70.0940%, Top-5 Accuracy: 90.8120%, Time consumed:169.06s\n",
      "Test set: Epoch: 44, Average loss:1.7311, Top-1 Accuracy: 70.6700%, Top-5 Accuracy: 92.0800%, Time consumed:15.18s\n",
      "\n",
      "새로운 최고 top-1 정확도: 70.67%, top-5 정확도: 92.08%\n",
      "새로운 최고 top-5 정확도: 92.08%\n",
      "Accuracy improved (70.65% --> 70.67%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████████████▉                                                                           | 44/300 [2:15:08<13:02:11, 183.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45], Batch [50/196], Loss: 1.3682, LR: 0.010000\n",
      "Epoch [45], Batch [100/196], Loss: 2.5195, LR: 0.010000\n",
      "Epoch [45], Batch [150/196], Loss: 1.4815, LR: 0.010000\n",
      "Train set: Epoch: 45, Average loss:1.8645, LR: 0.010000 Top-1 Accuracy: 69.4460%, Top-5 Accuracy: 90.2160%, Time consumed:168.04s\n",
      "Test set: Epoch: 45, Average loss:1.7241, Top-1 Accuracy: 70.6900%, Top-5 Accuracy: 91.8400%, Time consumed:14.89s\n",
      "\n",
      "새로운 최고 top-1 정확도: 70.69%, top-5 정확도: 91.84%\n",
      "Accuracy improved (70.67% --> 70.69%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████████████▏                                                                          | 45/300 [2:18:12<12:58:57, 183.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46], Batch [50/196], Loss: 2.4450, LR: 0.010000\n",
      "Epoch [46], Batch [100/196], Loss: 2.9239, LR: 0.010000\n",
      "Epoch [46], Batch [150/196], Loss: 1.4418, LR: 0.010000\n",
      "Train set: Epoch: 46, Average loss:1.9037, LR: 0.010000 Top-1 Accuracy: 68.2880%, Top-5 Accuracy: 89.3700%, Time consumed:167.64s\n",
      "Test set: Epoch: 46, Average loss:1.7082, Top-1 Accuracy: 71.4700%, Top-5 Accuracy: 91.9300%, Time consumed:15.24s\n",
      "\n",
      "새로운 최고 top-1 정확도: 71.47%, top-5 정확도: 91.93%\n",
      "Accuracy improved (70.69% --> 71.47%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████████████▍                                                                          | 46/300 [2:21:15<12:55:42, 183.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47], Batch [50/196], Loss: 2.4097, LR: 0.010000\n",
      "Epoch [47], Batch [100/196], Loss: 1.4488, LR: 0.010000\n",
      "Epoch [47], Batch [150/196], Loss: 1.6313, LR: 0.010000\n",
      "Train set: Epoch: 47, Average loss:1.7979, LR: 0.010000 Top-1 Accuracy: 70.3960%, Top-5 Accuracy: 90.3600%, Time consumed:166.49s\n",
      "Test set: Epoch: 47, Average loss:1.6983, Top-1 Accuracy: 71.6300%, Top-5 Accuracy: 92.2700%, Time consumed:14.78s\n",
      "\n",
      "새로운 최고 top-1 정확도: 71.63%, top-5 정확도: 92.27%\n",
      "새로운 최고 top-5 정확도: 92.27%\n",
      "Accuracy improved (71.47% --> 71.63%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█████████████▊                                                                          | 47/300 [2:24:16<12:50:26, 182.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48], Batch [50/196], Loss: 1.3689, LR: 0.010000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.v2 as transforms_v2  # CutMix를 위한 v2 transforms 추가\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "from tools.tool import AccuracyEarlyStopping, WarmUpLR, SAM  # 수정된 AccuracyEarlyStopping 클래스 임포트\n",
    "from models.resnet import resnet18\n",
    "\n",
    "wandb.login(key=\"ef091b9abcea3186341ddf8995d62bde62d7469e\")\n",
    "wandb.init(project=\"PBL-2\", name=\"resnet18_cfc,lr=0.01,factor=0.5,smoothing,SGD_standard\")  \n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# WandB 설정\n",
    "config = {\n",
    "    \"model\": \"resnet18\",\n",
    "    \"batch_size\": 256,\n",
    "    \"num_epochs\": 300,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"optimizer\": \"SGD\",\n",
    "    \"seed\": 2025,\n",
    "    \"deterministic\": False,\n",
    "    \"patience\": 30,  # early stopping patience\n",
    "    \"max_epochs_wait\": float('inf'),  # 최대 30 에폭까지만 기다림\n",
    "    \"cutmix_alpha\": 1.0,  # CutMix 알파 파라미터 추가\n",
    "    \"cutmix_prob\": 0.5,   # CutMix 적용 확률 추가\n",
    "    \"crop_padding\": 4,    # RandomCrop 패딩 크기\n",
    "    \"crop_size\": 32,      # RandomCrop 크기 (CIFAR-100 이미지 크기는 32x32)\n",
    "    \"warmup_epochs\": 5,   # 웜업할 에폭 수 추가\n",
    "}\n",
    "wandb.config.update(config)\n",
    "\n",
    "# CIFAR-100 데이터셋 로드 - 기본 train/test 분할 사용\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(config[\"crop_size\"], padding=config[\"crop_padding\"]),  # 패딩 후 랜덤 크롭\n",
    "    transforms.RandomHorizontalFlip(),  # 수평 뒤집기\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR100(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR100(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "# DataLoader 생성\n",
    "trainloader = DataLoader(trainset, batch_size=config[\"batch_size\"], shuffle=True, num_workers=16,pin_memory=True)\n",
    "testloader = DataLoader(testset, batch_size=config[\"batch_size\"], shuffle=False, num_workers=16,pin_memory=True)\n",
    "\n",
    "print(f\"Train set size: {len(trainset)}\")\n",
    "print(f\"Test set size: {len(testset)}\")\n",
    "\n",
    "# CutMix 변환 정의\n",
    "cutmix = transforms_v2.CutMix(alpha=config[\"cutmix_alpha\"], num_classes=100)  # CIFAR-100은 100개 클래스\n",
    "\n",
    "def train(model, trainloader, criterion, optimizer, device, epoch, warmup_scheduler=None, warmup_epochs=5):\n",
    "    \"\"\"\n",
    "    학습 함수 (CutMix 적용)\n",
    "    \"\"\"\n",
    "    model.train()   # 모델을 학습 모드로 설정\n",
    "    start_time = time.time()  # 시간 측정 시작\n",
    "    running_loss = 0.0\n",
    "    correct_top1 = 0\n",
    "    correct_top5 = 0\n",
    "    total = 0\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(trainloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # CutMix 확률적 적용\n",
    "        if random.random() < config[\"cutmix_prob\"]:\n",
    "            inputs, labels = cutmix(inputs, labels)\n",
    "            # 이 경우 labels은 원-핫 인코딩 형태로 변환됨\n",
    "            use_cutmix = True\n",
    "        else:\n",
    "            use_cutmix = False\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # CutMix 적용 여부에 따라 손실 함수 선택\n",
    "        if use_cutmix:\n",
    "            # CutMix가 적용된 경우 (원-핫 인코딩된 레이블)\n",
    "            loss = torch.nn.functional.cross_entropy(outputs, labels)\n",
    "        else:\n",
    "            # 일반적인 경우 (정수 인덱스 레이블)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "        loss.backward()\n",
    "        optimizer.first_step(zero_grad=True)\n",
    "\n",
    "\n",
    "        \n",
    "        # 두 번째 forward-backward 패스\n",
    "        if use_cutmix:\n",
    "            # 새로운 forward 패스 필요\n",
    "            outputs = model(inputs)\n",
    "            loss = torch.nn.functional.cross_entropy(outputs, labels)\n",
    "        else:\n",
    "            # 새로운 forward 패스 필요\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.second_step(zero_grad=True)\n",
    "\n",
    "        # 학습률 스케줄러 업데이트 - warmup 스케줄러만 여기서 업데이트\n",
    "        if epoch < warmup_epochs and warmup_scheduler is not None:\n",
    "            warmup_scheduler.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # 정확도 계산 - CutMix 적용 여부에 따라 다르게 처리\n",
    "        if use_cutmix:\n",
    "            # 원-핫 인코딩된 레이블에서 argmax를 사용해 가장 큰 값의 인덱스 추출\n",
    "            _, label_idx = labels.max(1)\n",
    "        else:\n",
    "            # 정수 인덱스 레이블 그대로 사용\n",
    "            label_idx = labels\n",
    "        \n",
    "    \n",
    "        # top-1 정확도 계산\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += inputs.size(0)\n",
    "        correct_top1 += predicted.eq(label_idx).sum().item()\n",
    "        \n",
    "        # top-5 정확도 계산\n",
    "        _, top5_idx = outputs.topk(5, 1, largest=True, sorted=True)\n",
    "        correct_top5 += sum([1 for i in range(len(label_idx)) if label_idx[i] in top5_idx[i]])\n",
    "        \n",
    "        if (i + 1) % 50 == 0:  # 50 배치마다 출력\n",
    "            print(f'Epoch [{epoch+1}], Batch [{i+1}/{len(trainloader)}], Loss: {loss.item():.4f}, LR: {optimizer.param_groups[0][\"lr\"]:.6f}')\n",
    "    \n",
    "    epoch_loss = running_loss / len(trainloader)\n",
    "    accuracy_top1 = 100.0 * correct_top1 / total\n",
    "    accuracy_top5 = 100.0 * correct_top5 / total\n",
    "    \n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    # 학습 세트에 대한 성능 출력\n",
    "    print(f'Train set: Epoch: {epoch+1}, Average loss:{epoch_loss:.4f}, LR: {optimizer.param_groups[0][\"lr\"]:.6f} '\n",
    "          f'Top-1 Accuracy: {accuracy_top1:.4f}%, Top-5 Accuracy: {accuracy_top5:.4f}%, Time consumed:{train_time:.2f}s')\n",
    "    \n",
    "    return epoch_loss, accuracy_top1, accuracy_top5\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device, epoch, phase=\"test\"):\n",
    "    \"\"\"\n",
    "    평가 함수\n",
    "    \"\"\"\n",
    "    model.eval()  # 모델을 평가 모드로 설정\n",
    "    start_time = time.time()  # 시간 측정 시작\n",
    "    \n",
    "    eval_loss = 0.0\n",
    "    correct_top1 = 0\n",
    "    correct_top5 = 0\n",
    "    total = 0\n",
    "    \n",
    "    # 그래디언트 계산 비활성화\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # 순전파\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # 손실 계산\n",
    "            loss = criterion(outputs, labels)\n",
    "            eval_loss += loss.item()\n",
    "            \n",
    "            # top-1 정확도 계산\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct_top1 += (predicted == labels).sum().item()\n",
    "            \n",
    "            # top-5 정확도 계산\n",
    "            _, top5_idx = outputs.topk(5, 1, largest=True, sorted=True)\n",
    "            correct_top5 += top5_idx.eq(labels.view(-1, 1).expand_as(top5_idx)).sum().item()\n",
    "    \n",
    "    # 평균 손실 및 정확도 계산\n",
    "    eval_loss = eval_loss / len(dataloader)\n",
    "    accuracy_top1 = 100.0 * correct_top1 / total\n",
    "    accuracy_top5 = 100.0 * correct_top5 / total\n",
    "    \n",
    "    # 평가 시간 계산\n",
    "    eval_time = time.time() - start_time\n",
    "    \n",
    "    # 테스트 세트에 대한 성능 출력\n",
    "    print(f'{phase.capitalize()} set: Epoch: {epoch+1}, Average loss:{eval_loss:.4f}, '\n",
    "          f'Top-1 Accuracy: {accuracy_top1:.4f}%, Top-5 Accuracy: {accuracy_top5:.4f}%, Time consumed:{eval_time:.2f}s')\n",
    "    print()\n",
    "    \n",
    "    return eval_loss, accuracy_top1, accuracy_top5\n",
    "\n",
    "# 메인 학습 루프\n",
    "def main_training_loop(model, trainloader, testloader, criterion, optimizer, device, num_epochs, patience, max_epochs_wait, warmup_scheduler=None, main_scheduler=None, warmup_epochs=5):\n",
    "    \"\"\"\n",
    "    메인 학습 루프 (accuracy 기준 early stopping)\n",
    "    \"\"\"\n",
    "    # 정확도 기반 얼리 스토핑 사용\n",
    "    early_stopping = AccuracyEarlyStopping(patience=patience, verbose=True, path='checkpoint.pt', max_epochs=max_epochs_wait)\n",
    "    \n",
    "    best_test_acc_top1 = 0.0\n",
    "    best_test_acc_top5 = 0.0\n",
    "    \n",
    "    # 테스트 정확도 기록을 위한 리스트\n",
    "    test_acc_top1_history = []\n",
    "    \n",
    "    # tqdm을 사용한 진행 상황 표시\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        # 학습\n",
    "        train_loss, train_acc_top1, train_acc_top5 = train(\n",
    "            model, \n",
    "            trainloader, \n",
    "            criterion, \n",
    "            optimizer, \n",
    "            device, \n",
    "            epoch, \n",
    "            warmup_scheduler, \n",
    "            warmup_epochs\n",
    "        )\n",
    "        \n",
    "        # 테스트 데이터로 평가\n",
    "        test_loss, test_acc_top1, test_acc_top5 = evaluate(model, testloader, criterion, device, epoch, phase=\"test\")\n",
    "\n",
    "        # 웜업 이후 ReduceLROnPlateau 스케줄러 업데이트 \n",
    "        if epoch >= warmup_epochs and main_scheduler is not None:\n",
    "            main_scheduler.step(test_acc_top1)  # 테스트 정확도에 따라 학습률 업데이트       \n",
    "            \n",
    "        # 테스트 정확도 기록\n",
    "        test_acc_top1_history.append(test_acc_top1)\n",
    "        \n",
    "        # WandB에 로깅\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_accuracy_top1\": train_acc_top1,\n",
    "            \"train_accuracy_top5\": train_acc_top5,\n",
    "            \"test_loss\": test_loss,\n",
    "            \"test_accuracy_top1\": test_acc_top1,\n",
    "            \"test_accuracy_top5\": test_acc_top5\n",
    "        })\n",
    "            \n",
    "        # 최고 정확도 모델 저장 (top-1 기준)\n",
    "        if test_acc_top1 > best_test_acc_top1:\n",
    "            best_test_acc_top1 = test_acc_top1\n",
    "            best_test_acc_top5_at_best_top1 = test_acc_top5\n",
    "            print(f'새로운 최고 top-1 정확도: {best_test_acc_top1:.2f}%, top-5 정확도: {best_test_acc_top5_at_best_top1:.2f}%')\n",
    "            # 모델 저장\n",
    "            model_path = f'best_model_{wandb.run.name}.pth'\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            \n",
    "            # WandB에 모델 아티팩트 저장\n",
    "            wandb.save(model_path)\n",
    "        \n",
    "        # top-5 accuracy 기록 업데이트\n",
    "        if test_acc_top5 > best_test_acc_top5:\n",
    "            best_test_acc_top5 = test_acc_top5\n",
    "            print(f'새로운 최고 top-5 정확도: {best_test_acc_top5:.2f}%')\n",
    "\n",
    "        # Early stopping 체크 (test_acc_top1 기준)\n",
    "        early_stopping(test_acc_top1, model, epoch)\n",
    "        if early_stopping.early_stop:\n",
    "            print(f\"에폭 {epoch+1}에서 학습 조기 종료. 최고 성능 에폭: {early_stopping.best_epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    # 훈련 완료 후 최고 모델 로드\n",
    "    print(\"테스트 정확도 기준 최고 모델 로드 중...\")\n",
    "    model_path = f'best_model_{wandb.run.name}.pth'\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    # 최종 테스트 세트 평가\n",
    "    final_test_loss, final_test_acc_top1, final_test_acc_top5 = evaluate(model, testloader, criterion, device, num_epochs-1, phase=\"test\")\n",
    "    \n",
    "    print(f'완료! 최고 테스트 top-1 정확도: {best_test_acc_top1:.2f}%, 최고 테스트 top-5 정확도: {best_test_acc_top5:.2f}%')\n",
    "    print(f'최종 테스트 top-1 정확도: {final_test_acc_top1:.2f}%, 최종 테스트 top-5 정확도: {final_test_acc_top5:.2f}%')\n",
    "    \n",
    "    # WandB에 최종 결과 기록\n",
    "    wandb.run.summary[\"best_test_accuracy_top1\"] = best_test_acc_top1\n",
    "    wandb.run.summary[\"best_test_accuracy_top5\"] = best_test_acc_top5\n",
    "    wandb.run.summary[\"final_test_accuracy_top1\"] = final_test_acc_top1\n",
    "    wandb.run.summary[\"final_test_accuracy_top5\"] = final_test_acc_top5\n",
    "\n",
    "    # Early stopping 정보 저장\n",
    "    if early_stopping.early_stop:\n",
    "        wandb.run.summary[\"early_stopped\"] = True\n",
    "        wandb.run.summary[\"early_stopped_epoch\"] = epoch+1\n",
    "        wandb.run.summary[\"best_epoch\"] = early_stopping.best_epoch+1\n",
    "    else:\n",
    "        wandb.run.summary[\"early_stopped\"] = False\n",
    "\n",
    "\n",
    "# 디바이스 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 모델 초기화\n",
    "# 또는 매개변수 커스터마이징\n",
    "model = resnet18().to(device)\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)  # 기본 CrossEntropyLoss 사용 (라벨 스무딩 없음)\n",
    "base_optimizer = optim.SGD\n",
    "optimizer = SAM(model.parameters(), base_optimizer, lr=config[\"learning_rate\"], momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "# WarmUpLR 스케줄러 초기화\n",
    "# 웜업할 총 iteration 수 계산 (웜업 에폭 × 배치 수)\n",
    "warmup_steps = config[\"warmup_epochs\"] * len(trainloader)\n",
    "warmup_scheduler = WarmUpLR(optimizer, total_iters=warmup_steps)\n",
    "\n",
    "# 웜업 이후 사용할 스케줄러 설정 \n",
    "main_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    mode='max',           # 정확도를 모니터링하므로 'max' 모드 사용\n",
    "    factor=0.5,           # 학습률 감소 비율 (5배 감소)\n",
    "    patience=5,           # 몇 에폭 동안 개선이 없을 때 감소시킬지\n",
    "    verbose=True,         # 학습률 변경 시 출력\n",
    "    threshold=0.01,        # 개선으로 간주할 최소 변화량\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "# WandB에 모델 구조 기록\n",
    "wandb.watch(model, log=\"all\")\n",
    "\n",
    "# GPU 가속\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"{torch.cuda.device_count()}개의 GPU를 사용합니다.\")\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "# 훈련 시작 시간 기록\n",
    "start_time = time.time()\n",
    "\n",
    "# 메인 학습 루프 호출\n",
    "main_training_loop(\n",
    "    model=model,\n",
    "    trainloader=trainloader,\n",
    "    testloader=testloader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    num_epochs=config[\"num_epochs\"],\n",
    "    patience=config[\"patience\"],\n",
    "    max_epochs_wait=config[\"max_epochs_wait\"],\n",
    "    warmup_scheduler=warmup_scheduler,\n",
    "    main_scheduler=main_scheduler,\n",
    "    warmup_epochs=config[\"warmup_epochs\"]\n",
    ")\n",
    "\n",
    "# 훈련 종료 시간 기록 및 출력\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "wandb.log({\"total_training_time\": total_time})\n",
    "\n",
    "print(f\"전체 학습 시간: {total_time:.2f} 초\")\n",
    "\n",
    "# WandB 실행 종료\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815d90ff-2ed0-46e9-81aa-685289e8c626",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
