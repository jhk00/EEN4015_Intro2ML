{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "516f9d5f-6361-4b03-98ee-e1ba4de86b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/guswls/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/guswls/EEN4015_Intro2ML/pbl-2/wandb/run-20250428_094307-qmp4pxc4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/qmp4pxc4' target=\"_blank\">resnet18_cfc,lr=0.005,factor=0.5,SAM_SGD,PSKD,Nesterov=False</a></strong> to <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/qmp4pxc4' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/qmp4pxc4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Train set size: 50000\n",
      "Test set size: 10000\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2개의 GPU를 사용합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                       | 0/300 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Batch [50/391], Loss: 4.9841, LR: 0.000064\n",
      "Epoch [1], Batch [100/391], Loss: 4.8781, LR: 0.000128\n",
      "Epoch [1], Batch [150/391], Loss: 4.7926, LR: 0.000192\n",
      "Epoch [1], Batch [200/391], Loss: 4.7647, LR: 0.000256\n",
      "Epoch [1], Batch [250/391], Loss: 4.6973, LR: 0.000320\n",
      "Epoch [1], Batch [300/391], Loss: 4.7463, LR: 0.000384\n",
      "Epoch [1], Batch [350/391], Loss: 4.6145, LR: 0.000448\n",
      "Train set: Epoch: 1, Average loss:4.7872, LR: 0.000500 Top-1 Accuracy: 0.4140%, Top-5 Accuracy: 3.0600%, Time consumed:97.93s\n",
      "Test set: Epoch: 1, Average loss:4.2769, Top-1 Accuracy: 5.3800%, Top-5 Accuracy: 20.3400%, Time consumed:9.61s\n",
      "\n",
      "새로운 최고 top-1 정확도: 5.38%, top-5 정확도: 20.34%\n",
      "새로운 최고 top-5 정확도: 20.34%\n",
      "Accuracy improved (-inf% --> 5.38%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                                           | 1/300 [01:47<8:57:03, 107.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], Batch [50/391], Loss: 4.4090, LR: 0.000564\n",
      "Epoch [2], Batch [100/391], Loss: 4.4757, LR: 0.000628\n",
      "Epoch [2], Batch [150/391], Loss: 4.4261, LR: 0.000692\n",
      "Epoch [2], Batch [200/391], Loss: 4.5145, LR: 0.000756\n",
      "Epoch [2], Batch [250/391], Loss: 4.4606, LR: 0.000820\n",
      "Epoch [2], Batch [300/391], Loss: 4.4435, LR: 0.000884\n",
      "Epoch [2], Batch [350/391], Loss: 4.1525, LR: 0.000948\n",
      "Train set: Epoch: 2, Average loss:4.3887, LR: 0.001000 Top-1 Accuracy: 3.5200%, Top-5 Accuracy: 15.0420%, Time consumed:88.62s\n",
      "Test set: Epoch: 2, Average loss:3.9024, Top-1 Accuracy: 10.3500%, Top-5 Accuracy: 30.4600%, Time consumed:9.61s\n",
      "\n",
      "새로운 최고 top-1 정확도: 10.35%, top-5 정확도: 30.46%\n",
      "새로운 최고 top-5 정확도: 30.46%\n",
      "Accuracy improved (5.38% --> 10.35%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▌                                                                                           | 2/300 [03:26<8:28:04, 102.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3], Batch [50/391], Loss: 4.0975, LR: 0.001064\n",
      "Epoch [3], Batch [100/391], Loss: 4.0062, LR: 0.001128\n",
      "Epoch [3], Batch [150/391], Loss: 4.2694, LR: 0.001192\n",
      "Epoch [3], Batch [200/391], Loss: 3.9917, LR: 0.001256\n",
      "Epoch [3], Batch [250/391], Loss: 3.8835, LR: 0.001320\n",
      "Epoch [3], Batch [300/391], Loss: 3.9711, LR: 0.001384\n",
      "Epoch [3], Batch [350/391], Loss: 4.2466, LR: 0.001448\n",
      "Train set: Epoch: 3, Average loss:4.1331, LR: 0.001500 Top-1 Accuracy: 7.5720%, Top-5 Accuracy: 24.9180%, Time consumed:88.32s\n",
      "Test set: Epoch: 3, Average loss:3.6055, Top-1 Accuracy: 14.9500%, Top-5 Accuracy: 39.6200%, Time consumed:10.06s\n",
      "\n",
      "새로운 최고 top-1 정확도: 14.95%, top-5 정확도: 39.62%\n",
      "새로운 최고 top-5 정확도: 39.62%\n",
      "Accuracy improved (10.35% --> 14.95%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▉                                                                                           | 3/300 [05:04<8:18:01, 100.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4], Batch [50/391], Loss: 3.7567, LR: 0.001564\n",
      "Epoch [4], Batch [100/391], Loss: 3.7418, LR: 0.001628\n",
      "Epoch [4], Batch [150/391], Loss: 3.7180, LR: 0.001692\n",
      "Epoch [4], Batch [200/391], Loss: 3.7209, LR: 0.001756\n",
      "Epoch [4], Batch [250/391], Loss: 4.3997, LR: 0.001820\n",
      "Epoch [4], Batch [300/391], Loss: 3.8532, LR: 0.001884\n",
      "Epoch [4], Batch [350/391], Loss: 3.6864, LR: 0.001948\n",
      "Train set: Epoch: 4, Average loss:3.9515, LR: 0.002000 Top-1 Accuracy: 10.3800%, Top-5 Accuracy: 31.2380%, Time consumed:91.63s\n",
      "Test set: Epoch: 4, Average loss:3.3370, Top-1 Accuracy: 20.1900%, Top-5 Accuracy: 47.7000%, Time consumed:10.51s\n",
      "\n",
      "새로운 최고 top-1 정확도: 20.19%, top-5 정확도: 47.70%\n",
      "새로운 최고 top-5 정확도: 47.70%\n",
      "Accuracy improved (14.95% --> 20.19%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▏                                                                                          | 4/300 [06:47<8:19:53, 101.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5], Batch [50/391], Loss: 3.5232, LR: 0.002064\n",
      "Epoch [5], Batch [100/391], Loss: 3.4514, LR: 0.002128\n",
      "Epoch [5], Batch [150/391], Loss: 4.3166, LR: 0.002192\n",
      "Epoch [5], Batch [200/391], Loss: 3.8393, LR: 0.002256\n",
      "Epoch [5], Batch [250/391], Loss: 4.3358, LR: 0.002320\n",
      "Epoch [5], Batch [300/391], Loss: 3.9721, LR: 0.002384\n",
      "Epoch [5], Batch [350/391], Loss: 3.3670, LR: 0.002448\n",
      "Train set: Epoch: 5, Average loss:3.7586, LR: 0.002500 Top-1 Accuracy: 13.9400%, Top-5 Accuracy: 38.1240%, Time consumed:88.64s\n",
      "Test set: Epoch: 5, Average loss:3.0614, Top-1 Accuracy: 24.6400%, Top-5 Accuracy: 54.2400%, Time consumed:9.89s\n",
      "\n",
      "새로운 최고 top-1 정확도: 24.64%, top-5 정확도: 54.24%\n",
      "새로운 최고 top-5 정확도: 54.24%\n",
      "Accuracy improved (20.19% --> 24.64%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▌                                                                                          | 5/300 [08:26<8:13:42, 100.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6], Batch [50/391], Loss: 3.5331, LR: 0.002564\n",
      "Epoch [6], Batch [100/391], Loss: 3.2857, LR: 0.002628\n",
      "Epoch [6], Batch [150/391], Loss: 3.8268, LR: 0.002692\n",
      "Epoch [6], Batch [200/391], Loss: 3.2004, LR: 0.002756\n",
      "Epoch [6], Batch [250/391], Loss: 3.3955, LR: 0.002820\n",
      "Epoch [6], Batch [300/391], Loss: 4.0279, LR: 0.002884\n",
      "Epoch [6], Batch [350/391], Loss: 3.9807, LR: 0.002948\n",
      "Train set: Epoch: 6, Average loss:3.5744, LR: 0.003000 Top-1 Accuracy: 17.6360%, Top-5 Accuracy: 43.5940%, Time consumed:88.22s\n",
      "Test set: Epoch: 6, Average loss:2.7830, Top-1 Accuracy: 29.9700%, Top-5 Accuracy: 61.5800%, Time consumed:9.98s\n",
      "\n",
      "새로운 최고 top-1 정확도: 29.97%, top-5 정확도: 61.58%\n",
      "새로운 최고 top-5 정확도: 61.58%\n",
      "Accuracy improved (24.64% --> 29.97%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▊                                                                                           | 6/300 [10:04<8:08:44, 99.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7], Batch [50/391], Loss: 3.2715, LR: 0.003064\n",
      "Epoch [7], Batch [100/391], Loss: 3.2450, LR: 0.003128\n",
      "Epoch [7], Batch [150/391], Loss: 4.1590, LR: 0.003192\n",
      "Epoch [7], Batch [200/391], Loss: 4.1400, LR: 0.003256\n",
      "Epoch [7], Batch [250/391], Loss: 2.7780, LR: 0.003320\n",
      "Epoch [7], Batch [300/391], Loss: 3.6980, LR: 0.003384\n",
      "Epoch [7], Batch [350/391], Loss: 2.8369, LR: 0.003448\n",
      "Train set: Epoch: 7, Average loss:3.4069, LR: 0.003500 Top-1 Accuracy: 20.9100%, Top-5 Accuracy: 48.6740%, Time consumed:89.52s\n",
      "Test set: Epoch: 7, Average loss:2.5771, Top-1 Accuracy: 33.8000%, Top-5 Accuracy: 66.0000%, Time consumed:10.45s\n",
      "\n",
      "새로운 최고 top-1 정확도: 33.80%, top-5 정확도: 66.00%\n",
      "새로운 최고 top-5 정확도: 66.00%\n",
      "Accuracy improved (29.97% --> 33.80%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██▏                                                                                          | 7/300 [11:44<8:07:48, 99.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8], Batch [50/391], Loss: 4.1290, LR: 0.003564\n",
      "Epoch [8], Batch [100/391], Loss: 3.9856, LR: 0.003628\n",
      "Epoch [8], Batch [150/391], Loss: 3.9483, LR: 0.003692\n",
      "Epoch [8], Batch [200/391], Loss: 2.6350, LR: 0.003756\n",
      "Epoch [8], Batch [250/391], Loss: 2.9117, LR: 0.003820\n",
      "Epoch [8], Batch [300/391], Loss: 4.2636, LR: 0.003884\n",
      "Epoch [8], Batch [350/391], Loss: 4.1528, LR: 0.003948\n",
      "Train set: Epoch: 8, Average loss:3.2924, LR: 0.004000 Top-1 Accuracy: 23.3760%, Top-5 Accuracy: 52.2480%, Time consumed:88.54s\n",
      "Test set: Epoch: 8, Average loss:2.5250, Top-1 Accuracy: 36.0000%, Top-5 Accuracy: 67.0000%, Time consumed:10.00s\n",
      "\n",
      "새로운 최고 top-1 정확도: 36.00%, top-5 정확도: 67.00%\n",
      "새로운 최고 top-5 정확도: 67.00%\n",
      "Accuracy improved (33.80% --> 36.00%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▍                                                                                          | 8/300 [13:23<8:04:26, 99.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9], Batch [50/391], Loss: 2.4473, LR: 0.004064\n",
      "Epoch [9], Batch [100/391], Loss: 2.4675, LR: 0.004128\n",
      "Epoch [9], Batch [150/391], Loss: 3.6678, LR: 0.004192\n",
      "Epoch [9], Batch [200/391], Loss: 3.8519, LR: 0.004256\n",
      "Epoch [9], Batch [250/391], Loss: 2.5438, LR: 0.004320\n",
      "Epoch [9], Batch [300/391], Loss: 2.8565, LR: 0.004384\n",
      "Epoch [9], Batch [350/391], Loss: 2.5511, LR: 0.004448\n",
      "Train set: Epoch: 9, Average loss:3.0936, LR: 0.004500 Top-1 Accuracy: 27.7080%, Top-5 Accuracy: 57.6320%, Time consumed:88.47s\n",
      "Test set: Epoch: 9, Average loss:2.2094, Top-1 Accuracy: 41.4800%, Top-5 Accuracy: 74.1400%, Time consumed:9.58s\n",
      "\n",
      "새로운 최고 top-1 정확도: 41.48%, top-5 정확도: 74.14%\n",
      "새로운 최고 top-5 정확도: 74.14%\n",
      "Accuracy improved (36.00% --> 41.48%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▊                                                                                          | 9/300 [15:01<8:00:54, 99.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10], Batch [50/391], Loss: 4.0279, LR: 0.004564\n",
      "Epoch [10], Batch [100/391], Loss: 3.5507, LR: 0.004628\n",
      "Epoch [10], Batch [150/391], Loss: 3.4905, LR: 0.004692\n",
      "Epoch [10], Batch [200/391], Loss: 2.4074, LR: 0.004756\n",
      "Epoch [10], Batch [250/391], Loss: 3.5186, LR: 0.004820\n",
      "Epoch [10], Batch [300/391], Loss: 2.3246, LR: 0.004884\n",
      "Epoch [10], Batch [350/391], Loss: 2.8741, LR: 0.004948\n",
      "Train set: Epoch: 10, Average loss:2.9671, LR: 0.005000 Top-1 Accuracy: 30.4620%, Top-5 Accuracy: 60.9860%, Time consumed:88.00s\n",
      "Test set: Epoch: 10, Average loss:2.1232, Top-1 Accuracy: 43.6200%, Top-5 Accuracy: 75.3900%, Time consumed:11.19s\n",
      "\n",
      "새로운 최고 top-1 정확도: 43.62%, top-5 정확도: 75.39%\n",
      "새로운 최고 top-5 정확도: 75.39%\n",
      "Accuracy improved (41.48% --> 43.62%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|███                                                                                         | 10/300 [16:41<7:59:38, 99.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11], Batch [50/391], Loss: 2.3117, LR: 0.005000\n",
      "Epoch [11], Batch [100/391], Loss: 3.8350, LR: 0.005000\n",
      "Epoch [11], Batch [150/391], Loss: 2.9102, LR: 0.005000\n",
      "Epoch [11], Batch [200/391], Loss: 3.0734, LR: 0.005000\n",
      "Epoch [11], Batch [250/391], Loss: 3.7073, LR: 0.005000\n",
      "Epoch [11], Batch [300/391], Loss: 3.5252, LR: 0.005000\n",
      "Epoch [11], Batch [350/391], Loss: 2.3787, LR: 0.005000\n",
      "Train set: Epoch: 11, Average loss:2.8918, LR: 0.005000 Top-1 Accuracy: 32.7980%, Top-5 Accuracy: 63.3840%, Time consumed:89.11s\n",
      "Test set: Epoch: 11, Average loss:1.9331, Top-1 Accuracy: 47.5600%, Top-5 Accuracy: 79.2300%, Time consumed:9.73s\n",
      "\n",
      "새로운 최고 top-1 정확도: 47.56%, top-5 정확도: 79.23%\n",
      "새로운 최고 top-5 정확도: 79.23%\n",
      "Accuracy improved (43.62% --> 47.56%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▎                                                                                        | 11/300 [18:20<7:57:45, 99.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12], Batch [50/391], Loss: 2.0144, LR: 0.005000\n",
      "Epoch [12], Batch [100/391], Loss: 1.8822, LR: 0.005000\n",
      "Epoch [12], Batch [150/391], Loss: 3.1046, LR: 0.005000\n",
      "Epoch [12], Batch [200/391], Loss: 1.9461, LR: 0.005000\n",
      "Epoch [12], Batch [250/391], Loss: 3.1428, LR: 0.005000\n",
      "Epoch [12], Batch [300/391], Loss: 2.0900, LR: 0.005000\n",
      "Epoch [12], Batch [350/391], Loss: 2.3456, LR: 0.005000\n",
      "Train set: Epoch: 12, Average loss:2.7804, LR: 0.005000 Top-1 Accuracy: 35.4660%, Top-5 Accuracy: 66.0000%, Time consumed:88.50s\n",
      "Test set: Epoch: 12, Average loss:1.8600, Top-1 Accuracy: 49.7700%, Top-5 Accuracy: 80.0600%, Time consumed:9.47s\n",
      "\n",
      "새로운 최고 top-1 정확도: 49.77%, top-5 정확도: 80.06%\n",
      "새로운 최고 top-5 정확도: 80.06%\n",
      "Accuracy improved (47.56% --> 49.77%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▋                                                                                        | 12/300 [19:58<7:54:38, 98.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13], Batch [50/391], Loss: 2.2516, LR: 0.005000\n",
      "Epoch [13], Batch [100/391], Loss: 1.9506, LR: 0.005000\n",
      "Epoch [13], Batch [150/391], Loss: 3.4137, LR: 0.005000\n",
      "Epoch [13], Batch [200/391], Loss: 1.8333, LR: 0.005000\n",
      "Epoch [13], Batch [250/391], Loss: 3.5963, LR: 0.005000\n",
      "Epoch [13], Batch [300/391], Loss: 1.8046, LR: 0.005000\n",
      "Epoch [13], Batch [350/391], Loss: 1.8695, LR: 0.005000\n",
      "Train set: Epoch: 13, Average loss:2.6118, LR: 0.005000 Top-1 Accuracy: 38.8680%, Top-5 Accuracy: 69.3360%, Time consumed:88.45s\n",
      "Test set: Epoch: 13, Average loss:1.8054, Top-1 Accuracy: 51.0800%, Top-5 Accuracy: 81.1200%, Time consumed:9.71s\n",
      "\n",
      "새로운 최고 top-1 정확도: 51.08%, top-5 정확도: 81.12%\n",
      "새로운 최고 top-5 정확도: 81.12%\n",
      "Accuracy improved (49.77% --> 51.08%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▉                                                                                        | 13/300 [21:36<7:52:16, 98.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14], Batch [50/391], Loss: 3.3791, LR: 0.005000\n",
      "Epoch [14], Batch [100/391], Loss: 3.7049, LR: 0.005000\n",
      "Epoch [14], Batch [150/391], Loss: 2.0236, LR: 0.005000\n",
      "Epoch [14], Batch [200/391], Loss: 2.3825, LR: 0.005000\n",
      "Epoch [14], Batch [250/391], Loss: 1.8789, LR: 0.005000\n",
      "Epoch [14], Batch [300/391], Loss: 1.8078, LR: 0.005000\n",
      "Epoch [14], Batch [350/391], Loss: 2.1530, LR: 0.005000\n",
      "Train set: Epoch: 14, Average loss:2.5006, LR: 0.005000 Top-1 Accuracy: 41.7020%, Top-5 Accuracy: 72.0100%, Time consumed:88.18s\n",
      "Test set: Epoch: 14, Average loss:1.6697, Top-1 Accuracy: 54.3300%, Top-5 Accuracy: 83.0900%, Time consumed:9.70s\n",
      "\n",
      "새로운 최고 top-1 정확도: 54.33%, top-5 정확도: 83.09%\n",
      "새로운 최고 top-5 정확도: 83.09%\n",
      "Accuracy improved (51.08% --> 54.33%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▎                                                                                       | 14/300 [23:14<7:49:44, 98.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15], Batch [50/391], Loss: 1.6699, LR: 0.005000\n",
      "Epoch [15], Batch [100/391], Loss: 1.6309, LR: 0.005000\n",
      "Epoch [15], Batch [150/391], Loss: 1.6944, LR: 0.005000\n",
      "Epoch [15], Batch [200/391], Loss: 2.6390, LR: 0.005000\n",
      "Epoch [15], Batch [250/391], Loss: 1.8607, LR: 0.005000\n",
      "Epoch [15], Batch [300/391], Loss: 1.9456, LR: 0.005000\n",
      "Epoch [15], Batch [350/391], Loss: 3.1134, LR: 0.005000\n",
      "Train set: Epoch: 15, Average loss:2.4637, LR: 0.005000 Top-1 Accuracy: 43.4840%, Top-5 Accuracy: 73.5660%, Time consumed:88.70s\n",
      "Test set: Epoch: 15, Average loss:1.6291, Top-1 Accuracy: 55.1100%, Top-5 Accuracy: 83.8700%, Time consumed:9.83s\n",
      "\n",
      "새로운 최고 top-1 정확도: 55.11%, top-5 정확도: 83.87%\n",
      "새로운 최고 top-5 정확도: 83.87%\n",
      "Accuracy improved (54.33% --> 55.11%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▌                                                                                       | 15/300 [24:53<7:48:24, 98.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16], Batch [50/391], Loss: 2.4026, LR: 0.005000\n",
      "Epoch [16], Batch [100/391], Loss: 3.1648, LR: 0.005000\n",
      "Epoch [16], Batch [150/391], Loss: 1.8172, LR: 0.005000\n",
      "Epoch [16], Batch [200/391], Loss: 3.2186, LR: 0.005000\n",
      "Epoch [16], Batch [250/391], Loss: 2.8162, LR: 0.005000\n",
      "Epoch [16], Batch [300/391], Loss: 1.9897, LR: 0.005000\n",
      "Epoch [16], Batch [350/391], Loss: 2.7830, LR: 0.005000\n",
      "Train set: Epoch: 16, Average loss:2.4845, LR: 0.005000 Top-1 Accuracy: 43.8520%, Top-5 Accuracy: 73.3340%, Time consumed:88.45s\n",
      "Test set: Epoch: 16, Average loss:1.5370, Top-1 Accuracy: 57.5000%, Top-5 Accuracy: 85.3200%, Time consumed:9.55s\n",
      "\n",
      "새로운 최고 top-1 정확도: 57.50%, top-5 정확도: 85.32%\n",
      "새로운 최고 top-5 정확도: 85.32%\n",
      "Accuracy improved (55.11% --> 57.50%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▉                                                                                       | 16/300 [26:31<7:46:13, 98.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17], Batch [50/391], Loss: 1.6198, LR: 0.005000\n",
      "Epoch [17], Batch [100/391], Loss: 1.9242, LR: 0.005000\n",
      "Epoch [17], Batch [150/391], Loss: 1.8508, LR: 0.005000\n",
      "Epoch [17], Batch [200/391], Loss: 1.8277, LR: 0.005000\n",
      "Epoch [17], Batch [250/391], Loss: 3.1782, LR: 0.005000\n",
      "Epoch [17], Batch [300/391], Loss: 1.7352, LR: 0.005000\n",
      "Epoch [17], Batch [350/391], Loss: 1.5974, LR: 0.005000\n",
      "Train set: Epoch: 17, Average loss:2.3404, LR: 0.005000 Top-1 Accuracy: 45.8700%, Top-5 Accuracy: 75.2880%, Time consumed:87.71s\n",
      "Test set: Epoch: 17, Average loss:1.4756, Top-1 Accuracy: 59.0800%, Top-5 Accuracy: 86.2200%, Time consumed:10.67s\n",
      "\n",
      "새로운 최고 top-1 정확도: 59.08%, top-5 정확도: 86.22%\n",
      "새로운 최고 top-5 정확도: 86.22%\n",
      "Accuracy improved (57.50% --> 59.08%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████▏                                                                                      | 17/300 [28:10<7:44:46, 98.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18], Batch [50/391], Loss: 3.4696, LR: 0.005000\n",
      "Epoch [18], Batch [100/391], Loss: 3.3266, LR: 0.005000\n",
      "Epoch [18], Batch [150/391], Loss: 1.7883, LR: 0.005000\n",
      "Epoch [18], Batch [200/391], Loss: 2.9952, LR: 0.005000\n",
      "Epoch [18], Batch [250/391], Loss: 3.1996, LR: 0.005000\n",
      "Epoch [18], Batch [300/391], Loss: 1.6657, LR: 0.005000\n",
      "Epoch [18], Batch [350/391], Loss: 1.4917, LR: 0.005000\n",
      "Train set: Epoch: 18, Average loss:2.2963, LR: 0.005000 Top-1 Accuracy: 47.4500%, Top-5 Accuracy: 76.7520%, Time consumed:88.35s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████▌                                                                                      | 18/300 [29:49<7:43:49, 98.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 18, Average loss:1.4867, Top-1 Accuracy: 58.8600%, Top-5 Accuracy: 86.1900%, Time consumed:10.66s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [19], Batch [50/391], Loss: 3.6255, LR: 0.005000\n",
      "Epoch [19], Batch [100/391], Loss: 2.5262, LR: 0.005000\n",
      "Epoch [19], Batch [150/391], Loss: 2.3289, LR: 0.005000\n",
      "Epoch [19], Batch [200/391], Loss: 1.5136, LR: 0.005000\n",
      "Epoch [19], Batch [250/391], Loss: 1.6041, LR: 0.005000\n",
      "Epoch [19], Batch [300/391], Loss: 1.6856, LR: 0.005000\n",
      "Epoch [19], Batch [350/391], Loss: 3.9033, LR: 0.005000\n",
      "Train set: Epoch: 19, Average loss:2.2101, LR: 0.005000 Top-1 Accuracy: 49.0740%, Top-5 Accuracy: 77.8180%, Time consumed:89.05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████▊                                                                                      | 19/300 [31:28<7:42:21, 98.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 19, Average loss:1.4762, Top-1 Accuracy: 58.9500%, Top-5 Accuracy: 86.1400%, Time consumed:9.76s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [20], Batch [50/391], Loss: 1.4418, LR: 0.005000\n",
      "Epoch [20], Batch [100/391], Loss: 1.4309, LR: 0.005000\n",
      "Epoch [20], Batch [150/391], Loss: 1.6487, LR: 0.005000\n",
      "Epoch [20], Batch [200/391], Loss: 1.4376, LR: 0.005000\n",
      "Epoch [20], Batch [250/391], Loss: 1.3766, LR: 0.005000\n",
      "Epoch [20], Batch [300/391], Loss: 1.3441, LR: 0.005000\n",
      "Epoch [20], Batch [350/391], Loss: 2.0048, LR: 0.005000\n",
      "Train set: Epoch: 20, Average loss:2.2078, LR: 0.005000 Top-1 Accuracy: 49.5840%, Top-5 Accuracy: 77.7160%, Time consumed:88.38s\n",
      "Test set: Epoch: 20, Average loss:1.3895, Top-1 Accuracy: 61.0900%, Top-5 Accuracy: 87.8600%, Time consumed:9.62s\n",
      "\n",
      "새로운 최고 top-1 정확도: 61.09%, top-5 정확도: 87.86%\n",
      "새로운 최고 top-5 정확도: 87.86%\n",
      "Accuracy improved (59.08% --> 61.09%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████▏                                                                                     | 20/300 [33:06<7:40:02, 98.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21], Batch [50/391], Loss: 1.5082, LR: 0.005000\n",
      "Epoch [21], Batch [100/391], Loss: 1.6141, LR: 0.005000\n",
      "Epoch [21], Batch [150/391], Loss: 3.5873, LR: 0.005000\n",
      "Epoch [21], Batch [200/391], Loss: 3.2034, LR: 0.005000\n",
      "Epoch [21], Batch [250/391], Loss: 1.7333, LR: 0.005000\n",
      "Epoch [21], Batch [300/391], Loss: 2.8674, LR: 0.005000\n",
      "Epoch [21], Batch [350/391], Loss: 2.0307, LR: 0.005000\n",
      "Train set: Epoch: 21, Average loss:2.1304, LR: 0.005000 Top-1 Accuracy: 51.7560%, Top-5 Accuracy: 79.3240%, Time consumed:89.36s\n",
      "Test set: Epoch: 21, Average loss:1.3320, Top-1 Accuracy: 62.5100%, Top-5 Accuracy: 88.4000%, Time consumed:10.03s\n",
      "\n",
      "새로운 최고 top-1 정확도: 62.51%, top-5 정확도: 88.40%\n",
      "새로운 최고 top-5 정확도: 88.40%\n",
      "Accuracy improved (61.09% --> 62.51%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████▍                                                                                     | 21/300 [34:46<7:39:51, 98.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22], Batch [50/391], Loss: 2.2387, LR: 0.005000\n",
      "Epoch [22], Batch [100/391], Loss: 3.4170, LR: 0.005000\n",
      "Epoch [22], Batch [150/391], Loss: 1.4927, LR: 0.005000\n",
      "Epoch [22], Batch [200/391], Loss: 1.5200, LR: 0.005000\n",
      "Epoch [22], Batch [250/391], Loss: 1.4007, LR: 0.005000\n",
      "Epoch [22], Batch [300/391], Loss: 3.1340, LR: 0.005000\n",
      "Epoch [22], Batch [350/391], Loss: 1.3100, LR: 0.005000\n",
      "Train set: Epoch: 22, Average loss:2.0758, LR: 0.005000 Top-1 Accuracy: 53.6240%, Top-5 Accuracy: 80.9900%, Time consumed:89.10s\n",
      "Test set: Epoch: 22, Average loss:1.3046, Top-1 Accuracy: 63.5000%, Top-5 Accuracy: 88.8100%, Time consumed:11.08s\n",
      "\n",
      "새로운 최고 top-1 정확도: 63.50%, top-5 정확도: 88.81%\n",
      "새로운 최고 top-5 정확도: 88.81%\n",
      "Accuracy improved (62.51% --> 63.50%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████▋                                                                                     | 22/300 [36:26<7:40:21, 99.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23], Batch [50/391], Loss: 3.2886, LR: 0.005000\n",
      "Epoch [23], Batch [100/391], Loss: 3.4439, LR: 0.005000\n",
      "Epoch [23], Batch [150/391], Loss: 3.2690, LR: 0.005000\n",
      "Epoch [23], Batch [200/391], Loss: 1.3734, LR: 0.005000\n",
      "Epoch [23], Batch [250/391], Loss: 1.9904, LR: 0.005000\n",
      "Epoch [23], Batch [300/391], Loss: 1.2982, LR: 0.005000\n",
      "Epoch [23], Batch [350/391], Loss: 3.2244, LR: 0.005000\n",
      "Train set: Epoch: 23, Average loss:2.1630, LR: 0.005000 Top-1 Accuracy: 51.6800%, Top-5 Accuracy: 79.3380%, Time consumed:89.05s\n",
      "Test set: Epoch: 23, Average loss:1.2810, Top-1 Accuracy: 64.1200%, Top-5 Accuracy: 89.4200%, Time consumed:9.66s\n",
      "\n",
      "새로운 최고 top-1 정확도: 64.12%, top-5 정확도: 89.42%\n",
      "새로운 최고 top-5 정확도: 89.42%\n",
      "Accuracy improved (63.50% --> 64.12%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███████                                                                                     | 23/300 [38:05<7:38:10, 99.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24], Batch [50/391], Loss: 1.2322, LR: 0.005000\n",
      "Epoch [24], Batch [100/391], Loss: 1.2255, LR: 0.005000\n",
      "Epoch [24], Batch [150/391], Loss: 1.2204, LR: 0.005000\n",
      "Epoch [24], Batch [200/391], Loss: 3.8813, LR: 0.005000\n",
      "Epoch [24], Batch [250/391], Loss: 3.2014, LR: 0.005000\n",
      "Epoch [24], Batch [300/391], Loss: 2.9834, LR: 0.005000\n",
      "Epoch [24], Batch [350/391], Loss: 1.3371, LR: 0.005000\n",
      "Train set: Epoch: 24, Average loss:2.0392, LR: 0.005000 Top-1 Accuracy: 54.2280%, Top-5 Accuracy: 81.5540%, Time consumed:88.54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███████▎                                                                                    | 24/300 [39:43<7:35:00, 98.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 24, Average loss:1.2772, Top-1 Accuracy: 63.9000%, Top-5 Accuracy: 89.3000%, Time consumed:9.61s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [25], Batch [50/391], Loss: 1.2434, LR: 0.005000\n",
      "Epoch [25], Batch [100/391], Loss: 1.1332, LR: 0.005000\n",
      "Epoch [25], Batch [150/391], Loss: 1.2760, LR: 0.005000\n",
      "Epoch [25], Batch [200/391], Loss: 1.2368, LR: 0.005000\n",
      "Epoch [25], Batch [250/391], Loss: 1.5270, LR: 0.005000\n",
      "Epoch [25], Batch [300/391], Loss: 1.2233, LR: 0.005000\n",
      "Epoch [25], Batch [350/391], Loss: 1.2335, LR: 0.005000\n",
      "Train set: Epoch: 25, Average loss:2.0572, LR: 0.005000 Top-1 Accuracy: 54.5420%, Top-5 Accuracy: 81.2680%, Time consumed:88.88s\n",
      "Test set: Epoch: 25, Average loss:1.2507, Top-1 Accuracy: 64.7200%, Top-5 Accuracy: 89.6900%, Time consumed:9.49s\n",
      "\n",
      "새로운 최고 top-1 정확도: 64.72%, top-5 정확도: 89.69%\n",
      "새로운 최고 top-5 정확도: 89.69%\n",
      "Accuracy improved (64.12% --> 64.72%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███████▋                                                                                    | 25/300 [41:22<7:32:55, 98.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26], Batch [50/391], Loss: 3.3507, LR: 0.005000\n",
      "Epoch [26], Batch [100/391], Loss: 1.1831, LR: 0.005000\n",
      "Epoch [26], Batch [150/391], Loss: 3.2594, LR: 0.005000\n",
      "Epoch [26], Batch [200/391], Loss: 2.9448, LR: 0.005000\n",
      "Epoch [26], Batch [250/391], Loss: 1.5708, LR: 0.005000\n",
      "Epoch [26], Batch [300/391], Loss: 2.7126, LR: 0.005000\n",
      "Epoch [26], Batch [350/391], Loss: 3.4049, LR: 0.005000\n",
      "Train set: Epoch: 26, Average loss:2.0005, LR: 0.005000 Top-1 Accuracy: 55.7600%, Top-5 Accuracy: 82.1460%, Time consumed:89.15s\n",
      "Test set: Epoch: 26, Average loss:1.2407, Top-1 Accuracy: 65.1400%, Top-5 Accuracy: 89.9900%, Time consumed:9.57s\n",
      "\n",
      "새로운 최고 top-1 정확도: 65.14%, top-5 정확도: 89.99%\n",
      "새로운 최고 top-5 정확도: 89.99%\n",
      "Accuracy improved (64.72% --> 65.14%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███████▉                                                                                    | 26/300 [43:01<7:31:30, 98.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27], Batch [50/391], Loss: 2.4417, LR: 0.002500\n",
      "Epoch [27], Batch [100/391], Loss: 1.1312, LR: 0.002500\n",
      "Epoch [27], Batch [150/391], Loss: 2.0816, LR: 0.002500\n",
      "Epoch [27], Batch [200/391], Loss: 3.3309, LR: 0.002500\n",
      "Epoch [27], Batch [250/391], Loss: 1.0575, LR: 0.002500\n",
      "Epoch [27], Batch [300/391], Loss: 2.6975, LR: 0.002500\n",
      "Epoch [27], Batch [350/391], Loss: 1.1127, LR: 0.002500\n",
      "Train set: Epoch: 27, Average loss:1.8469, LR: 0.002500 Top-1 Accuracy: 59.0440%, Top-5 Accuracy: 84.6580%, Time consumed:89.17s\n",
      "Test set: Epoch: 27, Average loss:1.1238, Top-1 Accuracy: 68.2800%, Top-5 Accuracy: 91.2500%, Time consumed:9.59s\n",
      "\n",
      "새로운 최고 top-1 정확도: 68.28%, top-5 정확도: 91.25%\n",
      "새로운 최고 top-5 정확도: 91.25%\n",
      "Accuracy improved (65.14% --> 68.28%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|████████▎                                                                                   | 27/300 [44:40<7:30:03, 98.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28], Batch [50/391], Loss: 3.0497, LR: 0.002500\n",
      "Epoch [28], Batch [100/391], Loss: 0.9903, LR: 0.002500\n",
      "Epoch [28], Batch [150/391], Loss: 1.6507, LR: 0.002500\n",
      "Epoch [28], Batch [200/391], Loss: 1.0794, LR: 0.002500\n",
      "Epoch [28], Batch [250/391], Loss: 1.0856, LR: 0.002500\n",
      "Epoch [28], Batch [300/391], Loss: 2.4266, LR: 0.002500\n",
      "Epoch [28], Batch [350/391], Loss: 1.1535, LR: 0.002500\n",
      "Train set: Epoch: 28, Average loss:1.8866, LR: 0.002500 Top-1 Accuracy: 58.9700%, Top-5 Accuracy: 84.3340%, Time consumed:87.74s\n",
      "Test set: Epoch: 28, Average loss:1.0963, Top-1 Accuracy: 69.1400%, Top-5 Accuracy: 91.6200%, Time consumed:10.17s\n",
      "\n",
      "새로운 최고 top-1 정확도: 69.14%, top-5 정확도: 91.62%\n",
      "새로운 최고 top-5 정확도: 91.62%\n",
      "Accuracy improved (68.28% --> 69.14%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|████████▌                                                                                   | 28/300 [46:18<7:27:21, 98.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29], Batch [50/391], Loss: 1.1578, LR: 0.002500\n",
      "Epoch [29], Batch [100/391], Loss: 1.0118, LR: 0.002500\n",
      "Epoch [29], Batch [150/391], Loss: 1.6954, LR: 0.002500\n",
      "Epoch [29], Batch [200/391], Loss: 2.2318, LR: 0.002500\n",
      "Epoch [29], Batch [250/391], Loss: 1.0011, LR: 0.002500\n",
      "Epoch [29], Batch [300/391], Loss: 3.3583, LR: 0.002500\n",
      "Epoch [29], Batch [350/391], Loss: 1.0382, LR: 0.002500\n",
      "Train set: Epoch: 29, Average loss:1.8418, LR: 0.002500 Top-1 Accuracy: 59.8600%, Top-5 Accuracy: 84.4620%, Time consumed:87.99s\n",
      "Test set: Epoch: 29, Average loss:1.0948, Top-1 Accuracy: 69.2200%, Top-5 Accuracy: 91.4500%, Time consumed:11.38s\n",
      "\n",
      "새로운 최고 top-1 정확도: 69.22%, top-5 정확도: 91.45%\n",
      "Accuracy improved (69.14% --> 69.22%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▉                                                                                   | 29/300 [47:58<7:26:57, 98.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30], Batch [50/391], Loss: 0.9975, LR: 0.002500\n",
      "Epoch [30], Batch [100/391], Loss: 3.3450, LR: 0.002500\n",
      "Epoch [30], Batch [150/391], Loss: 0.9811, LR: 0.002500\n",
      "Epoch [30], Batch [200/391], Loss: 1.0115, LR: 0.002500\n",
      "Epoch [30], Batch [250/391], Loss: 1.1351, LR: 0.002500\n",
      "Epoch [30], Batch [300/391], Loss: 2.3745, LR: 0.002500\n",
      "Epoch [30], Batch [350/391], Loss: 3.0490, LR: 0.002500\n",
      "Train set: Epoch: 30, Average loss:1.8852, LR: 0.002500 Top-1 Accuracy: 59.3860%, Top-5 Accuracy: 84.1140%, Time consumed:88.17s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█████████▏                                                                                  | 30/300 [49:35<7:23:38, 98.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 30, Average loss:1.0958, Top-1 Accuracy: 69.0400%, Top-5 Accuracy: 91.9000%, Time consumed:9.55s\n",
      "\n",
      "새로운 최고 top-5 정확도: 91.90%\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [31], Batch [50/391], Loss: 1.0097, LR: 0.002500\n",
      "Epoch [31], Batch [100/391], Loss: 1.1226, LR: 0.002500\n",
      "Epoch [31], Batch [150/391], Loss: 2.2630, LR: 0.002500\n",
      "Epoch [31], Batch [200/391], Loss: 0.8900, LR: 0.002500\n",
      "Epoch [31], Batch [250/391], Loss: 0.8745, LR: 0.002500\n",
      "Epoch [31], Batch [300/391], Loss: 1.2484, LR: 0.002500\n",
      "Epoch [31], Batch [350/391], Loss: 1.0266, LR: 0.002500\n",
      "Train set: Epoch: 31, Average loss:1.8651, LR: 0.002500 Top-1 Accuracy: 59.2220%, Top-5 Accuracy: 84.2920%, Time consumed:92.37s\n",
      "Test set: Epoch: 31, Average loss:1.0983, Top-1 Accuracy: 69.4100%, Top-5 Accuracy: 91.4700%, Time consumed:9.64s\n",
      "\n",
      "새로운 최고 top-1 정확도: 69.41%, top-5 정확도: 91.47%\n",
      "Accuracy improved (69.22% --> 69.41%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█████████▌                                                                                  | 31/300 [51:18<7:26:55, 99.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32], Batch [50/391], Loss: 3.2248, LR: 0.002500\n",
      "Epoch [32], Batch [100/391], Loss: 3.3852, LR: 0.002500\n",
      "Epoch [32], Batch [150/391], Loss: 0.8970, LR: 0.002500\n",
      "Epoch [32], Batch [200/391], Loss: 1.0949, LR: 0.002500\n",
      "Epoch [32], Batch [250/391], Loss: 1.4564, LR: 0.002500\n",
      "Epoch [32], Batch [300/391], Loss: 1.2411, LR: 0.002500\n",
      "Epoch [32], Batch [350/391], Loss: 3.4706, LR: 0.002500\n",
      "Train set: Epoch: 32, Average loss:1.7531, LR: 0.002500 Top-1 Accuracy: 61.6220%, Top-5 Accuracy: 85.7480%, Time consumed:88.94s\n",
      "Test set: Epoch: 32, Average loss:1.0659, Top-1 Accuracy: 69.6900%, Top-5 Accuracy: 91.7900%, Time consumed:10.49s\n",
      "\n",
      "새로운 최고 top-1 정확도: 69.69%, top-5 정확도: 91.79%\n",
      "Accuracy improved (69.41% --> 69.69%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█████████▊                                                                                  | 32/300 [52:57<7:25:14, 99.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33], Batch [50/391], Loss: 1.4979, LR: 0.002500\n",
      "Epoch [33], Batch [100/391], Loss: 1.0297, LR: 0.002500\n",
      "Epoch [33], Batch [150/391], Loss: 2.4105, LR: 0.002500\n",
      "Epoch [33], Batch [200/391], Loss: 0.9963, LR: 0.002500\n",
      "Epoch [33], Batch [250/391], Loss: 0.9904, LR: 0.002500\n",
      "Epoch [33], Batch [300/391], Loss: 2.6646, LR: 0.002500\n",
      "Epoch [33], Batch [350/391], Loss: 0.9498, LR: 0.002500\n",
      "Train set: Epoch: 33, Average loss:1.7212, LR: 0.002500 Top-1 Accuracy: 62.3700%, Top-5 Accuracy: 86.0840%, Time consumed:88.70s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|██████████                                                                                  | 33/300 [54:37<7:22:56, 99.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 33, Average loss:1.0724, Top-1 Accuracy: 69.4400%, Top-5 Accuracy: 91.8100%, Time consumed:10.50s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [34], Batch [50/391], Loss: 1.5153, LR: 0.001250\n",
      "Epoch [34], Batch [100/391], Loss: 0.8078, LR: 0.001250\n",
      "Epoch [34], Batch [150/391], Loss: 0.7609, LR: 0.001250\n",
      "Epoch [34], Batch [200/391], Loss: 2.9414, LR: 0.001250\n",
      "Epoch [34], Batch [250/391], Loss: 0.9179, LR: 0.001250\n",
      "Epoch [34], Batch [300/391], Loss: 1.7219, LR: 0.001250\n",
      "Epoch [34], Batch [350/391], Loss: 1.5608, LR: 0.001250\n",
      "Train set: Epoch: 34, Average loss:1.6076, LR: 0.001250 Top-1 Accuracy: 65.4880%, Top-5 Accuracy: 87.8160%, Time consumed:89.40s\n",
      "Test set: Epoch: 34, Average loss:1.0481, Top-1 Accuracy: 70.5000%, Top-5 Accuracy: 92.0900%, Time consumed:9.50s\n",
      "\n",
      "새로운 최고 top-1 정확도: 70.50%, top-5 정확도: 92.09%\n",
      "새로운 최고 top-5 정확도: 92.09%\n",
      "Accuracy improved (69.69% --> 70.50%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|██████████▍                                                                                 | 34/300 [56:16<7:20:52, 99.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35], Batch [50/391], Loss: 3.0907, LR: 0.001250\n",
      "Epoch [35], Batch [100/391], Loss: 3.2131, LR: 0.001250\n",
      "Epoch [35], Batch [150/391], Loss: 0.8644, LR: 0.001250\n",
      "Epoch [35], Batch [200/391], Loss: 0.8107, LR: 0.001250\n",
      "Epoch [35], Batch [250/391], Loss: 2.1484, LR: 0.001250\n",
      "Epoch [35], Batch [300/391], Loss: 0.9309, LR: 0.001250\n",
      "Epoch [35], Batch [350/391], Loss: 2.0848, LR: 0.001250\n",
      "Train set: Epoch: 35, Average loss:1.7594, LR: 0.001250 Top-1 Accuracy: 63.0800%, Top-5 Accuracy: 86.1120%, Time consumed:89.01s\n",
      "Test set: Epoch: 35, Average loss:1.0302, Top-1 Accuracy: 71.1800%, Top-5 Accuracy: 92.5000%, Time consumed:10.46s\n",
      "\n",
      "새로운 최고 top-1 정확도: 71.18%, top-5 정확도: 92.50%\n",
      "새로운 최고 top-5 정확도: 92.50%\n",
      "Accuracy improved (70.50% --> 71.18%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████▋                                                                                 | 35/300 [57:56<7:19:37, 99.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36], Batch [50/391], Loss: 0.9378, LR: 0.001250\n",
      "Epoch [36], Batch [100/391], Loss: 0.8094, LR: 0.001250\n",
      "Epoch [36], Batch [150/391], Loss: 3.1786, LR: 0.001250\n",
      "Epoch [36], Batch [200/391], Loss: 3.2908, LR: 0.001250\n",
      "Epoch [36], Batch [250/391], Loss: 2.9345, LR: 0.001250\n",
      "Epoch [36], Batch [300/391], Loss: 0.8475, LR: 0.001250\n",
      "Epoch [36], Batch [350/391], Loss: 0.8403, LR: 0.001250\n",
      "Train set: Epoch: 36, Average loss:1.7097, LR: 0.001250 Top-1 Accuracy: 64.0880%, Top-5 Accuracy: 86.7880%, Time consumed:89.44s\n",
      "Test set: Epoch: 36, Average loss:1.0269, Top-1 Accuracy: 71.5100%, Top-5 Accuracy: 92.3600%, Time consumed:10.32s\n",
      "\n",
      "새로운 최고 top-1 정확도: 71.51%, top-5 정확도: 92.36%\n",
      "Accuracy improved (71.18% --> 71.51%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|███████████                                                                                 | 36/300 [59:36<7:18:34, 99.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37], Batch [50/391], Loss: 2.2029, LR: 0.001250\n",
      "Epoch [37], Batch [100/391], Loss: 0.8746, LR: 0.001250\n",
      "Epoch [37], Batch [150/391], Loss: 0.8921, LR: 0.001250\n",
      "Epoch [37], Batch [200/391], Loss: 0.9007, LR: 0.001250\n",
      "Epoch [37], Batch [250/391], Loss: 2.2329, LR: 0.001250\n",
      "Epoch [37], Batch [300/391], Loss: 3.0951, LR: 0.001250\n",
      "Epoch [37], Batch [350/391], Loss: 2.4746, LR: 0.001250\n",
      "Train set: Epoch: 37, Average loss:1.7263, LR: 0.001250 Top-1 Accuracy: 63.0800%, Top-5 Accuracy: 85.9220%, Time consumed:88.24s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|███████████                                                                               | 37/300 [1:01:14<7:15:18, 99.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 37, Average loss:1.0399, Top-1 Accuracy: 70.8800%, Top-5 Accuracy: 92.3500%, Time consumed:10.20s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [38], Batch [50/391], Loss: 2.6773, LR: 0.001250\n",
      "Epoch [38], Batch [100/391], Loss: 2.6273, LR: 0.001250\n",
      "Epoch [38], Batch [150/391], Loss: 1.8081, LR: 0.001250\n",
      "Epoch [38], Batch [200/391], Loss: 3.1680, LR: 0.001250\n",
      "Epoch [38], Batch [250/391], Loss: 2.4700, LR: 0.001250\n",
      "Epoch [38], Batch [300/391], Loss: 0.9662, LR: 0.001250\n",
      "Epoch [38], Batch [350/391], Loss: 1.7458, LR: 0.001250\n",
      "Train set: Epoch: 38, Average loss:1.7587, LR: 0.001250 Top-1 Accuracy: 63.6120%, Top-5 Accuracy: 86.3640%, Time consumed:93.12s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|███████████▎                                                                             | 38/300 [1:02:57<7:18:36, 100.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 38, Average loss:1.0563, Top-1 Accuracy: 70.7600%, Top-5 Accuracy: 92.0900%, Time consumed:9.96s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [39], Batch [50/391], Loss: 3.1134, LR: 0.001250\n",
      "Epoch [39], Batch [100/391], Loss: 0.7997, LR: 0.001250\n",
      "Epoch [39], Batch [150/391], Loss: 2.3523, LR: 0.001250\n",
      "Epoch [39], Batch [200/391], Loss: 2.6843, LR: 0.001250\n",
      "Epoch [39], Batch [250/391], Loss: 0.7672, LR: 0.001250\n",
      "Epoch [39], Batch [300/391], Loss: 0.7910, LR: 0.001250\n",
      "Epoch [39], Batch [350/391], Loss: 3.2759, LR: 0.001250\n",
      "Train set: Epoch: 39, Average loss:1.6478, LR: 0.001250 Top-1 Accuracy: 64.9960%, Top-5 Accuracy: 87.1800%, Time consumed:88.08s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|███████████▋                                                                              | 39/300 [1:04:35<7:13:40, 99.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 39, Average loss:1.0199, Top-1 Accuracy: 71.4100%, Top-5 Accuracy: 92.5600%, Time consumed:9.87s\n",
      "\n",
      "새로운 최고 top-5 정확도: 92.56%\n",
      "EarlyStopping 카운터: 3 / 30\n",
      "Epoch [40], Batch [50/391], Loss: 2.6512, LR: 0.000625\n",
      "Epoch [40], Batch [100/391], Loss: 2.8732, LR: 0.000625\n",
      "Epoch [40], Batch [150/391], Loss: 0.9254, LR: 0.000625\n",
      "Epoch [40], Batch [200/391], Loss: 0.7611, LR: 0.000625\n",
      "Epoch [40], Batch [250/391], Loss: 2.3325, LR: 0.000625\n",
      "Epoch [40], Batch [300/391], Loss: 0.8219, LR: 0.000625\n",
      "Epoch [40], Batch [350/391], Loss: 2.9745, LR: 0.000625\n",
      "Train set: Epoch: 40, Average loss:1.6301, LR: 0.000625 Top-1 Accuracy: 66.2360%, Top-5 Accuracy: 88.3740%, Time consumed:88.05s\n",
      "Test set: Epoch: 40, Average loss:0.9983, Top-1 Accuracy: 72.2100%, Top-5 Accuracy: 92.8100%, Time consumed:10.36s\n",
      "\n",
      "새로운 최고 top-1 정확도: 72.21%, top-5 정확도: 92.81%\n",
      "새로운 최고 top-5 정확도: 92.81%\n",
      "Accuracy improved (71.51% --> 72.21%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|████████████                                                                              | 40/300 [1:06:14<7:10:38, 99.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41], Batch [50/391], Loss: 0.8193, LR: 0.000625\n",
      "Epoch [41], Batch [100/391], Loss: 0.8722, LR: 0.000625\n",
      "Epoch [41], Batch [150/391], Loss: 0.8603, LR: 0.000625\n",
      "Epoch [41], Batch [200/391], Loss: 0.9833, LR: 0.000625\n",
      "Epoch [41], Batch [250/391], Loss: 1.6577, LR: 0.000625\n",
      "Epoch [41], Batch [300/391], Loss: 3.2474, LR: 0.000625\n",
      "Epoch [41], Batch [350/391], Loss: 0.8022, LR: 0.000625\n",
      "Train set: Epoch: 41, Average loss:1.6163, LR: 0.000625 Top-1 Accuracy: 65.8860%, Top-5 Accuracy: 87.5560%, Time consumed:88.56s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████▎                                                                             | 41/300 [1:07:52<7:07:28, 99.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 41, Average loss:1.0324, Top-1 Accuracy: 71.3800%, Top-5 Accuracy: 92.5000%, Time consumed:9.64s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [42], Batch [50/391], Loss: 2.6398, LR: 0.000625\n",
      "Epoch [42], Batch [100/391], Loss: 1.8260, LR: 0.000625\n",
      "Epoch [42], Batch [150/391], Loss: 2.0127, LR: 0.000625\n",
      "Epoch [42], Batch [200/391], Loss: 0.7735, LR: 0.000625\n",
      "Epoch [42], Batch [250/391], Loss: 1.4428, LR: 0.000625\n",
      "Epoch [42], Batch [300/391], Loss: 3.3410, LR: 0.000625\n",
      "Epoch [42], Batch [350/391], Loss: 3.2878, LR: 0.000625\n",
      "Train set: Epoch: 42, Average loss:1.6886, LR: 0.000625 Top-1 Accuracy: 65.2960%, Top-5 Accuracy: 87.2960%, Time consumed:94.89s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████▍                                                                            | 42/300 [1:09:37<7:13:59, 100.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 42, Average loss:0.9996, Top-1 Accuracy: 72.2100%, Top-5 Accuracy: 92.7400%, Time consumed:10.46s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [43], Batch [50/391], Loss: 0.8467, LR: 0.000625\n",
      "Epoch [43], Batch [100/391], Loss: 3.1805, LR: 0.000625\n",
      "Epoch [43], Batch [150/391], Loss: 0.9502, LR: 0.000625\n",
      "Epoch [43], Batch [200/391], Loss: 0.7937, LR: 0.000625\n",
      "Epoch [43], Batch [250/391], Loss: 1.2253, LR: 0.000625\n",
      "Epoch [43], Batch [300/391], Loss: 2.4830, LR: 0.000625\n",
      "Epoch [43], Batch [350/391], Loss: 1.1133, LR: 0.000625\n",
      "Train set: Epoch: 43, Average loss:1.6080, LR: 0.000625 Top-1 Accuracy: 66.1240%, Top-5 Accuracy: 87.7520%, Time consumed:92.22s\n",
      "Test set: Epoch: 43, Average loss:0.9821, Top-1 Accuracy: 72.4400%, Top-5 Accuracy: 92.8600%, Time consumed:11.12s\n",
      "\n",
      "새로운 최고 top-1 정확도: 72.44%, top-5 정확도: 92.86%\n",
      "새로운 최고 top-5 정확도: 92.86%\n",
      "Accuracy improved (72.21% --> 72.44%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████▊                                                                            | 43/300 [1:11:21<7:15:42, 101.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44], Batch [50/391], Loss: 1.8510, LR: 0.000625\n",
      "Epoch [44], Batch [100/391], Loss: 0.7743, LR: 0.000625\n",
      "Epoch [44], Batch [150/391], Loss: 0.7675, LR: 0.000625\n",
      "Epoch [44], Batch [200/391], Loss: 1.1492, LR: 0.000625\n",
      "Epoch [44], Batch [250/391], Loss: 2.1994, LR: 0.000625\n",
      "Epoch [44], Batch [300/391], Loss: 0.8176, LR: 0.000625\n",
      "Epoch [44], Batch [350/391], Loss: 2.7312, LR: 0.000625\n",
      "Train set: Epoch: 44, Average loss:1.7080, LR: 0.000625 Top-1 Accuracy: 65.1760%, Top-5 Accuracy: 87.3460%, Time consumed:90.19s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████████████                                                                            | 44/300 [1:13:01<7:12:31, 101.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 44, Average loss:1.0033, Top-1 Accuracy: 72.0000%, Top-5 Accuracy: 92.7200%, Time consumed:10.37s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [45], Batch [50/391], Loss: 3.0042, LR: 0.000625\n",
      "Epoch [45], Batch [100/391], Loss: 2.6957, LR: 0.000625\n",
      "Epoch [45], Batch [150/391], Loss: 0.6656, LR: 0.000625\n",
      "Epoch [45], Batch [200/391], Loss: 2.5016, LR: 0.000625\n",
      "Epoch [45], Batch [250/391], Loss: 2.1529, LR: 0.000625\n",
      "Epoch [45], Batch [300/391], Loss: 2.0846, LR: 0.000625\n",
      "Epoch [45], Batch [350/391], Loss: 0.6938, LR: 0.000625\n",
      "Train set: Epoch: 45, Average loss:1.6153, LR: 0.000625 Top-1 Accuracy: 67.2620%, Top-5 Accuracy: 88.8220%, Time consumed:91.08s\n",
      "Test set: Epoch: 45, Average loss:0.9882, Top-1 Accuracy: 72.5100%, Top-5 Accuracy: 92.9500%, Time consumed:9.75s\n",
      "\n",
      "새로운 최고 top-1 정확도: 72.51%, top-5 정확도: 92.95%\n",
      "새로운 최고 top-5 정확도: 92.95%\n",
      "Accuracy improved (72.44% --> 72.51%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████████████▎                                                                           | 45/300 [1:14:43<7:10:28, 101.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46], Batch [50/391], Loss: 0.7669, LR: 0.000312\n",
      "Epoch [46], Batch [100/391], Loss: 0.8366, LR: 0.000312\n",
      "Epoch [46], Batch [150/391], Loss: 0.8130, LR: 0.000312\n",
      "Epoch [46], Batch [200/391], Loss: 0.8863, LR: 0.000312\n",
      "Epoch [46], Batch [250/391], Loss: 0.7586, LR: 0.000312\n",
      "Epoch [46], Batch [300/391], Loss: 3.1480, LR: 0.000312\n",
      "Epoch [46], Batch [350/391], Loss: 0.7779, LR: 0.000312\n",
      "Train set: Epoch: 46, Average loss:1.6017, LR: 0.000312 Top-1 Accuracy: 67.2480%, Top-5 Accuracy: 88.6420%, Time consumed:88.51s\n",
      "Test set: Epoch: 46, Average loss:0.9787, Top-1 Accuracy: 72.7400%, Top-5 Accuracy: 92.8300%, Time consumed:10.56s\n",
      "\n",
      "새로운 최고 top-1 정확도: 72.74%, top-5 정확도: 92.83%\n",
      "Accuracy improved (72.51% --> 72.74%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████████████▋                                                                           | 46/300 [1:16:22<7:06:15, 100.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47], Batch [50/391], Loss: 0.7208, LR: 0.000312\n",
      "Epoch [47], Batch [100/391], Loss: 0.7570, LR: 0.000312\n",
      "Epoch [47], Batch [150/391], Loss: 2.7646, LR: 0.000312\n",
      "Epoch [47], Batch [200/391], Loss: 2.6389, LR: 0.000312\n",
      "Epoch [47], Batch [250/391], Loss: 2.9528, LR: 0.000312\n",
      "Epoch [47], Batch [300/391], Loss: 2.9685, LR: 0.000312\n",
      "Epoch [47], Batch [350/391], Loss: 2.9078, LR: 0.000312\n",
      "Train set: Epoch: 47, Average loss:1.6410, LR: 0.000312 Top-1 Accuracy: 66.0100%, Top-5 Accuracy: 87.6060%, Time consumed:92.86s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█████████████▉                                                                           | 47/300 [1:18:05<7:07:13, 101.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 47, Average loss:0.9760, Top-1 Accuracy: 72.7400%, Top-5 Accuracy: 92.9400%, Time consumed:9.91s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [48], Batch [50/391], Loss: 2.3957, LR: 0.000312\n",
      "Epoch [48], Batch [100/391], Loss: 2.0320, LR: 0.000312\n",
      "Epoch [48], Batch [150/391], Loss: 2.6735, LR: 0.000312\n",
      "Epoch [48], Batch [200/391], Loss: 2.6117, LR: 0.000312\n",
      "Epoch [48], Batch [250/391], Loss: 0.7797, LR: 0.000312\n",
      "Epoch [48], Batch [300/391], Loss: 0.8203, LR: 0.000312\n",
      "Epoch [48], Batch [350/391], Loss: 0.8437, LR: 0.000312\n",
      "Train set: Epoch: 48, Average loss:1.6882, LR: 0.000312 Top-1 Accuracy: 65.2960%, Top-5 Accuracy: 87.1920%, Time consumed:88.81s\n",
      "Test set: Epoch: 48, Average loss:0.9710, Top-1 Accuracy: 72.9300%, Top-5 Accuracy: 92.9700%, Time consumed:9.59s\n",
      "\n",
      "새로운 최고 top-1 정확도: 72.93%, top-5 정확도: 92.97%\n",
      "새로운 최고 top-5 정확도: 92.97%\n",
      "Accuracy improved (72.74% --> 72.93%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████████████▏                                                                          | 48/300 [1:19:43<7:02:11, 100.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49], Batch [50/391], Loss: 1.3628, LR: 0.000312\n",
      "Epoch [49], Batch [100/391], Loss: 0.6067, LR: 0.000312\n",
      "Epoch [49], Batch [150/391], Loss: 0.8820, LR: 0.000312\n",
      "Epoch [49], Batch [200/391], Loss: 3.0395, LR: 0.000312\n",
      "Epoch [49], Batch [250/391], Loss: 2.8694, LR: 0.000312\n",
      "Epoch [49], Batch [300/391], Loss: 0.8140, LR: 0.000312\n",
      "Epoch [49], Batch [350/391], Loss: 0.7640, LR: 0.000312\n",
      "Train set: Epoch: 49, Average loss:1.4926, LR: 0.000312 Top-1 Accuracy: 68.8620%, Top-5 Accuracy: 89.4700%, Time consumed:89.26s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████████████▌                                                                          | 49/300 [1:21:22<6:58:26, 100.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 49, Average loss:0.9846, Top-1 Accuracy: 72.5500%, Top-5 Accuracy: 92.8000%, Time consumed:9.61s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [50], Batch [50/391], Loss: 0.7196, LR: 0.000312\n",
      "Epoch [50], Batch [100/391], Loss: 2.7024, LR: 0.000312\n",
      "Epoch [50], Batch [150/391], Loss: 2.4418, LR: 0.000312\n",
      "Epoch [50], Batch [200/391], Loss: 0.6647, LR: 0.000312\n",
      "Epoch [50], Batch [250/391], Loss: 0.6194, LR: 0.000312\n",
      "Epoch [50], Batch [300/391], Loss: 0.7737, LR: 0.000312\n",
      "Epoch [50], Batch [350/391], Loss: 3.0627, LR: 0.000312\n",
      "Train set: Epoch: 50, Average loss:1.7328, LR: 0.000312 Top-1 Accuracy: 64.8720%, Top-5 Accuracy: 86.8540%, Time consumed:89.04s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████████████▊                                                                          | 50/300 [1:23:03<6:57:43, 100.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 50, Average loss:0.9814, Top-1 Accuracy: 72.6800%, Top-5 Accuracy: 92.7600%, Time consumed:11.74s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [51], Batch [50/391], Loss: 1.0473, LR: 0.000312\n",
      "Epoch [51], Batch [100/391], Loss: 0.7386, LR: 0.000312\n",
      "Epoch [51], Batch [150/391], Loss: 1.4020, LR: 0.000312\n",
      "Epoch [51], Batch [200/391], Loss: 1.0326, LR: 0.000312\n",
      "Epoch [51], Batch [250/391], Loss: 2.3448, LR: 0.000312\n",
      "Epoch [51], Batch [300/391], Loss: 0.6484, LR: 0.000312\n",
      "Epoch [51], Batch [350/391], Loss: 0.7912, LR: 0.000312\n",
      "Train set: Epoch: 51, Average loss:1.5717, LR: 0.000312 Top-1 Accuracy: 67.7620%, Top-5 Accuracy: 88.7960%, Time consumed:88.98s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████████████▎                                                                          | 51/300 [1:24:42<6:54:07, 99.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 51, Average loss:0.9869, Top-1 Accuracy: 72.6700%, Top-5 Accuracy: 92.8000%, Time consumed:9.72s\n",
      "\n",
      "EarlyStopping 카운터: 3 / 30\n",
      "Epoch [52], Batch [50/391], Loss: 2.9738, LR: 0.000156\n",
      "Epoch [52], Batch [100/391], Loss: 3.0381, LR: 0.000156\n",
      "Epoch [52], Batch [150/391], Loss: 2.8135, LR: 0.000156\n",
      "Epoch [52], Batch [200/391], Loss: 0.7772, LR: 0.000156\n",
      "Epoch [52], Batch [250/391], Loss: 2.9382, LR: 0.000156\n",
      "Epoch [52], Batch [300/391], Loss: 2.8247, LR: 0.000156\n",
      "Epoch [52], Batch [350/391], Loss: 0.6345, LR: 0.000156\n",
      "Train set: Epoch: 52, Average loss:1.6094, LR: 0.000156 Top-1 Accuracy: 67.1800%, Top-5 Accuracy: 88.2040%, Time consumed:89.00s\n",
      "Test set: Epoch: 52, Average loss:0.9689, Top-1 Accuracy: 73.1200%, Top-5 Accuracy: 93.0200%, Time consumed:9.63s\n",
      "\n",
      "새로운 최고 top-1 정확도: 73.12%, top-5 정확도: 93.02%\n",
      "새로운 최고 top-5 정확도: 93.02%\n",
      "Accuracy improved (72.93% --> 73.12%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████████████▌                                                                          | 52/300 [1:26:21<6:51:20, 99.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53], Batch [50/391], Loss: 0.7515, LR: 0.000156\n",
      "Epoch [53], Batch [100/391], Loss: 0.7303, LR: 0.000156\n",
      "Epoch [53], Batch [150/391], Loss: 0.7290, LR: 0.000156\n",
      "Epoch [53], Batch [200/391], Loss: 0.7466, LR: 0.000156\n",
      "Epoch [53], Batch [250/391], Loss: 0.7805, LR: 0.000156\n",
      "Epoch [53], Batch [300/391], Loss: 2.9102, LR: 0.000156\n",
      "Epoch [53], Batch [350/391], Loss: 1.7402, LR: 0.000156\n",
      "Train set: Epoch: 53, Average loss:1.5823, LR: 0.000156 Top-1 Accuracy: 67.4220%, Top-5 Accuracy: 88.3820%, Time consumed:89.45s\n",
      "Test set: Epoch: 53, Average loss:0.9646, Top-1 Accuracy: 73.1300%, Top-5 Accuracy: 92.9400%, Time consumed:9.66s\n",
      "\n",
      "새로운 최고 top-1 정확도: 73.13%, top-5 정확도: 92.94%\n",
      "Accuracy improved (73.12% --> 73.13%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████████████▉                                                                          | 53/300 [1:28:00<6:49:29, 99.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54], Batch [50/391], Loss: 2.7158, LR: 0.000156\n",
      "Epoch [54], Batch [100/391], Loss: 0.8150, LR: 0.000156\n",
      "Epoch [54], Batch [150/391], Loss: 0.7764, LR: 0.000156\n",
      "Epoch [54], Batch [200/391], Loss: 3.0702, LR: 0.000156\n",
      "Epoch [54], Batch [250/391], Loss: 2.9178, LR: 0.000156\n",
      "Epoch [54], Batch [300/391], Loss: 0.8440, LR: 0.000156\n",
      "Epoch [54], Batch [350/391], Loss: 2.7067, LR: 0.000156\n",
      "Epoch [55], Batch [300/391], Loss: 1.5852, LR: 0.000156\n",
      "Epoch [55], Batch [350/391], Loss: 0.7867, LR: 0.000156\n",
      "Train set: Epoch: 55, Average loss:1.6146, LR: 0.000156 Top-1 Accuracy: 67.1940%, Top-5 Accuracy: 88.3260%, Time consumed:89.66s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|████████████████▌                                                                         | 55/300 [1:31:18<6:45:37, 99.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 55, Average loss:0.9792, Top-1 Accuracy: 72.8500%, Top-5 Accuracy: 92.8500%, Time consumed:10.00s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [56], Batch [50/391], Loss: 1.8211, LR: 0.000156\n",
      "Epoch [56], Batch [100/391], Loss: 0.7571, LR: 0.000156\n",
      "Epoch [56], Batch [150/391], Loss: 0.7982, LR: 0.000156\n",
      "Epoch [56], Batch [200/391], Loss: 2.3582, LR: 0.000156\n",
      "Epoch [56], Batch [250/391], Loss: 2.5387, LR: 0.000156\n",
      "Epoch [56], Batch [300/391], Loss: 0.7781, LR: 0.000156\n",
      "Epoch [56], Batch [350/391], Loss: 0.6664, LR: 0.000156\n",
      "Train set: Epoch: 56, Average loss:1.6709, LR: 0.000156 Top-1 Accuracy: 66.1220%, Top-5 Accuracy: 87.6260%, Time consumed:88.31s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|████████████████▊                                                                         | 56/300 [1:32:56<6:42:41, 99.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 56, Average loss:0.9885, Top-1 Accuracy: 72.5800%, Top-5 Accuracy: 92.7300%, Time consumed:9.98s\n",
      "\n",
      "EarlyStopping 카운터: 3 / 30\n",
      "Epoch [57], Batch [50/391], Loss: 0.7122, LR: 0.000156\n",
      "Epoch [57], Batch [100/391], Loss: 0.7299, LR: 0.000156\n",
      "Epoch [57], Batch [150/391], Loss: 0.7346, LR: 0.000156\n",
      "Epoch [57], Batch [200/391], Loss: 2.4018, LR: 0.000156\n",
      "Epoch [57], Batch [250/391], Loss: 0.7262, LR: 0.000156\n",
      "Epoch [57], Batch [300/391], Loss: 0.7709, LR: 0.000156\n",
      "Epoch [57], Batch [350/391], Loss: 0.7345, LR: 0.000156\n",
      "Train set: Epoch: 57, Average loss:1.5396, LR: 0.000156 Top-1 Accuracy: 67.8280%, Top-5 Accuracy: 88.7000%, Time consumed:88.14s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█████████████████                                                                         | 57/300 [1:34:35<6:40:35, 98.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 57, Average loss:0.9748, Top-1 Accuracy: 72.9800%, Top-5 Accuracy: 92.7600%, Time consumed:10.51s\n",
      "\n",
      "EarlyStopping 카운터: 4 / 30\n",
      "Epoch [58], Batch [50/391], Loss: 0.6216, LR: 0.000078\n",
      "Epoch [58], Batch [100/391], Loss: 3.0238, LR: 0.000078\n",
      "Epoch [58], Batch [150/391], Loss: 2.8522, LR: 0.000078\n",
      "Epoch [58], Batch [200/391], Loss: 0.6686, LR: 0.000078\n",
      "Epoch [58], Batch [250/391], Loss: 2.8806, LR: 0.000078\n",
      "Epoch [58], Batch [300/391], Loss: 2.7007, LR: 0.000078\n",
      "Epoch [58], Batch [350/391], Loss: 0.7428, LR: 0.000078\n",
      "Train set: Epoch: 58, Average loss:1.6050, LR: 0.000078 Top-1 Accuracy: 67.1780%, Top-5 Accuracy: 88.0020%, Time consumed:88.47s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█████████████████▍                                                                        | 58/300 [1:36:13<6:37:59, 98.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 58, Average loss:0.9689, Top-1 Accuracy: 73.1000%, Top-5 Accuracy: 92.9600%, Time consumed:9.64s\n",
      "\n",
      "EarlyStopping 카운터: 5 / 30\n",
      "Epoch [59], Batch [50/391], Loss: 0.7886, LR: 0.000078\n",
      "Epoch [59], Batch [100/391], Loss: 0.6787, LR: 0.000078\n",
      "Epoch [59], Batch [150/391], Loss: 1.7662, LR: 0.000078\n",
      "Epoch [59], Batch [200/391], Loss: 2.9111, LR: 0.000078\n",
      "Epoch [59], Batch [250/391], Loss: 2.7021, LR: 0.000078\n",
      "Epoch [59], Batch [300/391], Loss: 2.2466, LR: 0.000078\n",
      "Epoch [59], Batch [350/391], Loss: 0.7067, LR: 0.000078\n",
      "Train set: Epoch: 59, Average loss:1.5665, LR: 0.000078 Top-1 Accuracy: 67.4940%, Top-5 Accuracy: 88.3180%, Time consumed:89.61s\n",
      "Test set: Epoch: 59, Average loss:0.9621, Top-1 Accuracy: 73.1400%, Top-5 Accuracy: 93.0500%, Time consumed:10.44s\n",
      "\n",
      "새로운 최고 top-1 정확도: 73.14%, top-5 정확도: 93.05%\n",
      "새로운 최고 top-5 정확도: 93.05%\n",
      "Accuracy improved (73.13% --> 73.14%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█████████████████▋                                                                        | 59/300 [1:37:53<6:38:19, 99.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60], Batch [50/391], Loss: 0.8377, LR: 0.000078\n",
      "Epoch [60], Batch [100/391], Loss: 3.0541, LR: 0.000078\n",
      "Epoch [60], Batch [150/391], Loss: 0.7587, LR: 0.000078\n",
      "Epoch [60], Batch [200/391], Loss: 0.7772, LR: 0.000078\n",
      "Epoch [60], Batch [250/391], Loss: 3.0076, LR: 0.000078\n",
      "Epoch [60], Batch [300/391], Loss: 0.6652, LR: 0.000078\n",
      "Epoch [60], Batch [350/391], Loss: 0.8110, LR: 0.000078\n",
      "Train set: Epoch: 60, Average loss:1.6183, LR: 0.000078 Top-1 Accuracy: 67.0020%, Top-5 Accuracy: 87.8040%, Time consumed:88.32s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████████████                                                                        | 60/300 [1:39:31<6:35:14, 98.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 60, Average loss:0.9754, Top-1 Accuracy: 72.9800%, Top-5 Accuracy: 92.8600%, Time consumed:9.65s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [61], Batch [50/391], Loss: 0.7314, LR: 0.000078\n",
      "Epoch [61], Batch [100/391], Loss: 1.0794, LR: 0.000078\n",
      "Epoch [61], Batch [150/391], Loss: 0.7984, LR: 0.000078\n",
      "Epoch [61], Batch [200/391], Loss: 3.1945, LR: 0.000078\n",
      "Epoch [61], Batch [250/391], Loss: 3.2672, LR: 0.000078\n",
      "Epoch [61], Batch [300/391], Loss: 2.4339, LR: 0.000078\n",
      "Epoch [61], Batch [350/391], Loss: 0.7312, LR: 0.000078\n",
      "Train set: Epoch: 61, Average loss:1.5731, LR: 0.000078 Top-1 Accuracy: 68.0760%, Top-5 Accuracy: 88.9440%, Time consumed:88.15s\n",
      "Test set: Epoch: 61, Average loss:0.9643, Top-1 Accuracy: 73.2500%, Top-5 Accuracy: 92.9600%, Time consumed:11.62s\n",
      "\n",
      "새로운 최고 top-1 정확도: 73.25%, top-5 정확도: 92.96%\n",
      "Accuracy improved (73.14% --> 73.25%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████████████▎                                                                       | 61/300 [1:41:11<6:35:02, 99.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [62], Batch [50/391], Loss: 2.2019, LR: 0.000078\n",
      "Epoch [62], Batch [100/391], Loss: 0.8094, LR: 0.000078\n",
      "Epoch [62], Batch [150/391], Loss: 0.6745, LR: 0.000078\n",
      "Epoch [62], Batch [200/391], Loss: 0.6280, LR: 0.000078\n",
      "Epoch [62], Batch [250/391], Loss: 0.7053, LR: 0.000078\n",
      "Epoch [62], Batch [300/391], Loss: 2.6707, LR: 0.000078\n",
      "Epoch [62], Batch [350/391], Loss: 0.6606, LR: 0.000078\n",
      "Train set: Epoch: 62, Average loss:1.5667, LR: 0.000078 Top-1 Accuracy: 68.1960%, Top-5 Accuracy: 88.8640%, Time consumed:89.03s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██████████████████▌                                                                       | 62/300 [1:42:51<6:34:05, 99.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 62, Average loss:0.9658, Top-1 Accuracy: 73.2400%, Top-5 Accuracy: 92.9400%, Time consumed:10.72s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [63], Batch [50/391], Loss: 0.6563, LR: 0.000078\n",
      "Epoch [63], Batch [100/391], Loss: 3.1349, LR: 0.000078\n",
      "Epoch [63], Batch [150/391], Loss: 0.6753, LR: 0.000078\n",
      "Epoch [63], Batch [200/391], Loss: 0.7630, LR: 0.000078\n",
      "Epoch [63], Batch [250/391], Loss: 2.8857, LR: 0.000078\n",
      "Epoch [63], Batch [300/391], Loss: 0.7425, LR: 0.000078\n",
      "Epoch [63], Batch [350/391], Loss: 0.7722, LR: 0.000078\n",
      "Train set: Epoch: 63, Average loss:1.5502, LR: 0.000078 Top-1 Accuracy: 67.9420%, Top-5 Accuracy: 88.5500%, Time consumed:90.29s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██████████████████▉                                                                       | 63/300 [1:44:31<6:33:06, 99.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 63, Average loss:0.9538, Top-1 Accuracy: 73.2000%, Top-5 Accuracy: 93.0900%, Time consumed:9.63s\n",
      "\n",
      "새로운 최고 top-5 정확도: 93.09%\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [64], Batch [50/391], Loss: 0.7204, LR: 0.000039\n",
      "Epoch [64], Batch [100/391], Loss: 0.7609, LR: 0.000039\n",
      "Epoch [64], Batch [150/391], Loss: 2.8286, LR: 0.000039\n",
      "Epoch [64], Batch [200/391], Loss: 2.9137, LR: 0.000039\n",
      "Epoch [64], Batch [250/391], Loss: 2.8185, LR: 0.000039\n",
      "Epoch [64], Batch [300/391], Loss: 2.9135, LR: 0.000039\n",
      "Epoch [64], Batch [350/391], Loss: 0.8691, LR: 0.000039\n",
      "Train set: Epoch: 64, Average loss:1.6332, LR: 0.000039 Top-1 Accuracy: 66.7580%, Top-5 Accuracy: 88.0060%, Time consumed:90.90s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|███████████████████▏                                                                      | 64/300 [1:46:12<6:32:38, 99.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 64, Average loss:0.9642, Top-1 Accuracy: 73.1000%, Top-5 Accuracy: 92.9300%, Time consumed:9.61s\n",
      "\n",
      "EarlyStopping 카운터: 3 / 30\n",
      "Epoch [65], Batch [50/391], Loss: 0.5709, LR: 0.000039\n",
      "Epoch [65], Batch [100/391], Loss: 1.5622, LR: 0.000039\n",
      "Epoch [65], Batch [150/391], Loss: 1.6327, LR: 0.000039\n",
      "Epoch [65], Batch [200/391], Loss: 3.1874, LR: 0.000039\n",
      "Epoch [65], Batch [250/391], Loss: 0.8976, LR: 0.000039\n",
      "Epoch [65], Batch [300/391], Loss: 2.5643, LR: 0.000039\n",
      "Epoch [65], Batch [350/391], Loss: 2.2809, LR: 0.000039\n",
      "Train set: Epoch: 65, Average loss:1.6320, LR: 0.000039 Top-1 Accuracy: 67.1020%, Top-5 Accuracy: 88.2720%, Time consumed:89.32s\n",
      "Test set: Epoch: 65, Average loss:0.9618, Top-1 Accuracy: 73.3700%, Top-5 Accuracy: 92.9800%, Time consumed:9.65s\n",
      "\n",
      "새로운 최고 top-1 정확도: 73.37%, top-5 정확도: 92.98%\n",
      "Accuracy improved (73.25% --> 73.37%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|███████████████████▌                                                                      | 65/300 [1:47:51<6:30:14, 99.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [66], Batch [50/391], Loss: 0.8094, LR: 0.000039\n",
      "Epoch [66], Batch [100/391], Loss: 0.6445, LR: 0.000039\n",
      "Epoch [66], Batch [150/391], Loss: 2.6343, LR: 0.000039\n",
      "Epoch [66], Batch [200/391], Loss: 1.9647, LR: 0.000039\n",
      "Epoch [66], Batch [250/391], Loss: 3.0690, LR: 0.000039\n",
      "Epoch [66], Batch [300/391], Loss: 0.7399, LR: 0.000039\n",
      "Epoch [66], Batch [350/391], Loss: 0.6982, LR: 0.000039\n",
      "Train set: Epoch: 66, Average loss:1.5892, LR: 0.000039 Top-1 Accuracy: 68.3360%, Top-5 Accuracy: 89.1260%, Time consumed:88.50s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|███████████████████▊                                                                      | 66/300 [1:49:30<6:28:18, 99.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 66, Average loss:0.9847, Top-1 Accuracy: 72.8700%, Top-5 Accuracy: 92.7400%, Time consumed:10.90s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [67], Batch [50/391], Loss: 2.7565, LR: 0.000039\n",
      "Epoch [67], Batch [100/391], Loss: 0.7091, LR: 0.000039\n",
      "Epoch [67], Batch [150/391], Loss: 2.4917, LR: 0.000039\n",
      "Epoch [67], Batch [200/391], Loss: 0.6620, LR: 0.000039\n",
      "Epoch [67], Batch [250/391], Loss: 0.7099, LR: 0.000039\n",
      "Epoch [67], Batch [300/391], Loss: 2.6288, LR: 0.000039\n",
      "Epoch [67], Batch [350/391], Loss: 0.8173, LR: 0.000039\n",
      "Train set: Epoch: 67, Average loss:1.5592, LR: 0.000039 Top-1 Accuracy: 68.4620%, Top-5 Accuracy: 88.9880%, Time consumed:88.63s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|████████████████████                                                                      | 67/300 [1:51:09<6:25:35, 99.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 67, Average loss:0.9929, Top-1 Accuracy: 72.8200%, Top-5 Accuracy: 92.7700%, Time consumed:10.02s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [68], Batch [50/391], Loss: 0.6709, LR: 0.000039\n",
      "Epoch [68], Batch [100/391], Loss: 0.6647, LR: 0.000039\n",
      "Epoch [68], Batch [150/391], Loss: 0.8005, LR: 0.000039\n",
      "Epoch [68], Batch [200/391], Loss: 1.8954, LR: 0.000039\n",
      "Epoch [68], Batch [250/391], Loss: 2.9493, LR: 0.000039\n",
      "Epoch [68], Batch [300/391], Loss: 0.6622, LR: 0.000039\n",
      "Epoch [68], Batch [350/391], Loss: 0.7340, LR: 0.000039\n",
      "Train set: Epoch: 68, Average loss:1.6100, LR: 0.000039 Top-1 Accuracy: 67.2480%, Top-5 Accuracy: 88.0080%, Time consumed:88.91s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|████████████████████▍                                                                     | 68/300 [1:52:48<6:23:55, 99.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 68, Average loss:0.9777, Top-1 Accuracy: 73.1000%, Top-5 Accuracy: 92.8500%, Time consumed:10.37s\n",
      "\n",
      "EarlyStopping 카운터: 3 / 30\n",
      "Epoch [69], Batch [50/391], Loss: 0.7863, LR: 0.000039\n",
      "Epoch [69], Batch [100/391], Loss: 0.6794, LR: 0.000039\n",
      "Epoch [69], Batch [150/391], Loss: 0.7590, LR: 0.000039\n",
      "Epoch [69], Batch [200/391], Loss: 2.8107, LR: 0.000039\n",
      "Epoch [69], Batch [250/391], Loss: 2.8839, LR: 0.000039\n",
      "Epoch [69], Batch [300/391], Loss: 0.8273, LR: 0.000039\n",
      "Epoch [69], Batch [350/391], Loss: 0.6842, LR: 0.000039\n",
      "Train set: Epoch: 69, Average loss:1.5630, LR: 0.000039 Top-1 Accuracy: 67.7540%, Top-5 Accuracy: 88.3860%, Time consumed:89.23s\n",
      "Test set: Epoch: 69, Average loss:0.9575, Top-1 Accuracy: 73.4100%, Top-5 Accuracy: 93.0500%, Time consumed:9.76s\n",
      "\n",
      "새로운 최고 top-1 정확도: 73.41%, top-5 정확도: 93.05%\n",
      "Accuracy improved (73.37% --> 73.41%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|████████████████████▋                                                                     | 69/300 [1:54:27<6:22:14, 99.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [71], Batch [50/391], Loss: 0.7435, LR: 0.000020\n",
      "Epoch [71], Batch [100/391], Loss: 0.7717, LR: 0.000020\n",
      "Epoch [71], Batch [150/391], Loss: 3.0329, LR: 0.000020\n",
      "Epoch [71], Batch [200/391], Loss: 0.5977, LR: 0.000020\n",
      "Epoch [71], Batch [250/391], Loss: 2.6608, LR: 0.000020\n",
      "Epoch [71], Batch [300/391], Loss: 1.7673, LR: 0.000020\n",
      "Epoch [71], Batch [350/391], Loss: 0.6856, LR: 0.000020\n",
      "Train set: Epoch: 71, Average loss:1.6092, LR: 0.000020 Top-1 Accuracy: 67.7360%, Top-5 Accuracy: 88.7080%, Time consumed:88.80s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|█████████████████████▎                                                                    | 71/300 [1:57:48<6:20:02, 99.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 71, Average loss:1.0049, Top-1 Accuracy: 72.4000%, Top-5 Accuracy: 92.6600%, Time consumed:10.05s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [72], Batch [50/391], Loss: 2.8715, LR: 0.000020\n",
      "Epoch [72], Batch [100/391], Loss: 0.7412, LR: 0.000020\n",
      "Epoch [72], Batch [150/391], Loss: 3.1831, LR: 0.000020\n",
      "Epoch [72], Batch [200/391], Loss: 0.8289, LR: 0.000020\n",
      "Epoch [72], Batch [250/391], Loss: 2.9327, LR: 0.000020\n",
      "Epoch [72], Batch [300/391], Loss: 0.8347, LR: 0.000020\n",
      "Epoch [72], Batch [350/391], Loss: 0.7238, LR: 0.000020\n",
      "Train set: Epoch: 72, Average loss:1.5519, LR: 0.000020 Top-1 Accuracy: 68.0040%, Top-5 Accuracy: 88.6340%, Time consumed:88.03s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|█████████████████████▌                                                                    | 72/300 [1:59:26<6:16:35, 99.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 72, Average loss:0.9777, Top-1 Accuracy: 73.1600%, Top-5 Accuracy: 92.8000%, Time consumed:9.96s\n",
      "\n",
      "EarlyStopping 카운터: 3 / 30\n",
      "Epoch [73], Batch [50/391], Loss: 2.1969, LR: 0.000020\n",
      "Epoch [73], Batch [100/391], Loss: 2.4667, LR: 0.000020\n",
      "Epoch [73], Batch [150/391], Loss: 3.0950, LR: 0.000020\n",
      "Epoch [73], Batch [200/391], Loss: 2.4884, LR: 0.000020\n",
      "Epoch [73], Batch [250/391], Loss: 0.6474, LR: 0.000020\n",
      "Epoch [73], Batch [300/391], Loss: 0.8556, LR: 0.000020\n",
      "Epoch [73], Batch [350/391], Loss: 1.9038, LR: 0.000020\n",
      "Train set: Epoch: 73, Average loss:1.5758, LR: 0.000020 Top-1 Accuracy: 68.2060%, Top-5 Accuracy: 88.7020%, Time consumed:90.11s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|█████████████████████▉                                                                    | 73/300 [2:01:05<6:15:30, 99.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 73, Average loss:0.9674, Top-1 Accuracy: 73.0700%, Top-5 Accuracy: 92.8300%, Time consumed:9.49s\n",
      "\n",
      "EarlyStopping 카운터: 4 / 30\n",
      "Epoch [74], Batch [50/391], Loss: 0.8108, LR: 0.000020\n",
      "Epoch [74], Batch [100/391], Loss: 0.7274, LR: 0.000020\n",
      "Epoch [74], Batch [150/391], Loss: 0.6039, LR: 0.000020\n",
      "Epoch [74], Batch [200/391], Loss: 3.0490, LR: 0.000020\n",
      "Epoch [74], Batch [250/391], Loss: 0.7158, LR: 0.000020\n",
      "Epoch [74], Batch [300/391], Loss: 0.7136, LR: 0.000020\n",
      "Epoch [74], Batch [350/391], Loss: 3.2002, LR: 0.000020\n",
      "Train set: Epoch: 74, Average loss:1.5809, LR: 0.000020 Top-1 Accuracy: 67.4340%, Top-5 Accuracy: 88.2540%, Time consumed:88.59s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██████████████████████▏                                                                   | 74/300 [2:02:44<6:13:44, 99.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 74, Average loss:1.0067, Top-1 Accuracy: 72.6600%, Top-5 Accuracy: 92.7200%, Time consumed:10.55s\n",
      "\n",
      "EarlyStopping 카운터: 5 / 30\n",
      "Epoch [75], Batch [50/391], Loss: 2.4259, LR: 0.000020\n",
      "Epoch [75], Batch [100/391], Loss: 0.7049, LR: 0.000020\n",
      "Epoch [75], Batch [150/391], Loss: 0.8007, LR: 0.000020\n",
      "Epoch [75], Batch [200/391], Loss: 0.7773, LR: 0.000020\n",
      "Epoch [75], Batch [250/391], Loss: 0.7584, LR: 0.000020\n",
      "Epoch [75], Batch [300/391], Loss: 2.3663, LR: 0.000020\n",
      "Epoch [75], Batch [350/391], Loss: 0.7846, LR: 0.000020\n",
      "Train set: Epoch: 75, Average loss:1.5229, LR: 0.000020 Top-1 Accuracy: 69.8760%, Top-5 Accuracy: 90.2080%, Time consumed:89.04s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██████████████████████▌                                                                   | 75/300 [2:04:24<6:12:17, 99.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 75, Average loss:0.9759, Top-1 Accuracy: 73.0100%, Top-5 Accuracy: 92.8500%, Time consumed:10.37s\n",
      "\n",
      "EarlyStopping 카운터: 6 / 30\n",
      "Epoch [76], Batch [50/391], Loss: 2.6311, LR: 0.000010\n",
      "Epoch [76], Batch [100/391], Loss: 3.0600, LR: 0.000010\n",
      "Epoch [76], Batch [150/391], Loss: 2.6338, LR: 0.000010\n",
      "Epoch [76], Batch [200/391], Loss: 2.9943, LR: 0.000010\n",
      "Epoch [76], Batch [250/391], Loss: 0.9231, LR: 0.000010\n",
      "Epoch [76], Batch [300/391], Loss: 0.6125, LR: 0.000010\n",
      "Epoch [76], Batch [350/391], Loss: 1.3476, LR: 0.000010\n",
      "Train set: Epoch: 76, Average loss:1.5911, LR: 0.000010 Top-1 Accuracy: 67.4940%, Top-5 Accuracy: 88.1540%, Time consumed:88.66s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██████████████████████▊                                                                   | 76/300 [2:06:02<6:09:58, 99.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 76, Average loss:0.9882, Top-1 Accuracy: 72.8500%, Top-5 Accuracy: 92.8100%, Time consumed:10.01s\n",
      "\n",
      "EarlyStopping 카운터: 7 / 30\n",
      "Epoch [77], Batch [50/391], Loss: 3.1403, LR: 0.000010\n",
      "Epoch [77], Batch [100/391], Loss: 2.6777, LR: 0.000010\n",
      "Epoch [77], Batch [150/391], Loss: 0.5985, LR: 0.000010\n",
      "Epoch [77], Batch [200/391], Loss: 0.8605, LR: 0.000010\n",
      "Epoch [77], Batch [250/391], Loss: 0.8350, LR: 0.000010\n",
      "Epoch [77], Batch [300/391], Loss: 0.6764, LR: 0.000010\n",
      "Epoch [77], Batch [350/391], Loss: 0.7527, LR: 0.000010\n",
      "Train set: Epoch: 77, Average loss:1.6595, LR: 0.000010 Top-1 Accuracy: 65.9180%, Top-5 Accuracy: 87.1000%, Time consumed:91.22s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|███████████████████████                                                                   | 77/300 [2:07:44<6:10:58, 99.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 77, Average loss:0.9613, Top-1 Accuracy: 73.0200%, Top-5 Accuracy: 92.9000%, Time consumed:10.26s\n",
      "\n",
      "EarlyStopping 카운터: 8 / 30\n",
      "Epoch [78], Batch [50/391], Loss: 0.5972, LR: 0.000010\n",
      "Epoch [78], Batch [100/391], Loss: 3.1424, LR: 0.000010\n",
      "Epoch [78], Batch [150/391], Loss: 2.8083, LR: 0.000010\n",
      "Epoch [78], Batch [200/391], Loss: 0.8322, LR: 0.000010\n",
      "Epoch [78], Batch [250/391], Loss: 0.7193, LR: 0.000010\n",
      "Epoch [78], Batch [300/391], Loss: 0.8205, LR: 0.000010\n",
      "Epoch [78], Batch [350/391], Loss: 1.8758, LR: 0.000010\n",
      "Train set: Epoch: 78, Average loss:1.6145, LR: 0.000010 Top-1 Accuracy: 67.1360%, Top-5 Accuracy: 87.7860%, Time consumed:89.30s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|███████████████████████▍                                                                  | 78/300 [2:09:23<6:08:39, 99.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 78, Average loss:0.9572, Top-1 Accuracy: 73.2300%, Top-5 Accuracy: 92.8200%, Time consumed:9.92s\n",
      "\n",
      "EarlyStopping 카운터: 9 / 30\n",
      "Epoch [79], Batch [50/391], Loss: 3.1378, LR: 0.000010\n",
      "Epoch [79], Batch [100/391], Loss: 0.6250, LR: 0.000010\n",
      "Epoch [79], Batch [150/391], Loss: 2.2486, LR: 0.000010\n",
      "Epoch [79], Batch [200/391], Loss: 0.6953, LR: 0.000010\n",
      "Epoch [79], Batch [250/391], Loss: 2.6254, LR: 0.000010\n",
      "Epoch [79], Batch [300/391], Loss: 2.4304, LR: 0.000010\n",
      "Epoch [79], Batch [350/391], Loss: 2.2215, LR: 0.000010\n",
      "Train set: Epoch: 79, Average loss:1.6515, LR: 0.000010 Top-1 Accuracy: 66.4040%, Top-5 Accuracy: 87.2140%, Time consumed:88.79s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|███████████████████████▋                                                                  | 79/300 [2:11:02<6:06:15, 99.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 79, Average loss:0.9590, Top-1 Accuracy: 73.2200%, Top-5 Accuracy: 92.9100%, Time consumed:10.17s\n",
      "\n",
      "EarlyStopping 카운터: 10 / 30\n",
      "Epoch [80], Batch [50/391], Loss: 0.7294, LR: 0.000010\n",
      "Epoch [80], Batch [100/391], Loss: 0.7429, LR: 0.000010\n",
      "Epoch [80], Batch [150/391], Loss: 0.6674, LR: 0.000010\n",
      "Epoch [80], Batch [200/391], Loss: 3.0694, LR: 0.000010\n",
      "Epoch [80], Batch [250/391], Loss: 0.7928, LR: 0.000010\n",
      "Epoch [80], Batch [300/391], Loss: 0.7045, LR: 0.000010\n",
      "Epoch [80], Batch [350/391], Loss: 1.7287, LR: 0.000010\n",
      "Train set: Epoch: 80, Average loss:1.6014, LR: 0.000010 Top-1 Accuracy: 67.5960%, Top-5 Accuracy: 88.1080%, Time consumed:88.34s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|████████████████████████                                                                  | 80/300 [2:12:41<6:03:24, 99.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 80, Average loss:0.9616, Top-1 Accuracy: 72.9800%, Top-5 Accuracy: 92.9900%, Time consumed:10.01s\n",
      "\n",
      "EarlyStopping 카운터: 11 / 30\n",
      "Epoch [81], Batch [50/391], Loss: 0.7624, LR: 0.000010\n",
      "Epoch [81], Batch [100/391], Loss: 2.4860, LR: 0.000010\n",
      "Epoch [81], Batch [150/391], Loss: 0.8131, LR: 0.000010\n",
      "Epoch [81], Batch [200/391], Loss: 2.8714, LR: 0.000010\n",
      "Epoch [81], Batch [250/391], Loss: 0.6791, LR: 0.000010\n",
      "Epoch [81], Batch [300/391], Loss: 1.8739, LR: 0.000010\n",
      "Epoch [81], Batch [350/391], Loss: 2.4233, LR: 0.000010\n",
      "Train set: Epoch: 81, Average loss:1.5783, LR: 0.000010 Top-1 Accuracy: 68.1860%, Top-5 Accuracy: 88.7940%, Time consumed:88.77s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|████████████████████████▎                                                                 | 81/300 [2:14:19<6:00:54, 98.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 81, Average loss:0.9718, Top-1 Accuracy: 73.1200%, Top-5 Accuracy: 92.8300%, Time consumed:9.56s\n",
      "\n",
      "EarlyStopping 카운터: 12 / 30\n",
      "Epoch [82], Batch [50/391], Loss: 0.6694, LR: 0.000005\n",
      "Epoch [82], Batch [100/391], Loss: 0.6349, LR: 0.000005\n",
      "Epoch [82], Batch [150/391], Loss: 3.0534, LR: 0.000005\n",
      "Epoch [82], Batch [200/391], Loss: 0.7428, LR: 0.000005\n",
      "Epoch [82], Batch [250/391], Loss: 2.0349, LR: 0.000005\n",
      "Epoch [82], Batch [300/391], Loss: 0.7938, LR: 0.000005\n",
      "Epoch [82], Batch [350/391], Loss: 0.8058, LR: 0.000005\n",
      "Train set: Epoch: 82, Average loss:1.6932, LR: 0.000005 Top-1 Accuracy: 65.2580%, Top-5 Accuracy: 86.8660%, Time consumed:88.70s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|████████████████████████▌                                                                 | 82/300 [2:15:57<5:58:42, 98.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 82, Average loss:0.9742, Top-1 Accuracy: 72.8300%, Top-5 Accuracy: 92.9200%, Time consumed:9.66s\n",
      "\n",
      "EarlyStopping 카운터: 13 / 30\n",
      "Epoch [83], Batch [50/391], Loss: 0.7613, LR: 0.000005\n",
      "Epoch [83], Batch [100/391], Loss: 1.6647, LR: 0.000005\n",
      "Epoch [83], Batch [150/391], Loss: 0.8022, LR: 0.000005\n",
      "Epoch [83], Batch [200/391], Loss: 0.6693, LR: 0.000005\n",
      "Epoch [83], Batch [250/391], Loss: 2.6225, LR: 0.000005\n",
      "Epoch [83], Batch [300/391], Loss: 0.8107, LR: 0.000005\n",
      "Epoch [83], Batch [350/391], Loss: 2.9327, LR: 0.000005\n",
      "Train set: Epoch: 83, Average loss:1.5833, LR: 0.000005 Top-1 Accuracy: 67.5940%, Top-5 Accuracy: 88.6820%, Time consumed:88.03s\n",
      "Test set: Epoch: 83, Average loss:0.9542, Top-1 Accuracy: 73.5400%, Top-5 Accuracy: 93.1100%, Time consumed:9.89s\n",
      "\n",
      "새로운 최고 top-1 정확도: 73.54%, top-5 정확도: 93.11%\n",
      "새로운 최고 top-5 정확도: 93.11%\n",
      "Accuracy improved (73.41% --> 73.54%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|████████████████████████▉                                                                 | 83/300 [2:17:35<5:56:26, 98.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [84], Batch [50/391], Loss: 0.6822, LR: 0.000005\n",
      "Epoch [84], Batch [100/391], Loss: 2.9422, LR: 0.000005\n",
      "Epoch [84], Batch [150/391], Loss: 0.8208, LR: 0.000005\n",
      "Epoch [84], Batch [200/391], Loss: 3.0820, LR: 0.000005\n",
      "Epoch [84], Batch [250/391], Loss: 2.3998, LR: 0.000005\n",
      "Epoch [84], Batch [300/391], Loss: 0.8270, LR: 0.000005\n",
      "Epoch [84], Batch [350/391], Loss: 2.6798, LR: 0.000005\n",
      "Train set: Epoch: 84, Average loss:1.5449, LR: 0.000005 Top-1 Accuracy: 68.7220%, Top-5 Accuracy: 89.1860%, Time consumed:88.81s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|█████████████████████████▏                                                                | 84/300 [2:19:14<5:55:08, 98.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 84, Average loss:0.9652, Top-1 Accuracy: 73.2000%, Top-5 Accuracy: 92.9300%, Time consumed:10.06s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [85], Batch [50/391], Loss: 3.1750, LR: 0.000005\n",
      "Epoch [85], Batch [100/391], Loss: 0.9099, LR: 0.000005\n",
      "Epoch [85], Batch [150/391], Loss: 3.1208, LR: 0.000005\n",
      "Epoch [85], Batch [200/391], Loss: 0.7848, LR: 0.000005\n",
      "Epoch [85], Batch [250/391], Loss: 2.2019, LR: 0.000005\n",
      "Epoch [85], Batch [300/391], Loss: 0.9147, LR: 0.000005\n",
      "Epoch [85], Batch [350/391], Loss: 2.6767, LR: 0.000005\n",
      "Train set: Epoch: 85, Average loss:1.6986, LR: 0.000005 Top-1 Accuracy: 65.5780%, Top-5 Accuracy: 87.1240%, Time consumed:89.40s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|█████████████████████████▌                                                                | 85/300 [2:20:54<5:54:49, 99.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 85, Average loss:0.9633, Top-1 Accuracy: 73.3200%, Top-5 Accuracy: 92.9600%, Time consumed:10.47s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [86], Batch [50/391], Loss: 1.3468, LR: 0.000005\n",
      "Epoch [86], Batch [100/391], Loss: 0.6675, LR: 0.000005\n",
      "Epoch [86], Batch [150/391], Loss: 0.6510, LR: 0.000005\n",
      "Epoch [86], Batch [200/391], Loss: 0.6816, LR: 0.000005\n",
      "Epoch [86], Batch [250/391], Loss: 0.7254, LR: 0.000005\n",
      "Epoch [86], Batch [300/391], Loss: 0.7233, LR: 0.000005\n",
      "Epoch [86], Batch [350/391], Loss: 0.7876, LR: 0.000005\n",
      "Train set: Epoch: 86, Average loss:1.5736, LR: 0.000005 Top-1 Accuracy: 68.6480%, Top-5 Accuracy: 88.8140%, Time consumed:88.81s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|█████████████████████████▊                                                                | 86/300 [2:22:34<5:54:18, 99.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 86, Average loss:0.9628, Top-1 Accuracy: 73.0800%, Top-5 Accuracy: 93.0400%, Time consumed:11.27s\n",
      "\n",
      "EarlyStopping 카운터: 3 / 30\n",
      "Epoch [87], Batch [50/391], Loss: 3.0372, LR: 0.000005\n",
      "Epoch [87], Batch [100/391], Loss: 3.0189, LR: 0.000005\n",
      "Epoch [87], Batch [150/391], Loss: 0.8062, LR: 0.000005\n",
      "Epoch [87], Batch [200/391], Loss: 3.3239, LR: 0.000005\n",
      "Epoch [87], Batch [250/391], Loss: 1.7928, LR: 0.000005\n",
      "Epoch [87], Batch [300/391], Loss: 3.1878, LR: 0.000005\n",
      "Epoch [87], Batch [350/391], Loss: 2.1818, LR: 0.000005\n",
      "Train set: Epoch: 87, Average loss:1.6775, LR: 0.000005 Top-1 Accuracy: 66.5960%, Top-5 Accuracy: 87.5540%, Time consumed:88.51s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██████████████████████████                                                                | 87/300 [2:24:12<5:51:22, 98.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 87, Average loss:0.9681, Top-1 Accuracy: 73.1800%, Top-5 Accuracy: 92.9500%, Time consumed:9.62s\n",
      "\n",
      "EarlyStopping 카운터: 4 / 30\n",
      "Epoch [88], Batch [50/391], Loss: 0.7554, LR: 0.000002\n",
      "Epoch [88], Batch [100/391], Loss: 1.1131, LR: 0.000002\n",
      "Epoch [88], Batch [150/391], Loss: 0.7094, LR: 0.000002\n",
      "Epoch [88], Batch [200/391], Loss: 0.8113, LR: 0.000002\n",
      "Epoch [88], Batch [250/391], Loss: 0.7072, LR: 0.000002\n",
      "Epoch [88], Batch [300/391], Loss: 0.7138, LR: 0.000002\n",
      "Epoch [88], Batch [350/391], Loss: 2.5104, LR: 0.000002\n",
      "Train set: Epoch: 88, Average loss:1.5766, LR: 0.000002 Top-1 Accuracy: 68.2620%, Top-5 Accuracy: 88.7800%, Time consumed:88.30s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██████████████████████████▍                                                               | 88/300 [2:25:51<5:49:42, 98.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 88, Average loss:0.9950, Top-1 Accuracy: 72.6300%, Top-5 Accuracy: 92.7400%, Time consumed:10.65s\n",
      "\n",
      "EarlyStopping 카운터: 5 / 30\n",
      "Epoch [89], Batch [50/391], Loss: 0.7223, LR: 0.000002\n",
      "Epoch [89], Batch [100/391], Loss: 0.6739, LR: 0.000002\n",
      "Epoch [89], Batch [150/391], Loss: 2.9011, LR: 0.000002\n",
      "Epoch [89], Batch [200/391], Loss: 2.6058, LR: 0.000002\n",
      "Epoch [89], Batch [250/391], Loss: 0.7737, LR: 0.000002\n",
      "Epoch [89], Batch [300/391], Loss: 0.6783, LR: 0.000002\n",
      "Epoch [89], Batch [350/391], Loss: 3.0047, LR: 0.000002\n",
      "Train set: Epoch: 89, Average loss:1.5498, LR: 0.000002 Top-1 Accuracy: 69.0620%, Top-5 Accuracy: 89.5160%, Time consumed:91.45s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██████████████████████████▋                                                               | 89/300 [2:27:33<5:50:46, 99.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 89, Average loss:0.9597, Top-1 Accuracy: 73.2300%, Top-5 Accuracy: 92.9600%, Time consumed:10.10s\n",
      "\n",
      "EarlyStopping 카운터: 6 / 30\n",
      "Epoch [90], Batch [50/391], Loss: 2.3923, LR: 0.000002\n",
      "Epoch [90], Batch [100/391], Loss: 1.5545, LR: 0.000002\n",
      "Epoch [90], Batch [150/391], Loss: 0.7651, LR: 0.000002\n",
      "Epoch [90], Batch [200/391], Loss: 0.9310, LR: 0.000002\n",
      "Epoch [90], Batch [250/391], Loss: 2.7640, LR: 0.000002\n",
      "Epoch [90], Batch [300/391], Loss: 0.8078, LR: 0.000002\n",
      "Epoch [90], Batch [350/391], Loss: 1.9371, LR: 0.000002\n",
      "Train set: Epoch: 90, Average loss:1.5212, LR: 0.000002 Top-1 Accuracy: 68.9280%, Top-5 Accuracy: 89.4440%, Time consumed:89.45s\n",
      "Test set: Epoch: 90, Average loss:0.9515, Top-1 Accuracy: 73.6400%, Top-5 Accuracy: 93.0700%, Time consumed:10.63s\n",
      "\n",
      "새로운 최고 top-1 정확도: 73.64%, top-5 정확도: 93.07%\n",
      "Accuracy improved (73.54% --> 73.64%). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████████████████████                                                               | 90/300 [2:29:13<5:49:42, 99.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [91], Batch [50/391], Loss: 0.6025, LR: 0.000002\n",
      "Epoch [91], Batch [100/391], Loss: 0.7306, LR: 0.000002\n",
      "Epoch [91], Batch [150/391], Loss: 2.7062, LR: 0.000002\n",
      "Epoch [91], Batch [200/391], Loss: 1.7090, LR: 0.000002\n",
      "Epoch [91], Batch [250/391], Loss: 1.7697, LR: 0.000002\n",
      "Epoch [91], Batch [300/391], Loss: 0.7244, LR: 0.000002\n",
      "Epoch [91], Batch [350/391], Loss: 2.9519, LR: 0.000002\n",
      "Train set: Epoch: 91, Average loss:1.5543, LR: 0.000002 Top-1 Accuracy: 67.4000%, Top-5 Accuracy: 88.1860%, Time consumed:91.72s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██████████████████████████▉                                                              | 91/300 [2:30:56<5:51:18, 100.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 91, Average loss:0.9617, Top-1 Accuracy: 73.3000%, Top-5 Accuracy: 92.9800%, Time consumed:11.32s\n",
      "\n",
      "EarlyStopping 카운터: 1 / 30\n",
      "Epoch [92], Batch [50/391], Loss: 2.9926, LR: 0.000002\n",
      "Epoch [92], Batch [100/391], Loss: 2.3458, LR: 0.000002\n",
      "Epoch [92], Batch [150/391], Loss: 0.7151, LR: 0.000002\n",
      "Epoch [92], Batch [200/391], Loss: 2.7763, LR: 0.000002\n",
      "Epoch [92], Batch [250/391], Loss: 1.2809, LR: 0.000002\n",
      "Epoch [92], Batch [300/391], Loss: 0.7595, LR: 0.000002\n",
      "Epoch [92], Batch [350/391], Loss: 0.8093, LR: 0.000002\n",
      "Train set: Epoch: 92, Average loss:1.6439, LR: 0.000002 Top-1 Accuracy: 67.1520%, Top-5 Accuracy: 88.2640%, Time consumed:89.97s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███████████████████████████▎                                                             | 92/300 [2:32:36<5:48:17, 100.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 92, Average loss:0.9660, Top-1 Accuracy: 73.1600%, Top-5 Accuracy: 92.9300%, Time consumed:9.60s\n",
      "\n",
      "EarlyStopping 카운터: 2 / 30\n",
      "Epoch [93], Batch [50/391], Loss: 2.1084, LR: 0.000002\n",
      "Epoch [93], Batch [100/391], Loss: 3.1251, LR: 0.000002\n",
      "Epoch [93], Batch [150/391], Loss: 3.0188, LR: 0.000002\n",
      "Epoch [93], Batch [200/391], Loss: 0.7178, LR: 0.000002\n",
      "Epoch [93], Batch [250/391], Loss: 0.7795, LR: 0.000002\n",
      "Epoch [93], Batch [300/391], Loss: 2.6279, LR: 0.000002\n",
      "Epoch [93], Batch [350/391], Loss: 0.7728, LR: 0.000002\n",
      "Train set: Epoch: 93, Average loss:1.5014, LR: 0.000002 Top-1 Accuracy: 69.7680%, Top-5 Accuracy: 89.7360%, Time consumed:88.36s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███████████████████████████▉                                                              | 93/300 [2:34:15<5:44:51, 99.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 93, Average loss:0.9740, Top-1 Accuracy: 73.1800%, Top-5 Accuracy: 93.0100%, Time consumed:10.39s\n",
      "\n",
      "EarlyStopping 카운터: 3 / 30\n",
      "Epoch [94], Batch [50/391], Loss: 2.9138, LR: 0.000001\n",
      "Epoch [94], Batch [100/391], Loss: 1.6873, LR: 0.000001\n",
      "Epoch [94], Batch [150/391], Loss: 0.8577, LR: 0.000001\n",
      "Epoch [94], Batch [200/391], Loss: 0.7366, LR: 0.000001\n",
      "Epoch [94], Batch [250/391], Loss: 3.0142, LR: 0.000001\n",
      "Epoch [94], Batch [300/391], Loss: 0.8072, LR: 0.000001\n",
      "Epoch [94], Batch [350/391], Loss: 0.6324, LR: 0.000001\n",
      "Train set: Epoch: 94, Average loss:1.5540, LR: 0.000001 Top-1 Accuracy: 68.0220%, Top-5 Accuracy: 88.6620%, Time consumed:88.55s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|████████████████████████████▏                                                             | 94/300 [2:35:53<5:41:22, 99.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 94, Average loss:0.9580, Top-1 Accuracy: 73.4200%, Top-5 Accuracy: 92.9700%, Time consumed:9.64s\n",
      "\n",
      "EarlyStopping 카운터: 4 / 30\n",
      "Epoch [95], Batch [50/391], Loss: 2.8742, LR: 0.000001\n",
      "Epoch [95], Batch [100/391], Loss: 1.6166, LR: 0.000001\n",
      "Epoch [95], Batch [150/391], Loss: 2.5605, LR: 0.000001\n",
      "Epoch [95], Batch [200/391], Loss: 0.8593, LR: 0.000001\n",
      "Epoch [95], Batch [250/391], Loss: 0.7774, LR: 0.000001\n",
      "Epoch [95], Batch [300/391], Loss: 2.3342, LR: 0.000001\n",
      "Epoch [95], Batch [350/391], Loss: 2.8108, LR: 0.000001\n",
      "Train set: Epoch: 95, Average loss:1.5891, LR: 0.000001 Top-1 Accuracy: 68.0260%, Top-5 Accuracy: 88.6320%, Time consumed:88.82s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|████████████████████████████▌                                                             | 95/300 [2:37:31<5:38:43, 99.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 95, Average loss:0.9507, Top-1 Accuracy: 73.4900%, Top-5 Accuracy: 93.1900%, Time consumed:9.64s\n",
      "\n",
      "새로운 최고 top-5 정확도: 93.19%\n",
      "EarlyStopping 카운터: 5 / 30\n",
      "Epoch [96], Batch [50/391], Loss: 3.2498, LR: 0.000001\n",
      "Epoch [96], Batch [100/391], Loss: 0.8464, LR: 0.000001\n",
      "Epoch [96], Batch [150/391], Loss: 0.7618, LR: 0.000001\n",
      "Epoch [96], Batch [200/391], Loss: 0.6894, LR: 0.000001\n",
      "Epoch [96], Batch [250/391], Loss: 3.1124, LR: 0.000001\n",
      "Epoch [96], Batch [300/391], Loss: 2.6991, LR: 0.000001\n",
      "Epoch [96], Batch [350/391], Loss: 2.4144, LR: 0.000001\n",
      "Train set: Epoch: 96, Average loss:1.6150, LR: 0.000001 Top-1 Accuracy: 67.3180%, Top-5 Accuracy: 88.2220%, Time consumed:88.77s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|████████████████████████████▊                                                             | 96/300 [2:39:10<5:36:31, 98.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 96, Average loss:0.9704, Top-1 Accuracy: 73.2600%, Top-5 Accuracy: 92.8900%, Time consumed:9.82s\n",
      "\n",
      "EarlyStopping 카운터: 6 / 30\n",
      "Epoch [97], Batch [50/391], Loss: 0.7403, LR: 0.000001\n",
      "Epoch [97], Batch [100/391], Loss: 2.9664, LR: 0.000001\n",
      "Epoch [97], Batch [150/391], Loss: 0.7712, LR: 0.000001\n",
      "Epoch [97], Batch [200/391], Loss: 1.1121, LR: 0.000001\n",
      "Epoch [97], Batch [250/391], Loss: 0.7063, LR: 0.000001\n",
      "Epoch [97], Batch [300/391], Loss: 3.1211, LR: 0.000001\n",
      "Epoch [97], Batch [350/391], Loss: 1.6817, LR: 0.000001\n",
      "Train set: Epoch: 97, Average loss:1.6072, LR: 0.000001 Top-1 Accuracy: 67.1520%, Top-5 Accuracy: 88.4440%, Time consumed:88.34s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|█████████████████████████████                                                             | 97/300 [2:40:49<5:34:51, 98.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 97, Average loss:0.9739, Top-1 Accuracy: 73.0600%, Top-5 Accuracy: 92.8400%, Time consumed:10.61s\n",
      "\n",
      "EarlyStopping 카운터: 7 / 30\n",
      "Epoch [98], Batch [50/391], Loss: 1.2113, LR: 0.000001\n",
      "Epoch [98], Batch [100/391], Loss: 0.7724, LR: 0.000001\n",
      "Epoch [98], Batch [150/391], Loss: 2.8891, LR: 0.000001\n",
      "Epoch [98], Batch [200/391], Loss: 1.4875, LR: 0.000001\n",
      "Epoch [98], Batch [250/391], Loss: 2.7954, LR: 0.000001\n",
      "Epoch [98], Batch [300/391], Loss: 2.0494, LR: 0.000001\n",
      "Epoch [98], Batch [350/391], Loss: 0.7037, LR: 0.000001\n",
      "Train set: Epoch: 98, Average loss:1.5642, LR: 0.000001 Top-1 Accuracy: 68.2180%, Top-5 Accuracy: 88.8640%, Time consumed:90.49s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|█████████████████████████████▍                                                            | 98/300 [2:42:29<5:34:19, 99.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 98, Average loss:0.9646, Top-1 Accuracy: 73.1000%, Top-5 Accuracy: 93.0000%, Time consumed:9.59s\n",
      "\n",
      "EarlyStopping 카운터: 8 / 30\n",
      "Epoch [99], Batch [50/391], Loss: 1.6105, LR: 0.000001\n",
      "Epoch [99], Batch [100/391], Loss: 0.6603, LR: 0.000001\n",
      "Epoch [99], Batch [150/391], Loss: 0.6655, LR: 0.000001\n",
      "Epoch [99], Batch [200/391], Loss: 3.1762, LR: 0.000001\n",
      "Epoch [99], Batch [250/391], Loss: 0.7432, LR: 0.000001\n",
      "Epoch [99], Batch [300/391], Loss: 0.6235, LR: 0.000001\n",
      "Epoch [99], Batch [350/391], Loss: 2.6357, LR: 0.000001\n",
      "Train set: Epoch: 99, Average loss:1.6328, LR: 0.000001 Top-1 Accuracy: 66.9100%, Top-5 Accuracy: 87.8640%, Time consumed:90.50s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|█████████████████████████████▋                                                            | 99/300 [2:44:10<5:34:07, 99.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 99, Average loss:0.9839, Top-1 Accuracy: 73.0800%, Top-5 Accuracy: 92.8000%, Time consumed:10.24s\n",
      "\n",
      "EarlyStopping 카운터: 9 / 30\n",
      "Epoch [100], Batch [50/391], Loss: 2.3497, LR: 0.000001\n",
      "Epoch [100], Batch [100/391], Loss: 3.4052, LR: 0.000001\n",
      "Epoch [100], Batch [150/391], Loss: 2.4297, LR: 0.000001\n",
      "Epoch [100], Batch [200/391], Loss: 2.0851, LR: 0.000001\n",
      "Epoch [100], Batch [250/391], Loss: 0.7044, LR: 0.000001\n",
      "Epoch [100], Batch [300/391], Loss: 2.1042, LR: 0.000001\n",
      "Epoch [100], Batch [350/391], Loss: 2.2862, LR: 0.000001\n",
      "Train set: Epoch: 100, Average loss:1.6392, LR: 0.000001 Top-1 Accuracy: 67.5440%, Top-5 Accuracy: 88.7240%, Time consumed:89.98s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|█████████████████████████████▋                                                           | 100/300 [2:45:49<5:32:25, 99.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 100, Average loss:0.9923, Top-1 Accuracy: 72.9200%, Top-5 Accuracy: 92.8200%, Time consumed:9.72s\n",
      "\n",
      "EarlyStopping 카운터: 10 / 30\n",
      "Epoch [101], Batch [50/391], Loss: 1.6849, LR: 0.000001\n",
      "Epoch [101], Batch [100/391], Loss: 1.9287, LR: 0.000001\n",
      "Epoch [101], Batch [150/391], Loss: 3.2279, LR: 0.000001\n",
      "Epoch [101], Batch [200/391], Loss: 3.0536, LR: 0.000001\n",
      "Epoch [101], Batch [250/391], Loss: 0.5672, LR: 0.000001\n",
      "Epoch [101], Batch [300/391], Loss: 0.6792, LR: 0.000001\n",
      "Epoch [101], Batch [350/391], Loss: 2.2098, LR: 0.000001\n",
      "Train set: Epoch: 101, Average loss:1.6793, LR: 0.000001 Top-1 Accuracy: 66.9920%, Top-5 Accuracy: 88.3500%, Time consumed:89.08s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|█████████████████████████████▉                                                           | 101/300 [2:47:28<5:29:42, 99.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 101, Average loss:0.9637, Top-1 Accuracy: 73.2700%, Top-5 Accuracy: 92.9700%, Time consumed:9.58s\n",
      "\n",
      "EarlyStopping 카운터: 11 / 30\n",
      "Epoch [102], Batch [50/391], Loss: 2.1960, LR: 0.000001\n",
      "Epoch [102], Batch [100/391], Loss: 0.7312, LR: 0.000001\n",
      "Epoch [102], Batch [150/391], Loss: 1.6692, LR: 0.000001\n",
      "Epoch [102], Batch [200/391], Loss: 2.9638, LR: 0.000001\n",
      "Epoch [102], Batch [250/391], Loss: 3.1371, LR: 0.000001\n",
      "Epoch [102], Batch [300/391], Loss: 0.9495, LR: 0.000001\n",
      "Epoch [102], Batch [350/391], Loss: 0.7091, LR: 0.000001\n",
      "Train set: Epoch: 102, Average loss:1.5788, LR: 0.000001 Top-1 Accuracy: 67.6840%, Top-5 Accuracy: 88.6000%, Time consumed:88.71s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|██████████████████████████████▎                                                          | 102/300 [2:49:07<5:27:58, 99.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 102, Average loss:0.9567, Top-1 Accuracy: 73.4000%, Top-5 Accuracy: 93.0600%, Time consumed:10.62s\n",
      "\n",
      "EarlyStopping 카운터: 12 / 30\n",
      "Epoch [103], Batch [50/391], Loss: 2.6783, LR: 0.000001\n",
      "Epoch [103], Batch [100/391], Loss: 0.8257, LR: 0.000001\n",
      "Epoch [103], Batch [150/391], Loss: 2.3256, LR: 0.000001\n",
      "Epoch [103], Batch [200/391], Loss: 2.8512, LR: 0.000001\n",
      "Epoch [103], Batch [250/391], Loss: 2.4490, LR: 0.000001\n",
      "Epoch [103], Batch [300/391], Loss: 0.8055, LR: 0.000001\n",
      "Epoch [103], Batch [350/391], Loss: 3.1510, LR: 0.000001\n",
      "Train set: Epoch: 103, Average loss:1.5882, LR: 0.000001 Top-1 Accuracy: 67.7800%, Top-5 Accuracy: 88.5260%, Time consumed:88.99s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|██████████████████████████████▌                                                          | 103/300 [2:50:46<5:25:33, 99.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 103, Average loss:0.9496, Top-1 Accuracy: 73.3800%, Top-5 Accuracy: 93.0900%, Time consumed:9.63s\n",
      "\n",
      "EarlyStopping 카운터: 13 / 30\n",
      "Epoch [104], Batch [50/391], Loss: 0.8778, LR: 0.000001\n",
      "Epoch [104], Batch [100/391], Loss: 0.6727, LR: 0.000001\n",
      "Epoch [104], Batch [150/391], Loss: 0.7119, LR: 0.000001\n",
      "Epoch [104], Batch [200/391], Loss: 0.6805, LR: 0.000001\n",
      "Epoch [104], Batch [250/391], Loss: 0.6917, LR: 0.000001\n",
      "Epoch [104], Batch [300/391], Loss: 3.1568, LR: 0.000001\n",
      "Epoch [104], Batch [350/391], Loss: 0.7461, LR: 0.000001\n",
      "Train set: Epoch: 104, Average loss:1.4866, LR: 0.000001 Top-1 Accuracy: 69.2200%, Top-5 Accuracy: 89.5440%, Time consumed:89.26s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|██████████████████████████████▊                                                          | 104/300 [2:52:25<5:24:02, 99.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 104, Average loss:0.9674, Top-1 Accuracy: 73.1100%, Top-5 Accuracy: 92.9300%, Time consumed:10.03s\n",
      "\n",
      "EarlyStopping 카운터: 14 / 30\n",
      "Epoch [105], Batch [50/391], Loss: 0.7265, LR: 0.000001\n",
      "Epoch [105], Batch [100/391], Loss: 2.3682, LR: 0.000001\n",
      "Epoch [105], Batch [150/391], Loss: 0.7349, LR: 0.000001\n",
      "Epoch [105], Batch [200/391], Loss: 2.9269, LR: 0.000001\n",
      "Epoch [105], Batch [250/391], Loss: 0.7823, LR: 0.000001\n",
      "Epoch [105], Batch [300/391], Loss: 0.6559, LR: 0.000001\n",
      "Epoch [105], Batch [350/391], Loss: 0.7067, LR: 0.000001\n",
      "Train set: Epoch: 105, Average loss:1.6671, LR: 0.000001 Top-1 Accuracy: 65.9920%, Top-5 Accuracy: 87.4420%, Time consumed:89.12s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███████████████████████████████▏                                                         | 105/300 [2:54:04<5:21:54, 99.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 105, Average loss:0.9582, Top-1 Accuracy: 73.1800%, Top-5 Accuracy: 92.9300%, Time consumed:9.57s\n",
      "\n",
      "EarlyStopping 카운터: 15 / 30\n",
      "Epoch [106], Batch [50/391], Loss: 0.9357, LR: 0.000001\n",
      "Epoch [106], Batch [100/391], Loss: 3.1064, LR: 0.000001\n",
      "Epoch [106], Batch [150/391], Loss: 2.8176, LR: 0.000001\n",
      "Epoch [106], Batch [200/391], Loss: 2.3291, LR: 0.000001\n",
      "Epoch [106], Batch [250/391], Loss: 0.7025, LR: 0.000001\n",
      "Epoch [106], Batch [300/391], Loss: 0.7426, LR: 0.000001\n",
      "Epoch [106], Batch [350/391], Loss: 0.8327, LR: 0.000001\n",
      "Train set: Epoch: 106, Average loss:1.6093, LR: 0.000001 Top-1 Accuracy: 67.0580%, Top-5 Accuracy: 87.9440%, Time consumed:88.35s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███████████████████████████████▍                                                         | 106/300 [2:55:42<5:19:42, 98.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 106, Average loss:0.9674, Top-1 Accuracy: 73.1000%, Top-5 Accuracy: 92.9100%, Time consumed:10.12s\n",
      "\n",
      "EarlyStopping 카운터: 16 / 30\n",
      "Epoch [107], Batch [50/391], Loss: 3.0357, LR: 0.000001\n",
      "Epoch [107], Batch [100/391], Loss: 0.7279, LR: 0.000001\n",
      "Epoch [107], Batch [150/391], Loss: 1.7373, LR: 0.000001\n",
      "Epoch [107], Batch [200/391], Loss: 3.0585, LR: 0.000001\n",
      "Epoch [107], Batch [250/391], Loss: 2.9022, LR: 0.000001\n",
      "Epoch [107], Batch [300/391], Loss: 0.7887, LR: 0.000001\n",
      "Epoch [107], Batch [350/391], Loss: 3.1752, LR: 0.000001\n",
      "Train set: Epoch: 107, Average loss:1.6069, LR: 0.000001 Top-1 Accuracy: 67.4820%, Top-5 Accuracy: 88.3340%, Time consumed:90.37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███████████████████████████████▋                                                         | 107/300 [2:57:22<5:19:09, 99.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 107, Average loss:0.9547, Top-1 Accuracy: 73.4100%, Top-5 Accuracy: 93.1100%, Time consumed:9.65s\n",
      "\n",
      "EarlyStopping 카운터: 17 / 30\n",
      "Epoch [108], Batch [50/391], Loss: 0.8682, LR: 0.000001\n",
      "Epoch [108], Batch [100/391], Loss: 0.6657, LR: 0.000001\n",
      "Epoch [108], Batch [150/391], Loss: 0.7307, LR: 0.000001\n",
      "Epoch [108], Batch [200/391], Loss: 3.0684, LR: 0.000001\n",
      "Epoch [108], Batch [250/391], Loss: 2.9598, LR: 0.000001\n",
      "Epoch [108], Batch [300/391], Loss: 0.7293, LR: 0.000001\n",
      "Epoch [108], Batch [350/391], Loss: 2.3353, LR: 0.000001\n",
      "Train set: Epoch: 108, Average loss:1.6044, LR: 0.000001 Top-1 Accuracy: 67.4700%, Top-5 Accuracy: 88.4500%, Time consumed:88.50s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|████████████████████████████████                                                         | 108/300 [2:59:02<5:18:11, 99.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 108, Average loss:0.9698, Top-1 Accuracy: 73.1200%, Top-5 Accuracy: 92.9800%, Time consumed:11.42s\n",
      "\n",
      "EarlyStopping 카운터: 18 / 30\n",
      "Epoch [109], Batch [50/391], Loss: 1.3243, LR: 0.000001\n",
      "Epoch [109], Batch [100/391], Loss: 0.7330, LR: 0.000001\n",
      "Epoch [109], Batch [150/391], Loss: 0.7027, LR: 0.000001\n",
      "Epoch [109], Batch [200/391], Loss: 0.6732, LR: 0.000001\n",
      "Epoch [109], Batch [250/391], Loss: 2.1762, LR: 0.000001\n",
      "Epoch [109], Batch [300/391], Loss: 0.6834, LR: 0.000001\n",
      "Epoch [109], Batch [350/391], Loss: 1.2117, LR: 0.000001\n",
      "Train set: Epoch: 109, Average loss:1.5455, LR: 0.000001 Top-1 Accuracy: 68.5060%, Top-5 Accuracy: 89.2240%, Time consumed:90.65s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|████████████████████████████████▎                                                        | 109/300 [3:00:44<5:18:10, 99.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 109, Average loss:0.9666, Top-1 Accuracy: 73.2900%, Top-5 Accuracy: 93.0000%, Time consumed:10.50s\n",
      "\n",
      "EarlyStopping 카운터: 19 / 30\n",
      "Epoch [110], Batch [50/391], Loss: 0.7562, LR: 0.000001\n",
      "Epoch [110], Batch [100/391], Loss: 0.9126, LR: 0.000001\n",
      "Epoch [110], Batch [150/391], Loss: 0.6424, LR: 0.000001\n",
      "Epoch [110], Batch [200/391], Loss: 0.6050, LR: 0.000001\n",
      "Epoch [110], Batch [250/391], Loss: 3.1130, LR: 0.000001\n",
      "Epoch [110], Batch [300/391], Loss: 0.6771, LR: 0.000001\n",
      "Epoch [110], Batch [350/391], Loss: 0.6277, LR: 0.000001\n",
      "Train set: Epoch: 110, Average loss:1.7288, LR: 0.000001 Top-1 Accuracy: 65.0940%, Top-5 Accuracy: 86.5900%, Time consumed:89.28s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|████████████████████████████████▋                                                        | 110/300 [3:02:22<5:15:29, 99.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 110, Average loss:0.9612, Top-1 Accuracy: 73.1900%, Top-5 Accuracy: 93.0400%, Time consumed:9.61s\n",
      "\n",
      "EarlyStopping 카운터: 20 / 30\n",
      "Epoch [111], Batch [50/391], Loss: 0.6363, LR: 0.000001\n",
      "Epoch [111], Batch [100/391], Loss: 0.6534, LR: 0.000001\n",
      "Epoch [111], Batch [150/391], Loss: 0.7219, LR: 0.000001\n",
      "Epoch [111], Batch [200/391], Loss: 0.8143, LR: 0.000001\n",
      "Epoch [111], Batch [250/391], Loss: 1.3571, LR: 0.000001\n",
      "Epoch [111], Batch [300/391], Loss: 0.8235, LR: 0.000001\n",
      "Epoch [111], Batch [350/391], Loss: 0.7298, LR: 0.000001\n",
      "Train set: Epoch: 112, Average loss:1.5533, LR: 0.000001 Top-1 Accuracy: 69.0680%, Top-5 Accuracy: 89.2820%, Time consumed:88.96s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|█████████████████████████████████▏                                                       | 112/300 [3:05:40<5:11:10, 99.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 112, Average loss:0.9581, Top-1 Accuracy: 73.2600%, Top-5 Accuracy: 93.0100%, Time consumed:9.90s\n",
      "\n",
      "EarlyStopping 카운터: 22 / 30\n",
      "Epoch [113], Batch [50/391], Loss: 2.3824, LR: 0.000001\n",
      "Epoch [113], Batch [100/391], Loss: 0.6735, LR: 0.000001\n",
      "Epoch [113], Batch [150/391], Loss: 0.6432, LR: 0.000001\n",
      "Epoch [113], Batch [200/391], Loss: 2.9748, LR: 0.000001\n",
      "Epoch [113], Batch [250/391], Loss: 3.0994, LR: 0.000001\n",
      "Epoch [113], Batch [300/391], Loss: 0.7215, LR: 0.000001\n",
      "Epoch [113], Batch [350/391], Loss: 0.7452, LR: 0.000001\n",
      "Train set: Epoch: 113, Average loss:1.5510, LR: 0.000001 Top-1 Accuracy: 68.1940%, Top-5 Accuracy: 88.9180%, Time consumed:88.49s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|█████████████████████████████████▌                                                       | 113/300 [3:07:19<5:08:55, 99.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 113, Average loss:0.9736, Top-1 Accuracy: 73.0700%, Top-5 Accuracy: 92.7700%, Time consumed:10.18s\n",
      "\n",
      "EarlyStopping 카운터: 23 / 30\n",
      "Epoch [114], Batch [50/391], Loss: 0.8645, LR: 0.000001\n",
      "Epoch [114], Batch [100/391], Loss: 0.8733, LR: 0.000001\n",
      "Epoch [114], Batch [150/391], Loss: 0.6472, LR: 0.000001\n",
      "Epoch [114], Batch [200/391], Loss: 2.9587, LR: 0.000001\n",
      "Epoch [114], Batch [250/391], Loss: 0.6635, LR: 0.000001\n",
      "Epoch [114], Batch [300/391], Loss: 2.3052, LR: 0.000001\n",
      "Epoch [114], Batch [350/391], Loss: 0.7825, LR: 0.000001\n",
      "Train set: Epoch: 114, Average loss:1.5733, LR: 0.000001 Top-1 Accuracy: 67.7720%, Top-5 Accuracy: 88.2240%, Time consumed:88.43s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|█████████████████████████████████▊                                                       | 114/300 [3:08:57<5:06:18, 98.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 114, Average loss:0.9668, Top-1 Accuracy: 73.1600%, Top-5 Accuracy: 92.9200%, Time consumed:9.63s\n",
      "\n",
      "EarlyStopping 카운터: 24 / 30\n",
      "Epoch [115], Batch [50/391], Loss: 3.2944, LR: 0.000001\n",
      "Epoch [115], Batch [100/391], Loss: 0.6782, LR: 0.000001\n",
      "Epoch [115], Batch [150/391], Loss: 0.7312, LR: 0.000001\n",
      "Epoch [115], Batch [200/391], Loss: 2.7221, LR: 0.000001\n",
      "Epoch [115], Batch [250/391], Loss: 0.6066, LR: 0.000001\n",
      "Epoch [115], Batch [300/391], Loss: 0.8089, LR: 0.000001\n",
      "Epoch [115], Batch [350/391], Loss: 0.7421, LR: 0.000001\n",
      "Train set: Epoch: 115, Average loss:1.6048, LR: 0.000001 Top-1 Accuracy: 67.7140%, Top-5 Accuracy: 88.6160%, Time consumed:88.65s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|██████████████████████████████████                                                       | 115/300 [3:10:36<5:04:40, 98.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 115, Average loss:0.9730, Top-1 Accuracy: 73.0700%, Top-5 Accuracy: 92.8500%, Time consumed:10.17s\n",
      "\n",
      "EarlyStopping 카운터: 25 / 30\n",
      "Epoch [116], Batch [50/391], Loss: 2.6250, LR: 0.000001\n",
      "Epoch [116], Batch [100/391], Loss: 2.8137, LR: 0.000001\n",
      "Epoch [116], Batch [150/391], Loss: 0.6366, LR: 0.000001\n",
      "Epoch [116], Batch [200/391], Loss: 3.1010, LR: 0.000001\n",
      "Epoch [116], Batch [250/391], Loss: 2.1306, LR: 0.000001\n",
      "Epoch [116], Batch [300/391], Loss: 0.7525, LR: 0.000001\n",
      "Epoch [116], Batch [350/391], Loss: 1.8907, LR: 0.000001\n",
      "Train set: Epoch: 116, Average loss:1.5292, LR: 0.000001 Top-1 Accuracy: 68.9140%, Top-5 Accuracy: 89.2000%, Time consumed:89.60s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|██████████████████████████████████▍                                                      | 116/300 [3:12:16<5:03:45, 99.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 116, Average loss:0.9598, Top-1 Accuracy: 73.1500%, Top-5 Accuracy: 93.0300%, Time consumed:10.00s\n",
      "\n",
      "EarlyStopping 카운터: 26 / 30\n",
      "Epoch [117], Batch [50/391], Loss: 0.7475, LR: 0.000001\n",
      "Epoch [117], Batch [100/391], Loss: 2.8719, LR: 0.000001\n",
      "Epoch [117], Batch [150/391], Loss: 1.3277, LR: 0.000001\n",
      "Epoch [117], Batch [200/391], Loss: 1.9171, LR: 0.000001\n",
      "Epoch [117], Batch [250/391], Loss: 0.6419, LR: 0.000001\n",
      "Epoch [117], Batch [300/391], Loss: 3.4279, LR: 0.000001\n",
      "Epoch [117], Batch [350/391], Loss: 2.7917, LR: 0.000001\n",
      "Train set: Epoch: 117, Average loss:1.6598, LR: 0.000001 Top-1 Accuracy: 65.9380%, Top-5 Accuracy: 87.4360%, Time consumed:89.31s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|██████████████████████████████████▋                                                      | 117/300 [3:13:55<5:02:22, 99.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 117, Average loss:0.9714, Top-1 Accuracy: 73.0400%, Top-5 Accuracy: 92.8800%, Time consumed:10.02s\n",
      "\n",
      "EarlyStopping 카운터: 27 / 30\n",
      "Epoch [118], Batch [50/391], Loss: 0.8762, LR: 0.000001\n",
      "Epoch [118], Batch [100/391], Loss: 0.6879, LR: 0.000001\n",
      "Epoch [118], Batch [150/391], Loss: 0.6695, LR: 0.000001\n",
      "Epoch [118], Batch [200/391], Loss: 0.6715, LR: 0.000001\n",
      "Epoch [118], Batch [250/391], Loss: 1.0966, LR: 0.000001\n",
      "Epoch [118], Batch [300/391], Loss: 0.7461, LR: 0.000001\n",
      "Epoch [118], Batch [350/391], Loss: 0.7099, LR: 0.000001\n",
      "Train set: Epoch: 118, Average loss:1.6310, LR: 0.000001 Top-1 Accuracy: 66.6720%, Top-5 Accuracy: 87.7040%, Time consumed:92.33s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███████████████████████████████████                                                      | 118/300 [3:15:37<5:03:15, 99.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 118, Average loss:0.9729, Top-1 Accuracy: 72.9700%, Top-5 Accuracy: 92.8700%, Time consumed:9.59s\n",
      "\n",
      "EarlyStopping 카운터: 28 / 30\n",
      "Epoch [119], Batch [50/391], Loss: 0.7429, LR: 0.000001\n",
      "Epoch [119], Batch [100/391], Loss: 0.7052, LR: 0.000001\n",
      "Epoch [119], Batch [150/391], Loss: 2.3201, LR: 0.000001\n",
      "Epoch [119], Batch [200/391], Loss: 0.8259, LR: 0.000001\n",
      "Epoch [119], Batch [250/391], Loss: 2.4787, LR: 0.000001\n",
      "Epoch [119], Batch [300/391], Loss: 2.7187, LR: 0.000001\n",
      "Epoch [119], Batch [350/391], Loss: 3.0349, LR: 0.000001\n",
      "Train set: Epoch: 119, Average loss:1.5617, LR: 0.000001 Top-1 Accuracy: 68.0120%, Top-5 Accuracy: 88.6920%, Time consumed:88.29s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███████████████████████████████████▎                                                     | 119/300 [3:17:15<5:00:14, 99.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 119, Average loss:0.9606, Top-1 Accuracy: 73.4800%, Top-5 Accuracy: 93.0400%, Time consumed:10.19s\n",
      "\n",
      "EarlyStopping 카운터: 29 / 30\n",
      "Epoch [120], Batch [50/391], Loss: 1.4878, LR: 0.000001\n",
      "Epoch [120], Batch [100/391], Loss: 0.7332, LR: 0.000001\n",
      "Epoch [120], Batch [150/391], Loss: 2.8880, LR: 0.000001\n",
      "Epoch [120], Batch [200/391], Loss: 0.8008, LR: 0.000001\n",
      "Epoch [120], Batch [250/391], Loss: 2.7406, LR: 0.000001\n",
      "Epoch [120], Batch [300/391], Loss: 0.6972, LR: 0.000001\n",
      "Epoch [120], Batch [350/391], Loss: 0.9070, LR: 0.000001\n",
      "Train set: Epoch: 120, Average loss:1.6509, LR: 0.000001 Top-1 Accuracy: 66.5000%, Top-5 Accuracy: 87.4680%, Time consumed:92.01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████████▉                                                     | 119/300 [3:18:58<5:02:38, 100.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 120, Average loss:0.9525, Top-1 Accuracy: 73.3500%, Top-5 Accuracy: 93.0500%, Time consumed:10.28s\n",
      "\n",
      "EarlyStopping 카운터: 30 / 30\n",
      "에폭 120에서 학습 조기 종료. 최고 성능 에폭: 90\n",
      "테스트 정확도 기준 최고 모델 로드 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 300, Average loss:0.9515, Top-1 Accuracy: 73.6400%, Top-5 Accuracy: 93.0700%, Time consumed:9.73s\n",
      "\n",
      "완료! 최고 테스트 top-1 정확도: 73.64%, 최고 테스트 top-5 정확도: 93.19%\n",
      "최종 테스트 top-1 정확도: 73.64%, 최종 테스트 top-5 정확도: 93.07%\n",
      "전체 학습 시간: 11948.04 초\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>learning_rate</td><td>▂▃▄▆█████▄▄▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_accuracy_top1</td><td>▁▂▄▅▅▇▇▇▇▇██████████████████████████████</td></tr><tr><td>test_accuracy_top5</td><td>▁▄▅▅▇▇▇▇▇▇██████████████████████████████</td></tr><tr><td>test_loss</td><td>█▆▅▄▄▃▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>total_training_time</td><td>▁</td></tr><tr><td>train_accuracy_top1</td><td>▁▂▃▄▄▅▆▇▇▇█▇▇███████████████████████████</td></tr><tr><td>train_accuracy_top5</td><td>▁▂▃▅▅▆▇▆▇▇▇█████████████████████████████</td></tr><tr><td>train_loss</td><td>█▇▄▄▄▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>90</td></tr><tr><td>best_test_accuracy_top1</td><td>73.64</td></tr><tr><td>best_test_accuracy_top5</td><td>93.19</td></tr><tr><td>early_stopped</td><td>True</td></tr><tr><td>early_stopped_epoch</td><td>120</td></tr><tr><td>epoch</td><td>120</td></tr><tr><td>final_test_accuracy_top1</td><td>73.64</td></tr><tr><td>final_test_accuracy_top5</td><td>93.07</td></tr><tr><td>learning_rate</td><td>0.0</td></tr><tr><td>test_accuracy_top1</td><td>73.35</td></tr><tr><td>test_accuracy_top5</td><td>93.05</td></tr><tr><td>test_loss</td><td>0.95254</td></tr><tr><td>total_training_time</td><td>11948.03757</td></tr><tr><td>train_accuracy_top1</td><td>66.5</td></tr><tr><td>train_accuracy_top5</td><td>87.468</td></tr><tr><td>train_loss</td><td>1.6509</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">resnet18_cfc,lr=0.005,factor=0.5,SAM_SGD,PSKD,Nesterov=False</strong> at: <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/qmp4pxc4' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/qmp4pxc4</a><br> View project at: <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250428_094307-qmp4pxc4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.v2 as transforms_v2  # CutMix를 위한 v2 transforms 추가\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "from tools.tool import AccuracyEarlyStopping, WarmUpLR, SAM, PSKD  # 수정된 AccuracyEarlyStopping 클래스 임포트\n",
    "from models.resnet import resnet18\n",
    "\n",
    "wandb.login(key=\"ef091b9abcea3186341ddf8995d62bde62d7469e\")\n",
    "wandb.init(project=\"PBL-2\", name=\"resnet18_cfc,lr=0.005,factor=0.5,SAM_SGD,PSKD,Nesterov=False\")  \n",
    "\n",
    "# WandB 설정 - ResNeXt 코드의 파라미터 사용하되 모델만 resnet18로 변경\n",
    "config = {\n",
    "    # 모델 설정\n",
    "    \"model\": \"resnet18\",  # 모델만 resnet18로 유지\n",
    "    \"batch_size\": 128,    \n",
    "    \"num_epochs\": 300,\n",
    "    \n",
    "    \"learning_rate\": 0.005,  \n",
    "    \"optimizer\": \"SAM_SGD\",\n",
    "    \"momentum\": 0.9,\n",
    "    \"weight_decay\": 5e-4,\n",
    "    \"nesterov\": False,\n",
    "    \n",
    "    # SAM 옵티마이저 설정\n",
    "    \"rho\": 0.05,\n",
    "    \"adaptive\": False,\n",
    "    \n",
    "    # 학습 과정 설정\n",
    "    \"seed\": 2025,\n",
    "    \"deterministic\": False,\n",
    "    \"patience\": 30,  # early stopping patience\n",
    "    \"max_epochs_wait\": float('inf'),\n",
    "    \n",
    "    # 데이터 증강 설정\n",
    "    \"cutmix_alpha\": 1.0,  # CutMix 알파 파라미터\n",
    "    \"cutmix_prob\": 0.5,   # CutMix 적용 확률\n",
    "    \"crop_padding\": 4,    # RandomCrop 패딩 크기\n",
    "    \"crop_size\": 32,      # RandomCrop 크기 (CIFAR-100 이미지 크기는 32x32)\n",
    "    \n",
    "    # 스케줄러 설정 - ResNeXt 파라미터 적용\n",
    "    \"warmup_epochs\": 10,  # ResNeXt와 동일하게 설정\n",
    "    \"lr_scheduler\": \"ReduceLROnPlateau\",\n",
    "    \"lr_factor\": 0.5,\n",
    "    \"lr_patience\": 5,\n",
    "    \"lr_threshold\": 0.1,\n",
    "    \"min_lr\": 1e-6,\n",
    "    \n",
    "    # 시스템 설정\n",
    "    \"num_workers\": 32,\n",
    "    \"pin_memory\": True,\n",
    "}\n",
    "\n",
    "wandb.config.update(config)\n",
    "\n",
    "# CIFAR-100 데이터셋 로드 - 기본 train/test 분할 사용\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(config[\"crop_size\"], padding=config[\"crop_padding\"]),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR100(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR100(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "# DataLoader 생성 - config 사용\n",
    "trainloader = DataLoader(\n",
    "    trainset, \n",
    "    batch_size=config[\"batch_size\"], \n",
    "    shuffle=True, \n",
    "    pin_memory=config[\"pin_memory\"], \n",
    "    num_workers=config[\"num_workers\"]\n",
    ")\n",
    "\n",
    "testloader = DataLoader(\n",
    "    testset, \n",
    "    batch_size=config[\"batch_size\"], \n",
    "    shuffle=False, \n",
    "    pin_memory=config[\"pin_memory\"], \n",
    "    num_workers=config[\"num_workers\"]\n",
    ")\n",
    "\n",
    "print(f\"Train set size: {len(trainset)}\")\n",
    "print(f\"Test set size: {len(testset)}\")\n",
    "\n",
    "# CutMix 변환 정의\n",
    "cutmix = transforms_v2.CutMix(alpha=config[\"cutmix_alpha\"], num_classes=100)  # CIFAR-100은 100개 클래스\n",
    "\n",
    "def train(model, trainloader, criterion, optimizer, device, epoch, warmup_scheduler=None, warmup_epochs=None):\n",
    "    \"\"\"\n",
    "    학습 함수 (CutMix 및 PSKD 적용)\n",
    "    \"\"\"\n",
    "    # config에서 warmup_epochs 가져오기 (None이면)\n",
    "    if warmup_epochs is None:\n",
    "        warmup_epochs = config[\"warmup_epochs\"]\n",
    "        \n",
    "    model.train()   # 모델을 학습 모드로 설정\n",
    "    start_time = time.time()  # 시간 측정 시작\n",
    "    running_loss = 0.0\n",
    "    correct_top1 = 0\n",
    "    correct_top5 = 0\n",
    "    total = 0\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(trainloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # CutMix 확률적 적용\n",
    "        if random.random() < config[\"cutmix_prob\"]:\n",
    "            inputs, labels = cutmix(inputs, labels)\n",
    "            # 이 경우 labels은 원-핫 인코딩 형태로 변환됨\n",
    "            use_cutmix = True\n",
    "        else:\n",
    "            # 일반 레이블을 원-핫 인코딩으로 변환 (PSKD에 필요)\n",
    "            batch_size = labels.size(0)\n",
    "            one_hot_labels = torch.zeros(batch_size, 100).to(device)  # CIFAR-100은 100개 클래스\n",
    "            one_hot_labels.scatter_(1, labels.unsqueeze(1), 1)\n",
    "            use_cutmix = False\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # SAM 첫 번째 스텝을 위한 손실 계산\n",
    "        if use_cutmix:\n",
    "            # CutMix가 적용된 경우 (이미 원-핫 인코딩된 레이블)\n",
    "            loss = criterion(outputs, labels)\n",
    "        else:\n",
    "            # 일반적인 경우 (원-핫 인코딩으로 변환한 레이블)\n",
    "            loss = criterion(outputs, one_hot_labels)\n",
    "            \n",
    "        loss.backward()\n",
    "        optimizer.first_step(zero_grad=True)\n",
    "        \n",
    "        # SAM 두 번째 스텝을 위한 손실 계산\n",
    "        outputs = model(inputs)\n",
    "        if use_cutmix:\n",
    "            loss = criterion(outputs, labels)\n",
    "        else:\n",
    "            loss = criterion(outputs, one_hot_labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.second_step(zero_grad=True)\n",
    "        \n",
    "        # 학습률 스케줄러 업데이트 - warmup 스케줄러만 여기서 업데이트\n",
    "        if epoch < warmup_epochs and warmup_scheduler is not None:\n",
    "            warmup_scheduler.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # 정확도 계산 - CutMix 적용 여부에 따라 다르게 처리\n",
    "        if use_cutmix:\n",
    "            # 원-핫 인코딩된 레이블에서 argmax를 사용해 가장 큰 값의 인덱스 추출\n",
    "            _, label_idx = labels.max(1)\n",
    "        else:\n",
    "            # 정수 인덱스 레이블 그대로 사용\n",
    "            label_idx = labels\n",
    "            \n",
    "        # top-1 정확도 계산\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += inputs.size(0)\n",
    "        correct_top1 += predicted.eq(label_idx).sum().item()\n",
    "        \n",
    "        # top-5 정확도 계산\n",
    "        _, top5_idx = outputs.topk(5, 1, largest=True, sorted=True)\n",
    "        correct_top5 += sum([1 for i in range(len(label_idx)) if label_idx[i] in top5_idx[i]])\n",
    "        \n",
    "        if (i + 1) % 50 == 0:  # 50 배치마다 출력\n",
    "            print(f'Epoch [{epoch+1}], Batch [{i+1}/{len(trainloader)}], Loss: {loss.item():.4f}, LR: {optimizer.param_groups[0][\"lr\"]:.6f}')\n",
    "    \n",
    "    epoch_loss = running_loss / len(trainloader)\n",
    "    accuracy_top1 = 100.0 * correct_top1 / total\n",
    "    accuracy_top5 = 100.0 * correct_top5 / total\n",
    "    \n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    # 학습 세트에 대한 성능 출력\n",
    "    print(f'Train set: Epoch: {epoch+1}, Average loss:{epoch_loss:.4f}, LR: {optimizer.param_groups[0][\"lr\"]:.6f} '\n",
    "          f'Top-1 Accuracy: {accuracy_top1:.4f}%, Top-5 Accuracy: {accuracy_top5:.4f}%, Time consumed:{train_time:.2f}s')\n",
    "    \n",
    "    return epoch_loss, accuracy_top1, accuracy_top5\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device, epoch, phase=\"test\"):\n",
    "    \"\"\"\n",
    "    평가 함수 (PSKD 손실 함수 적용)\n",
    "    \"\"\"\n",
    "    model.eval()  # 모델을 평가 모드로 설정\n",
    "    start_time = time.time()  # 시간 측정 시작\n",
    "    \n",
    "    eval_loss = 0.0\n",
    "    correct_top1 = 0\n",
    "    correct_top5 = 0\n",
    "    total = 0\n",
    "    \n",
    "    # 그래디언트 계산 비활성화\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # 원-핫 인코딩 변환 (PSKD에 필요)\n",
    "            batch_size = labels.size(0)\n",
    "            one_hot_labels = torch.zeros(batch_size, 100).to(device)  # CIFAR-100은 100개 클래스\n",
    "            one_hot_labels.scatter_(1, labels.unsqueeze(1), 1)\n",
    "            \n",
    "            # 순전파\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # PSKD 손실 계산\n",
    "            loss = criterion(outputs, one_hot_labels)\n",
    "            eval_loss += loss.item()\n",
    "            \n",
    "            # top-1 정확도 계산\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct_top1 += (predicted == labels).sum().item()\n",
    "            \n",
    "            # top-5 정확도 계산\n",
    "            _, top5_idx = outputs.topk(5, 1, largest=True, sorted=True)\n",
    "            correct_top5 += top5_idx.eq(labels.view(-1, 1).expand_as(top5_idx)).sum().item()\n",
    "    \n",
    "    # 평균 손실 및 정확도 계산\n",
    "    eval_loss = eval_loss / len(dataloader)\n",
    "    accuracy_top1 = 100.0 * correct_top1 / total\n",
    "    accuracy_top5 = 100.0 * correct_top5 / total\n",
    "    \n",
    "    # 평가 시간 계산\n",
    "    eval_time = time.time() - start_time\n",
    "    \n",
    "    # 테스트 세트에 대한 성능 출력\n",
    "    print(f'{phase.capitalize()} set: Epoch: {epoch+1}, Average loss:{eval_loss:.4f}, '\n",
    "          f'Top-1 Accuracy: {accuracy_top1:.4f}%, Top-5 Accuracy: {accuracy_top5:.4f}%, Time consumed:{eval_time:.2f}s')\n",
    "    print()\n",
    "    \n",
    "    return eval_loss, accuracy_top1, accuracy_top5\n",
    "\n",
    "# 메인 학습 루프\n",
    "def main_training_loop(model, trainloader, testloader, criterion, optimizer, device, num_epochs=None, patience=None, max_epochs_wait=None, warmup_scheduler=None, main_scheduler=None, warmup_epochs=None):\n",
    "    \"\"\"\n",
    "    메인 학습 루프 (accuracy 기준 early stopping) - config에서 기본값 가져오기\n",
    "    \"\"\"\n",
    "    # config에서 값 가져오기 (None이면)\n",
    "    if num_epochs is None:\n",
    "        num_epochs = config[\"num_epochs\"]\n",
    "    if patience is None:\n",
    "        patience = config[\"patience\"]\n",
    "    if max_epochs_wait is None:\n",
    "        max_epochs_wait = config[\"max_epochs_wait\"]\n",
    "    if warmup_epochs is None:\n",
    "        warmup_epochs = config[\"warmup_epochs\"]\n",
    "        \n",
    "    # 정확도 기반 얼리 스토핑 사용\n",
    "    early_stopping = AccuracyEarlyStopping(patience=patience, verbose=True, path='checkpoint.pt', max_epochs=max_epochs_wait)\n",
    "    \n",
    "    best_test_acc_top1 = 0.0\n",
    "    best_test_acc_top5 = 0.0\n",
    "    \n",
    "    # 테스트 정확도 기록을 위한 리스트\n",
    "    test_acc_top1_history = []\n",
    "    \n",
    "    # tqdm을 사용한 진행 상황 표시\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        # 학습\n",
    "        train_loss, train_acc_top1, train_acc_top5 = train(\n",
    "            model, \n",
    "            trainloader, \n",
    "            criterion, \n",
    "            optimizer, \n",
    "            device, \n",
    "            epoch, \n",
    "            warmup_scheduler, \n",
    "            warmup_epochs\n",
    "        )\n",
    "        \n",
    "        # 테스트 데이터로 평가\n",
    "        test_loss, test_acc_top1, test_acc_top5 = evaluate(model, testloader, criterion, device, epoch, phase=\"test\")\n",
    "\n",
    "        # 웜업 이후 스케줄러 업데이트 \n",
    "        if epoch >= warmup_epochs and main_scheduler is not None:\n",
    "            if isinstance(main_scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "                main_scheduler.step(test_acc_top1)  # 테스트 정확도에 따라 학습률 업데이트\n",
    "            else:\n",
    "                main_scheduler.step()  # 다른 스케줄러 (예: CosineAnnealingLR)\n",
    "            \n",
    "        # 테스트 정확도 기록\n",
    "        test_acc_top1_history.append(test_acc_top1)\n",
    "        \n",
    "        # WandB에 로깅\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_accuracy_top1\": train_acc_top1,\n",
    "            \"train_accuracy_top5\": train_acc_top5,\n",
    "            \"test_loss\": test_loss,\n",
    "            \"test_accuracy_top1\": test_acc_top1,\n",
    "            \"test_accuracy_top5\": test_acc_top5\n",
    "        })\n",
    "            \n",
    "        # 최고 정확도 모델 저장 (top-1 기준)\n",
    "        if test_acc_top1 > best_test_acc_top1:\n",
    "            best_test_acc_top1 = test_acc_top1\n",
    "            best_test_acc_top5_at_best_top1 = test_acc_top5\n",
    "            print(f'새로운 최고 top-1 정확도: {best_test_acc_top1:.2f}%, top-5 정확도: {best_test_acc_top5_at_best_top1:.2f}%')\n",
    "            # 모델 저장\n",
    "            model_path = f'best_model_{wandb.run.name}.pth'\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            \n",
    "            # WandB에 모델 아티팩트 저장\n",
    "            wandb.save(model_path)\n",
    "        \n",
    "        # top-5 accuracy 기록 업데이트\n",
    "        if test_acc_top5 > best_test_acc_top5:\n",
    "            best_test_acc_top5 = test_acc_top5\n",
    "            print(f'새로운 최고 top-5 정확도: {best_test_acc_top5:.2f}%')\n",
    "\n",
    "        # Early stopping 체크 (test_acc_top1 기준)\n",
    "        early_stopping(test_acc_top1, model, epoch)\n",
    "        if early_stopping.early_stop:\n",
    "            print(f\"에폭 {epoch+1}에서 학습 조기 종료. 최고 성능 에폭: {early_stopping.best_epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    # 훈련 완료 후 최고 모델 로드\n",
    "    print(\"테스트 정확도 기준 최고 모델 로드 중...\")\n",
    "    model_path = f'best_model_{wandb.run.name}.pth'\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    # 최종 테스트 세트 평가\n",
    "    final_test_loss, final_test_acc_top1, final_test_acc_top5 = evaluate(model, testloader, criterion, device, num_epochs-1, phase=\"test\")\n",
    "    \n",
    "    print(f'완료! 최고 테스트 top-1 정확도: {best_test_acc_top1:.2f}%, 최고 테스트 top-5 정확도: {best_test_acc_top5:.2f}%')\n",
    "    print(f'최종 테스트 top-1 정확도: {final_test_acc_top1:.2f}%, 최종 테스트 top-5 정확도: {final_test_acc_top5:.2f}%')\n",
    "    \n",
    "    # WandB에 최종 결과 기록\n",
    "    wandb.run.summary[\"best_test_accuracy_top1\"] = best_test_acc_top1\n",
    "    wandb.run.summary[\"best_test_accuracy_top5\"] = best_test_acc_top5\n",
    "    wandb.run.summary[\"final_test_accuracy_top1\"] = final_test_acc_top1\n",
    "    wandb.run.summary[\"final_test_accuracy_top5\"] = final_test_acc_top5\n",
    "\n",
    "    # Early stopping 정보 저장\n",
    "    if early_stopping.early_stop:\n",
    "        wandb.run.summary[\"early_stopped\"] = True\n",
    "        wandb.run.summary[\"early_stopped_epoch\"] = epoch+1\n",
    "        wandb.run.summary[\"best_epoch\"] = early_stopping.best_epoch+1\n",
    "    else:\n",
    "        wandb.run.summary[\"early_stopped\"] = False\n",
    "\n",
    "\n",
    "# 디바이스 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 모델 초기화 - config 기반\n",
    "if config[\"model\"] == \"resnet18\":\n",
    "    model = resnet18().to(device)\n",
    "else:\n",
    "    raise ValueError(f\"지원되지 않는 모델: {config['model']}\")\n",
    "\n",
    "# PSKD 손실 함수 설정 (두 번째 코드의 손실 함수 유지)\n",
    "criterion = PSKD()\n",
    "\n",
    "# 옵티마이저 설정 - ResNeXt와 동일한 파라미터 적용\n",
    "if config[\"optimizer\"] == \"SAM_SGD\":\n",
    "    base_optimizer = optim.SGD\n",
    "    optimizer = SAM(\n",
    "        model.parameters(), \n",
    "        base_optimizer, \n",
    "        lr=config[\"learning_rate\"],\n",
    "        momentum=config[\"momentum\"],\n",
    "        weight_decay=config[\"weight_decay\"],\n",
    "        nesterov=config[\"nesterov\"],\n",
    "        rho=config[\"rho\"],\n",
    "        adaptive=config[\"adaptive\"]\n",
    "    )\n",
    "else:\n",
    "    raise ValueError(f\"지원되지 않는 옵티마이저: {config['optimizer']}\")\n",
    "\n",
    "# WarmUpLR 스케줄러 초기화 - ResNeXt와 동일하게 10 에폭으로 설정\n",
    "warmup_steps = config[\"warmup_epochs\"] * len(trainloader)\n",
    "warmup_scheduler = WarmUpLR(optimizer, total_iters=warmup_steps)\n",
    "\n",
    "# 웜업 이후 사용할 스케줄러 설정 - ResNeXt와 동일한 파라미터 적용\n",
    "if config[\"lr_scheduler\"] == \"ReduceLROnPlateau\":\n",
    "    main_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, \n",
    "        mode='max',\n",
    "        factor=config[\"lr_factor\"],\n",
    "        patience=config[\"lr_patience\"],\n",
    "        verbose=True,\n",
    "        threshold=config[\"lr_threshold\"],\n",
    "        min_lr=config[\"min_lr\"]\n",
    "    )\n",
    "else:\n",
    "    raise ValueError(f\"지원되지 않는 스케줄러: {config['lr_scheduler']}\")\n",
    "\n",
    "# WandB에 모델 구조 기록\n",
    "wandb.watch(model, log=\"all\")\n",
    "\n",
    "# GPU 가속 - 여러 GPU 사용\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"{torch.cuda.device_count()}개의 GPU를 사용합니다.\")\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "# 훈련 시작 시간 기록\n",
    "start_time = time.time()\n",
    "\n",
    "# 메인 학습 루프 호출 - 명시적인 파라미터 전달 대신 기본값(config에서 자동으로 가져옴) 사용\n",
    "main_training_loop(\n",
    "    model=model,\n",
    "    trainloader=trainloader,\n",
    "    testloader=testloader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    warmup_scheduler=warmup_scheduler,\n",
    "    main_scheduler=main_scheduler\n",
    ")\n",
    "\n",
    "# 훈련 종료 시간 기록 및 출력\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "wandb.log({\"total_training_time\": total_time})\n",
    "\n",
    "print(f\"전체 학습 시간: {total_time:.2f} 초\")\n",
    "\n",
    "# WandB 실행 종료\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57b9218-aa24-4297-bb92-473c215e6767",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
