{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516f9d5f-6361-4b03-98ee-e1ba4de86b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/guswls/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/guswls/EEN4015_Intro2ML/pbl-2/wandb/run-20250411_160129-1bhbdsep</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/1bhbdsep' target=\"_blank\">resnet18-cutmix</a></strong> to <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/1bhbdsep' target=\"_blank\">https://wandb.ai/sokjh1310-hanyang-university/PBL-2/runs/1bhbdsep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Using device: cuda\n",
      "2개의 GPU를 사용합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                       | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Batch [50/391], Loss: 4.0091\n",
      "Epoch [1], Batch [100/391], Loss: 3.9891\n",
      "Epoch [1], Batch [150/391], Loss: 3.7799\n",
      "Epoch [1], Batch [200/391], Loss: 3.6455\n",
      "Epoch [1], Batch [250/391], Loss: 3.7078\n",
      "Epoch [1], Batch [300/391], Loss: 3.6388\n",
      "Epoch [1], Batch [350/391], Loss: 3.1598\n",
      "Train set: Epoch: 1, Average loss:3.6887, LR: 0.001000 Top-1 Accuracy: 13.2660%, Top-5 Accuracy: 36.3280%, Time consumed:138.04s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▉                                                                                           | 1/100 [02:42<4:27:52, 162.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 1, Average loss:3.3946, Top-1 Accuracy: 19.6200%, Top-5 Accuracy: 46.6900%, Time consumed:24.21s\n",
      "\n",
      "New best top-1 accuracy: 19.62%, top-5 accuracy: 46.69%\n",
      "New best top-5 accuracy: 46.69%\n",
      "Epoch [2], Batch [50/391], Loss: 3.0589\n",
      "Epoch [2], Batch [100/391], Loss: 3.1191\n",
      "Epoch [2], Batch [150/391], Loss: 2.7881\n",
      "Epoch [2], Batch [200/391], Loss: 2.8302\n",
      "Epoch [2], Batch [250/391], Loss: 2.6513\n",
      "Epoch [2], Batch [300/391], Loss: 2.7857\n",
      "Epoch [2], Batch [350/391], Loss: 2.3993\n",
      "Train set: Epoch: 2, Average loss:2.7871, LR: 0.001000 Top-1 Accuracy: 28.6640%, Top-5 Accuracy: 60.4860%, Time consumed:133.60s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▊                                                                                          | 2/100 [05:21<4:21:57, 160.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 2, Average loss:2.5855, Top-1 Accuracy: 33.0800%, Top-5 Accuracy: 65.4000%, Time consumed:25.28s\n",
      "\n",
      "New best top-1 accuracy: 33.08%, top-5 accuracy: 65.40%\n",
      "New best top-5 accuracy: 65.40%\n",
      "Epoch [3], Batch [50/391], Loss: 2.4285\n",
      "Epoch [3], Batch [100/391], Loss: 2.2038\n",
      "Epoch [3], Batch [150/391], Loss: 2.2922\n",
      "Epoch [3], Batch [200/391], Loss: 2.1802\n",
      "Epoch [3], Batch [250/391], Loss: 2.0384\n",
      "Epoch [3], Batch [300/391], Loss: 2.2779\n",
      "Epoch [3], Batch [350/391], Loss: 2.3236\n",
      "Train set: Epoch: 3, Average loss:2.1784, LR: 0.001000 Top-1 Accuracy: 41.3240%, Top-5 Accuracy: 74.3320%, Time consumed:142.59s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▊                                                                                         | 3/100 [08:07<4:23:46, 163.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 3, Average loss:2.3836, Top-1 Accuracy: 38.2300%, Top-5 Accuracy: 70.1200%, Time consumed:23.74s\n",
      "\n",
      "New best top-1 accuracy: 38.23%, top-5 accuracy: 70.12%\n",
      "New best top-5 accuracy: 70.12%\n",
      "Epoch [4], Batch [50/391], Loss: 1.7502\n",
      "Epoch [4], Batch [100/391], Loss: 1.8550\n",
      "Epoch [4], Batch [150/391], Loss: 1.6262\n",
      "Epoch [4], Batch [200/391], Loss: 1.8721\n",
      "Epoch [4], Batch [250/391], Loss: 1.6512\n",
      "Epoch [4], Batch [300/391], Loss: 1.7207\n",
      "Epoch [4], Batch [350/391], Loss: 1.6392\n",
      "Train set: Epoch: 4, Average loss:1.7704, LR: 0.001000 Top-1 Accuracy: 50.8460%, Top-5 Accuracy: 81.9060%, Time consumed:144.95s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▋                                                                                        | 4/100 [10:58<4:25:37, 166.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 4, Average loss:1.8603, Top-1 Accuracy: 48.7100%, Top-5 Accuracy: 79.7200%, Time consumed:25.27s\n",
      "\n",
      "New best top-1 accuracy: 48.71%, top-5 accuracy: 79.72%\n",
      "New best top-5 accuracy: 79.72%\n",
      "Epoch [5], Batch [50/391], Loss: 1.2719\n",
      "Epoch [5], Batch [100/391], Loss: 1.3769\n",
      "Epoch [5], Batch [150/391], Loss: 1.5925\n",
      "Epoch [5], Batch [200/391], Loss: 1.4389\n",
      "Epoch [5], Batch [250/391], Loss: 1.4264\n",
      "Epoch [5], Batch [300/391], Loss: 1.4523\n",
      "Epoch [5], Batch [350/391], Loss: 1.3304\n",
      "Train set: Epoch: 5, Average loss:1.4339, LR: 0.001000 Top-1 Accuracy: 58.9460%, Top-5 Accuracy: 87.4760%, Time consumed:145.63s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▌                                                                                       | 5/100 [13:48<4:25:32, 167.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 5, Average loss:1.9187, Top-1 Accuracy: 48.6400%, Top-5 Accuracy: 79.3500%, Time consumed:25.08s\n",
      "\n",
      "Epoch [6], Batch [50/391], Loss: 1.1000\n",
      "Epoch [6], Batch [100/391], Loss: 0.9617\n",
      "Epoch [6], Batch [150/391], Loss: 1.3693\n",
      "Epoch [6], Batch [200/391], Loss: 1.1276\n",
      "Epoch [6], Batch [250/391], Loss: 0.8863\n",
      "Epoch [6], Batch [300/391], Loss: 1.3932\n",
      "Epoch [6], Batch [350/391], Loss: 1.0701\n",
      "Train set: Epoch: 6, Average loss:1.1362, LR: 0.001000 Top-1 Accuracy: 66.4320%, Top-5 Accuracy: 91.8860%, Time consumed:138.36s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████▌                                                                                      | 6/100 [16:31<4:20:06, 166.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 6, Average loss:1.8652, Top-1 Accuracy: 51.3600%, Top-5 Accuracy: 81.3000%, Time consumed:24.30s\n",
      "\n",
      "New best top-1 accuracy: 51.36%, top-5 accuracy: 81.30%\n",
      "New best top-5 accuracy: 81.30%\n",
      "Epoch [7], Batch [50/391], Loss: 0.7025\n",
      "Epoch [7], Batch [100/391], Loss: 0.7820\n",
      "Epoch [7], Batch [150/391], Loss: 0.6128\n",
      "Epoch [7], Batch [200/391], Loss: 0.8296\n",
      "Epoch [7], Batch [250/391], Loss: 0.6264\n",
      "Epoch [7], Batch [300/391], Loss: 1.0520\n",
      "Epoch [7], Batch [350/391], Loss: 0.7147\n",
      "Train set: Epoch: 7, Average loss:0.8296, LR: 0.001000 Top-1 Accuracy: 74.7740%, Top-5 Accuracy: 95.7240%, Time consumed:133.71s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████▍                                                                                     | 7/100 [19:09<4:13:10, 163.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 7, Average loss:1.8084, Top-1 Accuracy: 52.6700%, Top-5 Accuracy: 82.4500%, Time consumed:23.97s\n",
      "\n",
      "New best top-1 accuracy: 52.67%, top-5 accuracy: 82.45%\n",
      "New best top-5 accuracy: 82.45%\n",
      "Epoch [8], Batch [50/391], Loss: 0.3586\n",
      "Epoch [8], Batch [100/391], Loss: 0.4930\n",
      "Epoch [8], Batch [150/391], Loss: 0.5492\n",
      "Epoch [8], Batch [200/391], Loss: 0.5007\n",
      "Epoch [8], Batch [250/391], Loss: 0.4338\n",
      "Epoch [8], Batch [300/391], Loss: 0.4716\n",
      "Epoch [8], Batch [350/391], Loss: 0.6598\n",
      "Train set: Epoch: 8, Average loss:0.5549, LR: 0.001000 Top-1 Accuracy: 82.9240%, Top-5 Accuracy: 98.1340%, Time consumed:132.51s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███████▎                                                                                    | 8/100 [21:46<4:07:16, 161.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Epoch: 8, Average loss:1.9458, Top-1 Accuracy: 53.2900%, Top-5 Accuracy: 82.3400%, Time consumed:24.16s\n",
      "\n",
      "New best top-1 accuracy: 53.29%, top-5 accuracy: 82.34%\n",
      "Epoch [9], Batch [50/391], Loss: 0.1705\n",
      "Epoch [9], Batch [100/391], Loss: 0.3146\n",
      "Epoch [9], Batch [150/391], Loss: 0.2883\n",
      "Epoch [9], Batch [200/391], Loss: 0.3016\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "\n",
    "from models.resnet import resnet18, resnet34, resnet50\n",
    "\n",
    "wandb.login(key=\"ef091b9abcea3186341ddf8995d62bde62d7469e\")\n",
    "wandb.init(project=\"PBL-2\", name=\"resnet18-cutmix\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# 학습 재현성 고정\n",
    "def fix_seed(seed, deterministic=False):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    if deterministic:\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "    else:\n",
    "        torch.backends.cudnn.benchmark = True  # 성능 향상을 위해 True로 변경\n",
    "\n",
    "deterministic=True와 benchmark=False는 확실히 학습 속도를 저하시킬 수 있습니다.\n",
    "특히 torch.backends.cudnn.benchmark=False는 CUDA가 최적의 알고리즘을 찾기 위한 \n",
    "벤치마킹을 수행하지 않게 만들어 성능이 떨어질 수 있습니다.\n",
    "# 속도 우선 설정 -> 완벽한 재현성은 보장되지 않음 \n",
    "\n",
    "fix_seed(2025, deterministic=False)\n",
    "\"\"\"\n",
    "\n",
    "# WandB 설정\n",
    "config = {\n",
    "    \"model\": \"resnet18\",\n",
    "    \"batch_size\": 128,\n",
    "    \"num_epochs\": 100,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"seed\": 2025,\n",
    "    \"deterministic\": False,\n",
    "}\n",
    "wandb.config.update(config)\n",
    "\n",
    "# CIFAR-100 데이터셋 로드\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR100(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = DataLoader(trainset, batch_size=config[\"batch_size\"], shuffle=True, num_workers=16)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR100(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = DataLoader(testset, batch_size=config[\"batch_size\"], shuffle=False, num_workers=16)\n",
    "\n",
    "def train(model, trainloader, criterion, optimizer, device, epoch):\n",
    "    \"\"\"\n",
    "    학습 함수\n",
    "    \"\"\"\n",
    "    model.train()   # 모델을 학습 모드로 설정\n",
    "    start_time = time.time()  # 시간 측정 시작\n",
    "    running_loss = 0.0\n",
    "    correct_top1 = 0\n",
    "    correct_top5 = 0\n",
    "    total = 0\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(trainloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # top-1 정확도 계산\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct_top1 += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        # top-5 정확도 계산\n",
    "        _, top5_idx = outputs.topk(5, 1, largest=True, sorted=True)\n",
    "        correct_top5 += top5_idx.eq(labels.view(-1, 1).expand_as(top5_idx)).sum().item()\n",
    "        \n",
    "        if (i + 1) % 50 == 0:  # 50 배치마다 출력\n",
    "            print(f'Epoch [{epoch+1}], Batch [{i+1}/{len(trainloader)}], Loss: {loss.item():.4f}')\n",
    "    \n",
    "    epoch_loss = running_loss / len(trainloader)\n",
    "    accuracy_top1 = 100.0 * correct_top1 / total\n",
    "    accuracy_top5 = 100.0 * correct_top5 / total\n",
    "    \n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    # 학습 세트에 대한 성능 출력\n",
    "    print(f'Train set: Epoch: {epoch+1}, Average loss:{epoch_loss:.4f}, LR: {optimizer.param_groups[0][\"lr\"]:.6f} '\n",
    "          f'Top-1 Accuracy: {accuracy_top1:.4f}%, Top-5 Accuracy: {accuracy_top5:.4f}%, Time consumed:{train_time:.2f}s')\n",
    "    \n",
    "    return epoch_loss, accuracy_top1, accuracy_top5\n",
    "\n",
    "def evaluate(model, testloader, criterion, device, epoch):\n",
    "    \"\"\"\n",
    "    평가 함수\n",
    "    \"\"\"\n",
    "    model.eval()  # 모델을 평가 모드로 설정\n",
    "    start_time = time.time()  # 시간 측정 시작\n",
    "    \n",
    "    test_loss = 0.0\n",
    "    correct_top1 = 0\n",
    "    correct_top5 = 0\n",
    "    total = 0\n",
    "    \n",
    "    # 그래디언트 계산 비활성화\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # 순전파\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # 손실 계산\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            # top-1 정확도 계산\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct_top1 += (predicted == labels).sum().item()\n",
    "            \n",
    "            # top-5 정확도 계산\n",
    "            _, top5_idx = outputs.topk(5, 1, largest=True, sorted=True)\n",
    "            correct_top5 += top5_idx.eq(labels.view(-1, 1).expand_as(top5_idx)).sum().item()\n",
    "    \n",
    "    # 평균 손실 및 정확도 계산\n",
    "    test_loss = test_loss / len(testloader)\n",
    "    accuracy_top1 = 100.0 * correct_top1 / total\n",
    "    accuracy_top5 = 100.0 * correct_top5 / total\n",
    "    \n",
    "    # 평가 시간 계산\n",
    "    eval_time = time.time() - start_time\n",
    "    \n",
    "    # 테스트 세트에 대한 성능 출력\n",
    "    print(f'Test set: Epoch: {epoch+1}, Average loss:{test_loss:.4f}, '\n",
    "          f'Top-1 Accuracy: {accuracy_top1:.4f}%, Top-5 Accuracy: {accuracy_top5:.4f}%, Time consumed:{eval_time:.2f}s')\n",
    "    print()\n",
    "    \n",
    "    return test_loss, accuracy_top1, accuracy_top5\n",
    "\n",
    "\n",
    "# 메인 학습 루프\n",
    "def main_training_loop(model, trainloader, testloader, criterion, optimizer, device, num_epochs=10):\n",
    "    \"\"\"\n",
    "    메인 학습 루프\n",
    "    \"\"\"\n",
    "    best_acc_top1 = 0.0\n",
    "    best_acc_top5 = 0.0\n",
    "    \n",
    "    # tqdm을 사용한 진행 상황 표시\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        # 학습\n",
    "        train_loss, train_acc_top1, train_acc_top5 = train(model, trainloader, criterion, optimizer, device, epoch)\n",
    "        \n",
    "        # 평가\n",
    "        test_loss, test_acc_top1, test_acc_top5 = evaluate(model, testloader, criterion, device, epoch)\n",
    "        \n",
    "        # WandB에 로깅\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_accuracy_top1\": train_acc_top1,\n",
    "            \"train_accuracy_top5\": train_acc_top5,\n",
    "            \"test_loss\": test_loss,\n",
    "            \"test_accuracy_top1\": test_acc_top1,\n",
    "            \"test_accuracy_top5\": test_acc_top5\n",
    "        })\n",
    "            \n",
    "        # 최고 정확도 모델 저장 (top-1 기준)\n",
    "        if test_acc_top1 > best_acc_top1:\n",
    "            best_acc_top1 = test_acc_top1\n",
    "            best_acc_top5_at_best_top1 = test_acc_top5\n",
    "            print(f'New best top-1 accuracy: {best_acc_top1:.2f}%, top-5 accuracy: {best_acc_top5_at_best_top1:.2f}%')\n",
    "            \n",
    "            # 모델 저장\n",
    "            model_path = f'best_model_{wandb.run.name}.pth'\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            \n",
    "            # WandB에 모델 아티팩트 저장\n",
    "            wandb.save(model_path)\n",
    "        \n",
    "        # top-5 accuracy 기록 업데이트\n",
    "        if test_acc_top5 > best_acc_top5:\n",
    "            best_acc_top5 = test_acc_top5\n",
    "            print(f'New best top-5 accuracy: {best_acc_top5:.2f}%')\n",
    "    \n",
    "    print(f'Finish! Best top-1 accuracy: {best_acc_top1:.2f}%, Best top-5 accuracy: {best_acc_top5:.2f}%')\n",
    "    wandb.run.summary[\"best_accuracy_top1\"] = best_acc_top1\n",
    "    wandb.run.summary[\"best_accuracy_top5\"] = best_acc_top5\n",
    "\n",
    "# 디바이스 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 모델 초기화\n",
    "model = resnet18().to(device)  \n",
    "criterion = nn.CrossEntropyLoss()  # 손실 함수 정의\n",
    "optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"])  # 옵티마이저 정의\n",
    "\n",
    "# WandB에 모델 구조 기록\n",
    "wandb.watch(model, log=\"all\")\n",
    "\n",
    "# GPU 가속\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"{torch.cuda.device_count()}개의 GPU를 사용합니다.\")\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "# 훈련 시작 시간 기록\n",
    "start_time = time.time()\n",
    "\n",
    "# 메인 학습 루프 호출\n",
    "main_training_loop(\n",
    "    model=model,\n",
    "    trainloader=trainloader,\n",
    "    testloader=testloader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    num_epochs=config[\"num_epochs\"]\n",
    ")\n",
    "\n",
    "# 훈련 종료 시간 기록 및 출력\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "wandb.log({\"total_training_time\": total_time})\n",
    "\n",
    "print(f\"Total training time: {total_time:.2f} seconds\")\n",
    "\n",
    "# WandB 실행 종료\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaaa646-eb14-44be-a97a-fde2ee3adf0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
